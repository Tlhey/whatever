<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Papers Collection | Tlhey</title><meta name="author" content="Tlhey"><meta name="copyright" content="Tlhey"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Counterfactual fairnessCounterfactual fairnesslink: https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf Definitions: defs$A$: Protected attributes, se">
<meta property="og:type" content="article">
<meta property="og:title" content="Papers Collection">
<meta property="og:url" content="https://tlhey.github.io/whatever/2024/07/14/2024-07-14-Papers-Collection/index.html">
<meta property="og:site_name" content="Tlhey">
<meta property="og:description" content="Counterfactual fairnessCounterfactual fairnesslink: https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf Definitions: defs$A$: Protected attributes, se">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://tlhey.github.io/whatever/img/Lain_004.jpeg">
<meta property="article:published_time" content="2024-07-15T01:24:36.000Z">
<meta property="article:modified_time" content="2025-04-27T18:57:59.527Z">
<meta property="article:author" content="Tlhey">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tlhey.github.io/whatever/img/Lain_004.jpeg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Papers Collection",
  "url": "https://tlhey.github.io/whatever/2024/07/14/2024-07-14-Papers-Collection/",
  "image": "https://tlhey.github.io/whatever/img/Lain_004.jpeg",
  "datePublished": "2024-07-15T01:24:36.000Z",
  "dateModified": "2025-04-27T18:57:59.527Z",
  "author": [
    {
      "@type": "Person",
      "name": "Tlhey",
      "url": "https://tlhey.github.io/whatever/"
    }
  ]
}</script><link rel="shortcut icon" href="/whatever/img/favicon.png"><link rel="canonical" href="https://tlhey.github.io/whatever/2024/07/14/2024-07-14-Papers-Collection/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/whatever/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/whatever/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Papers Collection',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/modify.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(img/background.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/whatever/img/Navi.png" onerror="this.onerror=null;this.src='/whatever/img/friend_404.gif'" alt="avatar"></div><div class="site-data text-center"><a href="/whatever/archives/"><div class="headline">Articles</div><div class="length-num">43</div></a><a href="/whatever/tags/"><div class="headline">Tags</div><div class="length-num">2</div></a><a href="/whatever/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/whatever/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/whatever/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/whatever/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/whatever/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/whatever/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/whatever/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/whatever/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/whatever/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/Lain_004.jpeg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/whatever/"><img class="site-icon" src="/whatever/img/Navi.png" alt="Logo"><span class="site-name">Tlhey</span></a><a class="nav-page-title" href="/whatever/"><span class="site-name">Papers Collection</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/whatever/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/whatever/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/whatever/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/whatever/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/whatever/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/whatever/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/whatever/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/whatever/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Papers Collection</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2024-07-15T01:24:36.000Z" title="Created 2024-07-14 21:24:36">2024-07-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-04-27T18:57:59.527Z" title="Updated 2025-04-27 14:57:59">2025-04-27</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url(/img/Lain_004.jpeg);"></div><article class="container post-content" id="article-container"><h1 id="Counterfactual-fairness"><a href="#Counterfactual-fairness" class="headerlink" title="Counterfactual fairness"></a>Counterfactual fairness</h1><p>Counterfactual fairness<br>link: <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf</a></p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>Definitions:</p>
<h4 id="defs"><a href="#defs" class="headerlink" title="defs"></a>defs</h4><p>$A$: Protected attributes, sensitive features<br>$X$: features of individuals, excluding A<br>$U$: latent features not observed, represented<br>$Y$: predictor    </p>
<h4 id="Fairness-through-unawareness-FTU"><a href="#Fairness-through-unawareness-FTU" class="headerlink" title="Fairness through unawareness (FTU):"></a>Fairness through unawareness (FTU):</h4><p><em>An algorithm is fair so long as any protected attributes $A$ are not explicitly used in the decision-making process.</em><br>Shortcoming: $X$ might intersects $A$</p>
<h4 id="Individual-Fairness-IF"><a href="#Individual-Fairness-IF" class="headerlink" title="Individual Fairness (IF)."></a>Individual Fairness (IF).</h4><p>For distance metric(should be carefully choosen), $d(\cdot , \cdot)$, if $d(i, j)$ is small, then $\hat Y(X^{(i)}, A^{(i)}) \approx \hat Y(X^{(j)}, A^{(j)})$</p>
<h4 id="Demographic-Parity-DP-人口统计学意义上的平等"><a href="#Demographic-Parity-DP-人口统计学意义上的平等" class="headerlink" title="Demographic Parity (DP)(人口统计学意义上的平等)"></a>Demographic Parity (DP)(人口统计学意义上的平等)</h4><p>Predictor $\hat Y$ satisfies demographic partiy if $P(\hat Y|A=0)=P(\hat Y|A=1)$ </p>
<h4 id="Equality-of-Opportunity"><a href="#Equality-of-Opportunity" class="headerlink" title="Equality of Opportunity"></a>Equality of Opportunity</h4><p>$P(\hat Y|A=0, Y=1)=P(\hat Y|A=1, Y=1)$ </p>
<h3 id="Causal-Models-因果推断-Counterfacutal、"><a href="#Causal-Models-因果推断-Counterfacutal、" class="headerlink" title="Causal Models(因果推断), Counterfacutal、"></a>Causal Models(因果推断), Counterfacutal、</h3><p>Casual Model $(U, V, F)$,<br>$U$: latent background variables,<br>$V$: observed variables, <br>$F={f_1. f_2, \cdots, f_n}$, for each $V_i=f_i(pa_i, U_{pa_i})\in V, pa_i \subseteq V \backslash {V_i}$ </p>
<p><strong>Three Steps of Inference</strong>\</p>
<ul>
<li>Abduction：for a given prior on $U$, compute the posterior distribution of $U$ given the evidence $W = w$</li>
<li>Action：substitute the equations for $Z$ with the interventional values $z$, resulting in the modified set of equations $F_z$</li>
<li>Prediction:</li>
</ul>
<h1 id="FairGAD"><a href="#FairGAD" class="headerlink" title="FairGAD"></a>FairGAD</h1><p><a target="_blank" rel="noopener" href="https://openreview.net/forum?id=3cE6NKYy8x">https://openreview.net/forum?id=3cE6NKYy8x</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.04937">https://arxiv.org/abs/2307.04937</a></p>
<h2 id="Fair-GAD-problem"><a href="#Fair-GAD-problem" class="headerlink" title="Fair GAD problem"></a>Fair GAD problem</h2><p><strong>GAD</strong><br>$G=(V, E, X)$, <br>node feature matrix $X\in \R^{n\times d}$, <br>Adjacency matrix $A\in {0,1}^{n\times n}$, <br>Anomaly labels $Y\in {0, 1}^n$, predicted $\hat Y$, <br><strong>Fair GAD</strong><br>sensitive attributes $S\in {0, 1}^n$, a binary feature $X$.<br>Performance matrix: accuracy and <em>AUCROC</em>: Area under the ROC Curve <br>Unfairness Mextrics, Statistic Parity(SP):$SP = |P(\hat Y=1|S=0)−P(\hat Y =1|S=1)|$, <br>Equality of Odds <em>(EOO)</em>: $SP = |P(\hat Y=1|S=0, Y=1)−P(\hat Y =1|S=1, Y=1)|$</p>
<h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><ul>
<li>Reddit:<br>graph structure： linking two user posted the name subreddit within 24h.<br>Node feature: Embedding from post histories.</li>
<li>Twitter:<br>graph structure:: A follows B.<br>Node feature: demographic infromation using M3 system, multimodal, multilingual, multi attirbute demographix inderence framework.</li>
</ul>
<h2 id="GAD-Methods"><a href="#GAD-Methods" class="headerlink" title="GAD Methods"></a>GAD Methods</h2><h3 id="DOMINANT-Ding-et-al-2019a"><a href="#DOMINANT-Ding-et-al-2019a" class="headerlink" title="DOMINANT (Ding et al., 2019a)"></a>DOMINANT (Ding et al., 2019a)</h3><h3 id="CONAD-Xu-et-al-2022"><a href="#CONAD-Xu-et-al-2022" class="headerlink" title="CONAD (Xu et al., 2022)"></a>CONAD (Xu et al., 2022)</h3><h3 id="COLA-Liu-et-al-2021"><a href="#COLA-Liu-et-al-2021" class="headerlink" title="COLA (Liu et al., 2021)"></a>COLA (Liu et al., 2021)</h3><h3 id="VGOD-Huang-et-al-2023"><a href="#VGOD-Huang-et-al-2023" class="headerlink" title="VGOD (Huang et al., 2023)"></a>VGOD (Huang et al., 2023)</h3><h2 id="Non-Graph-AD-methods"><a href="#Non-Graph-AD-methods" class="headerlink" title="Non-Graph AD methods"></a>Non-Graph AD methods</h2><ul>
<li>DONE (Bandyopadhyay et al., 2020)</li>
<li>AdONE (Bandyopadhyay et al., 2020)</li>
<li>ECOD (Li et al., 2022)</li>
<li>VAE (Kingma &amp; Welling, 2014)</li>
<li>ONE (Bandyopadhyay et al., 2019)</li>
<li>LOF (Breunig et al., 2000)</li>
<li>F (Liu et al., 2008)</li>
</ul>
<h2 id="Fainess-Method"><a href="#Fainess-Method" class="headerlink" title="Fainess Method:"></a>Fainess Method:</h2><h3 id="FAIROD-Shekhar-et-al-2021"><a href="#FAIROD-Shekhar-et-al-2021" class="headerlink" title="FAIROD (Shekhar et al., 2021)"></a>FAIROD (Shekhar et al., 2021)</h3><h3 id="CORRELATION-Shekhar-et-al-2021"><a href="#CORRELATION-Shekhar-et-al-2021" class="headerlink" title="CORRELATION (Shekhar et al., 2021)"></a>CORRELATION (Shekhar et al., 2021)</h3><h3 id="HIN-Zeng-et-al-2021"><a href="#HIN-Zeng-et-al-2021" class="headerlink" title="HIN (Zeng et al., 2021)"></a>HIN (Zeng et al., 2021)</h3><h3 id="EDITS-Dong-et-al-2022"><a href="#EDITS-Dong-et-al-2022" class="headerlink" title="EDITS (Dong et al., 2022)"></a>EDITS (Dong et al., 2022)</h3><h3 id="FAIRWALK-Rahman-et-al-2019"><a href="#FAIRWALK-Rahman-et-al-2019" class="headerlink" title="FAIRWALK (Rahman et al., 2019)"></a>FAIRWALK (Rahman et al., 2019)</h3><h2 id="Distance"><a href="#Distance" class="headerlink" title="Distance"></a>Distance</h2><h3 id="Wasserstein-Distance"><a href="#Wasserstein-Distance" class="headerlink" title="Wasserstein Distance"></a>Wasserstein Distance</h3><h3 id="Minkowski-distance"><a href="#Minkowski-distance" class="headerlink" title="Minkowski distance"></a>Minkowski distance</h3><h1 id="2024-Counterfactual-Learning-on-Graphs-A-Survey"><a href="#2024-Counterfactual-Learning-on-Graphs-A-Survey" class="headerlink" title="2024 Counterfactual Learning on Graphs: A Survey"></a>2024 Counterfactual Learning on Graphs: A Survey</h1><p>3.5.1 How to create synthetic dataset </p>
<h1 id="2022-Learning-Fair-Node-Representations-with-Graph-Counter-factual-Fairness"><a href="#2022-Learning-Fair-Node-Representations-with-Graph-Counter-factual-Fairness" class="headerlink" title="2022 Learning Fair Node Representations with Graph Counter factual Fairness"></a>2022 Learning Fair Node Representations with Graph Counter factual Fairness</h1><p>Two limitation on existing CF on graph:</p>
<ol>
<li>$S_i$ affect the predetection. Red</li>
<li>$S_i$ affect $A, X_i$ Green</li>
</ol>
<p>GEAR: Graph Counterfactually Fair Node Representation</p>
<ol>
<li>subgraph generation<br>Node <strong>Importance Score</strong> by prune range of casualmodel to <strong>ego-centric subgraph</strong>( node and its neighbour)</li>
<li>Counterfactual Data Argmentation:<br>Graph Auto encodder and fair contrains: <strong>self-pertubation</strong>(flip its $S_i$), <strong>neighbour pertubatiob</strong></li>
<li>Node Representation Learning  :<br>Siamese network to minimize discrepancy</li>
</ol>
<p><strong>Def, Graph conterfactual fairness:</strong><br>An encoder $\Phi(\cdot)$ satisfies graph counterfactual fairness if for any node $i$:<br>$$P((Z_i)<em>{S \leftarrow s’} | X = \mathbf{X}, A = \mathbf{A}) = P((Z_i)</em>{S \leftarrow s’’} | X = \mathbf{X}, A = \mathbf{A})$$<br>for all $s’ \neq s’’$, where $s’, s’’ \in {0, 1}^n$ are arbitrary sensitive attribute values of all nodes, $Z_i = (\Phi(\mathbf{X}, \mathbf{A}))_i$ denotes the node representations.</p>
<p>$\Phi$, minimize the discrepancy between representation $\Phi(X_{S\leftarrow s’}, A_{S\leftarrow s’})$ and $\Phi(X_{S\leftarrow s’’}, A_{S\leftarrow s’’})$</p>
<h3 id="GEAR"><a href="#GEAR" class="headerlink" title="GEAR"></a>GEAR</h3><h3 id="1-subgraph-generation"><a href="#1-subgraph-generation" class="headerlink" title="1) subgraph generation"></a>1) subgraph generation</h3><p>Personalized Pagerank algorithm:<br>Importance score $\mathbf R=\alpha (\mathbf I-(1-\alpha \mathbf {\bar A}))$, $\mathbf I$, identity<br>$R_{i,j}$ How node $j$ is important for node $i$, $\alpha \in [0,1]$</p>
<p>$\mathbf {\bar A}=\mathbf A \mathbf D^{-1} $ column-normalized adjacency matric, $\mathbf D: \mathbf D_{i, i}=\sum_j A{i, j}$</p>
<p>$\mathcal{G}^{(i)}=Sub(i, \mathcal{G}, k)$ :, subgraph generation</p>
<ul>
<li><p>$\mathcal{G}^{(i)} = { \mathcal{V}^{(i)}, \mathcal{E}^{(i)}, \mathbf{X}^{(i)} } = { \mathbf{A}^{(i)}, \mathbf{X}^{(i)} },<br>$ Vertive, Edge, Features with $S={s_i}_{i=1}^n $ includes in $X$, and $X^{\neg s} = { x_1^{\neg s}, …, x_n^{\neg s} } $, where $ x_i^{\neg s} = x_i \setminus s_i$</p>
</li>
<li><p>$\mathcal{V}^{(i)} = \text{TOP}(\mathbf{R}_{i,:}, k),$</p>
</li>
<li><p>$\mathbf{A}^{(i)} = \mathbf{A}<em>{\mathcal{V}^{(i)}, \mathcal{V}^{(i)}}, \quad \mathbf{X}^{(i)} = \mathbf{X}</em>{\mathcal{V}^{(i)}, :},<br>$,</p>
</li>
</ul>
<h3 id="2）Counterfactual-Data-Augmentation"><a href="#2）Counterfactual-Data-Augmentation" class="headerlink" title="2）Counterfactual Data Augmentation"></a>2）Counterfactual Data Augmentation</h3><p><strong>GraphVAG</strong>: graph variational auto-encoder<br>latent embedding $H={h_1, h_2, \cdots, h_k}$  $H$ is sampled from $q(H|X, A)$,  $p(𝐻)$ is a standard Normal prior distribution<br>$\mathcal{L}=$</p>
<p>$\tilde{s}_i$: summary of neighbor info, aggregationof all nodes in subgarph $\mathcal{G}^{(i)}$<br>$\tilde{s}<em>i = \frac{1}{|\mathcal{V}^{(i)}|} \sum</em>{j \in \mathcal{V}^{(i)}} s_j$</p>
<p>Discriminator,$D(\cdot)$<br>$D(\mathbf{H}, b)$  predicts the probability of whether the summary of sensitive attribute values is in range $b$</p>
<p>Fairness Constraint<br>$L_d = \sum_{b \in B} \mathbb{E} [\log(D(\mathbf{H}, b))]$<br>$L_d$ is a regularizer to minimize the mutual information between the summary of sensitive attribute values and the<br>embeddings</p>
<p><strong>Final Loss</strong> for Counterfactual Data Augmentation<br>$L_a = L_r + \beta L_d$<br>$\beta$ is a hyperparameter for the weight of fairness constraint<br>Use alternating SGD for optimization: </p>
<ol>
<li>minimize $L_{a}$ by fixing the discriminator and updating parameters in other parts; </li>
<li>minimize $−L_{a}$ with respect to the discriminator while other parts fixed.</li>
</ol>
<h4 id="Self-Perturbation"><a href="#Self-Perturbation" class="headerlink" title="Self-Perturbation"></a>Self-Perturbation</h4><p>$\overline{\mathcal{G}}^{(i)} = { \mathcal{G}^{(i)}_{S_i \leftarrow 1-s_i} }$ (flipping sensitive feature)</p>
<h4 id="Neighbor-Perturbation"><a href="#Neighbor-Perturbation" class="headerlink" title="Neighbor-Perturbation"></a>Neighbor-Perturbation</h4><p>$\underline{\mathcal{G}}^{(i)} = \left{ \mathcal{G}^{(i)}<em>{S^{(i)}</em>{\setminus i} \leftarrow \text{SMP}(S^{(i)}<em>{\mathcal{V}^{(i)}</em>{\setminus i}})} \right}$</p>
<p>subgraph $\mathcal{G}^{(i)}$ ego($i$)-center subgraph with noes $\mathcal{V}^{(i)}$, exclude node $i$: $\mathcal{V}^{(i)}<em>{\setminus i}$, randomly preterbe the sentsitice value of other nodes: $SMP(\mathcal{V}^{(i)}</em>{\setminus i})$</p>
<p>Reconstruction Loss (GraphVAE Module)<br>$L_r = \mathbb{E}_{q(\mathbf{H}|X, A)} \left[ -\log(p(X, A | \mathbf{H}, S)) \right] + \text{KL}[q(\mathbf{H} | X, A) | p(\mathbf{H})]$</p>
<h3 id="3-Fair-Representation-learning"><a href="#3-Fair-Representation-learning" class="headerlink" title="3) Fair Representation learning"></a>3) Fair Representation learning</h3><p><strong>Fairness Loss</strong><br>$<br>L_f = \frac{1}{|\mathcal{V}|} \sum_{i \in \mathcal{V}} \left( (1 - \lambda_s) d(z_i, \bar{z}_i) + \lambda_s d(z_i, \underline{z}_i) \right),<br>$<br>$\lambda_s$ hyperparam control neig-preturbation weight</p>
<p><strong>Node Representations</strong></p>
<ul>
<li>$<br>z_i = (\phi(\mathbf{X}^{(i)}, \mathbf{A}^{(i)}))_i,<br>$</li>
<li>$<br>\bar{z}<em>i = \text{AGG} \left( \left{ (\phi(\mathbf{X}^{(i)}</em>{S_i \leftarrow 1-s_i}, \mathbf{A}^{(i)}_{S_i \leftarrow 1-s_i}))_i \right} \right),<br>$</li>
<li>$<br>\underline{z}<em>i = \text{AGG} \left( \left{ (\phi(\mathbf{X}^{(i)}</em>{S_i \leftarrow \text{SMP}(S^{(i)}<em>{\mathcal{V}^{(i)}</em>{\setminus i}})}, \mathbf{A}^{(i)}<em>{S_i \leftarrow \text{SMP}(S^{(i)}</em>{\mathcal{V}^{(i)}_{\setminus i}})})_i \right} \right),<br>$</li>
</ul>
<p>Prediction Loss<br>$L_p = \frac{1}{n} \sum_{i \in [n]} l(f(z_i), y_i),$ $l$: could be CE(Cross entropy), $f(\cdot)$ makes predictions for downstream tasks with the representations, i.e.$ \hat y_i=f(z_i)$</p>
<p>Overall Loss<br>$<br>L = L_p + \lambda L_f + \mu | \theta |^2,<br>$</p>
<h3 id="Dataset-creation"><a href="#Dataset-creation" class="headerlink" title="Dataset creation"></a>Dataset creation</h3><p>Sensitive Attributes<br>$S_i \sim \text{Bernoulli}(p),$ $p=0.4$ percent $S_i=1$</p>
<p>Latent Embeddings<br>$Z_i \sim \mathcal{N}(0, \mathbf{I}),$ <br>$\mathbf{I}$ identity, dimension of $Z_i$: $d_s=50$</p>
<p>Node Features<br>$X_i = \mathcal{S}(Z_i) + S_i \mathbf{v},$<br>sampling operation $S(\cdot)$ select 25 dims from $Z_i$, $\mathbf{v} \sim \mathcal{N}(0, \mathbf{I})$</p>
<p>Graph Structure<br>$P(A_{i,j} = 1) = \sigma(\text{cos}(Z_i, Z_j) + a \mathbf{1}(S_i = S_j)),$<br>$\sigma$ sigmoid function, $\mathbf{1}(S_i = S_j)==S_i = S_j. \alpha=0.01$</p>
<p>Node Labels<br>$Y_i = \mathcal{B}(w Z_i + w_s \frac{\sum_{j \in \mathcal{N}_i} S_j}{|\mathcal{N}_i|}),$<br>$\mathcal{B}$ Bernulli distribution,$\mathcal{N}_i$ set of neighbors of node i $w, w_i$ weight vector</p>
<h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><p>Using Synthetic dataset, Bail, Credit</p>
<h1 id="24-Three-Revisits-to-Node-Level-Graph-Anomaly-Detection"><a href="#24-Three-Revisits-to-Node-Level-Graph-Anomaly-Detection" class="headerlink" title="24 Three Revisits to Node-Level Graph Anomaly Detection"></a>24 Three Revisits to Node-Level Graph Anomaly Detection</h1><p>Outliers, Message Passing and Hyperbolic Neural Networks</p>
<h3 id="Previous-Outlier-injection-method"><a href="#Previous-Outlier-injection-method" class="headerlink" title="Previous Outlier injection method"></a>Previous Outlier injection method</h3><p>$\mathcal{G}=(\mathcal{V}, \mathcal{E}, X, y)$: vertice set, edge set, attibute matrix, label of class</p>
<ul>
<li><p><strong>Contextual(cntxt.) outlier injection</strong><br>Normalize features $x_i’=\frac{x_i}{||x_i||_1}$<br>Sample $o$ nodes from $\mathcal{V}$ as $\mathcal{V}_c$. without replacement<br>For node $i$ in $\mathcal{V}_c$, sample $q$ nodes from $\mathcal{V}_r=\mathcal{V}- \mathcal{V}_c$, among them choose the farthest one $j = \text{argmax}_k(||x_i’-x_k’||_2)$ to replace $x_i$ with $x_j$.</p>
</li>
<li><p><strong>Strctural(stct.) outlier injection</strong><br>create $t$ groups sized $s$ with anomalous nodes.<br>sample $o=t\times s$ from $\mathcal{V}$ without replacement<br>Then randoms partition into $t$ groups.<br>Add edges to make them a clique(fully connected), then drop edges with $p$ probability</p>
</li>
</ul>
<h4 id="Score-function"><a href="#Score-function" class="headerlink" title="Score function"></a>Score function</h4><p>The farthest node will have large $||\tilde{\mathbf x}_i||_2$ <br>A structural outlier node $i$ will have many neighbors leads to large $||\tilde{\mathbf a}_i||_1$ </p>
<p>Score function: $score_{norm}(i)=\alpha||\tilde{\mathbf x}_i||_2+(1-\alpha)||\tilde {\mathbf a}_i||_1$,  $\tilde{\mathbf x}_i$: $x_i$ after outlier injection, $\tilde{\mathbf a}<em>i$: $a_i$ after outlier injection, $A</em>{ii}=1$<br>where cntxt OD, $\alpha=1$, stct OD, $\alpha=0$ :  $\alpha$ ratio of two methods </p>
<p>test 1: ROC-AUC<br>For each dataset, use original dataset v.s. l2-nrom for each $x_i$<br>do anomaly injection. apply GAD Method to get  $score_{norm}$</p>
<h3 id="Novel-Anomaly-injection-method"><a href="#Novel-Anomaly-injection-method" class="headerlink" title="Novel Anomaly injection method"></a>Novel Anomaly injection method</h3><h2 id="Sum-in-terms-of-Dataset"><a href="#Sum-in-terms-of-Dataset" class="headerlink" title="Sum in terms of Dataset"></a>Sum in terms of Dataset</h2><p>从数据集的角度来说：</p>
<h3 id="FairGAD-1"><a href="#FairGAD-1" class="headerlink" title="FairGAD:"></a>FairGAD:</h3><p>Reddit:</p>
<ul>
<li>数据来源：Post on politic related subReddit</li>
<li>Labelling Y: based on FACTOID(Sakketou et al., 2022), use the num of posted link(left or right)</li>
<li>Graph construciton:</li>
</ul>
<h1 id="CaD-VAE"><a href="#CaD-VAE" class="headerlink" title="CaD-VAE"></a>CaD-VAE</h1><p> Causal Disentangled Variational Auto-Encoder<br>Causal Disentangled Variational Auto-Encoder for Preference Understanding in Recommendation<br>Link: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2304.07922">https://arxiv.org/pdf/2304.07922</a></p>
<p>Challenges: inability to disentangle the latent factor<br>DLR: Disentangled Representation learning<br>     - DEAR: (Disentangled gEnerative cAusal Representation (DEAR)) <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.02637">https://arxiv.org/abs/2010.02637</a><br>     - CasualVAE: <a target="_blank" rel="noopener" href="https://doi.org/10.1109/CVPR46437.2021.00947">https://doi.org/10.1109/CVPR46437.2021.00947</a></p>
<p><img src="/whatever/2024-07-14-Papers-Collection/image.png" alt="alt text"></p>
<h2 id="In-Casual-Layer-The-SCM-is"><a href="#In-Casual-Layer-The-SCM-is" class="headerlink" title="In Casual Layer: The SCM is"></a>In Casual Layer: The SCM is</h2><h3 id="2-1"><a href="#2-1" class="headerlink" title="2.1"></a>2.1</h3><ul>
<li><p>$u \in {1, \ldots, U}$: user index</p>
</li>
<li><p>$i \in {1, \ldots, I}$: item index </p>
</li>
<li><p>$\mathcal{D}=(U, I, X)$: dataset  </p>
<ul>
<li>For a user $u$, the historical interactions $D_u = {x_{u,i} : x_{u,i} \in {0,1}}$ form a multi-hot vector.</li>
<li>$x_{u,i} = 0$ means no recorded interaction between user $u$ and item $i$.</li>
<li>$x_{u,i} = 1$ means an interaction between user $u$ and item $i$, such as a click.</li>
</ul>
</li>
<li><p>$x_u$ denotes all interactions of the user $u$:<br>$$x_u = {x_{u,i} : x_{u,i} = 1}$$</p>
<ul>
<li>Users may have diverse interests and interact with items that belong to many high-level concepts, such as preferred film directors, actors, genres, and year of production.</li>
</ul>
</li>
</ul>
<h3 id="2-2"><a href="#2-2" class="headerlink" title="2.2"></a>2.2</h3><p>$$z = g \left( (I - A^T)^{-1} \epsilon \right) := F_\alpha (\epsilon)$$</p>
<ul>
<li><p>$z$: causal variable</p>
</li>
<li><p>$\epsilon$: exogenous variables from a normal distribution - $\mathcal{N}(0, I)$</p>
</li>
<li><p>$g$: nonlinear element-wise transformations</p>
</li>
<li><p>$\alpha$: parameters $(A, g)$.</p>
</li>
<li><p>$A$: weighted adjacency matrix: $A_{ij}$ is non-zero only if $[z]_i$ is a parent of $[z]_j$. The binary adjacency matrix $I_A$ indicates where $A \neq 0$</p>
</li>
<li><p>To ensure disentanglement, labels of concepts $c$ are used as additional information</p>
<ul>
<li>If $g$ is invertible, the equation can be rephrased as:<br> $$g_i^{-1}(z_i) = A_i^T g_i^{-1}(z) + \epsilon_i$$<br> This implies that after a nonlinear transformation $g$, the factors $z$ satisfy a linear SCM.</li>
</ul>
</li>
</ul>
<ol>
<li><strong>Generative Model Assumption</strong>:<ul>
<li>For a user $u$, the generative model parameterized by $\theta$ assumes that the observed data are generated from the following distribution:<br>$$p_\theta(x_u) = \mathbb{E}<em>{p</em>\theta(c)} \left[ \iint p_\theta (x_u | \epsilon, z_u, c) p_\theta (\epsilon, z_u | c) d\epsilon dz_u \right]$$<br>Here, $x_u$ is the observed data for user $u$, $\epsilon$ are the exogenous variables, $z_u$ are the latent variables, and $c$ are the labels of the concepts.</li>
</ul>
</li>
</ol>
<h1 id="GUIDE"><a href="#GUIDE" class="headerlink" title="GUIDE"></a>GUIDE</h1><ul>
<li><p>Paper:<br> <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9671990">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9671990</a></p>
</li>
<li><p>Github:<br> <a target="_blank" rel="noopener" href="https://github.com/yushuowiki/GUIDE_pytorch">https://github.com/yushuowiki/GUIDE_pytorch</a></p>
</li>
</ul>
<p><img src="/whatever/2024-07-14-Papers-Collection/image-1.png" alt="alt text"></p>
<p>Structure: 主要用（三阶和四阶）Motif来encode<br>EncoderResidual Attention Layer</p>
<p>Attribute: 就是普通的X<br>Encoder用三层GCN。</p>
<p>24.02的 FairGAD<br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2402.15988">https://arxiv.org/pdf/2402.15988</a><br><a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=3cE6NKYy8x">https://openreview.net/pdf?id=3cE6NKYy8x</a><br><a target="_blank" rel="noopener" href="https://github.com/nigelnnk/FairGAD">https://github.com/nigelnnk/FairGAD</a><br>造数据集的<br>DOMINANT 19<br>CONAD 22<br>Cola 21<br> VGOD 23</p>
<p>23的GFCN<br>Graph Fairing Convolutional Networks for Anomaly Detection<br><a target="_blank" rel="noopener" href="https://github.com/MahsaMesgaran/GFCN">https://github.com/MahsaMesgaran/GFCN</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.10274">https://arxiv.org/pdf/2010.10274</a></p>
<p>VGOD 23.01<br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2210.12941">https://arxiv.org/pdf/2210.12941</a></p>
<p>Edits</p>
<p>很多数据集和model<br><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/5eaafd67434a4cfb1cf829722c65f184-Paper-Datasets_and_Benchmarks.pdf">https://proceedings.neurips.cc/paper_files/paper/2023/file/5eaafd67434a4cfb1cf829722c65f184-Paper-Datasets_and_Benchmarks.pdf</a><br><img src="/whatever/2024-07-14-Papers-Collection/image-3.png" alt="alt text"></p>
<h1 id="一讲Deep-Casual-Learning-21的"><a href="#一讲Deep-Casual-Learning-21的" class="headerlink" title="一讲Deep Casual Learning 21的"></a>一讲Deep Casual Learning 21的</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/ftp/arxiv/papers/2211/2211.03374.pdf">https://arxiv.org/ftp/arxiv/papers/2211/2211.03374.pdf</a><br><img src="/whatever/2024-07-14-Papers-Collection/image-4.png" alt="alt text"></p>
<h1 id="Disentanglement-learn"><a href="#Disentanglement-learn" class="headerlink" title="Disentanglement learn"></a>Disentanglement learn</h1><h2 id="Fair-Rep-learn-by-disentanglement-19"><a href="#Fair-Rep-learn-by-disentanglement-19" class="headerlink" title="Fair Rep learn by disentanglement 19"></a>Fair Rep learn by disentanglement 19</h2><p><a target="_blank" rel="noopener" href="https://proceedings.mlr.press/v97/creager19a/creager19a.pdf">https://proceedings.mlr.press/v97/creager19a/creager19a.pdf</a><br><img src="/whatever/2024-07-14-Papers-Collection/image-6.png" alt="alt text"></p>
<h2 id="CAF-也是disen"><a href="#CAF-也是disen" class="headerlink" title="CAF 也是disen,,"></a>CAF 也是disen,,</h2><h2 id="DEFEND-24"><a href="#DEFEND-24" class="headerlink" title="DEFEND 24"></a>DEFEND 24</h2><p>paper： <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2406.00987">https://arxiv.org/pdf/2406.00987</a><br><img src="/whatever/2024-07-14-Papers-Collection/image-7.png" alt="alt text"></p>
<h1 id="Counterfactual-Augmentation"><a href="#Counterfactual-Augmentation" class="headerlink" title="Counterfactual Augmentation"></a>Counterfactual Augmentation</h1><h2 id="CFGAD-24"><a href="#CFGAD-24" class="headerlink" title="CFGAD 24"></a>CFGAD 24</h2><p><a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/30524">https://ojs.aaai.org/index.php/AAAI/article/view/30524</a><br>Counterfactual Graph Learning for Anomaly Detection with Feature<br>Disentanglement and Generation (Student Abstract)</p>
<h2 id="NIFTY-21"><a href="#NIFTY-21" class="headerlink" title="NIFTY 21"></a>NIFTY 21</h2><ul>
<li>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2102.13186">https://arxiv.org/pdf/2102.13186</a></li>
<li>Code: <a target="_blank" rel="noopener" href="https://github.com/chirag126/nifty?tab=readme-ov-file">https://github.com/chirag126/nifty?tab=readme-ov-file</a></li>
</ul>
<p><img src="/whatever/2024-07-14-Papers-Collection/image-2.png" alt="alt text"></p>
<p>Augmented:</p>
<ul>
<li>Node level <ul>
<li>attribute masking $r \sim \mathcal{B}(P_n)$</li>
<li>$\tilde{\mathbf{x}}_u = \mathbf{x}_u + \mathbf{r} \circ \delta$, where $\delta \in \mathbb{R}^M$ is sampled from a normal distribution.</li>
</ul>
</li>
<li><h2 id="sens-attribute-level"><a href="#sens-attribute-level" class="headerlink" title="sens attribute level"></a>sens attribute level</h2></li>
<li>edge level</li>
</ul>
<h2 id="DEFEND"><a href="#DEFEND" class="headerlink" title="DEFEND"></a>DEFEND</h2><p><img src="/whatever/2024-07-14-Papers-Collection/image-5.png" alt="alt text"></p>
<h2 id="GEAR-22"><a href="#GEAR-22" class="headerlink" title="GEAR 22"></a>GEAR 22</h2><p>c</p>
<h2 id="MCCNIFTY-21"><a href="#MCCNIFTY-21" class="headerlink" title="MCCNIFTY 21"></a>MCCNIFTY 21</h2><h2 id="Fairness-Aware-21"><a href="#Fairness-Aware-21" class="headerlink" title="Fairness-Aware 21"></a>Fairness-Aware 21</h2><h2 id="CAF-23"><a href="#CAF-23" class="headerlink" title="CAF 23"></a>CAF 23</h2><p>paper: <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2307.04937">https://arxiv.org/pdf/2307.04937</a><br>code: <a target="_blank" rel="noopener" href="https://github.com/TimeLovercc/CAF-GNN?tab=readme-ov-file">https://github.com/TimeLovercc/CAF-GNN?tab=readme-ov-file</a></p>
<p><img src="/whatever/2024-07-14-Papers-Collection/image-10.png" alt="alt text"></p>
<h2 id="FairGNN"><a href="#FairGNN" class="headerlink" title="FairGNN"></a>FairGNN</h2><p>uses adversarial training to achieve fairness on graphs. It trains the learned representation via an adversary which is optimized to predict the sensitive attribute</p>
<h2 id="EDITS-23"><a href="#EDITS-23" class="headerlink" title="EDITS 23"></a>EDITS 23</h2><p>is a pre-processing method for fair graph learning. It aims to debias the input network to remove the sensitive<br>information in the graph data</p>
<h2 id="Fatra-24"><a href="#Fatra-24" class="headerlink" title="Fatra 24"></a>Fatra 24</h2><h2 id="CAGAD-24"><a href="#CAGAD-24" class="headerlink" title="CAGAD 24"></a>CAGAD 24</h2><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10564850">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10564850</a><br>heterophily dominant neighbors: most of its neighbors have different class labels from the target node</p>
<ol>
<li>GPNN graph pointer nn:  detect heter nodes<br>composed of encoder and decoder</li>
<li>DDMP (deniosing difussion probabilistic model): translate, create anomaly neigbors for heter nodes</li>
<li>GAT Graph attention network: detect anomaly nodes<br>有点想加一个PRAUC的测试指标： 所以当我们希望模型在正负样本上都能表现较好时使用 ROC-AUC 衡量，如果我们只关注模型对正样本的分辨能力使用 PR-AUC 更好</li>
</ol>
<h2 id="GFCN-24"><a href="#GFCN-24" class="headerlink" title="GFCN 24"></a>GFCN 24</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.10274">https://arxiv.org/abs/2010.10274</a></p>
<h2 id="GAD-NR-24-in-Pygod"><a href="#GAD-NR-24-in-Pygod" class="headerlink" title="GAD-NR 24 (in Pygod)"></a>GAD-NR 24 (in Pygod)</h2><p><img src="/whatever/2024-07-14-Papers-Collection/image-11.png" alt="alt text"></p>
<h1 id="GAD-with-node-rep-learn"><a href="#GAD-with-node-rep-learn" class="headerlink" title="GAD with node rep learn"></a>GAD with node rep learn</h1><h2 id="a-survey-on-GAD-21"><a href="#a-survey-on-GAD-21" class="headerlink" title="a survey on GAD -21"></a>a survey on GAD -21</h2><p>method and datasets<br><a target="_blank" rel="noopener" href="https://github.com/XiaoxiaoMa-MQ/Awesome-Deep-Graph-Anomaly-Detection">https://github.com/XiaoxiaoMa-MQ/Awesome-Deep-Graph-Anomaly-Detection</a></p>
<h2 id="a-survey-23-Graph-Learning-for-Anomaly-Analytics-Algorithms-Applications-and-Challenges"><a href="#a-survey-23-Graph-Learning-for-Anomaly-Analytics-Algorithms-Applications-and-Challenges" class="headerlink" title="a survey 23: Graph Learning for Anomaly Analytics: Algorithms, Applications, and Challenges"></a>a survey 23: Graph Learning for Anomaly Analytics: Algorithms, Applications, and Challenges</h2><p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/full/10.1145/3570906">https://dl.acm.org/doi/full/10.1145/3570906</a></p>
<h2 id="ADA-GAD-24-AAAI（Anomaly-Denoised-Autoencoders-for-Graph-Anomaly-Detection）"><a href="#ADA-GAD-24-AAAI（Anomaly-Denoised-Autoencoders-for-Graph-Anomaly-Detection）" class="headerlink" title="ADA-GAD 24 AAAI（Anomaly-Denoised Autoencoders for Graph Anomaly Detection）"></a>ADA-GAD 24 AAAI（Anomaly-Denoised Autoencoders for Graph Anomaly Detection）</h2><p><a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/28691">https://ojs.aaai.org/index.php/AAAI/article/view/28691</a></p>
<p>感觉最后写出来的应该类似是 Improving fairness for node-level GAE based GAD models via disentanglement learning</p>
<h1 id="Domain-Adaptation"><a href="#Domain-Adaptation" class="headerlink" title="Domain Adaptation"></a>Domain Adaptation</h1><p>属于transfer learning<br>2.2 GDA的两个用途：node/graph classification</p>
<ul>
<li>$\mathcal{U}\in{S,T}$ Domain</li>
<li>$P_{\mathcal{U}}(X,Y)$: joint feature and label distribution </li>
<li>${(x_i,y_i)}_{i=1}^N$: labeled source data </li>
<li>${(x_i)}_{i=1}^M$: unlabeled target data IID sampled from the source and target domain respectively.</li>
<li>$\phi:\mathcal{X}\rightarrow\mathcal{H}$: a feature encoder</li>
<li>$g:\mathcal{H}\rightarrow\mathcal{Y}$: a classifier </li>
<li>$\epsilon_{\mathcal{U}}(g\circ\phi)=P_{\mathcal{U}}(g(\phi(X))\neq Y)$:classification error in domain $\mathcal{U}$ </li>
<li>The objective is to train the model with available data to minimize target error $\epsilon_T(g\circ\phi)$ when predicting target labels.</li>
</ul>
<p>A popular DA strategy is to learn domain-invariant representation, ensuring similar $P_S(H)$ and $P_T(H)$ and minimizing the source error $\epsilon_S(g\circ\phi)$ to retain classification capability simultaneously (<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.05801">Zhao et al., 2019</a>). This is achieved through </p>
<ul>
<li>Feature Shift: $P_S(X|Y) \neq P_T(X|Y)$<ul>
<li>Assume ndoe feature $x_u$，$u \in \mathcal{V}$ are IID sampled from $P(X|Y)$. Therefore, $P(X = x|Y = y) = \prod_{u \in \mathcal{V}} P(X = x_u|Y = y_u)$</li>
</ul>
</li>
</ul>
<p>Preassumption on model:</p>
<p> $X\leftarrow Y \rightarrow A$. Lables are generated first, then A and X are generated.</p>
<ul>
<li>Strcture Shift: $P_S(A, Y) \neq P_T(A, Y)$<ul>
<li>Given joint distribution of $A$, and node labels $P(A, Y)$</li>
</ul>
</li>
</ul>
<p>Preassumption:</p>
<ol>
<li>Model: $X\leftarrow Y \rightarrow A$. Lables are generated first, then A and X are generated.</li>
<li>No Feature Shift: $P_S(X|Y) = P_T(X|Y)$</li>
</ol>
<p>Structure Shift: $P_{U}(A, Y) = P_{U}(A|Y)P_{U}(Y)$ </p>
<ul>
<li>Conditional Structure Shift: $P_S(A|Y) \neq P_T(A|Y)$</li>
<li>Label Shift: $P_S(Y) \neq P_T(Y)$</li>
</ul>
<p>Because of the interconnected nature of graph data, the IID is not satisfied for strcture shift, and new alogrithm is needed for solving CSS.</p>
<p> structure shift is unique to graphs. In contrast to feature shift, which is analogous to non-IID feature shift in non-graph data, structure shift cannot be solved by adapting traditional conditional shift methods. Therefore, we assume feature shift is resolved, i.e., $P_S(X|Y) = P_T</p>
<p>Even if $P_S(H^{(k)}|Y) = P_T(H^{(k)}|Y)$<br>CSS may lead to $P_S(H^{(k+1)}|Y) \neq P_T(H^{(k+1)}|Y)$</p>
<h3 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h3>  <!-- $$h_u^{(k+1)} = \text{UPT}\left(h_u^{(k)}, \text{AGG}\left(\{\{h_v^{(k)} : v \in \mathcal{N}_u\}\}\right)\right)$$ where
- $\{\{\cdot\}\}$: Multiset
- $h_u^{(k+1)}$: The updated representation of node $u$ at layer $k+1$.
- $\text{AGG}(\cdot)$: Aggregates message from neighbors.
- $\text{UPT}(\cdot)$: Update function --> 

<!-- (这个公式没有办法deploy成功) -->


<p><strong>Theorem 3.3 (Sufficient conditions for addressing CSS).</strong></p>
<p><em>Given the following assumptions</em></p>
<ul>
<li><em>Conditional Alignment in the previous layer k</em> <ul>
<li>$P_S(H^{(k)}|Y) = P_T(H^{(k)}|Y)$ and $\forall u \in \mathcal{V}<em>u$, <em>given</em> $Y = y_u$, $h_u^{(k)}$ <em>is independently sampled from</em> $P</em>{\mathcal{U}}(H^{(k)}|Y)$.</li>
</ul>
</li>
<li><em>Edge Conditional Independence</em> <ul>
<li><em>Given node labels</em> $y$, <em>edges mutually independently exist in the graph</em>.</li>
</ul>
</li>
</ul>
<p><em>If there exists a transformation that modifies the neighborhood of node</em> $u$: $\mathcal{N}_u \rightarrow \tilde{\mathcal{N}}_u, \forall u \in \mathcal{V}_S$, <em>such that</em></p>
<ul>
<li>$P_S(|\tilde{\mathcal{N}}_u||Y_u = i) = P_T(|\tilde{\mathcal{N}}_u||Y_u = i)$ </li>
<li>$P_S(Y_v|Y_u = i, v \in \tilde{\mathcal{N}}_u) = P_T(Y_v|Y_u = i, v \in \mathcal{N}_u), \forall i, v \in \mathcal{Y}$</li>
</ul>
<p><em>then</em><br>$P_S(H^{(k+1)}|Y) = P_T(H^{(k+1)}|Y) \text{ is satisfied}$</p>
<p>$\phi_\gamma$: GNN encoding with edge weight adjusting<br>$\phi$: GNN encoding without adjusting<br>last-layer alignment $P_S(H^{(L)} \mid Y) = P_T(H^{(L)} \mid Y)$can be achieved with $h_S^{(L)} = \phi_\gamma(x_S, A_S)$ and $h_T^{(L)} = \phi(x_T, A_T)$. Note that based on conditional alignment in the distribution of randomly sampled node representations $P_S(H^{(L)} \mid Y) = P_T(H^{(L)} \mid Y)$ and under the conditions in Thm 3.3, $P_S(\mathbf{H}^{(L)} \mid Y) = P_T(\mathbf{H}^{(L)} \mid Y)$ can also be achieved in the matrix form.</p>
<p>$G_s=(A_s,X_s)$<br>$G_t=(A_t,X_t)$<br>$g \circ \phi_\gamma$<br>$g \circ \phi$<br>$\hat Y_s$<br>$\hat Y_t$</p>
<p>Drawback of StrucRW</p>
<ol>
<li>using $w$ instead of $\gamma$ to reweigt $G_s$</li>
<li>Rough estimation for $w$</li>
<li>Not considering LS</li>
</ol>
<h1 id="LLM-GAD"><a href="#LLM-GAD" class="headerlink" title="LLM GAD"></a>LLM GAD</h1><h2 id="problem"><a href="#problem" class="headerlink" title="problem"></a>problem</h2><p>GNN缺点：<br>GNN的message passing会导致N和A趋同，降低识别率<br>尽管在Heterophilic graph上有改进，但是没有改变single node rep的本质</p>
<h2 id="method"><a href="#method" class="headerlink" title="method"></a>method</h2><p>(1) Sequence Construction<br>(2) Coherence-Aware Rep Computation<br>(3) Anomaly Detection via LLMs</p>
<p><strong>text coherence</strong><br>elvalueated by </p>
<ul>
<li>llama 2: LLM model</li>
<li>LCD-G: cross-domain coherence eval od sentence<br><img src="/whatever/2024-07-14-Papers-Collection/image-12.png" alt="alt text"><br>48,509 normal sequences and 7,108 anomalous sequences</li>
</ul>
<h3 id="Sequence-Construction"><a href="#Sequence-Construction" class="headerlink" title="Sequence Construction"></a>Sequence Construction</h3><p>Multi sequences for each node by random walk (local)</p>
<ul>
<li>starting from the target node (以target node为中点)</li>
<li>iteratively sampling neighboring nodes and their connecting edges. (h:点, e:边, hzhzhzh)</li>
</ul>
<h3 id="Coherence-Aware-Rep-Computation"><a href="#Coherence-Aware-Rep-Computation" class="headerlink" title="Coherence-Aware Rep Computation"></a>Coherence-Aware Rep Computation</h3><p>micro</p>
<ul>
<li>AGG info from edges within same sequence</li>
</ul>
<p>macro</p>
<ul>
<li>holistic edge information within the<br>entire graph</li>
</ul>
<h3 id="AD-via-LLMs"><a href="#AD-via-LLMs" class="headerlink" title="AD via LLMs"></a>AD via LLMs</h3></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://tlhey.github.io/whatever">Tlhey</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://tlhey.github.io/whatever/2024/07/14/2024-07-14-Papers-Collection/">https://tlhey.github.io/whatever/2024/07/14/2024-07-14-Papers-Collection/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/whatever/img/Lain_004.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/whatever/2024/06/03/2024-06-03-Cytoid-AI-Charting/" title="Cytoid AI Charting"><img class="cover" src="/whatever/img/Lain_006.jpeg" onerror="onerror=null;src='/whatever/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">Cytoid AI Charting</div></div><div class="info-2"><div class="info-item-1"> 相关论文实现  Survey 1: https://www.qbitai.com/2022/03/33133.html 1.1 现有技术(1)：100k songs, 44GB datahttps://github.com/chrisdonahue/ddchttps://arxiv.org/pdf/1703.06891.pdf 1.2 GeneLive在DDC基础上improve：现有技术2：GenéLive! Generating Rhythm Actions in Love Live! | Proceedings of the AAAI Conference on Artificial Intelligencehttps://arxiv.org/abs/2202.12823https://github.com/chrisdonahue/ddc 1.3 现有技术3：MuG...</div></div></div></a><a class="pagination-related" href="/whatever/2024/08/13/2024-08-12-Music-tech-exploring/" title="Music tech exploring"><img class="cover" src="/whatever/img/Lain_005.jpeg" onerror="onerror=null;src='/whatever/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">Music tech exploring</div></div><div class="info-2"><div class="info-item-1">跟音乐相关的ML应该先看survey 而不是自己做survey???  survey 17: Deep Learning Techniques for Music Generation – A Survey 17https://arxiv.org/pdf/1709.01620   symbolic AI – dealing with high-level symbolic representations (e.g., chords, harmony. . . ) and processes (harmonization, analysis. . . ); and sub-symbolic AI – dealing with low-level representations (e.g., sound, timbre. . . ) and processes (pitch recognition,classification. . . ).(a) Musical score of a C-major scale. (b) Chromagram obtained from the...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/whatever/img/Navi.png" onerror="this.onerror=null;this.src='/whatever/img/friend_404.gif'" alt="avatar"></div><div class="author-info-name">Tlhey</div><div class="author-info-description"></div><div class="site-data"><a href="/whatever/archives/"><div class="headline">Articles</div><div class="length-num">43</div></a><a href="/whatever/tags/"><div class="headline">Tags</div><div class="length-num">2</div></a><a href="/whatever/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Counterfactual-fairness"><span class="toc-number">1.</span> <span class="toc-text">Counterfactual fairness</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">1.0.1.</span> <span class="toc-text"></span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#defs"><span class="toc-number">1.0.1.1.</span> <span class="toc-text">defs</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Fairness-through-unawareness-FTU"><span class="toc-number">1.0.1.2.</span> <span class="toc-text">Fairness through unawareness (FTU):</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Individual-Fairness-IF"><span class="toc-number">1.0.1.3.</span> <span class="toc-text">Individual Fairness (IF).</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Demographic-Parity-DP-%E4%BA%BA%E5%8F%A3%E7%BB%9F%E8%AE%A1%E5%AD%A6%E6%84%8F%E4%B9%89%E4%B8%8A%E7%9A%84%E5%B9%B3%E7%AD%89"><span class="toc-number">1.0.1.4.</span> <span class="toc-text">Demographic Parity (DP)(人口统计学意义上的平等)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Equality-of-Opportunity"><span class="toc-number">1.0.1.5.</span> <span class="toc-text">Equality of Opportunity</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Causal-Models-%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD-Counterfacutal%E3%80%81"><span class="toc-number">1.0.2.</span> <span class="toc-text">Causal Models(因果推断), Counterfacutal、</span></a></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#FairGAD"><span class="toc-number">2.</span> <span class="toc-text">FairGAD</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Fair-GAD-problem"><span class="toc-number">2.1.</span> <span class="toc-text">Fair GAD problem</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data"><span class="toc-number">2.2.</span> <span class="toc-text">Data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GAD-Methods"><span class="toc-number">2.3.</span> <span class="toc-text">GAD Methods</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DOMINANT-Ding-et-al-2019a"><span class="toc-number">2.3.1.</span> <span class="toc-text">DOMINANT (Ding et al., 2019a)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CONAD-Xu-et-al-2022"><span class="toc-number">2.3.2.</span> <span class="toc-text">CONAD (Xu et al., 2022)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#COLA-Liu-et-al-2021"><span class="toc-number">2.3.3.</span> <span class="toc-text">COLA (Liu et al., 2021)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#VGOD-Huang-et-al-2023"><span class="toc-number">2.3.4.</span> <span class="toc-text">VGOD (Huang et al., 2023)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Non-Graph-AD-methods"><span class="toc-number">2.4.</span> <span class="toc-text">Non-Graph AD methods</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fainess-Method"><span class="toc-number">2.5.</span> <span class="toc-text">Fainess Method:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#FAIROD-Shekhar-et-al-2021"><span class="toc-number">2.5.1.</span> <span class="toc-text">FAIROD (Shekhar et al., 2021)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CORRELATION-Shekhar-et-al-2021"><span class="toc-number">2.5.2.</span> <span class="toc-text">CORRELATION (Shekhar et al., 2021)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HIN-Zeng-et-al-2021"><span class="toc-number">2.5.3.</span> <span class="toc-text">HIN (Zeng et al., 2021)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#EDITS-Dong-et-al-2022"><span class="toc-number">2.5.4.</span> <span class="toc-text">EDITS (Dong et al., 2022)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FAIRWALK-Rahman-et-al-2019"><span class="toc-number">2.5.5.</span> <span class="toc-text">FAIRWALK (Rahman et al., 2019)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Distance"><span class="toc-number">2.6.</span> <span class="toc-text">Distance</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Wasserstein-Distance"><span class="toc-number">2.6.1.</span> <span class="toc-text">Wasserstein Distance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Minkowski-distance"><span class="toc-number">2.6.2.</span> <span class="toc-text">Minkowski distance</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-Counterfactual-Learning-on-Graphs-A-Survey"><span class="toc-number">3.</span> <span class="toc-text">2024 Counterfactual Learning on Graphs: A Survey</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2022-Learning-Fair-Node-Representations-with-Graph-Counter-factual-Fairness"><span class="toc-number">4.</span> <span class="toc-text">2022 Learning Fair Node Representations with Graph Counter factual Fairness</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GEAR"><span class="toc-number">4.0.1.</span> <span class="toc-text">GEAR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-subgraph-generation"><span class="toc-number">4.0.2.</span> <span class="toc-text">1) subgraph generation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%BC%89Counterfactual-Data-Augmentation"><span class="toc-number">4.0.3.</span> <span class="toc-text">2）Counterfactual Data Augmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Self-Perturbation"><span class="toc-number">4.0.3.1.</span> <span class="toc-text">Self-Perturbation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Neighbor-Perturbation"><span class="toc-number">4.0.3.2.</span> <span class="toc-text">Neighbor-Perturbation</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Fair-Representation-learning"><span class="toc-number">4.0.4.</span> <span class="toc-text">3) Fair Representation learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dataset-creation"><span class="toc-number">4.0.5.</span> <span class="toc-text">Dataset creation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Result"><span class="toc-number">4.0.6.</span> <span class="toc-text">Result</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#24-Three-Revisits-to-Node-Level-Graph-Anomaly-Detection"><span class="toc-number">5.</span> <span class="toc-text">24 Three Revisits to Node-Level Graph Anomaly Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Previous-Outlier-injection-method"><span class="toc-number">5.0.1.</span> <span class="toc-text">Previous Outlier injection method</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Score-function"><span class="toc-number">5.0.1.1.</span> <span class="toc-text">Score function</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Novel-Anomaly-injection-method"><span class="toc-number">5.0.2.</span> <span class="toc-text">Novel Anomaly injection method</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sum-in-terms-of-Dataset"><span class="toc-number">5.1.</span> <span class="toc-text">Sum in terms of Dataset</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#FairGAD-1"><span class="toc-number">5.1.1.</span> <span class="toc-text">FairGAD:</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CaD-VAE"><span class="toc-number">6.</span> <span class="toc-text">CaD-VAE</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#In-Casual-Layer-The-SCM-is"><span class="toc-number">6.1.</span> <span class="toc-text">In Casual Layer: The SCM is</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1"><span class="toc-number">6.1.1.</span> <span class="toc-text">2.1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2"><span class="toc-number">6.1.2.</span> <span class="toc-text">2.2</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GUIDE"><span class="toc-number">7.</span> <span class="toc-text">GUIDE</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E8%AE%B2Deep-Casual-Learning-21%E7%9A%84"><span class="toc-number">8.</span> <span class="toc-text">一讲Deep Casual Learning 21的</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Disentanglement-learn"><span class="toc-number">9.</span> <span class="toc-text">Disentanglement learn</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Fair-Rep-learn-by-disentanglement-19"><span class="toc-number">9.1.</span> <span class="toc-text">Fair Rep learn by disentanglement 19</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CAF-%E4%B9%9F%E6%98%AFdisen"><span class="toc-number">9.2.</span> <span class="toc-text">CAF 也是disen,,</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DEFEND-24"><span class="toc-number">9.3.</span> <span class="toc-text">DEFEND 24</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Counterfactual-Augmentation"><span class="toc-number">10.</span> <span class="toc-text">Counterfactual Augmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#CFGAD-24"><span class="toc-number">10.1.</span> <span class="toc-text">CFGAD 24</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NIFTY-21"><span class="toc-number">10.2.</span> <span class="toc-text">NIFTY 21</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sens-attribute-level"><span class="toc-number">10.3.</span> <span class="toc-text">sens attribute level</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DEFEND"><span class="toc-number">10.4.</span> <span class="toc-text">DEFEND</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GEAR-22"><span class="toc-number">10.5.</span> <span class="toc-text">GEAR 22</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MCCNIFTY-21"><span class="toc-number">10.6.</span> <span class="toc-text">MCCNIFTY 21</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fairness-Aware-21"><span class="toc-number">10.7.</span> <span class="toc-text">Fairness-Aware 21</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CAF-23"><span class="toc-number">10.8.</span> <span class="toc-text">CAF 23</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FairGNN"><span class="toc-number">10.9.</span> <span class="toc-text">FairGNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#EDITS-23"><span class="toc-number">10.10.</span> <span class="toc-text">EDITS 23</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fatra-24"><span class="toc-number">10.11.</span> <span class="toc-text">Fatra 24</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CAGAD-24"><span class="toc-number">10.12.</span> <span class="toc-text">CAGAD 24</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GFCN-24"><span class="toc-number">10.13.</span> <span class="toc-text">GFCN 24</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GAD-NR-24-in-Pygod"><span class="toc-number">10.14.</span> <span class="toc-text">GAD-NR 24 (in Pygod)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GAD-with-node-rep-learn"><span class="toc-number">11.</span> <span class="toc-text">GAD with node rep learn</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#a-survey-on-GAD-21"><span class="toc-number">11.1.</span> <span class="toc-text">a survey on GAD -21</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#a-survey-23-Graph-Learning-for-Anomaly-Analytics-Algorithms-Applications-and-Challenges"><span class="toc-number">11.2.</span> <span class="toc-text">a survey 23: Graph Learning for Anomaly Analytics: Algorithms, Applications, and Challenges</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ADA-GAD-24-AAAI%EF%BC%88Anomaly-Denoised-Autoencoders-for-Graph-Anomaly-Detection%EF%BC%89"><span class="toc-number">11.3.</span> <span class="toc-text">ADA-GAD 24 AAAI（Anomaly-Denoised Autoencoders for Graph Anomaly Detection）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Domain-Adaptation"><span class="toc-number">12.</span> <span class="toc-text">Domain Adaptation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GNN"><span class="toc-number">12.0.1.</span> <span class="toc-text">GNN</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#LLM-GAD"><span class="toc-number">13.</span> <span class="toc-text">LLM GAD</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#problem"><span class="toc-number">13.1.</span> <span class="toc-text">problem</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#method"><span class="toc-number">13.2.</span> <span class="toc-text">method</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Sequence-Construction"><span class="toc-number">13.2.1.</span> <span class="toc-text">Sequence Construction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Coherence-Aware-Rep-Computation"><span class="toc-number">13.2.2.</span> <span class="toc-text">Coherence-Aware Rep Computation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AD-via-LLMs"><span class="toc-number">13.2.3.</span> <span class="toc-text">AD via LLMs</span></a></li></ol></li></ol></li></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/whatever/2025/04/27/2025-04-27-Before-Dwan/" title="2025-04-27-Before-Dwan"><img src="/whatever/img/Lain_003.jpeg" onerror="this.onerror=null;this.src='/whatever/img/404.jpg'" alt="2025-04-27-Before-Dwan"></a><div class="content"><a class="title" href="/whatever/2025/04/27/2025-04-27-Before-Dwan/" title="2025-04-27-Before-Dwan">2025-04-27-Before-Dwan</a><time datetime="2025-04-27T19:23:08.000Z" title="Created 2025-04-27 15:23:08">2025-04-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/whatever/2025/04/26/2025-04-26-Public-Security-Bureau/" title="2025-04-26-Public-Security-Bureau"><img src="/whatever/img/Liu_017.png" onerror="this.onerror=null;this.src='/whatever/img/404.jpg'" alt="2025-04-26-Public-Security-Bureau"></a><div class="content"><a class="title" href="/whatever/2025/04/26/2025-04-26-Public-Security-Bureau/" title="2025-04-26-Public-Security-Bureau">2025-04-26-Public-Security-Bureau</a><time datetime="2025-04-26T19:42:13.000Z" title="Created 2025-04-26 15:42:13">2025-04-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/whatever/2025/04/26/2025-04-25-Kite-Analysis/" title="2025-04-25-Kite-Analysis"><img src="/whatever/img/Liu_019.png" onerror="this.onerror=null;this.src='/whatever/img/404.jpg'" alt="2025-04-25-Kite-Analysis"></a><div class="content"><a class="title" href="/whatever/2025/04/26/2025-04-25-Kite-Analysis/" title="2025-04-25-Kite-Analysis">2025-04-25-Kite-Analysis</a><time datetime="2025-04-26T04:15:55.000Z" title="Created 2025-04-26 00:15:55">2025-04-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/whatever/2025/04/13/2025-04-13-T/" title="2025-04-13-T"><img src="/whatever/img/Lain_007.jpeg" onerror="this.onerror=null;this.src='/whatever/img/404.jpg'" alt="2025-04-13-T"></a><div class="content"><a class="title" href="/whatever/2025/04/13/2025-04-13-T/" title="2025-04-13-T">2025-04-13-T</a><time datetime="2025-04-14T01:50:45.000Z" title="Created 2025-04-13 21:50:45">2025-04-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/whatever/2025/04/13/2025-04-13-Reading-and-Books/" title="2025-04-13-Reading-and-Books"><img src="/whatever/img/Lain_005.jpeg" onerror="this.onerror=null;this.src='/whatever/img/404.jpg'" alt="2025-04-13-Reading-and-Books"></a><div class="content"><a class="title" href="/whatever/2025/04/13/2025-04-13-Reading-and-Books/" title="2025-04-13-Reading-and-Books">2025-04-13-Reading-and-Books</a><time datetime="2025-04-13T20:40:16.000Z" title="Created 2025-04-13 16:40:16">2025-04-13</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/Lain_004.jpeg);"><div id="footer-wrap"><div class="copyright">©2019 - 2025 By Tlhey</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/whatever/js/utils.js"></script><script src="/whatever/js/main.js"></script><div class="js-pjax"></div><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>