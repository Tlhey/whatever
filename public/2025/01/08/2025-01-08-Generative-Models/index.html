<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>2025-01-08-Generative-Models | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="article">
<meta property="og:title" content="2025-01-08-Generative-Models">
<meta property="og:url" content="http://example.com/2025/01/08/2025-01-08-Generative-Models/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-01-08T14:29:17.000Z">
<meta property="article:modified_time" content="2025-04-02T23:58:14.000Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-2025-01-08-Generative-Models" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/01/08/2025-01-08-Generative-Models/" class="article-date">
  <time class="dt-published" datetime="2025-01-08T14:29:17.000Z" itemprop="datePublished">2025-01-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      2025-01-08-Generative-Models
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <!-- www
## 01-08
### Histogram 
### Kernel Method
Kernel Density Estimation (KDE) ÊòØ‰∏ÄÁßçÁªüËÆ°ÊñπÊ≥ïÔºåÁî®‰∫é‰º∞ËÆ°‰∏Ä‰∏™ÈöèÊú∫ÂèòÈáèÁöÑ**ËøûÁª≠ÁöÑ**Ê¶ÇÁéáÂØÜÂ∫¶ÂáΩÊï∞ÔºàProbability Density Function, PDFÔºâ„ÄÇ

Áõ¥ÊñπÂõæÊúâ‰∏™ÈóÆÈ¢òÔºö

- **ÂÆÉÊòØÁ¶ªÊï£ÁöÑ**Ôºö‰Ω†Âè™ËÉΩÁúãÂà∞Âõ∫ÂÆöÁöÑÊó∂Èó¥Èó¥ÈöîÔºåÊØîÂ¶Ç10:00-11:00Ôºå11:00-12:00„ÄÇ
- **ÂÆÉ‰æùËµñÂàÜÁÆ±ÔºàbinÔºâÂ§ßÂ∞è**Ôºö‰∏çÂêåÁöÑÂàÜÁÆ±ÊñπÂºè‰ºöÂΩ±ÂìçÁõ¥ÊñπÂõæÁöÑÂΩ¢Áä∂„ÄÇ

**KDE Â∞±ÊòØ‰∏ÄÁßçËøûÁª≠ÁöÑÂàÜÂ∏É‰º∞ËÆ°ÊñπÊ≥ï**ÔºåÂÆÉ‰∏ç‰æùËµñ‰∫éÂàÜÁÆ±ÔºåËÄåÊòØÁî®‰∏Ä‰∏™ **‚ÄúÂπ≥ÊªëÁöÑÊõ≤Á∫ø‚Äù** Êù•Ë°®Á§∫Êï∞ÊçÆÁöÑÂàÜÂ∏É„ÄÇ  
‰Ω†ÂèØ‰ª•Êää KDE ÊÉ≥Ë±°ÊàêÔºö

- ÊØè‰∏™Êï∞ÊçÆÁÇπÈÉΩÁîª‰∏Ä‰∏™ **Â∞èÂ±±‰∏òÔºàkernelÔºâ**„ÄÇ
- ÁÑ∂ÂêéÊääËøô‰∫õÂ∞èÂ±±‰∏ò **Âè†Âä†Ëµ∑Êù•**ÔºåÂæóÂà∞‰∏Ä‰∏™ËøûÁª≠ÁöÑÊõ≤Á∫øÔºå‰ª£Ë°®Êï∞ÊçÆÁöÑÂàÜÂ∏É„ÄÇ

KDE ÁöÑÂÖ¨Âºè‰∏∫Ôºö
\(\hat{f}(x) = \frac{1}{n h} \sum_{i=1}^{n} K\left(\frac{x - x_i}{h}\right)\)

**Ëß£ÈáäÊØè‰∏™Á¨¶Âè∑**Ôºö

- **\( \hat{f}(x) \)**Ôºö‰º∞ËÆ°ÁöÑÊ¶ÇÁéáÂØÜÂ∫¶ÂáΩÊï∞„ÄÇ
- **\( n \)**ÔºöÊ†∑Êú¨Êï∞Èáè„ÄÇ
- **\( h \)**ÔºöÂπ≥ÊªëÂèÇÊï∞ÔºåÁß∞‰∏∫ **Â∏¶ÂÆΩÔºàbandwidthÔºâ**„ÄÇÂÆÉÂÜ≥ÂÆö‰∫ÜÂ∞èÂ±±‰∏òÁöÑ‚ÄúÂÆΩÂ∫¶‚Äù„ÄÇ
- **\( K \)**Ôºö**Ê†∏ÂáΩÊï∞ÔºàKernel FunctionÔºâ**ÔºåÂÜ≥ÂÆö‰∫ÜÂ∞èÂ±±‰∏òÁöÑÂΩ¢Áä∂„ÄÇ

Ê†∏ÂáΩÊï∞ÊòØ KDE ÁöÑÊ†∏ÂøÉ„ÄÇÂ∏∏ËßÅÁöÑÊ†∏ÂáΩÊï∞ÊúâÔºö

1. **È´òÊñØÊ†∏ÔºàGaussian KernelÔºâ**  
   ÂΩ¢Áä∂ÂÉèÊ≠£ÊÄÅÂàÜÂ∏ÉÁöÑÂ∞èÂ±±‰∏òÔºåÊúÄÂ∏∏Áî®ÁöÑÊ†∏ÂáΩÊï∞„ÄÇ

   \[
   K(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}
   \]

2. **ÁÆ±ÂΩ¢Ê†∏ÔºàBox KernelÔºâ**  
   ÊØè‰∏™Êï∞ÊçÆÁÇπÁîüÊàê‰∏Ä‰∏™‚ÄúÊñπÂΩ¢ÁöÑÂ∞èÂ±±‰∏ò‚ÄùÔºåËæπÁïåÊ∏ÖÊô∞Ôºå‰ΩÜ‰∏çÂπ≥Êªë„ÄÇ

3. **‰∏âËßíÊ†∏ÔºàTriangle KernelÔºâ**  
   ÁîüÊàê‰∏Ä‰∏™‰∏âËßíÂΩ¢ÁöÑÂ∞èÂ±±‰∏ò„ÄÇ

Â∏¶ÂÆΩÔºàBandwidthÔºâÂØπ KDE ÁöÑÂΩ±Âìç**

**Â∏¶ÂÆΩÔºàhÔºâ** ÊòØ KDE ‰∏≠‰∏Ä‰∏™ÈùûÂ∏∏ÈáçË¶ÅÁöÑÂèÇÊï∞„ÄÇÂÆÉÂÜ≥ÂÆö‰∫ÜÊØè‰∏™Â∞èÂ±±‰∏òÁöÑ **ÂÆΩÂ∫¶**Ôºå‰ªéËÄåÂΩ±ÂìçÊúÄÁªàÊõ≤Á∫øÁöÑÂπ≥ÊªëÁ®ãÂ∫¶„ÄÇ

- **Â∏¶ÂÆΩÂ∞è**ÔºöÊõ≤Á∫øÊõ¥Ë¥¥ËøëÊï∞ÊçÆÔºå‰ΩÜÂÆπÊòìÂá∫Áé∞‚ÄúËøáÊãüÂêà‚Äù„ÄÇ
- **Â∏¶ÂÆΩÂ§ß**ÔºöÊõ≤Á∫øÊõ¥Âπ≥ÊªëÔºå‰ΩÜÂèØËÉΩ‰ºöÂøΩÁï•‰∏Ä‰∫õÁªÜËäÇ„ÄÇ

### Series Methods
Imagine you're trying to approximate a complex function \( f(x) \) by expressing it as a combination of simpler functions (called **basis functions**). This is like saying:

\[ f(x) = \sum_{j=1}^{\infty} \beta_j \phi_j(x) \]

Where:
- \( \phi_j(x) \) are the **basis functions** (like sine, cosine, polynomials, etc.)
- \( \beta_j \) are the **coefficients** that tell us how much of each basis function to use.

---

### üß© **Orthogonal Basis**  
The basis functions \( \phi_j \) are said to be **orthogonal** if they satisfy the condition:

\[ \int \phi_j(x) \phi_k(x) dx = 0 \quad \text{for} \quad j \neq k \]

Think of orthogonal basis functions like directions that are at right angles to each other ‚Äî they don't overlap in their effects.

---

### üìö **Cosine Basis Example**
The notes give an example of using **cosine functions** as the basis:

\[ \phi_j(x) = \sqrt{2} \cos(2\pi j x) \]

These functions oscillate and can capture periodic patterns in the data.

---

### üìà **Wavelet Basis**
There's also a reference to **wavelet basis functions**, which are used to capture both **local** and **global** structures in the data.

---

### üîç **Key Formula for Density Estimation**  
The board shows that if we are estimating a **density function** \( f \), we can approximate it using the formula:

\[ \hat{f}(x) = \sum_{j=1}^{k} \hat{\beta}_j \phi_j(x) \]

Where:
- \( \hat{\beta}_j = \frac{1}{n} \sum_{i=1}^{n} \phi_j(X_i) \)  
  (This is the estimated coefficient based on sample data \( X_i \).)

---

### üß† **Key Idea: Selecting the Right \( k \)**
Choosing the right number of basis functions (\( k \)) is important. If \( k \) is too large, the model will **overfit** (too complicated). If \( k \) is too small, the model will **underfit** (too simple).




## 01-15


## Part 1: Risk Analysis

### Background and Setup

You have \( N \) points \( x_1, x_2, \ldots, x_N \in \mathbb{R}^d \). This means you have \( N \) data samples, each one is a \( d \)-dimensional vector. We assume these points lie in some space \( X \subset \mathbb{R}^d \), which is said to be a **compact set** (meaning it is closed and bounded in the mathematical sense).

### Key Smoothness Assumption

You mentioned an assumption:

\[
D^s p(x) - D^s p(y) \;\le\; L \,\|x - y\|
\]

1. **\( D^s p(x) \)**:  
   - This notation represents a high-order derivative (partial derivative) of a probability density function \(p(x)\).  
   - The superscript \( s \) is a **multi-index**.  
     - For instance, \( s = (s_1, s_2, \dots, s_d) \).  
     - Then \( D^s p(x)\) means we take the \((s_1 + s_2 + \cdots + s_d)\)-th partial derivative of \( p \) with respect to each coordinate appropriately:
       \[
       D^s p(x) \;=\; \frac{\partial^{\,s_1 + s_2 + \cdots + s_d} p(x)}{\partial x_1^{s_1}\,\partial x_2^{s_2}\,\cdots\,\partial x_d^{s_d}}.
       \]

2. **Interpretation of the inequality**:  
   \[
   D^s p(x) - D^s p(y) \;\le\; L\, \|x - y\|.
   \]  
   This says that **the change in the \(s\)-th derivative** between \(x\) and \(y\) is bounded by their distance times some constant \(L\). It suggests that \(p(x)\) is **smooth**‚Äîno wild jumps in its high-order derivatives. This is often used in probability density estimation and ensures continuity and differentiability in a controlled way.

3. **Why Compactness Matters**:  
   - If \( X \) is compact, it‚Äôs easier to control or bound various integrals and derivatives since \( x \) cannot go off to infinity.  
   - This is important in risk analysis because it helps with bounding error terms and ensuring integrals converge.

> **Reference for multi-index notation**:  
> - [Brilliant.org: Multi-Index Notation](https://brilliant.org/wiki/multi-index-notation/)  
> - [Wikipedia: Multi-index](https://en.wikipedia.org/wiki/Multi-index)  

---

## Part 2: More on \( D^s p(x) \) and Multi-Index Notation

If \( p(x) \) is a function of multiple variables, say \( p(x_1, x_2, \dots, x_d) \), then  
\[
s = (s_1, s_2, \dots, s_d)
\]  
tells us **how many times** we differentiate with respect to each variable \( x_i \).  

For example, if \( s = (2, 1, 0, \dots, 0) \), then  
\[
D^s p(x) \;=\; \frac{\partial^3 p(x)}{\partial x_1^2 \,\partial x_2^1}.
\]

### Intuitive View
- If \(s_1 = 2\), that means ‚Äútake the second derivative with respect to \(x_1\)‚Äù.  
- If \(s_2 = 1\), that means ‚Äútake the first derivative with respect to \(x_2\)‚Äù.  
- We multiply these partial derivatives together in the correct order.

This notation is just a concise way to keep track of all the derivatives in multiple dimensions.

---

## Part 3: Taylor Expansion (Taylor‚Äôs Theorem)

A general **Taylor expansion** around a point \( x \) says that if \(f\) is sufficiently smooth, we can write:

\[
f(x + h) 
\;=\;
f(x) \;+\; 
\sum_{k=1}^{m} \frac{1}{k!} \bigl( D^k f(x) \bigr) (h,\dots,h) \;+\; R_m,
\]

where \( R_m \) is the remainder term, and \( D^k f(x) \) is the \(k\)-th derivative of \(f\). In multiple dimensions, we typically see it in terms of partial derivatives:

\[
f(x + h) \;\approx\; 
f(x) 
\;+\; \nabla f(x) \cdot h
\;+\; \frac{1}{2} h^\top \nabla^2 f(x) \, h
\;+\; \dots
\]

This expansion is used **a lot** in analyzing the bias of estimators, numerical methods, and even in bounding differences between function values.

> **Reference for Taylor expansions**:  
> - [Wikipedia: Taylor's theorem](https://en.wikipedia.org/wiki/Taylor%27s_theorem)  
> - [MathWorld: Taylor Series](https://mathworld.wolfram.com/TaylorSeries.html)  

---

## Part 4: Kernel Density Estimation (KDE)

You also mentioned **Kernel Density Estimation**. It‚Äôs a method to estimate an unknown probability density function \( f(x) \) from data. The estimator looks like:

\[
\hat{f}(x) \;=\; \frac{1}{N h} \;\sum_{i=1}^{N} K\Bigl(\frac{x - X_i}{h}\Bigr),
\]

where
- \(K\) is a **kernel function** (often something like a Gaussian, Epanechnikov, etc.),  
- \(h\) is the **bandwidth** (a smoothing parameter).

### 4.1 Kernel Function Properties

A kernel \(K\) often satisfies:

1. \(\int K(u)\,du = 1\).  
2. \(\int u\,K(u)\,du = 0\). (Centered around 0)  
3. \(\int u^r K(u)\,du = 0\) for odd \(r\) if it‚Äôs symmetric, etc.

An example of a kernel is the **Epanechnikov kernel**:

\[
G(x) \;=\; \frac{3}{4}\,\bigl(1 - x^2\bigr) \, 1(\lvert x \rvert \le 1),
\]

where \(1(\lvert x \rvert \le 1)\) is the indicator function that is 1 if \(\lvert x \rvert \le 1\) and 0 otherwise. 

> **Reference for Kernel Density Estimation**:  
> - [‚ÄúKernel Density Estimation Explained‚Äù on Towards Data Science](https://towardsdatascience.com/kernel-density-estimation-explained-52045f84c726)  
> - [A Comprehensive Guide to KDE on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-kernel-density-estimation/)  

---

### 4.2 Bias of the KDE

The **bias** of an estimator \(\hat{f}(x)\) is:

\[
\text{Bias}(\hat{f}(x)) \;=\; 
E[\hat{f}(x)] \;-\; f(x).
\]

For KDE, we often find that:

\[
E[\hat{f}(x)]
\;=\; 
\int K\!\Bigl(\frac{x - t}{h}\Bigr) p(t)\, \frac{dt}{h}.
\]

By doing a change of variable and performing a Taylor expansion of \(p(\cdot)\), we eventually get:

\[
E[\hat{f}(x)]
\;=\; 
p(x) 
\;+\; 
\frac{h^2}{2}\,\mu_2(K)\,p''(x) 
\;+\; 
O(h^4),
\]

where \(\mu_2(K)\) is the second moment of the kernel. So the **leading term** of the bias is:

\[
\text{Bias}(\hat{f}(x))
\;=\;
\frac{h^2}{2}\,\mu_2(K)\,p''(x)
\;+\;
O(h^4).
\]

This tells us that the bias grows (roughly) like \(h^2\). If \(h\) is too big, the bias is large (over-smoothing), but if \(h\) is too small, you get high variance (under-smoothing). That‚Äôs why **bandwidth selection** is super important.

> **Reference for bias-variance in KDE**:  
> - [Lecture notes on Kernel Density Estimation (CMU)](https://www.stat.cmu.edu/~cshalizi/402/lectures/08-kernel-density/kde.pdf)  


## 02-28
Cold Diffusion


## 03-10
Á™ÅÁÑ∂ËßâÂæóËá™Â∑±ÊÇü‰∫ÜÔºüÔºü
How others put them together
https://www.youtube.com/watch?v=B-d_3xX6ss4
Ê†πÊçÆsong yangÁöÑËÆ∫ÊñáÁöÑÊó∂Èó¥Á∫ø„ÄÇ
1; sliced score model (ÂÆö‰πâ‰∫Üscore based model)
(https://proceedings.mlr.press/v115/song20a/song20a.pdf)

2; annealed Langevin Dynamics
(https://papers.neurips.cc/paper_files/paper/2019/hash/3001ef257407d5a371a96dcd947c7d93-Abstract.html)
langevin mcmc sample; https://zhuanlan.zhihu.com/p/797467112
the whole thing; https://yang-song.net/blog/2021/score/

3; Score-based GM through SED (Song et al. ICLR 2021)
(https://arxiv.org/pdf/2011.13456)
SED ËßÜËßíÁªü‰∏ÄÔºõ 
smld (ve) Âíå ddpm (vp)
sedÂíåof-odeÊúâ‰∏Ä‰∫õÂØπÂ∫îÂÖ≥Á≥ª

4; EDM 
Ôºàhttps://proceedings.neurips.cc/paper_files/paper/2022/file/a98846e9d9cc01cfb87eb694d946ce6b-Paper-Conference.pdfÔºâ
pf-odeËßÜËßíÁªü‰∏Ä‰∫Üdiffusion Ê®°Âûã

5; CM
Áî®‰∫Üedm

6; 







 -->

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/01/08/2025-01-08-Generative-Models/" data-id="cm9bnagsy001tzc3dhzzyh7h3" data-title="2025-01-08-Generative-Models" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2025/01/08/2025-01-09-Casual-Course/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          2025-01-09-Casual-Course
        
      </div>
    </a>
  
  
    <a href="/2025/01/06/2025-01-06-Update-on-RTIIP/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">2025-01-06-Update-on-RTIIP</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/music/" rel="tag">music</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tools/" rel="tag">tools</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/music/" style="font-size: 10px;">music</a> <a href="/tags/tools/" style="font-size: 10px;">tools</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/04/">April 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/03/">March 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">February 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/01/">January 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/11/">November 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/09/">September 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">July 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/04/01/2025-04-01-Linux-server-proxy-issue/">2025-04-01-Linux-server-proxy-issue</a>
          </li>
        
          <li>
            <a href="/2025/04/01/2025-04-01-mt-implementation-log/">2025-04-01-mt-implementation-log</a>
          </li>
        
          <li>
            <a href="/2025/03/09/2025-03-08-medication/">2025-03-08 medication</a>
          </li>
        
          <li>
            <a href="/2025/02/15/2025-02-15-DS/">2025-02-15-DS</a>
          </li>
        
          <li>
            <a href="/2025/01/29/2025-01-29-CV/">2025-01-29-CV</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>