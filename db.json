{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"node_modules/hexo-theme-landscape/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-landscape/source/fancybox/jquery.fancybox.min.css","path":"fancybox/jquery.fancybox.min.css","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-landscape/source/fancybox/jquery.fancybox.min.js","path":"fancybox/jquery.fancybox.min.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-landscape/source/js/jquery-3.6.4.min.js","path":"js/jquery-3.6.4.min.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-landscape/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":0,"renderable":1},{"_id":"source/img/Avatar.jpg","path":"img/Avatar.jpg","modified":1,"renderable":0},{"_id":"source/img/Background2.png","path":"img/Background2.png","modified":1,"renderable":0},{"_id":"source/img/Navi.jpg","path":"img/Navi.jpg","modified":1,"renderable":0},{"_id":"source/img/background.jpeg","path":"img/background.jpeg","modified":1,"renderable":0},{"_id":"source/img/bc1.jpg","path":"img/bc1.jpg","modified":1,"renderable":0},{"_id":"source/img/bc10.jpeg","path":"img/bc10.jpeg","modified":1,"renderable":0},{"_id":"source/img/bc11.jpeg","path":"img/bc11.jpeg","modified":1,"renderable":0},{"_id":"source/img/bc12.jpeg","path":"img/bc12.jpeg","modified":1,"renderable":0},{"_id":"source/img/bc2.jpg","path":"img/bc2.jpg","modified":1,"renderable":0},{"_id":"source/img/bc3.jpg","path":"img/bc3.jpg","modified":1,"renderable":0},{"_id":"source/img/bc5.jpeg","path":"img/bc5.jpeg","modified":1,"renderable":0},{"_id":"source/img/bc6.jpeg","path":"img/bc6.jpeg","modified":1,"renderable":0},{"_id":"source/img/bc7.jpeg","path":"img/bc7.jpeg","modified":1,"renderable":0},{"_id":"source/img/bc8.jpeg","path":"img/bc8.jpeg","modified":1,"renderable":0},{"_id":"source/img/bc9.jpeg","path":"img/bc9.jpeg","modified":1,"renderable":0},{"_id":"source/img/ruogu2.jpg","path":"img/ruogu2.jpg","modified":1,"renderable":0},{"_id":"source/img/bc4.jpg","path":"img/bc4.jpg","modified":1,"renderable":0}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"7d98d6592de80fdcd2949bd7401cec12afd98cdf","modified":1744306697738},{"_id":"node_modules/hexo-theme-landscape/package.json","hash":"06889bee30e4c39479467021da434d3a6a0990fc","modified":1744306701255},{"_id":"node_modules/hexo-theme-landscape/README.md","hash":"6497b70356271fd6f9f1dc862353be844c457a53","modified":1744306701255},{"_id":"node_modules/hexo-theme-landscape/_config.yml","hash":"a93d7b3990e45bc7247eecf01888f71674887a63","modified":1744306701272},{"_id":"node_modules/hexo-theme-landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1744306701097},{"_id":"node_modules/hexo-theme-landscape/languages/de-DE.yml","hash":"d29d1c4256b7ed9df42f511c2ff0a23ad5fd6c1f","modified":1744306701273},{"_id":"node_modules/hexo-theme-landscape/languages/en-GB.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1744306701275},{"_id":"node_modules/hexo-theme-landscape/languages/de.yml","hash":"3ebf0775abbee928c8d7bda943c191d166ded0d3","modified":1744306701273},{"_id":"node_modules/hexo-theme-landscape/languages/default.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1744306701274},{"_id":"node_modules/hexo-theme-landscape/languages/en-US.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1744306701275},{"_id":"node_modules/hexo-theme-landscape/languages/es-ES.yml","hash":"7008a8fc91f18d2a735864817b8ebda30c7a2c66","modified":1744306701276},{"_id":"node_modules/hexo-theme-landscape/languages/en.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1744306701276},{"_id":"node_modules/hexo-theme-landscape/languages/fr.yml","hash":"415e1c580ced8e4ce20b3b0aeedc3610341c76fb","modified":1744306701277},{"_id":"node_modules/hexo-theme-landscape/languages/es.yml","hash":"76edb1171b86532ef12cfd15f5f2c1ac3949f061","modified":1744306701277},{"_id":"node_modules/hexo-theme-landscape/languages/fr-FR.yml","hash":"8d09dbdab00a30a2870b56f7c0a7ca7deafa7b88","modified":1744306701277},{"_id":"node_modules/hexo-theme-landscape/languages/it-IT.yml","hash":"2cb6dc2fab9bd2dbe1c8bb869a9e8bf85a564fdd","modified":1744306701278},{"_id":"node_modules/hexo-theme-landscape/languages/hu-HU.yml","hash":"712d18664898fa21ba38d4973e90ef41a324ea25","modified":1744306701278},{"_id":"node_modules/hexo-theme-landscape/languages/hu.yml","hash":"284d557130bf54a74e7dcef9d42096130e4d9550","modified":1744306701278},{"_id":"node_modules/hexo-theme-landscape/languages/it.yml","hash":"89b7d91306b2c1a0f3ac023b657bf974f798a1e8","modified":1744306701278},{"_id":"node_modules/hexo-theme-landscape/languages/ja-JP.yml","hash":"08481267e0c112e1f6855620f2837ec4c4a98bbd","modified":1744306701279},{"_id":"node_modules/hexo-theme-landscape/languages/ja.yml","hash":"a73e1b9c80fd6e930e2628b393bfe3fb716a21a9","modified":1744306701279},{"_id":"node_modules/hexo-theme-landscape/languages/ko.yml","hash":"881d6a0a101706e0452af81c580218e0bfddd9cf","modified":1744306701281},{"_id":"node_modules/hexo-theme-landscape/languages/mn-MN.yml","hash":"b9e5f3e7c0c2f779cf2cfded6db847b5941637ca","modified":1744306701281},{"_id":"node_modules/hexo-theme-landscape/languages/ko-KR.yml","hash":"19209ad8f9d4057e8df808937f950eb265e1db69","modified":1744306701279},{"_id":"node_modules/hexo-theme-landscape/languages/mn.yml","hash":"2e7523951072a9403ead3840ad823edd1084c116","modified":1744306701281},{"_id":"node_modules/hexo-theme-landscape/languages/nl-NL.yml","hash":"5ebbc30021f05d99938f96dfff280392df7f91f0","modified":1744306701281},{"_id":"node_modules/hexo-theme-landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1744306701282},{"_id":"node_modules/hexo-theme-landscape/languages/ru-RU.yml","hash":"360d11a28bb768afb1dd15f63fa7fd3a8cc547ee","modified":1744306701283},{"_id":"node_modules/hexo-theme-landscape/languages/pt.yml","hash":"57d07b75d434fbfc33b0ddb543021cb5f53318a8","modified":1744306701283},{"_id":"node_modules/hexo-theme-landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1744306701281},{"_id":"node_modules/hexo-theme-landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1744306701283},{"_id":"node_modules/hexo-theme-landscape/languages/pt-PT.yml","hash":"0f852b6b228e6ea59aa3540574bb89b233f2a098","modified":1744306701282},{"_id":"node_modules/hexo-theme-landscape/languages/th-TH.yml","hash":"ebfdba9bc4842c829473c1e6e4544344f182724d","modified":1744306701283},{"_id":"node_modules/hexo-theme-landscape/languages/th.yml","hash":"84a55b00aa01f03982be294e43c33a20e6d32862","modified":1744306701284},{"_id":"node_modules/hexo-theme-landscape/languages/tr.yml","hash":"a1cdbfa17682d7a971de8ab8588bf57c74224b5b","modified":1744306701284},{"_id":"node_modules/hexo-theme-landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1744306701284},{"_id":"node_modules/hexo-theme-landscape/layout/category.ejs","hash":"97160b8111dd0283f8231408bcab4c87d31c1646","modified":1744306701182},{"_id":"node_modules/hexo-theme-landscape/layout/index.ejs","hash":"57281fc3812c877ec2d8e89ec87ede57b9789d4c","modified":1744306701191},{"_id":"node_modules/hexo-theme-landscape/scripts/fancybox.js","hash":"c857d7a5e4a5d71c743a009c5932bf84229db428","modified":1744306701223},{"_id":"node_modules/hexo-theme-landscape/layout/archive.ejs","hash":"97160b8111dd0283f8231408bcab4c87d31c1646","modified":1744306701175},{"_id":"node_modules/hexo-theme-landscape/layout/layout.ejs","hash":"0d1765036e4874500e68256fedb7470e96eeb6ee","modified":1744306701192},{"_id":"node_modules/hexo-theme-landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1744306701195},{"_id":"node_modules/hexo-theme-landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1744306701196},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/after-footer.ejs","hash":"1b89d0caba03a66a43d9c290a5e94fa438a89210","modified":1744306701139},{"_id":"node_modules/hexo-theme-landscape/layout/tag.ejs","hash":"97160b8111dd0283f8231408bcab4c87d31c1646","modified":1744306701199},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/archive.ejs","hash":"0039146b8ccbdf9b9f8bee58fc6c238f0e9921fc","modified":1744306701154},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/article.ejs","hash":"e9d4678e14be5e3cd5e34d783e5af6d6626092f5","modified":1744306701177},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/footer.ejs","hash":"3656eb692254346671abc03cb3ba1459829e0dce","modified":1744306701184},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/gauges-analytics.ejs","hash":"21a1e2a3907d1a3dad1cd0ab855fe6735f233c74","modified":1744306701186},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1744306701150},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/google-analytics.ejs","hash":"2ea7442ea1e1a8ab4e41e26c563f58413b59a3d0","modified":1744306701190},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/head.ejs","hash":"0e94f5722d4c44d3cc91be2f4fd30b9ab503b868","modified":1744306701190},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/header.ejs","hash":"6a5033d189554c9a6d42e2ef7952ae5c9742648e","modified":1744306701191},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1744306701192},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1744306701197},{"_id":"node_modules/hexo-theme-landscape/layout/_widget/recent_posts.ejs","hash":"60c4b012dcc656438ff59997e60367e5a21ab746","modified":1744306701197},{"_id":"node_modules/hexo-theme-landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1744306701181},{"_id":"node_modules/hexo-theme-landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1744306701167},{"_id":"node_modules/hexo-theme-landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1744306701199},{"_id":"node_modules/hexo-theme-landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1744306701200},{"_id":"node_modules/hexo-theme-landscape/source/css/_variables.styl","hash":"ca28281423ae57d76b6c1eb91cd845fd4e518bd6","modified":1744306701257},{"_id":"node_modules/hexo-theme-landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1744306701257},{"_id":"node_modules/hexo-theme-landscape/source/css/style.styl","hash":"e55a1d92954ed20f6887f92dc727bb995a010a43","modified":1744306701271},{"_id":"node_modules/hexo-theme-landscape/languages/zh-CN.yml","hash":"1efd95774f401c80193eac6ee3f1794bfe93dc5a","modified":1744306701284},{"_id":"node_modules/hexo-theme-landscape/source/fancybox/jquery.fancybox.min.css","hash":"1be9b79be02a1cfc5d96c4a5e0feb8f472babd95","modified":1744306701119},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1744306701180},{"_id":"node_modules/hexo-theme-landscape/source/js/script.js","hash":"49773efcb2221bbdf2d86f3f5c5ff2d841b528cc","modified":1744306701254},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1744306701185},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/date.ejs","hash":"f1458584b679545830b75bef2526e2f3eb931045","modified":1744306701183},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1744306701198},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1744306701194},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/title.ejs","hash":"4d7e62574ddf46de9b41605fe3140d77b5ddb26d","modified":1744306701201},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1744306701259},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1744306701263},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1744306701264},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/highlight.styl","hash":"9cc3b2927d814f2f6e8e188f9d3657b94f4c6ef3","modified":1744306701267},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/header.styl","hash":"268d2989acb06e2ddd06cc36a6918c6cd865476b","modified":1744306701267},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1744306701268},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1744306701269},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/article.styl","hash":"f608400a08cf137ab15ec1f44bac551950afe879","modified":1744306701261},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1744306701269},{"_id":"node_modules/hexo-theme-landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1744306701268},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1744306701270},{"_id":"node_modules/hexo-theme-landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1744306701266},{"_id":"node_modules/hexo-theme-landscape/source/js/jquery-3.6.4.min.js","hash":"eda46747c71d38a880bee44f9a439c3858bb8f99","modified":1744306701230},{"_id":"node_modules/hexo-theme-landscape/source/fancybox/jquery.fancybox.min.js","hash":"6181412e73966696d08e1e5b1243a572d0f22ba6","modified":1744306701253},{"_id":"node_modules/hexo-theme-landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1744306701217},{"_id":"source/2024-02-04-Sth-to-look.md","hash":"50a1ac8b33f06efe9c6083f19682f86741b7b65a","modified":1731509186000},{"_id":"source/2024-02-03.md","hash":"1b9ae9c30a3b722beb1ebf0216355912bef5bd16","modified":1732999223000},{"_id":"source/2024-02-05-ML.md","hash":"af7ee1fff54baf6e95d0bd3dcebd03720c4bd197","modified":1737843031000},{"_id":"source/2024-02-07-3-Internetworking.md","hash":"9d8dad43f35ad9566aa74568156aa57d710930f9","modified":1731509186000},{"_id":"source/2024-02-07-Transport-layer.md","hash":"80ccdfd70b34811ba177a9e4742a7aafd414791a","modified":1731509186000},{"_id":"source/2024-03-06-A-Trial-For-HW3-CS-311.md","hash":"77fe1e7749531138bf7419881ffc5ea211af623f","modified":1731509186000},{"_id":"source/2024-03-08-LHY-ML.md","hash":"1c8f9a0828d0d992117a4d586c5bc6ce0f6c55f3","modified":1734235097000},{"_id":"source/2024-05-19-CS224W-notes.md","hash":"6a52b3dbb19d0aa197e3e5df9a01724b2b7ea7f6","modified":1734236187000},{"_id":"source/2024-06-03-Cytoid-AI-Charting.md","hash":"56e8d5c131cb13f630f569401bc92f1698ab4e14","modified":1734234610000},{"_id":"source/2024-05-08-Meetings-log.md","hash":"3a9849b6ea009bc61b8b633beb1f1ae5c09a7c4a","modified":1734235144000},{"_id":"source/2024-05-29-Casual-Inference.md","hash":"aa1cdeeaed1848a76297750838d6f9042402389c","modified":1734261273000},{"_id":"source/2024-08-12-Music-tech-exploring.md","hash":"b5612318cb6f478f91cad012076807ddef275a28","modified":1734234602000},{"_id":"source/2024-07-14-Papers-Collection.md","hash":"6dbfad087347a8e97ef3febbaba9f35edea4df31","modified":1734667747000},{"_id":"source/2024-09-08-Interesting-music-repo.md","hash":"9a4fb0b17b4ae76a00a789edb3f4e4996e3cca69","modified":1734234684000},{"_id":"source/2024-09-08-Lofi.md","hash":"67cf9e23b9de825f68ae7df5d9ed6759639bff32","modified":1734234709000},{"_id":"source/2024-08-14-Webpages.md","hash":"4452601753ba13735e18b73f90ec5d994fe8fb41","modified":1734234620000},{"_id":"source/2024-10-25-Duke-courses-selection.md","hash":"fa3053d7b385ecfd5ee4d9cb301544ef5e1456bd","modified":1734263284000},{"_id":"source/2024-10-26-Magic.md","hash":"2017b0574d936a24b9ff52b57bbfe32809ea3008","modified":1734234526000},{"_id":"source/2024-11-16-DIP-Notes.md","hash":"c786005ce7330fe493b0427bed96269681eb7160","modified":1734234723000},{"_id":"source/2024-11-25-About-me.md","hash":"f493e1be791972d5cfcbcffcd50f5312ac3b524f","modified":1743878827000},{"_id":"source/2024-12-15-DECAF-paper.md","hash":"ff9e6cbb1e068f6ab9aad082870ffdc225dcf9b6","modified":1734513459000},{"_id":"source/2024-12-20-Lain.md","hash":"646ac479d0573e9baa28f2766252c41c5495aff4","modified":1734672042000},{"_id":"source/2024-12-20-Tighnari.md","hash":"e2436b80884738796157e375347862b64a279b27","modified":1734671191000},{"_id":"source/2025-01-06-Update-on-RTIIP.md","hash":"0694f2cec61ceb42bc18a99b2bd07e10cc7acaa9","modified":1743712623000},{"_id":"source/2025-01-08-Generative-Models.md","hash":"9739982e8da0c5b0b82d31f92fc5d17b298cc840","modified":1743638294000},{"_id":"source/2025-01-09-Casual-Course.md","hash":"9d8e731070123fa0ee9f0d8e7c66bea096c99b3c","modified":1743638156000},{"_id":"source/2025-01-10-Finance.md","hash":"4bca5f298fea4168e1efb7ba9765341104659fa5","modified":1740493482000},{"_id":"source/2025-01-11-NLP.md","hash":"b493edc7f0f968f403ab3b9ac3e848a75b6f1d32","modified":1736443709000},{"_id":"source/2025-01-29-CV.md","hash":"8132781983c443ed8e1732688fc1e4b4e3012dfe","modified":1744148443000},{"_id":"source/2025-02-15-DS.md","hash":"4938c0b7ee64f54cab91e372e09a9c4cc6c956d5","modified":1743638136000},{"_id":"source/2025-03-08-medication.md","hash":"42dac16470d9b3a89285556dacf99fa2064119f8","modified":1743471717000},{"_id":"source/2025-04-01-Linux-server-proxy-issue.md","hash":"a6667b4d5ff885bcf4395f99f2e6bdf6d6ee16ee","modified":1743636730000},{"_id":"source/2025-04-01-mt-implementation-log.md","hash":"6a6822d270646642e94f73f2390227523f6f3e8e","modified":1743783693000},{"_id":"source/hello.md","hash":"a834d098912a903fb3ca1f995004b91e42392505","modified":1743638342000},{"_id":"source/2024-02-04-Sth-to-look/image.png","hash":"ae94b78bdaaabba7bed6b896a30191358089e251","modified":1732460114000},{"_id":"source/.DS_Store","hash":"99e00ea143d45192a6a6de1256b233295859f16a","modified":1744306943489},{"_id":"source/2024-05-08-Meetings-log/image.png","hash":"b03d7da89e61fe376e3376ef2a90396e28e3ba47","modified":1732460114000},{"_id":"source/image.png","hash":"64e51e4658bb1ed1bacb1333bc0474afee182bc3","modified":1744043937000},{"_id":"source/2024-02-07-3-Internetworking/image.png","hash":"f34a380e10f9a02b605155dfb8577c750bbad88c","modified":1732460114000},{"_id":"source/2024-03-08-LHY-ML/image.png","hash":"7c8a16eab8aaeb5583da1a86104dfd66d47cbbfc","modified":1732460114000},{"_id":"source/2024-03-08-LHY-ML/image-2.png","hash":"38590cc9f60d28a120877e75602471f8e3bb41ce","modified":1732460114000},{"_id":"source/2024-05-08-Meetings-log/image-1.png","hash":"314adef3a197fdeb0e1971a4ad4b9886a9881336","modified":1732460114000},{"_id":"source/2024-05-29-Casual-Inference/image-1.png","hash":"e35a10588bb90e0aba58fc7d0c5c5a973893de6c","modified":1732460114000},{"_id":"source/2024-06-03-Cytoid-AI-Charting/image-1.png","hash":"002416b14ed970fc0bc7ec61550391eb285ff6ae","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-12.png","hash":"1b60177237fb63d3ae5f336ed576c7fd2b123285","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-4.png","hash":"ca128d8de576b61e79d1d95bad3af35437370276","modified":1732460114000},{"_id":"source/2025-01-29-CV/image-2.png","hash":"b4800b1e2439d06494ee836db5df570952017805","modified":1743961642000},{"_id":"source/2025-01-29-CV/image.png","hash":"68cb277c59a9c86d57d90e5205aff6720dc92faa","modified":1743884786000},{"_id":"source/2024-07-14-Papers-Collection/image-11.png","hash":"974e660f9f3bd57be8ef1ddcabf686a54defa22d","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-2.png","hash":"777d3866faf54545d6e56159f7da44fc2c8c1f5b","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-5.png","hash":"d5ff5cbeb38ea9c86b33744adb364e76e58dcbd6","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-8.png","hash":"e07a731ac8549c10afa34f346373c5893b2b4489","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-6.png","hash":"9d0dc4ed6502c3d393772e6b2a8891304205f824","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-7.png","hash":"76e5d181b3b6149a90e0da7c2ea4f2d830efec26","modified":1732460114000},{"_id":"source/2024-06-03-Cytoid-AI-Charting/image.png","hash":"7da09698c61486ee7c0b0539883ca466569623eb","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-1.png","hash":"2f1486ba82d933286ce4d77fc095e17e3e33035b","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image.png","hash":"3db5bd368d35c6a4a09c9cb9a7c53dfcd0799077","modified":1732460114000},{"_id":"source/2024-05-19-CS224W-notes/image.png","hash":"05dd95707a2d8d3e18cc644fede663dafb12a7c5","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-10.png","hash":"0e3c400c4262fb3984c3f99fc9aca8c87bb9debe","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-3.png","hash":"1f4d0e87e8f23f06826d311947838d24a6fb339f","modified":1732460114000},{"_id":"source/2024-02-04-Sth-to-look/1d559bbca4dc8ce283aec32a0bba4b1.png","hash":"629d4aa5733ae3a4ebbe23e46863c7f9e8c1aaee","modified":1732460114000},{"_id":"source/2024-07-14-Papers-Collection/image-9.png","hash":"3c08b9b64c874c908c83a74fe99f49d01025ae0f","modified":1732460114000},{"_id":"source/2024-02-05-ML/1d559bbca4dc8ce283aec32a0bba4b1.png","hash":"629d4aa5733ae3a4ebbe23e46863c7f9e8c1aaee","modified":1732460114000},{"_id":"source/2024-05-29-Casual-Inference/image-3.png","hash":"2962fa6b5d2aba05cdcbb1f5410dbe5fab2dc73f","modified":1732460114000},{"_id":"source/2024-05-29-Casual-Inference/image.png","hash":"13d8f97db11270a8a78c6c0c30bf038a3bb47394","modified":1732460114000},{"_id":"source/2024-05-19-CS224W-notes/image-1.png","hash":"87a0b7d706c5c2f60b76082bf26eb23399829f2d","modified":1732460114000},{"_id":"source/2024-03-08-LHY-ML/image-1.png","hash":"7b91259573f415876cdfd6cd2b9f833cb3448321","modified":1732460114000},{"_id":"source/2024-05-29-Casual-Inference/image-2.png","hash":"291f07f52cf2aa2fb1a9c16428268997d5880dc9","modified":1732460114000},{"_id":"source/2024-08-12-Music-tech-exploring/image.png","hash":"b58852022b125c56f4da101620f4f42412d7b135","modified":1732460114000},{"_id":"source/2024-08-12-Music-tech-exploring/image-1.png","hash":"c5b759e848f363c4acadf31cef4921e26edb1fb6","modified":1732460114000},{"_id":"source/2024-05-29-Casual-Inference/image-4.png","hash":"78c4a8d1a33ed92d2886495c6b071dd4022d1a93","modified":1732460114000},{"_id":"source/_posts/2024-05-08-Meetings-log/image.png","hash":"b03d7da89e61fe376e3376ef2a90396e28e3ba47","modified":1732460114000},{"_id":"source/_posts/2024-02-07-3-Internetworking/image.png","hash":"f34a380e10f9a02b605155dfb8577c750bbad88c","modified":1732460114000},{"_id":"source/_posts/2024-02-04-Sth-to-look/image.png","hash":"ae94b78bdaaabba7bed6b896a30191358089e251","modified":1732460114000},{"_id":"source/_posts/2024-06-03-Cytoid-AI-Charting/image-1.png","hash":"002416b14ed970fc0bc7ec61550391eb285ff6ae","modified":1732460114000},{"_id":"source/_posts/2024-05-08-Meetings-log/image-1.png","hash":"314adef3a197fdeb0e1971a4ad4b9886a9881336","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-12.png","hash":"1b60177237fb63d3ae5f336ed576c7fd2b123285","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-4.png","hash":"ca128d8de576b61e79d1d95bad3af35437370276","modified":1732460114000},{"_id":"source/_posts/2024-02-04-Sth-to-look.md","hash":"50a1ac8b33f06efe9c6083f19682f86741b7b65a","modified":1731509186000},{"_id":"source/_posts/2024-02-05-ML.md","hash":"af7ee1fff54baf6e95d0bd3dcebd03720c4bd197","modified":1737843031000},{"_id":"source/_posts/2024-02-07-3-Internetworking.md","hash":"9d8dad43f35ad9566aa74568156aa57d710930f9","modified":1731509186000},{"_id":"source/_posts/2024-02-07-Transport-layer.md","hash":"80ccdfd70b34811ba177a9e4742a7aafd414791a","modified":1731509186000},{"_id":"source/_posts/2024-03-06-A-Trial-For-HW3-CS-311.md","hash":"77fe1e7749531138bf7419881ffc5ea211af623f","modified":1731509186000},{"_id":"source/_posts/2024-05-19-CS224W-notes.md","hash":"6a52b3dbb19d0aa197e3e5df9a01724b2b7ea7f6","modified":1734236187000},{"_id":"source/_posts/2024-08-12-Music-tech-exploring.md","hash":"b5612318cb6f478f91cad012076807ddef275a28","modified":1734234602000},{"_id":"source/_posts/2024-08-14-Webpages.md","hash":"4452601753ba13735e18b73f90ec5d994fe8fb41","modified":1734234620000},{"_id":"source/_posts/2024-06-03-Cytoid-AI-Charting.md","hash":"56e8d5c131cb13f630f569401bc92f1698ab4e14","modified":1734234610000},{"_id":"source/_posts/2024-09-08-Lofi.md","hash":"67cf9e23b9de825f68ae7df5d9ed6759639bff32","modified":1734234709000},{"_id":"source/_posts/2024-10-25-Duke-courses-selection.md","hash":"fa3053d7b385ecfd5ee4d9cb301544ef5e1456bd","modified":1734263284000},{"_id":"source/_posts/2024-11-16-DIP-Notes.md","hash":"c786005ce7330fe493b0427bed96269681eb7160","modified":1734234723000},{"_id":"source/_posts/2024-11-25-About-me.md","hash":"f493e1be791972d5cfcbcffcd50f5312ac3b524f","modified":1743878827000},{"_id":"source/_posts/2024-12-15-DECAF-paper.md","hash":"ff9e6cbb1e068f6ab9aad082870ffdc225dcf9b6","modified":1734513459000},{"_id":"source/_posts/2024-10-26-Magic.md","hash":"2017b0574d936a24b9ff52b57bbfe32809ea3008","modified":1734234526000},{"_id":"source/_posts/2024-12-20-Tighnari.md","hash":"e2436b80884738796157e375347862b64a279b27","modified":1734671191000},{"_id":"source/_posts/2024-12-20-Lain.md","hash":"646ac479d0573e9baa28f2766252c41c5495aff4","modified":1734672042000},{"_id":"source/_posts/2025-01-06-Update-on-RTIIP.md","hash":"0694f2cec61ceb42bc18a99b2bd07e10cc7acaa9","modified":1743712623000},{"_id":"source/_posts/2024-05-08-Meetings-log.md","hash":"3a9849b6ea009bc61b8b633beb1f1ae5c09a7c4a","modified":1734235144000},{"_id":"source/_posts/2025-01-11-NLP.md","hash":"b493edc7f0f968f403ab3b9ac3e848a75b6f1d32","modified":1736443709000},{"_id":"source/_posts/2025-02-15-DS.md","hash":"4938c0b7ee64f54cab91e372e09a9c4cc6c956d5","modified":1743638136000},{"_id":"source/_posts/2025-03-08-medication.md","hash":"42dac16470d9b3a89285556dacf99fa2064119f8","modified":1743471717000},{"_id":"source/_posts/2025-04-01-mt-implementation-log.md","hash":"6a6822d270646642e94f73f2390227523f6f3e8e","modified":1743783693000},{"_id":"source/_posts/2025-01-08-Generative-Models.md","hash":"9739982e8da0c5b0b82d31f92fc5d17b298cc840","modified":1743638294000},{"_id":"source/_posts/2025-01-29-CV.md","hash":"8132781983c443ed8e1732688fc1e4b4e3012dfe","modified":1744148443000},{"_id":"source/_posts/hello.md","hash":"a834d098912a903fb3ca1f995004b91e42392505","modified":1743638342000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-11.png","hash":"974e660f9f3bd57be8ef1ddcabf686a54defa22d","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-2.png","hash":"777d3866faf54545d6e56159f7da44fc2c8c1f5b","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-6.png","hash":"9d0dc4ed6502c3d393772e6b2a8891304205f824","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-7.png","hash":"76e5d181b3b6149a90e0da7c2ea4f2d830efec26","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-8.png","hash":"e07a731ac8549c10afa34f346373c5893b2b4489","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-5.png","hash":"d5ff5cbeb38ea9c86b33744adb364e76e58dcbd6","modified":1732460114000},{"_id":"source/_posts/2024-06-03-Cytoid-AI-Charting/image.png","hash":"7da09698c61486ee7c0b0539883ca466569623eb","modified":1732460114000},{"_id":"source/_posts/2024-05-19-CS224W-notes/image.png","hash":"05dd95707a2d8d3e18cc644fede663dafb12a7c5","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-1.png","hash":"2f1486ba82d933286ce4d77fc095e17e3e33035b","modified":1732460114000},{"_id":"source/_posts/.DS_Store","hash":"221b624b4b8f03c811daa6c9b028d5f4b16cf561","modified":1744306834778},{"_id":"source/_posts/2024-03-08-LHY-ML/image.png","hash":"7c8a16eab8aaeb5583da1a86104dfd66d47cbbfc","modified":1732460114000},{"_id":"source/_posts/2024-05-29-Casual-Inference/image-1.png","hash":"e35a10588bb90e0aba58fc7d0c5c5a973893de6c","modified":1732460114000},{"_id":"source/_posts/2024-03-08-LHY-ML/image-2.png","hash":"38590cc9f60d28a120877e75602471f8e3bb41ce","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image.png","hash":"3db5bd368d35c6a4a09c9cb9a7c53dfcd0799077","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-10.png","hash":"0e3c400c4262fb3984c3f99fc9aca8c87bb9debe","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-3.png","hash":"1f4d0e87e8f23f06826d311947838d24a6fb339f","modified":1732460114000},{"_id":"source/_posts/2024-02-05-ML/1d559bbca4dc8ce283aec32a0bba4b1.png","hash":"629d4aa5733ae3a4ebbe23e46863c7f9e8c1aaee","modified":1732460114000},{"_id":"source/_posts/2024-07-14-Papers-Collection/image-9.png","hash":"3c08b9b64c874c908c83a74fe99f49d01025ae0f","modified":1732460114000},{"_id":"source/_posts/2024-02-04-Sth-to-look/1d559bbca4dc8ce283aec32a0bba4b1.png","hash":"629d4aa5733ae3a4ebbe23e46863c7f9e8c1aaee","modified":1732460114000},{"_id":"source/_posts/2024-05-19-CS224W-notes/image-1.png","hash":"87a0b7d706c5c2f60b76082bf26eb23399829f2d","modified":1732460114000},{"_id":"source/_posts/2024-05-29-Casual-Inference/image-3.png","hash":"2962fa6b5d2aba05cdcbb1f5410dbe5fab2dc73f","modified":1732460114000},{"_id":"source/_posts/2024-05-29-Casual-Inference/image.png","hash":"13d8f97db11270a8a78c6c0c30bf038a3bb47394","modified":1732460114000},{"_id":"source/_posts/2024-03-08-LHY-ML/image-1.png","hash":"7b91259573f415876cdfd6cd2b9f833cb3448321","modified":1732460114000},{"_id":"source/_posts/2024-05-29-Casual-Inference/image-2.png","hash":"291f07f52cf2aa2fb1a9c16428268997d5880dc9","modified":1732460114000},{"_id":"source/_posts/2024-08-12-Music-tech-exploring/image.png","hash":"b58852022b125c56f4da101620f4f42412d7b135","modified":1732460114000},{"_id":"source/_posts/2024-08-12-Music-tech-exploring/image-1.png","hash":"c5b759e848f363c4acadf31cef4921e26edb1fb6","modified":1732460114000},{"_id":"source/_posts/2024-05-29-Casual-Inference/image-4.png","hash":"78c4a8d1a33ed92d2886495c6b071dd4022d1a93","modified":1732460114000},{"_id":"source/_posts/2025-01-29-CV/image-2.png","hash":"b4800b1e2439d06494ee836db5df570952017805","modified":1743961642000},{"_id":"source/_posts/2025-01-29-CV/image.png","hash":"68cb277c59a9c86d57d90e5205aff6720dc92faa","modified":1743884786000},{"_id":"source/_posts/2024-03-08-LHY-ML.md","hash":"1c8f9a0828d0d992117a4d586c5bc6ce0f6c55f3","modified":1734235097000},{"_id":"source/_posts/2024-02-03.md","hash":"1b9ae9c30a3b722beb1ebf0216355912bef5bd16","modified":1732999223000},{"_id":"source/_posts/2024-07-14-Papers-Collection.md","hash":"6dbfad087347a8e97ef3febbaba9f35edea4df31","modified":1734667747000},{"_id":"source/_posts/2025-01-09-Casual-Course.md","hash":"9d8e731070123fa0ee9f0d8e7c66bea096c99b3c","modified":1743638156000},{"_id":"source/_posts/2024-09-08-Interesting-music-repo.md","hash":"9a4fb0b17b4ae76a00a789edb3f4e4996e3cca69","modified":1734234684000},{"_id":"source/_posts/2024-05-29-Casual-Inference.md","hash":"aa1cdeeaed1848a76297750838d6f9042402389c","modified":1734261273000},{"_id":"source/_posts/2025-04-01-Linux-server-proxy-issue.md","hash":"a6667b4d5ff885bcf4395f99f2e6bdf6d6ee16ee","modified":1743636730000},{"_id":"source/_posts/2025-01-10-Finance.md","hash":"4bca5f298fea4168e1efb7ba9765341104659fa5","modified":1740493482000},{"_id":"source/_posts/image.png","hash":"64e51e4658bb1ed1bacb1333bc0474afee182bc3","modified":1744043937000},{"_id":"source/img/Avatar.jpg","hash":"16602348e356cd5ea48d6e2668640610ad9666dd","modified":1732460114000},{"_id":"source/img/Navi.jpg","hash":"16602348e356cd5ea48d6e2668640610ad9666dd","modified":1732460114000},{"_id":"source/img/bc10.jpeg","hash":"b77095f4f88d27b1f10ad449d2dc2d94f8667ca0","modified":1732460122000},{"_id":"source/link/index.md","hash":"4bc8e066d552f8a9c1c5982818deb0fc78b93c32","modified":1731509186000},{"_id":"source/about/index.md","hash":"a9068cb6aaf8f3caf9fe906bc1385c822dbb7ca9","modified":1731509186000},{"_id":"source/img/ruogu2.jpg","hash":"3021f927b05161c382adcdd42741a7ef3adc7ad1","modified":1732460114000},{"_id":"source/img/bc9.jpeg","hash":"ea0dbc24d9fc46cf97ea9b2ad075d9bff2251c3b","modified":1732460122000},{"_id":"source/img/bc7.jpeg","hash":"6013f292bbdc9f31177eaa150a757c50cad381e6","modified":1732460122000},{"_id":"source/img/bc11.jpeg","hash":"e0e1b748a0f463287db2cf7652354af679e8fd6b","modified":1732460122000},{"_id":"source/img/bc5.jpeg","hash":"962bbfa9c1f7bae3c77de4d761955d845333181a","modified":1732460122000},{"_id":"source/img/background.jpeg","hash":"5ac26c9509f7d62c600f756b491745a83bf3531e","modified":1734865115000},{"_id":"source/img/bc12.jpeg","hash":"d2d98d6bd2686b62b70ff8688cc2eaabb56d4d8b","modified":1732460122000},{"_id":"source/img/bc6.jpeg","hash":"e5187288758a556520f57c581d33918f00df9853","modified":1732460122000},{"_id":"source/img/bc8.jpeg","hash":"310658a7e6e401af569d9032a215e021c7eabf4e","modified":1732460122000},{"_id":"source/img/bc1.jpg","hash":"34da7a317ba797a87a47a6e502e396089010b00d","modified":1732460114000},{"_id":"source/img/bc3.jpg","hash":"62869b7488ea1cc4099c62fd349dbbffeedb420d","modified":1732460114000},{"_id":"source/img/bc4.jpg","hash":"216c4c206d7aaed7cefbe1e601e2a51138b5972c","modified":1732460114000},{"_id":"source/img/bc2.jpg","hash":"e91bb5fa35867b046bd785a2f0a8e6410d755c8c","modified":1732460114000},{"_id":"source/img/Background2.png","hash":"a393dd6c1e11db971b2fa432fc035eb38adc360c","modified":1732460114000},{"_id":"public/link/index.html","hash":"96db48ea3a93c7c84257d9805c7789374e1244c3","modified":1744307031565},{"_id":"public/about/index.html","hash":"14ab87c8e379d5f71c43a215416d8b29a75335f5","modified":1744307031565},{"_id":"public/2025/04/01/2025-04-01-Linux-server-proxy-issue/index.html","hash":"ab2424ae41ff2a0f1796a77d1c2d414f3298f2d5","modified":1744307031565},{"_id":"public/2025/04/01/2025-04-01-mt-implementation-log/index.html","hash":"549c77a4497ba14e43b5cf0ff0716260d92d7f86","modified":1744307031565},{"_id":"public/2025/03/09/2025-03-08-medication/index.html","hash":"88368cf47bc5813c17ab21779efa49ac0def4ad8","modified":1744307031565},{"_id":"public/2025/02/15/2025-02-15-DS/index.html","hash":"187e325e39be5b8553e82e26dec87b23439a7e1d","modified":1744307031565},{"_id":"public/2025/01/09/2025-01-11-NLP/index.html","hash":"a85531d98219a0e0b19d2bf39f0fd77317085feb","modified":1744307031565},{"_id":"public/2025/01/08/2025-01-09-Casual-Course/index.html","hash":"6bf42402fb1ad88604d041ed5683f7a584f74389","modified":1744307031565},{"_id":"public/2025/01/06/2025-01-06-Update-on-RTIIP/index.html","hash":"b4dd3843a3bd3cfca93b2478ea42764af8b97fa5","modified":1744307031565},{"_id":"public/2024/12/20/2024-12-20-Lain/index.html","hash":"6ec1cb8eb9b36090818177e4ffc936b50f2d201b","modified":1744307031565},{"_id":"public/2024/12/20/2024-12-20-Tighnari/index.html","hash":"1f1c91e1765ecb53ceb68468c8c260bb41fa511a","modified":1744307031565},{"_id":"public/2024/12/15/2024-12-15-DECAF-paper/index.html","hash":"76fa893689cf45e6d2b8b7d3472f05fd66cc3ddb","modified":1744307031565},{"_id":"public/2024/11/16/2024-11-16-DIP-Notes/index.html","hash":"99c17025577543f739137d7a50e9ecd57358b5d3","modified":1744307031565},{"_id":"public/2024/11/10/hello/index.html","hash":"ef8d871ccd7870c27d66755f2e8a05746aa7642a","modified":1744307031565},{"_id":"public/2024/10/26/2024-10-26-Magic/index.html","hash":"06e962e1f6d11302e7017dda60325a296b2719de","modified":1744307031565},{"_id":"public/2024/09/08/2024-09-08-Lofi/index.html","hash":"929468df2453871cf1dbd42feca496507f63063c","modified":1744307031565},{"_id":"public/2024/10/25/2024-10-25-Duke-courses-selection/index.html","hash":"d4a1dfac44b485949a51a452750a4e9772ad2f56","modified":1744307031565},{"_id":"public/2024/09/08/2024-09-08-Interesting-music-repo/index.html","hash":"a313ae405911fb7b660184843caf1168d8785797","modified":1744307031565},{"_id":"public/2024/08/14/2024-08-14-Webpages/index.html","hash":"923f97a65deef3a43af7465f5fa694762d569640","modified":1744307031565},{"_id":"public/2024/06/03/2024-06-03-Cytoid-AI-Charting/index.html","hash":"64d640d9837332e626ff26766a2e07f8bf94a325","modified":1744307031565},{"_id":"public/2024/03/06/2024-03-06-A-Trial-For-HW3-CS-311/index.html","hash":"5175c09d5276a5a53d4623c1a706fc7836b0670c","modified":1744307031565},{"_id":"public/2024/02/07/2024-02-07-Transport-layer/index.html","hash":"b43476d761cd4ffa21735105352f87067024eb3a","modified":1744307031565},{"_id":"public/2024/02/07/2024-02-07-3-Internetworking/index.html","hash":"f4598944fda6e4ba164e4c0b82776efd0094309b","modified":1744307031565},{"_id":"public/2024/02/05/2024-02-05-ML/index.html","hash":"6061725cf6bd83aba137571005ffb52b2e1d8aea","modified":1744307031565},{"_id":"public/2024/02/04/2024-02-04-Sth-to-look/index.html","hash":"cd8ab887d5e1cf0376d87b1b4ffa44bc7716459b","modified":1744307031565},{"_id":"public/2024/02/03/2024-02-03/index.html","hash":"ff2bb011e64613fd07be705509f16398b01aa1f6","modified":1744307031565},{"_id":"public/archives/index.html","hash":"87566dc8a5b958a1e668eb96640b53cba71d3225","modified":1744307031565},{"_id":"public/archives/page/2/index.html","hash":"5e76fdd3248246112ea3bfa899a6f64071517183","modified":1744307031565},{"_id":"public/archives/page/3/index.html","hash":"901d01ecc0d73c50eaa2a156785e0fcf0faec6c2","modified":1744307031565},{"_id":"public/archives/page/4/index.html","hash":"2dfdc90b2a61da49d975bf26cea94ec13e39b7be","modified":1744307031565},{"_id":"public/archives/2024/index.html","hash":"8e76ea7755423739d0f0e3042ddb5271a55ad30f","modified":1744307031565},{"_id":"public/archives/2024/page/2/index.html","hash":"e8899c11b6eed0d4d8ad2bff69dd07b1c81ab987","modified":1744307031565},{"_id":"public/archives/2024/page/3/index.html","hash":"2fa1203c0efc19e385ce1ca3bef9fa4070ccfdc8","modified":1744307031565},{"_id":"public/archives/2024/02/index.html","hash":"ee19f54b5a0c7d07aef115677b8a87586b90d8a5","modified":1744307031565},{"_id":"public/archives/2024/03/index.html","hash":"9cc82b9d8f78bf2b4abcc386a3740abe91747dfc","modified":1744307031565},{"_id":"public/archives/2024/05/index.html","hash":"6e31a448b233b6fa6166a1cad40be7259b2ec543","modified":1744307031565},{"_id":"public/archives/2024/06/index.html","hash":"78fe39ed418a8f4ce53bfb20e0c7bdc2b2bf09cc","modified":1744307031565},{"_id":"public/archives/2024/07/index.html","hash":"f52a0ed7c8eb46aaf5983d0f94ad7cbc1a9503f9","modified":1744307031565},{"_id":"public/archives/2024/08/index.html","hash":"a1df921bb2e51a89817c9d82d6ce79e0befed74f","modified":1744307031565},{"_id":"public/archives/2024/09/index.html","hash":"811ed477421f3ee0cb9eafc8e96d697de227d79a","modified":1744307031565},{"_id":"public/archives/2024/10/index.html","hash":"243f306b17ffcfcafcc7fac08b55802bfdfd7502","modified":1744307031565},{"_id":"public/archives/2024/11/index.html","hash":"dd07892e96e19c0b77211ac67b82efb2c3aaa69d","modified":1744307031565},{"_id":"public/archives/2024/12/index.html","hash":"d9b880e0c7dbab51129826fc9f3e6f4999f72384","modified":1744307031565},{"_id":"public/archives/2025/index.html","hash":"c8e0bf73edb1417a49dcbd33bc61c8aa698aa9b3","modified":1744307031565},{"_id":"public/archives/2025/01/index.html","hash":"3f52ab17da51a724e6edce039a5e9c9fd6b71844","modified":1744307031565},{"_id":"public/archives/2025/02/index.html","hash":"14b46a59a2579c4b973ef1f3cf9c5c31630deaa1","modified":1744307031565},{"_id":"public/archives/2025/03/index.html","hash":"9a3bb5f763c47df7f4e987e48e2e21396c9e086d","modified":1744307031565},{"_id":"public/archives/2025/04/index.html","hash":"8b60fe0c77616f07ccd53dc15e74ec35dc4a6938","modified":1744307031565},{"_id":"public/tags/music/index.html","hash":"dc4c91f2bbfcfd3c6c7e2f8e23457a93bfa88f30","modified":1744307031565},{"_id":"public/tags/tools/index.html","hash":"05666ea5ee80911c72d426aaa656e2fd4933f15f","modified":1744307031565},{"_id":"public/2025/01/29/2025-01-29-CV/index.html","hash":"81f9a22c90ca4e6658ef1ef19669c24b1545079b","modified":1744307031565},{"_id":"public/2025/01/09/2025-01-10-Finance/index.html","hash":"9144eb3ed61ca11d49cfb6c9e2fb9cdfb650df39","modified":1744307031565},{"_id":"public/2025/01/08/2025-01-08-Generative-Models/index.html","hash":"13a661371c9a6e0abdb8acc03c09aaf6eb735a78","modified":1744307031565},{"_id":"public/2024/11/25/2024-11-25-About-me/index.html","hash":"eb910257da8794e970988cc7357b7f9368b06267","modified":1744307031565},{"_id":"public/2024/08/13/2024-08-12-Music-tech-exploring/index.html","hash":"62337ee0f0264c6b0f34f1a6523cfd3922714b7e","modified":1744307031565},{"_id":"public/2024/07/14/2024-07-14-Papers-Collection/index.html","hash":"6395e039ba86f4e1d50ec941ccd5e3c60fb36890","modified":1744307031565},{"_id":"public/2024/05/29/2024-05-29-Casual-Inference/index.html","hash":"676f07597197d36ec254a422d0c5315c65ea3bd8","modified":1744307031565},{"_id":"public/2024/05/19/2024-05-19-CS224W-notes/index.html","hash":"6529e5801b240469a329cf68e8d88978b4124214","modified":1744307031565},{"_id":"public/2024/05/08/2024-05-08-Meetings-log/index.html","hash":"9abbe99b09d4f5f7db47ce7af9b509aa420c89a6","modified":1744307031565},{"_id":"public/2024/03/08/2024-03-08-LHY-ML/index.html","hash":"b8daf2e3142ea0cabe5ed3a63289fdea72174198","modified":1744307031565},{"_id":"public/index.html","hash":"414a7ac006e6a00df1a9df527dc2aca0675063fd","modified":1744307031565},{"_id":"public/page/2/index.html","hash":"1927744b0797c8b6c269b0f0e6338d400ee58cd5","modified":1744307031565},{"_id":"public/page/3/index.html","hash":"598c80b2e4323b24c53ed9328991e59fe45f338c","modified":1744307031565},{"_id":"public/page/4/index.html","hash":"747c83a2bc474240f0afd2647de6b1e8b5c3b54b","modified":1744307031565},{"_id":"public/img/Avatar.jpg","hash":"16602348e356cd5ea48d6e2668640610ad9666dd","modified":1744307031565},{"_id":"public/img/Navi.jpg","hash":"16602348e356cd5ea48d6e2668640610ad9666dd","modified":1744307031565},{"_id":"public/img/bc10.jpeg","hash":"b77095f4f88d27b1f10ad449d2dc2d94f8667ca0","modified":1744307031565},{"_id":"public/fancybox/jquery.fancybox.min.css","hash":"1be9b79be02a1cfc5d96c4a5e0feb8f472babd95","modified":1744307031565},{"_id":"public/js/script.js","hash":"49773efcb2221bbdf2d86f3f5c5ff2d841b528cc","modified":1744307031565},{"_id":"public/css/style.css","hash":"ecc329be740a220cc188ff49b02da4847cb7ee5e","modified":1744307031565},{"_id":"public/js/jquery-3.6.4.min.js","hash":"eda46747c71d38a880bee44f9a439c3858bb8f99","modified":1744307031565},{"_id":"public/fancybox/jquery.fancybox.min.js","hash":"6181412e73966696d08e1e5b1243a572d0f22ba6","modified":1744307031565},{"_id":"public/img/ruogu2.jpg","hash":"3021f927b05161c382adcdd42741a7ef3adc7ad1","modified":1744307031565},{"_id":"public/img/bc9.jpeg","hash":"ea0dbc24d9fc46cf97ea9b2ad075d9bff2251c3b","modified":1744307031565},{"_id":"public/img/bc7.jpeg","hash":"6013f292bbdc9f31177eaa150a757c50cad381e6","modified":1744307031565},{"_id":"public/img/bc11.jpeg","hash":"e0e1b748a0f463287db2cf7652354af679e8fd6b","modified":1744307031565},{"_id":"public/img/bc5.jpeg","hash":"962bbfa9c1f7bae3c77de4d761955d845333181a","modified":1744307031565},{"_id":"public/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1744307031565},{"_id":"public/img/background.jpeg","hash":"5ac26c9509f7d62c600f756b491745a83bf3531e","modified":1744307031565},{"_id":"public/img/bc12.jpeg","hash":"d2d98d6bd2686b62b70ff8688cc2eaabb56d4d8b","modified":1744307031565},{"_id":"public/img/bc6.jpeg","hash":"e5187288758a556520f57c581d33918f00df9853","modified":1744307031565},{"_id":"public/img/bc8.jpeg","hash":"310658a7e6e401af569d9032a215e021c7eabf4e","modified":1744307031565},{"_id":"public/img/bc3.jpg","hash":"62869b7488ea1cc4099c62fd349dbbffeedb420d","modified":1744307031565},{"_id":"public/img/bc1.jpg","hash":"34da7a317ba797a87a47a6e502e396089010b00d","modified":1744307031565},{"_id":"public/img/bc4.jpg","hash":"216c4c206d7aaed7cefbe1e601e2a51138b5972c","modified":1744307031565},{"_id":"public/img/bc2.jpg","hash":"e91bb5fa35867b046bd785a2f0a8e6410d755c8c","modified":1744307031565},{"_id":"public/img/Background2.png","hash":"a393dd6c1e11db971b2fa432fc035eb38adc360c","modified":1744307031565}],"Category":[],"Data":[],"Page":[{"title":"link","date":"2024-11-11T03:03:29.000Z","_content":"\n- class_name: 友情链接\n  class_desc: 那些人，那些事\n  link_list:\n    - name: Ruogu\n      link: https://ruogu-alter.github.io/\n      avatar: img/ruogu2.jpg\n      descr: 喵喵喵\n\n","source":"link/index.md","raw":"---\ntitle: link\ndate: 2024-11-10 22:03:29\n---\n\n- class_name: 友情链接\n  class_desc: 那些人，那些事\n  link_list:\n    - name: Ruogu\n      link: https://ruogu-alter.github.io/\n      avatar: img/ruogu2.jpg\n      descr: 喵喵喵\n\n","updated":"2024-11-13T14:46:26.000Z","path":"link/index.html","comments":1,"layout":"page","_id":"cm9bndbkt00002b3d06mofnmq","content":"<ul>\n<li>class_name: 友情链接<br>class_desc: 那些人，那些事<br>link_list:<ul>\n<li>name: Ruogu<br>link: <a href=\"https://ruogu-alter.github.io/\">https://ruogu-alter.github.io/</a><br>avatar: img&#x2F;ruogu2.jpg<br>descr: 喵喵喵</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<ul>\n<li>class_name: 友情链接<br>class_desc: 那些人，那些事<br>link_list:<ul>\n<li>name: Ruogu<br>link: <a href=\"https://ruogu-alter.github.io/\">https://ruogu-alter.github.io/</a><br>avatar: img&#x2F;ruogu2.jpg<br>descr: 喵喵喵</li>\n</ul>\n</li>\n</ul>\n"},{"title":"about","date":"2024-11-11T02:47:18.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2024-11-10 21:47:18\n---\n","updated":"2024-11-13T14:46:26.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"cm9bndbku00012b3d3bfeadld","content":"","excerpt":"","more":""}],"Post":[{"title":"CS224W_notes","date":"2024-05-19T17:01:34.000Z","mathjax":true,"_content":" \n\n# 1 Introduction，Machine learning for graphs\n## 大纲\n大纲\n1. Traditional methods: Graphlets, Graph Kernels\n2. Methods for node embeddings: DeepWalk, Node2Vec\n3. Graph Neural Networks: GCN, GraphSAGE, GAT, Theory of GNNs\n4. Knowledge graphs and reasoning: TransE, BetaE\n5. Deep generative models for graphs\n6. Applications to Biomedicine, Science, Industry \n\n## Defs\n0. $G=(V, E, F)$ or $G(V, E)$\n1. Directed/ undirected\n2. Degree  \n   Directed $\\bar{k} = \\langle k \\rangle = \\frac{1}{N} \\sum_{i=1}^{N} k_i = \\frac{2E}{N}$  \n   Undirected in-degree + out-degree = (total) degree, $\\bar{k}= \\frac{E}{N}$ \n3. Bipartite Graph\n4. Folded/Projected Bipartite graph\n5. Representing graphs: Adjacency matrix Density of matrix $\\frac{E}{N^2}$\n   1. adjacency matrix\n   2. Edge List\n   3. Adjacency List\n6. Attribute of edges\n7. Weighted/Unweighted\n8. Self-edges\n9. Connectivity: (Un)Directed, Strong Connected Components (in Undirected)\n\n# 2 Traditional methods for ML on graph \nStructural Feature/ Node features  \nTrain on Random Forest, SVM, Neural Network; Apply on new graph. \n\n## Node\n### (1) Node Centrality\n233\n1. Eigenvector centrality: $c_v=\\frac{1}{\\lambda}\\sum_{u\\in N(v)}$\n2. Betweenness centrality  \nHere is the improved version of the formulas in the format you provided, while keeping the same style and explanation:\n\n---\n\n1. **Betweenness Centrality**  \n   Betweenness centrality \\( c_v \\) measures the extent to which a node \\( v \\) lies on the shortest paths between other nodes.  \n\n   $$\n   c_v = \\sum_{s \\neq v \\neq t} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}\n   $$\n\n   - \\( \\sigma_{st} \\): The number of shortest paths between nodes \\( s \\) and \\( t \\).  \n   - \\( \\sigma_{st}(v) \\): The number of shortest paths between \\( s \\) and \\( t \\) that pass through \\( v \\).\n\n---\n\n2. **Closeness Centrality**  \n   Closeness centrality \\( c_v \\) quantifies how close a node \\( v \\) is to all other nodes in the network.  \n\n   $$\n   c_v = \\frac{1}{\\sum_{u \\neq v} d(u, v)}\n   $$\n\n   - \\( d(u, v) \\): The shortest path length between node \\( u \\) and node \\( v \\).\n\n\n\n### (2) Clustering Coefficient \n\\[\ne_v = \\frac{\\text{Number of edges between neighbors of } v}{\\binom{k_v}{2}}, \\quad \\binom{k_v}{2} = \\frac{k_v (k_v - 1)}{2}\n\\] \n\n### (3) Graphlet: Rooted connected non-isomorphic subgraphs  \nGraphlet degree vector  \nClustering coefficient.\nFeature-based/ structure-based features.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Link\n### (1) Link prediction\n1. Links missing at random: Remove a random set of links and then aim to predict them\n2. Links over time: Given $G[t_0, t_0']$ a graph on edges up to time $t_0'$, output a ranked list $L$ of links (not in $G[t_0, t_0']$) that are predicted to appear in $G[t_1, t_1']$\n\n### (2) Local Neighborhood Overlap\n- Common neighbors: $|N(v_1) \\cap N(v_2)|$\n- Jaccard's coefficient: $\\frac{|N(v_1) \\cap N(v_2)|}{|N(v_1) \\cup N(v_2)|}$,  \n  Normalize common neighbor, assuming having the same number of neighbors\n- Adamic-Adar index: $\\sum_{u \\in N(v_1) \\cap N(v_2)} \\frac{1}{\\log k_u}$,  \n  Penalize those who have many neighbors\n\n### (3) Global Neighborhood Overlap \n- Katz index: $S_{uv}= \\sum_{l=1}^{\\infty} \\beta^l A^l_{uv}$,  \n  $A^l_{uv}$: number of paths of length $l$ between $u$ and $v$,  \n  $\\beta$: discount factor, the contribution of long paths  \n- Katz index matrix: $S= \\sum_{i=1}^\\infty \\beta^iA^i = (I-\\beta A)^{-1}-I$ \n\n## Graph  \n### Kernel method:\n1. **Kernel function**:  \n   $K(G, G')$ measures the similarity between two graphs $G$ and $G'$.  \n   Maps the graphs into a higher-dimensional space where linear methods can be applied to perform complex, non-linear tasks in the original space.\n   \n2. **Kernel Matrix**: $\\mathbf{K} = \\left( K(G, G') \\right)_{G, G'}$ is a symmetric matrix.  \n   It is positive semidefinite, meaning all its eigenvalues are non-negative.\n   \n3. **Feature Representation**:  \n   Feature mapping $\\phi(\\cdot)$ kernel function is expressed as dot product in feature space: $K(G, G') = \\phi(G)^\\top \\phi(G')$.\n   \ncite: [CSDN Blog](https://blog.csdn.net/PolarisRisingWar/article/details/115598815)\n\n### Design graph feature vector $\\phi(G)$\n**Bag-of-Words: BoW**  \nKey idea: use the word counts as features (#nodes as features, #degree, #graphlet, #color)\n\n### Graphlet features\nKey idea: Count the number of different graphlets in a graph.  \n$G_k=(g_1, g_2, \\cdots, g_{n_k})$\n\nGraphlet count vector $(f_G)=\\#(g_i \\subseteq G), \\; i \\leq n_k$\n\n$h_G= \\frac{f_G}{\\text{Sum}(F_G)}$,  \n$K(G, G')=H_G^\\top H_G'$\n\nNP-hard $O(nd^{k-1})$, expensive to calculate \n\n### Weisfeiler-Lehman Kernel\n[Weisfeiler-Lehman Kernel Blog](https://blog.csdn.net/PolarisRisingWar/article/details/117336622)\n\n# 3 Node Embedding\n## 3.1 Intro\nKey: How to define node similarity  \n\n\n<!-- Avoid direct Feature Engineering, and also reflect structural features -->\n### Encoder\nFeature representation ↔ feature embedding  \n<!-- If two nodes are similar in structure, they should be similar in embedding space -->\n<!-- Use dot product to measure similarity -->\nSimilarity $(u, v) \\approx z_u^T z_v$,  \n$ENC(u) = z_u$, $ENC(v) = z_v$, <!--ENC: Encoder-->  \n$z_u, z_v$ are $d$-dimensional in embedding space, $d$ usually 64-1000  \n$ENC(v)$ node in the input graph\n\n$ENC(v) = z_v = Z \\cdot v$  \nEncoder is a lookup, embedding matrix $Z \\in \\mathbb{R}^{d \\times |V|}$, $v \\in I^{|V|}$\n\n#### ENC\nShallow encoder: $d \\times |V|$  \nSome ways for ENC: DeepWalk, Node2Vec\n\n## 3.2 Random walk for Node Embedding\n### Notation\n- Vector $z_u$: embedding vector of node $u$ (what we aim to find)\n- $P(v|z_u)$: probability of visiting node $v$ on random walk starting from $u$. Used to measure similarity. \n- Softmax: $\\sigma(z)_i = \\frac{e^{z_i}}{\\sum e^{z_j}}$\n- Sigmoid: $S(x) = \\frac{1}{1 + e^{-x}}$\n\n### Random walk embedding\nUsing random strategy $R$: $P_R(u|v)$  \nGiven  \n$G=(V, E)$  \nGoal: Learn a mapping $f: u \\rightarrow \\mathbb{R}^d$  \n$$\n\\mathcal{L} = \\sum_{u \\in V} \\sum_{v \\in N_R(u)} -\\log\\left(\\frac{\\exp(z_u^\\top z_v)}{\\sum_{n \\in V} \\exp(z_u^\\top z_n)}\\right)\n$$  \n**Negative sampling**  \n$$\n\\log\\left(\\frac{\\exp(z_u^\\top z_v)}{\\sum_{n \\in V} \\exp(z_u^\\top z_n)}\\right) \\approx \\log\\left(\\sigma(z_u^\\top z_v)\\right) - \\sum_{i=1}^{k} \\log\\left(\\sigma(z_u^\\top z_{n_i})\\right), \\quad n_i \\sim P_V\n$$ -->\n\n### Random walk strategy \n#### DeepWalk\n[DeepWalk Paper](https://www.vldb.org/pvldb/vol10/p13-wu.pdf)\n\n#### Node2Vec\nNode2Vec\n\n**Hyperparameters:**\n- $p$: Return parameter\n- $q$: In-out parameter \n\n## 3.3 Embedding Entire Graph\n### Approach 1\nSum/mean $z_G = \\sum_{v \\in G} z_v$  \n[Embedding Entire Graph](https://arxiv.org/pdf/1509.09292)\n\n### Approach 2\nVirtual node  \n[Virtual Node Paper](https://arxiv.org/pdf/1511.05493)\n\n### Approach 3\nAnonymous walk:\n#### Sampling Anonymous walks\nDistribution have error less than $\\epsilon$ with probability, less than $\\delta$  \n$m = f(\\epsilon, \\sigma, \\delta)$\n\n#### Walk Embedding\n$\\Delta$\n\n# 4 Node Embedding using Random walk - PageRank\n## 4.1 Intro\nPageRank: $r_v = \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$  \n$d_u$: degree of node $u$  \n$A_{u,v}$: adjacency matrix  \n$r_v$: rank of node $v$  \n$N_R(v)$: neighbors of node $v$\n\n## 4.2 PageRank for Graph\n$r_v = \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$  \n$d_u$: degree of node $u$  \n$A_{u,v}$: adjacency matrix  \n$r_v$: rank of node $v$  \n$N_R(v)$: neighbors of node $v$\n\n## \n$r_v = \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$\n\n## \n- Personalized PageRank (Topic specific PageRank)  \n  Rank proximity of nodes to the teleport nodes $S$,  \n  Proximity on graphs: \n- PageRank with restarts:\n\n### Matrix Factorization\nFrobenius norm: $\\min_z ||A - Z^\\top Z||$  \n<img src=\"2024-05-19-CS224W-notes/image.png\" alt=\"Alt text\" width=\"400\" >\n\n# 5 Message passing & Node Classification\nClassical methods\n\n**Correlation:** nearby nodes have the same color  \n$A_{n \\times n}$: Adjacency matrix  \n$Y = \\{0, 1\\}^n$\n\n## Collective Classification:\n1. Local classifier \n2. Relational Classifier \n3. Collective Inference  \n   $1^{st}$ order Markov assumption: $P(Y_v) = P(Y_v | N_v)$\n\n- Relational classification\n- Iterative classification \n- Belief propagation\n\n# 6 GNN Model \n\n# 7 GNN Design Space\n\n# 8 Training GNN \n## 8.1 Data augmentation\n### Feature based \n### Structure based\n\n## 8.2 \n\n## 8.3 \n![alt text](2024-05-19-CS224W-notes/image-1.png)\n\n**Node Prediction**  \n- Transductive setting\n- Inductive setting \n\n**Training**  \nValidation (tuning hyperparameters)  \nTest set\n\n**Graph Prediction**  \n- Link Prediction -->\n\n# 9 Theory of GNN\nGCN, GAT, GraphSAGE, design space \n\n## 9.1\n\n## 9.2\nGCN Mean pooling fails  \nGraphSAGE mean-pool \n\nInjective Multiset function: $\\Phi(\\cdot)$: a non-linear function:  \n$\\Phi(\\sum_{x \\in S} f(x))$:  \nMulti-layer Perceptron  \n**Theorem:** Universal approximation theorem  \nA neural network can model any injective multiset function:  \n$MLP_{\\Phi}(\\sum_{x \\in S} MLP_{f}(x))$\n\n**Graph Isomorphism Network (GIN) Xue 2019** \n\n**WL Graph Kernel**  \nHash  \n$$\n\\left( c^{(k)}(v), \\{ c^{(k)}(u) \\}_{u \\in N(v)} \\right) \n$$\n\n$$\n\\text{MLP}_{\\Phi} \\left( (1 + \\epsilon) \\cdot \\text{MLP}_{f}(c^{(k)}(v)) + \\sum_{u \\in N(v)} \\text{MLP}_{f}(c^{(k)}(u)) \\right) \n$$\n\nwhere $\\epsilon$ is a learnable scalar\n\n$$\nc^{(k+1)}(v) = \\text{HASH} \\left( c^{(k)}(v), \\{ c^{(k)}(u) \\}_{u \\in N(v)} \\right)\n$$\n\n$$\n\\text{GINConv} \\left( c^{(k)}(v), \\{ c^{(k)}(u) \\}_{u \\in N(v)} \\right) = \\text{MLP}_{\\Phi} \\left( (1 + \\epsilon) \\cdot c^{(k)}(v) + \\sum_{u \\in N(v)} c^{(k)}(u) \\right)\n$$\n\n# 10 Heterogeneous Graphs and Knowledge Graph Embeddings\n## 10.1\n### Heterogeneous Graphs \n$G=(V, E, R, T)$\n\n## RGCN\n\n# VGAE\n讲的比较好的GAE和VGAE\n1. [AtYun Article](https://www.atyun.com/17976.html)\n2. [Spaces Article](https://spaces.ac.cn/archives/5253#%E7%BB%88%E7%82%B9%E7%AB%99)\n3. [CSDN Blog](https://blog.csdn.net/qq_16763983/article/details/120403055?spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-120403055-blog-119531815.235%5Ev43%5Epc_blog_bottom_relevance_base8&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-120403055-blog-119531815.235%5Ev43%5Epc_blog_bottom_relevance_base8&utm_relevant_index=13)\n\n### CNN code\n1. CNN 网络结构与部分 PyTorch: [CNBlogs 1](https://www.cnblogs.com/wpx123/p/17616156.html), [CNBlogs 2](https://www.cnblogs.com/wpx123/p/17621303.html)\n\n#### Optimizer：\nSGD, GD, Adam 都是 Optimizer 的种类\n1. [PyTorch 源代码解读](https://zhuanlan.zhihu.com/p/346205754), 以及各种参数 lr, gamma 的影响\n2. [简单讲解了 SGD， Adam 的原理](https://blog.csdn.net/xian0710830114/article/details/126551268)\n\n### 一个比较有用的 Casual Inference 综述的博客：\n[Casual Inference 综述](https://www.cnblogs.com/caoyusang/p/13518354.html)\n","source":"_posts/2024-05-19-CS224W-notes.md","raw":"---\ntitle: CS224W_notes\ndate: 2024-05-19 13:01:34\ntags: \nmathjax: true\n--- \n\n# 1 Introduction，Machine learning for graphs\n## 大纲\n大纲\n1. Traditional methods: Graphlets, Graph Kernels\n2. Methods for node embeddings: DeepWalk, Node2Vec\n3. Graph Neural Networks: GCN, GraphSAGE, GAT, Theory of GNNs\n4. Knowledge graphs and reasoning: TransE, BetaE\n5. Deep generative models for graphs\n6. Applications to Biomedicine, Science, Industry \n\n## Defs\n0. $G=(V, E, F)$ or $G(V, E)$\n1. Directed/ undirected\n2. Degree  \n   Directed $\\bar{k} = \\langle k \\rangle = \\frac{1}{N} \\sum_{i=1}^{N} k_i = \\frac{2E}{N}$  \n   Undirected in-degree + out-degree = (total) degree, $\\bar{k}= \\frac{E}{N}$ \n3. Bipartite Graph\n4. Folded/Projected Bipartite graph\n5. Representing graphs: Adjacency matrix Density of matrix $\\frac{E}{N^2}$\n   1. adjacency matrix\n   2. Edge List\n   3. Adjacency List\n6. Attribute of edges\n7. Weighted/Unweighted\n8. Self-edges\n9. Connectivity: (Un)Directed, Strong Connected Components (in Undirected)\n\n# 2 Traditional methods for ML on graph \nStructural Feature/ Node features  \nTrain on Random Forest, SVM, Neural Network; Apply on new graph. \n\n## Node\n### (1) Node Centrality\n233\n1. Eigenvector centrality: $c_v=\\frac{1}{\\lambda}\\sum_{u\\in N(v)}$\n2. Betweenness centrality  \nHere is the improved version of the formulas in the format you provided, while keeping the same style and explanation:\n\n---\n\n1. **Betweenness Centrality**  \n   Betweenness centrality \\( c_v \\) measures the extent to which a node \\( v \\) lies on the shortest paths between other nodes.  \n\n   $$\n   c_v = \\sum_{s \\neq v \\neq t} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}\n   $$\n\n   - \\( \\sigma_{st} \\): The number of shortest paths between nodes \\( s \\) and \\( t \\).  \n   - \\( \\sigma_{st}(v) \\): The number of shortest paths between \\( s \\) and \\( t \\) that pass through \\( v \\).\n\n---\n\n2. **Closeness Centrality**  \n   Closeness centrality \\( c_v \\) quantifies how close a node \\( v \\) is to all other nodes in the network.  \n\n   $$\n   c_v = \\frac{1}{\\sum_{u \\neq v} d(u, v)}\n   $$\n\n   - \\( d(u, v) \\): The shortest path length between node \\( u \\) and node \\( v \\).\n\n\n\n### (2) Clustering Coefficient \n\\[\ne_v = \\frac{\\text{Number of edges between neighbors of } v}{\\binom{k_v}{2}}, \\quad \\binom{k_v}{2} = \\frac{k_v (k_v - 1)}{2}\n\\] \n\n### (3) Graphlet: Rooted connected non-isomorphic subgraphs  \nGraphlet degree vector  \nClustering coefficient.\nFeature-based/ structure-based features.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Link\n### (1) Link prediction\n1. Links missing at random: Remove a random set of links and then aim to predict them\n2. Links over time: Given $G[t_0, t_0']$ a graph on edges up to time $t_0'$, output a ranked list $L$ of links (not in $G[t_0, t_0']$) that are predicted to appear in $G[t_1, t_1']$\n\n### (2) Local Neighborhood Overlap\n- Common neighbors: $|N(v_1) \\cap N(v_2)|$\n- Jaccard's coefficient: $\\frac{|N(v_1) \\cap N(v_2)|}{|N(v_1) \\cup N(v_2)|}$,  \n  Normalize common neighbor, assuming having the same number of neighbors\n- Adamic-Adar index: $\\sum_{u \\in N(v_1) \\cap N(v_2)} \\frac{1}{\\log k_u}$,  \n  Penalize those who have many neighbors\n\n### (3) Global Neighborhood Overlap \n- Katz index: $S_{uv}= \\sum_{l=1}^{\\infty} \\beta^l A^l_{uv}$,  \n  $A^l_{uv}$: number of paths of length $l$ between $u$ and $v$,  \n  $\\beta$: discount factor, the contribution of long paths  \n- Katz index matrix: $S= \\sum_{i=1}^\\infty \\beta^iA^i = (I-\\beta A)^{-1}-I$ \n\n## Graph  \n### Kernel method:\n1. **Kernel function**:  \n   $K(G, G')$ measures the similarity between two graphs $G$ and $G'$.  \n   Maps the graphs into a higher-dimensional space where linear methods can be applied to perform complex, non-linear tasks in the original space.\n   \n2. **Kernel Matrix**: $\\mathbf{K} = \\left( K(G, G') \\right)_{G, G'}$ is a symmetric matrix.  \n   It is positive semidefinite, meaning all its eigenvalues are non-negative.\n   \n3. **Feature Representation**:  \n   Feature mapping $\\phi(\\cdot)$ kernel function is expressed as dot product in feature space: $K(G, G') = \\phi(G)^\\top \\phi(G')$.\n   \ncite: [CSDN Blog](https://blog.csdn.net/PolarisRisingWar/article/details/115598815)\n\n### Design graph feature vector $\\phi(G)$\n**Bag-of-Words: BoW**  \nKey idea: use the word counts as features (#nodes as features, #degree, #graphlet, #color)\n\n### Graphlet features\nKey idea: Count the number of different graphlets in a graph.  \n$G_k=(g_1, g_2, \\cdots, g_{n_k})$\n\nGraphlet count vector $(f_G)=\\#(g_i \\subseteq G), \\; i \\leq n_k$\n\n$h_G= \\frac{f_G}{\\text{Sum}(F_G)}$,  \n$K(G, G')=H_G^\\top H_G'$\n\nNP-hard $O(nd^{k-1})$, expensive to calculate \n\n### Weisfeiler-Lehman Kernel\n[Weisfeiler-Lehman Kernel Blog](https://blog.csdn.net/PolarisRisingWar/article/details/117336622)\n\n# 3 Node Embedding\n## 3.1 Intro\nKey: How to define node similarity  \n\n\n<!-- Avoid direct Feature Engineering, and also reflect structural features -->\n### Encoder\nFeature representation ↔ feature embedding  \n<!-- If two nodes are similar in structure, they should be similar in embedding space -->\n<!-- Use dot product to measure similarity -->\nSimilarity $(u, v) \\approx z_u^T z_v$,  \n$ENC(u) = z_u$, $ENC(v) = z_v$, <!--ENC: Encoder-->  \n$z_u, z_v$ are $d$-dimensional in embedding space, $d$ usually 64-1000  \n$ENC(v)$ node in the input graph\n\n$ENC(v) = z_v = Z \\cdot v$  \nEncoder is a lookup, embedding matrix $Z \\in \\mathbb{R}^{d \\times |V|}$, $v \\in I^{|V|}$\n\n#### ENC\nShallow encoder: $d \\times |V|$  \nSome ways for ENC: DeepWalk, Node2Vec\n\n## 3.2 Random walk for Node Embedding\n### Notation\n- Vector $z_u$: embedding vector of node $u$ (what we aim to find)\n- $P(v|z_u)$: probability of visiting node $v$ on random walk starting from $u$. Used to measure similarity. \n- Softmax: $\\sigma(z)_i = \\frac{e^{z_i}}{\\sum e^{z_j}}$\n- Sigmoid: $S(x) = \\frac{1}{1 + e^{-x}}$\n\n### Random walk embedding\nUsing random strategy $R$: $P_R(u|v)$  \nGiven  \n$G=(V, E)$  \nGoal: Learn a mapping $f: u \\rightarrow \\mathbb{R}^d$  \n$$\n\\mathcal{L} = \\sum_{u \\in V} \\sum_{v \\in N_R(u)} -\\log\\left(\\frac{\\exp(z_u^\\top z_v)}{\\sum_{n \\in V} \\exp(z_u^\\top z_n)}\\right)\n$$  \n**Negative sampling**  \n$$\n\\log\\left(\\frac{\\exp(z_u^\\top z_v)}{\\sum_{n \\in V} \\exp(z_u^\\top z_n)}\\right) \\approx \\log\\left(\\sigma(z_u^\\top z_v)\\right) - \\sum_{i=1}^{k} \\log\\left(\\sigma(z_u^\\top z_{n_i})\\right), \\quad n_i \\sim P_V\n$$ -->\n\n### Random walk strategy \n#### DeepWalk\n[DeepWalk Paper](https://www.vldb.org/pvldb/vol10/p13-wu.pdf)\n\n#### Node2Vec\nNode2Vec\n\n**Hyperparameters:**\n- $p$: Return parameter\n- $q$: In-out parameter \n\n## 3.3 Embedding Entire Graph\n### Approach 1\nSum/mean $z_G = \\sum_{v \\in G} z_v$  \n[Embedding Entire Graph](https://arxiv.org/pdf/1509.09292)\n\n### Approach 2\nVirtual node  \n[Virtual Node Paper](https://arxiv.org/pdf/1511.05493)\n\n### Approach 3\nAnonymous walk:\n#### Sampling Anonymous walks\nDistribution have error less than $\\epsilon$ with probability, less than $\\delta$  \n$m = f(\\epsilon, \\sigma, \\delta)$\n\n#### Walk Embedding\n$\\Delta$\n\n# 4 Node Embedding using Random walk - PageRank\n## 4.1 Intro\nPageRank: $r_v = \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$  \n$d_u$: degree of node $u$  \n$A_{u,v}$: adjacency matrix  \n$r_v$: rank of node $v$  \n$N_R(v)$: neighbors of node $v$\n\n## 4.2 PageRank for Graph\n$r_v = \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$  \n$d_u$: degree of node $u$  \n$A_{u,v}$: adjacency matrix  \n$r_v$: rank of node $v$  \n$N_R(v)$: neighbors of node $v$\n\n## \n$r_v = \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$\n\n## \n- Personalized PageRank (Topic specific PageRank)  \n  Rank proximity of nodes to the teleport nodes $S$,  \n  Proximity on graphs: \n- PageRank with restarts:\n\n### Matrix Factorization\nFrobenius norm: $\\min_z ||A - Z^\\top Z||$  \n<img src=\"2024-05-19-CS224W-notes/image.png\" alt=\"Alt text\" width=\"400\" >\n\n# 5 Message passing & Node Classification\nClassical methods\n\n**Correlation:** nearby nodes have the same color  \n$A_{n \\times n}$: Adjacency matrix  \n$Y = \\{0, 1\\}^n$\n\n## Collective Classification:\n1. Local classifier \n2. Relational Classifier \n3. Collective Inference  \n   $1^{st}$ order Markov assumption: $P(Y_v) = P(Y_v | N_v)$\n\n- Relational classification\n- Iterative classification \n- Belief propagation\n\n# 6 GNN Model \n\n# 7 GNN Design Space\n\n# 8 Training GNN \n## 8.1 Data augmentation\n### Feature based \n### Structure based\n\n## 8.2 \n\n## 8.3 \n![alt text](2024-05-19-CS224W-notes/image-1.png)\n\n**Node Prediction**  \n- Transductive setting\n- Inductive setting \n\n**Training**  \nValidation (tuning hyperparameters)  \nTest set\n\n**Graph Prediction**  \n- Link Prediction -->\n\n# 9 Theory of GNN\nGCN, GAT, GraphSAGE, design space \n\n## 9.1\n\n## 9.2\nGCN Mean pooling fails  \nGraphSAGE mean-pool \n\nInjective Multiset function: $\\Phi(\\cdot)$: a non-linear function:  \n$\\Phi(\\sum_{x \\in S} f(x))$:  \nMulti-layer Perceptron  \n**Theorem:** Universal approximation theorem  \nA neural network can model any injective multiset function:  \n$MLP_{\\Phi}(\\sum_{x \\in S} MLP_{f}(x))$\n\n**Graph Isomorphism Network (GIN) Xue 2019** \n\n**WL Graph Kernel**  \nHash  \n$$\n\\left( c^{(k)}(v), \\{ c^{(k)}(u) \\}_{u \\in N(v)} \\right) \n$$\n\n$$\n\\text{MLP}_{\\Phi} \\left( (1 + \\epsilon) \\cdot \\text{MLP}_{f}(c^{(k)}(v)) + \\sum_{u \\in N(v)} \\text{MLP}_{f}(c^{(k)}(u)) \\right) \n$$\n\nwhere $\\epsilon$ is a learnable scalar\n\n$$\nc^{(k+1)}(v) = \\text{HASH} \\left( c^{(k)}(v), \\{ c^{(k)}(u) \\}_{u \\in N(v)} \\right)\n$$\n\n$$\n\\text{GINConv} \\left( c^{(k)}(v), \\{ c^{(k)}(u) \\}_{u \\in N(v)} \\right) = \\text{MLP}_{\\Phi} \\left( (1 + \\epsilon) \\cdot c^{(k)}(v) + \\sum_{u \\in N(v)} c^{(k)}(u) \\right)\n$$\n\n# 10 Heterogeneous Graphs and Knowledge Graph Embeddings\n## 10.1\n### Heterogeneous Graphs \n$G=(V, E, R, T)$\n\n## RGCN\n\n# VGAE\n讲的比较好的GAE和VGAE\n1. [AtYun Article](https://www.atyun.com/17976.html)\n2. [Spaces Article](https://spaces.ac.cn/archives/5253#%E7%BB%88%E7%82%B9%E7%AB%99)\n3. [CSDN Blog](https://blog.csdn.net/qq_16763983/article/details/120403055?spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-120403055-blog-119531815.235%5Ev43%5Epc_blog_bottom_relevance_base8&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-7-120403055-blog-119531815.235%5Ev43%5Epc_blog_bottom_relevance_base8&utm_relevant_index=13)\n\n### CNN code\n1. CNN 网络结构与部分 PyTorch: [CNBlogs 1](https://www.cnblogs.com/wpx123/p/17616156.html), [CNBlogs 2](https://www.cnblogs.com/wpx123/p/17621303.html)\n\n#### Optimizer：\nSGD, GD, Adam 都是 Optimizer 的种类\n1. [PyTorch 源代码解读](https://zhuanlan.zhihu.com/p/346205754), 以及各种参数 lr, gamma 的影响\n2. [简单讲解了 SGD， Adam 的原理](https://blog.csdn.net/xian0710830114/article/details/126551268)\n\n### 一个比较有用的 Casual Inference 综述的博客：\n[Casual Inference 综述](https://www.cnblogs.com/caoyusang/p/13518354.html)\n","slug":"2024-05-19-CS224W-notes","published":1,"updated":"2024-12-15T04:16:27.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagps000yzc3d7hmqckbt","content":"<h1 id=\"1-Introduction，Machine-learning-for-graphs\"><a href=\"#1-Introduction，Machine-learning-for-graphs\" class=\"headerlink\" title=\"1 Introduction，Machine learning for graphs\"></a>1 Introduction，Machine learning for graphs</h1><h2 id=\"大纲\"><a href=\"#大纲\" class=\"headerlink\" title=\"大纲\"></a>大纲</h2><p>大纲</p>\n<ol>\n<li>Traditional methods: Graphlets, Graph Kernels</li>\n<li>Methods for node embeddings: DeepWalk, Node2Vec</li>\n<li>Graph Neural Networks: GCN, GraphSAGE, GAT, Theory of GNNs</li>\n<li>Knowledge graphs and reasoning: TransE, BetaE</li>\n<li>Deep generative models for graphs</li>\n<li>Applications to Biomedicine, Science, Industry</li>\n</ol>\n<h2 id=\"Defs\"><a href=\"#Defs\" class=\"headerlink\" title=\"Defs\"></a>Defs</h2><ol start=\"0\">\n<li>$G&#x3D;(V, E, F)$ or $G(V, E)$</li>\n<li>Directed&#x2F; undirected</li>\n<li>Degree<br>Directed $\\bar{k} &#x3D; \\langle k \\rangle &#x3D; \\frac{1}{N} \\sum_{i&#x3D;1}^{N} k_i &#x3D; \\frac{2E}{N}$<br>Undirected in-degree + out-degree &#x3D; (total) degree, $\\bar{k}&#x3D; \\frac{E}{N}$ </li>\n<li>Bipartite Graph</li>\n<li>Folded&#x2F;Projected Bipartite graph</li>\n<li>Representing graphs: Adjacency matrix Density of matrix $\\frac{E}{N^2}$<ol>\n<li>adjacency matrix</li>\n<li>Edge List</li>\n<li>Adjacency List</li>\n</ol>\n</li>\n<li>Attribute of edges</li>\n<li>Weighted&#x2F;Unweighted</li>\n<li>Self-edges</li>\n<li>Connectivity: (Un)Directed, Strong Connected Components (in Undirected)</li>\n</ol>\n<h1 id=\"2-Traditional-methods-for-ML-on-graph\"><a href=\"#2-Traditional-methods-for-ML-on-graph\" class=\"headerlink\" title=\"2 Traditional methods for ML on graph\"></a>2 Traditional methods for ML on graph</h1><p>Structural Feature&#x2F; Node features<br>Train on Random Forest, SVM, Neural Network; Apply on new graph. </p>\n<h2 id=\"Node\"><a href=\"#Node\" class=\"headerlink\" title=\"Node\"></a>Node</h2><h3 id=\"1-Node-Centrality\"><a href=\"#1-Node-Centrality\" class=\"headerlink\" title=\"(1) Node Centrality\"></a>(1) Node Centrality</h3><p>233</p>\n<ol>\n<li>Eigenvector centrality: $c_v&#x3D;\\frac{1}{\\lambda}\\sum_{u\\in N(v)}$</li>\n<li>Betweenness centrality<br>Here is the improved version of the formulas in the format you provided, while keeping the same style and explanation:</li>\n</ol>\n<hr>\n<ol>\n<li><p><strong>Betweenness Centrality</strong><br>Betweenness centrality ( c_v ) measures the extent to which a node ( v ) lies on the shortest paths between other nodes.  </p>\n<p>$$<br>c_v &#x3D; \\sum_{s \\neq v \\neq t} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}<br>$$</p>\n<ul>\n<li>( \\sigma_{st} ): The number of shortest paths between nodes ( s ) and ( t ).  </li>\n<li>( \\sigma_{st}(v) ): The number of shortest paths between ( s ) and ( t ) that pass through ( v ).</li>\n</ul>\n</li>\n</ol>\n<hr>\n<ol start=\"2\">\n<li><p><strong>Closeness Centrality</strong><br>Closeness centrality ( c_v ) quantifies how close a node ( v ) is to all other nodes in the network.  </p>\n<p>$$<br>c_v &#x3D; \\frac{1}{\\sum_{u \\neq v} d(u, v)}<br>$$</p>\n<ul>\n<li>( d(u, v) ): The shortest path length between node ( u ) and node ( v ).</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"2-Clustering-Coefficient\"><a href=\"#2-Clustering-Coefficient\" class=\"headerlink\" title=\"(2) Clustering Coefficient\"></a>(2) Clustering Coefficient</h3><p>[<br>e_v &#x3D; \\frac{\\text{Number of edges between neighbors of } v}{\\binom{k_v}{2}}, \\quad \\binom{k_v}{2} &#x3D; \\frac{k_v (k_v - 1)}{2}<br>] </p>\n<h3 id=\"3-Graphlet-Rooted-connected-non-isomorphic-subgraphs\"><a href=\"#3-Graphlet-Rooted-connected-non-isomorphic-subgraphs\" class=\"headerlink\" title=\"(3) Graphlet: Rooted connected non-isomorphic subgraphs\"></a>(3) Graphlet: Rooted connected non-isomorphic subgraphs</h3><p>Graphlet degree vector<br>Clustering coefficient.<br>Feature-based&#x2F; structure-based features.</p>\n<h2 id=\"Link\"><a href=\"#Link\" class=\"headerlink\" title=\"Link\"></a>Link</h2><h3 id=\"1-Link-prediction\"><a href=\"#1-Link-prediction\" class=\"headerlink\" title=\"(1) Link prediction\"></a>(1) Link prediction</h3><ol>\n<li>Links missing at random: Remove a random set of links and then aim to predict them</li>\n<li>Links over time: Given $G[t_0, t_0’]$ a graph on edges up to time $t_0’$, output a ranked list $L$ of links (not in $G[t_0, t_0’]$) that are predicted to appear in $G[t_1, t_1’]$</li>\n</ol>\n<h3 id=\"2-Local-Neighborhood-Overlap\"><a href=\"#2-Local-Neighborhood-Overlap\" class=\"headerlink\" title=\"(2) Local Neighborhood Overlap\"></a>(2) Local Neighborhood Overlap</h3><ul>\n<li>Common neighbors: $|N(v_1) \\cap N(v_2)|$</li>\n<li>Jaccard’s coefficient: $\\frac{|N(v_1) \\cap N(v_2)|}{|N(v_1) \\cup N(v_2)|}$,<br>Normalize common neighbor, assuming having the same number of neighbors</li>\n<li>Adamic-Adar index: $\\sum_{u \\in N(v_1) \\cap N(v_2)} \\frac{1}{\\log k_u}$,<br>Penalize those who have many neighbors</li>\n</ul>\n<h3 id=\"3-Global-Neighborhood-Overlap\"><a href=\"#3-Global-Neighborhood-Overlap\" class=\"headerlink\" title=\"(3) Global Neighborhood Overlap\"></a>(3) Global Neighborhood Overlap</h3><ul>\n<li>Katz index: $S_{uv}&#x3D; \\sum_{l&#x3D;1}^{\\infty} \\beta^l A^l_{uv}$,<br>$A^l_{uv}$: number of paths of length $l$ between $u$ and $v$,<br>$\\beta$: discount factor, the contribution of long paths  </li>\n<li>Katz index matrix: $S&#x3D; \\sum_{i&#x3D;1}^\\infty \\beta^iA^i &#x3D; (I-\\beta A)^{-1}-I$</li>\n</ul>\n<h2 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h2><h3 id=\"Kernel-method\"><a href=\"#Kernel-method\" class=\"headerlink\" title=\"Kernel method:\"></a>Kernel method:</h3><ol>\n<li><p><strong>Kernel function</strong>:<br>$K(G, G’)$ measures the similarity between two graphs $G$ and $G’$.<br>Maps the graphs into a higher-dimensional space where linear methods can be applied to perform complex, non-linear tasks in the original space.</p>\n</li>\n<li><p><strong>Kernel Matrix</strong>: $\\mathbf{K} &#x3D; \\left( K(G, G’) \\right)_{G, G’}$ is a symmetric matrix.<br>It is positive semidefinite, meaning all its eigenvalues are non-negative.</p>\n</li>\n<li><p><strong>Feature Representation</strong>:<br>Feature mapping $\\phi(\\cdot)$ kernel function is expressed as dot product in feature space: $K(G, G’) &#x3D; \\phi(G)^\\top \\phi(G’)$.</p>\n</li>\n</ol>\n<p>cite: <a href=\"https://blog.csdn.net/PolarisRisingWar/article/details/115598815\">CSDN Blog</a></p>\n<h3 id=\"Design-graph-feature-vector-phi-G\"><a href=\"#Design-graph-feature-vector-phi-G\" class=\"headerlink\" title=\"Design graph feature vector $\\phi(G)$\"></a>Design graph feature vector $\\phi(G)$</h3><p><strong>Bag-of-Words: BoW</strong><br>Key idea: use the word counts as features (#nodes as features, #degree, #graphlet, #color)</p>\n<h3 id=\"Graphlet-features\"><a href=\"#Graphlet-features\" class=\"headerlink\" title=\"Graphlet features\"></a>Graphlet features</h3><p>Key idea: Count the number of different graphlets in a graph.<br>$G_k&#x3D;(g_1, g_2, \\cdots, g_{n_k})$</p>\n<p>Graphlet count vector $(f_G)&#x3D;#(g_i \\subseteq G), ; i \\leq n_k$</p>\n<p>$h_G&#x3D; \\frac{f_G}{\\text{Sum}(F_G)}$,<br>$K(G, G’)&#x3D;H_G^\\top H_G’$</p>\n<p>NP-hard $O(nd^{k-1})$, expensive to calculate </p>\n<h3 id=\"Weisfeiler-Lehman-Kernel\"><a href=\"#Weisfeiler-Lehman-Kernel\" class=\"headerlink\" title=\"Weisfeiler-Lehman Kernel\"></a>Weisfeiler-Lehman Kernel</h3><p><a href=\"https://blog.csdn.net/PolarisRisingWar/article/details/117336622\">Weisfeiler-Lehman Kernel Blog</a></p>\n<h1 id=\"3-Node-Embedding\"><a href=\"#3-Node-Embedding\" class=\"headerlink\" title=\"3 Node Embedding\"></a>3 Node Embedding</h1><h2 id=\"3-1-Intro\"><a href=\"#3-1-Intro\" class=\"headerlink\" title=\"3.1 Intro\"></a>3.1 Intro</h2><p>Key: How to define node similarity  </p>\n<!-- Avoid direct Feature Engineering, and also reflect structural features -->\n<h3 id=\"Encoder\"><a href=\"#Encoder\" class=\"headerlink\" title=\"Encoder\"></a>Encoder</h3><p>Feature representation ↔ feature embedding  </p>\n<!-- If two nodes are similar in structure, they should be similar in embedding space -->\n<!-- Use dot product to measure similarity -->\n<p>Similarity $(u, v) \\approx z_u^T z_v$,<br>$ENC(u) &#x3D; z_u$, $ENC(v) &#x3D; z_v$, <!--ENC: Encoder--><br>$z_u, z_v$ are $d$-dimensional in embedding space, $d$ usually 64-1000<br>$ENC(v)$ node in the input graph</p>\n<p>$ENC(v) &#x3D; z_v &#x3D; Z \\cdot v$<br>Encoder is a lookup, embedding matrix $Z \\in \\mathbb{R}^{d \\times |V|}$, $v \\in I^{|V|}$</p>\n<h4 id=\"ENC\"><a href=\"#ENC\" class=\"headerlink\" title=\"ENC\"></a>ENC</h4><p>Shallow encoder: $d \\times |V|$<br>Some ways for ENC: DeepWalk, Node2Vec</p>\n<h2 id=\"3-2-Random-walk-for-Node-Embedding\"><a href=\"#3-2-Random-walk-for-Node-Embedding\" class=\"headerlink\" title=\"3.2 Random walk for Node Embedding\"></a>3.2 Random walk for Node Embedding</h2><h3 id=\"Notation\"><a href=\"#Notation\" class=\"headerlink\" title=\"Notation\"></a>Notation</h3><ul>\n<li>Vector $z_u$: embedding vector of node $u$ (what we aim to find)</li>\n<li>$P(v|z_u)$: probability of visiting node $v$ on random walk starting from $u$. Used to measure similarity. </li>\n<li>Softmax: $\\sigma(z)_i &#x3D; \\frac{e^{z_i}}{\\sum e^{z_j}}$</li>\n<li>Sigmoid: $S(x) &#x3D; \\frac{1}{1 + e^{-x}}$</li>\n</ul>\n<h3 id=\"Random-walk-embedding\"><a href=\"#Random-walk-embedding\" class=\"headerlink\" title=\"Random walk embedding\"></a>Random walk embedding</h3><p>Using random strategy $R$: $P_R(u|v)$<br>Given<br>$G&#x3D;(V, E)$<br>Goal: Learn a mapping $f: u \\rightarrow \\mathbb{R}^d$<br>$$<br>\\mathcal{L} &#x3D; \\sum_{u \\in V} \\sum_{v \\in N_R(u)} -\\log\\left(\\frac{\\exp(z_u^\\top z_v)}{\\sum_{n \\in V} \\exp(z_u^\\top z_n)}\\right)<br>$$<br><strong>Negative sampling</strong><br>$$<br>\\log\\left(\\frac{\\exp(z_u^\\top z_v)}{\\sum_{n \\in V} \\exp(z_u^\\top z_n)}\\right) \\approx \\log\\left(\\sigma(z_u^\\top z_v)\\right) - \\sum_{i&#x3D;1}^{k} \\log\\left(\\sigma(z_u^\\top z_{n_i})\\right), \\quad n_i \\sim P_V<br>$$ –&gt;</p>\n<h3 id=\"Random-walk-strategy\"><a href=\"#Random-walk-strategy\" class=\"headerlink\" title=\"Random walk strategy\"></a>Random walk strategy</h3><h4 id=\"DeepWalk\"><a href=\"#DeepWalk\" class=\"headerlink\" title=\"DeepWalk\"></a>DeepWalk</h4><p><a href=\"https://www.vldb.org/pvldb/vol10/p13-wu.pdf\">DeepWalk Paper</a></p>\n<h4 id=\"Node2Vec\"><a href=\"#Node2Vec\" class=\"headerlink\" title=\"Node2Vec\"></a>Node2Vec</h4><p>Node2Vec</p>\n<p><strong>Hyperparameters:</strong></p>\n<ul>\n<li>$p$: Return parameter</li>\n<li>$q$: In-out parameter</li>\n</ul>\n<h2 id=\"3-3-Embedding-Entire-Graph\"><a href=\"#3-3-Embedding-Entire-Graph\" class=\"headerlink\" title=\"3.3 Embedding Entire Graph\"></a>3.3 Embedding Entire Graph</h2><h3 id=\"Approach-1\"><a href=\"#Approach-1\" class=\"headerlink\" title=\"Approach 1\"></a>Approach 1</h3><p>Sum&#x2F;mean $z_G &#x3D; \\sum_{v \\in G} z_v$<br><a href=\"https://arxiv.org/pdf/1509.09292\">Embedding Entire Graph</a></p>\n<h3 id=\"Approach-2\"><a href=\"#Approach-2\" class=\"headerlink\" title=\"Approach 2\"></a>Approach 2</h3><p>Virtual node<br><a href=\"https://arxiv.org/pdf/1511.05493\">Virtual Node Paper</a></p>\n<h3 id=\"Approach-3\"><a href=\"#Approach-3\" class=\"headerlink\" title=\"Approach 3\"></a>Approach 3</h3><p>Anonymous walk:</p>\n<h4 id=\"Sampling-Anonymous-walks\"><a href=\"#Sampling-Anonymous-walks\" class=\"headerlink\" title=\"Sampling Anonymous walks\"></a>Sampling Anonymous walks</h4><p>Distribution have error less than $\\epsilon$ with probability, less than $\\delta$<br>$m &#x3D; f(\\epsilon, \\sigma, \\delta)$</p>\n<h4 id=\"Walk-Embedding\"><a href=\"#Walk-Embedding\" class=\"headerlink\" title=\"Walk Embedding\"></a>Walk Embedding</h4><p>$\\Delta$</p>\n<h1 id=\"4-Node-Embedding-using-Random-walk-PageRank\"><a href=\"#4-Node-Embedding-using-Random-walk-PageRank\" class=\"headerlink\" title=\"4 Node Embedding using Random walk - PageRank\"></a>4 Node Embedding using Random walk - PageRank</h1><h2 id=\"4-1-Intro\"><a href=\"#4-1-Intro\" class=\"headerlink\" title=\"4.1 Intro\"></a>4.1 Intro</h2><p>PageRank: $r_v &#x3D; \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$<br>$d_u$: degree of node $u$<br>$A_{u,v}$: adjacency matrix<br>$r_v$: rank of node $v$<br>$N_R(v)$: neighbors of node $v$</p>\n<h2 id=\"4-2-PageRank-for-Graph\"><a href=\"#4-2-PageRank-for-Graph\" class=\"headerlink\" title=\"4.2 PageRank for Graph\"></a>4.2 PageRank for Graph</h2><p>$r_v &#x3D; \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$<br>$d_u$: degree of node $u$<br>$A_{u,v}$: adjacency matrix<br>$r_v$: rank of node $v$<br>$N_R(v)$: neighbors of node $v$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$r_v &#x3D; \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$</p>\n<h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>Personalized PageRank (Topic specific PageRank)<br>Rank proximity of nodes to the teleport nodes $S$,<br>Proximity on graphs: </li>\n<li>PageRank with restarts:</li>\n</ul>\n<h3 id=\"Matrix-Factorization\"><a href=\"#Matrix-Factorization\" class=\"headerlink\" title=\"Matrix Factorization\"></a>Matrix Factorization</h3><p>Frobenius norm: $\\min_z ||A - Z^\\top Z||$<br><img src=\"2024-05-19-CS224W-notes/image.png\" alt=\"Alt text\" width=\"400\" ></p>\n<h1 id=\"5-Message-passing-Node-Classification\"><a href=\"#5-Message-passing-Node-Classification\" class=\"headerlink\" title=\"5 Message passing &amp; Node Classification\"></a>5 Message passing &amp; Node Classification</h1><p>Classical methods</p>\n<p><strong>Correlation:</strong> nearby nodes have the same color<br>$A_{n \\times n}$: Adjacency matrix<br>$Y &#x3D; {0, 1}^n$</p>\n<h2 id=\"Collective-Classification\"><a href=\"#Collective-Classification\" class=\"headerlink\" title=\"Collective Classification:\"></a>Collective Classification:</h2><ol>\n<li>Local classifier </li>\n<li>Relational Classifier </li>\n<li>Collective Inference<br>$1^{st}$ order Markov assumption: $P(Y_v) &#x3D; P(Y_v | N_v)$</li>\n</ol>\n<ul>\n<li>Relational classification</li>\n<li>Iterative classification </li>\n<li>Belief propagation</li>\n</ul>\n<h1 id=\"6-GNN-Model\"><a href=\"#6-GNN-Model\" class=\"headerlink\" title=\"6 GNN Model\"></a>6 GNN Model</h1><h1 id=\"7-GNN-Design-Space\"><a href=\"#7-GNN-Design-Space\" class=\"headerlink\" title=\"7 GNN Design Space\"></a>7 GNN Design Space</h1><h1 id=\"8-Training-GNN\"><a href=\"#8-Training-GNN\" class=\"headerlink\" title=\"8 Training GNN\"></a>8 Training GNN</h1><h2 id=\"8-1-Data-augmentation\"><a href=\"#8-1-Data-augmentation\" class=\"headerlink\" title=\"8.1 Data augmentation\"></a>8.1 Data augmentation</h2><h3 id=\"Feature-based\"><a href=\"#Feature-based\" class=\"headerlink\" title=\"Feature based\"></a>Feature based</h3><h3 id=\"Structure-based\"><a href=\"#Structure-based\" class=\"headerlink\" title=\"Structure based\"></a>Structure based</h3><h2 id=\"8-2\"><a href=\"#8-2\" class=\"headerlink\" title=\"8.2\"></a>8.2</h2><h2 id=\"8-3\"><a href=\"#8-3\" class=\"headerlink\" title=\"8.3\"></a>8.3</h2><p><img src=\"/2024-05-19-CS224W-notes/image-1.png\" alt=\"alt text\"></p>\n<p><strong>Node Prediction</strong>  </p>\n<ul>\n<li>Transductive setting</li>\n<li>Inductive setting</li>\n</ul>\n<p><strong>Training</strong><br>Validation (tuning hyperparameters)<br>Test set</p>\n<p><strong>Graph Prediction</strong>  </p>\n<ul>\n<li>Link Prediction –&gt;</li>\n</ul>\n<h1 id=\"9-Theory-of-GNN\"><a href=\"#9-Theory-of-GNN\" class=\"headerlink\" title=\"9 Theory of GNN\"></a>9 Theory of GNN</h1><p>GCN, GAT, GraphSAGE, design space </p>\n<h2 id=\"9-1\"><a href=\"#9-1\" class=\"headerlink\" title=\"9.1\"></a>9.1</h2><h2 id=\"9-2\"><a href=\"#9-2\" class=\"headerlink\" title=\"9.2\"></a>9.2</h2><p>GCN Mean pooling fails<br>GraphSAGE mean-pool </p>\n<p>Injective Multiset function: $\\Phi(\\cdot)$: a non-linear function:<br>$\\Phi(\\sum_{x \\in S} f(x))$:<br>Multi-layer Perceptron<br><strong>Theorem:</strong> Universal approximation theorem<br>A neural network can model any injective multiset function:<br>$MLP_{\\Phi}(\\sum_{x \\in S} MLP_{f}(x))$</p>\n<p><strong>Graph Isomorphism Network (GIN) Xue 2019</strong> </p>\n<p><strong>WL Graph Kernel</strong><br>Hash<br>$$<br>\\left( c^{(k)}(v), { c^{(k)}(u) }_{u \\in N(v)} \\right)<br>$$</p>\n<p>$$<br>\\text{MLP}<em>{\\Phi} \\left( (1 + \\epsilon) \\cdot \\text{MLP}</em>{f}(c^{(k)}(v)) + \\sum_{u \\in N(v)} \\text{MLP}_{f}(c^{(k)}(u)) \\right)<br>$$</p>\n<p>where $\\epsilon$ is a learnable scalar</p>\n<p>$$<br>c^{(k+1)}(v) &#x3D; \\text{HASH} \\left( c^{(k)}(v), { c^{(k)}(u) }_{u \\in N(v)} \\right)<br>$$</p>\n<p>$$<br>\\text{GINConv} \\left( c^{(k)}(v), { c^{(k)}(u) }<em>{u \\in N(v)} \\right) &#x3D; \\text{MLP}</em>{\\Phi} \\left( (1 + \\epsilon) \\cdot c^{(k)}(v) + \\sum_{u \\in N(v)} c^{(k)}(u) \\right)<br>$$</p>\n<h1 id=\"10-Heterogeneous-Graphs-and-Knowledge-Graph-Embeddings\"><a href=\"#10-Heterogeneous-Graphs-and-Knowledge-Graph-Embeddings\" class=\"headerlink\" title=\"10 Heterogeneous Graphs and Knowledge Graph Embeddings\"></a>10 Heterogeneous Graphs and Knowledge Graph Embeddings</h1><h2 id=\"10-1\"><a href=\"#10-1\" class=\"headerlink\" title=\"10.1\"></a>10.1</h2><h3 id=\"Heterogeneous-Graphs\"><a href=\"#Heterogeneous-Graphs\" class=\"headerlink\" title=\"Heterogeneous Graphs\"></a>Heterogeneous Graphs</h3><p>$G&#x3D;(V, E, R, T)$</p>\n<h2 id=\"RGCN\"><a href=\"#RGCN\" class=\"headerlink\" title=\"RGCN\"></a>RGCN</h2><h1 id=\"VGAE\"><a href=\"#VGAE\" class=\"headerlink\" title=\"VGAE\"></a>VGAE</h1><p>讲的比较好的GAE和VGAE</p>\n<ol>\n<li><a href=\"https://www.atyun.com/17976.html\">AtYun Article</a></li>\n<li><a href=\"https://spaces.ac.cn/archives/5253#%E7%BB%88%E7%82%B9%E7%AB%99\">Spaces Article</a></li>\n<li><a href=\"https://blog.csdn.net/qq_16763983/article/details/120403055?spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7-120403055-blog-119531815.235%5Ev43%5Epc_blog_bottom_relevance_base8&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7-120403055-blog-119531815.235%5Ev43%5Epc_blog_bottom_relevance_base8&utm_relevant_index=13\">CSDN Blog</a></li>\n</ol>\n<h3 id=\"CNN-code\"><a href=\"#CNN-code\" class=\"headerlink\" title=\"CNN code\"></a>CNN code</h3><ol>\n<li>CNN 网络结构与部分 PyTorch: <a href=\"https://www.cnblogs.com/wpx123/p/17616156.html\">CNBlogs 1</a>, <a href=\"https://www.cnblogs.com/wpx123/p/17621303.html\">CNBlogs 2</a></li>\n</ol>\n<h4 id=\"Optimizer：\"><a href=\"#Optimizer：\" class=\"headerlink\" title=\"Optimizer：\"></a>Optimizer：</h4><p>SGD, GD, Adam 都是 Optimizer 的种类</p>\n<ol>\n<li><a href=\"https://zhuanlan.zhihu.com/p/346205754\">PyTorch 源代码解读</a>, 以及各种参数 lr, gamma 的影响</li>\n<li><a href=\"https://blog.csdn.net/xian0710830114/article/details/126551268\">简单讲解了 SGD， Adam 的原理</a></li>\n</ol>\n<h3 id=\"一个比较有用的-Casual-Inference-综述的博客：\"><a href=\"#一个比较有用的-Casual-Inference-综述的博客：\" class=\"headerlink\" title=\"一个比较有用的 Casual Inference 综述的博客：\"></a>一个比较有用的 Casual Inference 综述的博客：</h3><p><a href=\"https://www.cnblogs.com/caoyusang/p/13518354.html\">Casual Inference 综述</a></p>\n","excerpt":"","more":"<h1 id=\"1-Introduction，Machine-learning-for-graphs\"><a href=\"#1-Introduction，Machine-learning-for-graphs\" class=\"headerlink\" title=\"1 Introduction，Machine learning for graphs\"></a>1 Introduction，Machine learning for graphs</h1><h2 id=\"大纲\"><a href=\"#大纲\" class=\"headerlink\" title=\"大纲\"></a>大纲</h2><p>大纲</p>\n<ol>\n<li>Traditional methods: Graphlets, Graph Kernels</li>\n<li>Methods for node embeddings: DeepWalk, Node2Vec</li>\n<li>Graph Neural Networks: GCN, GraphSAGE, GAT, Theory of GNNs</li>\n<li>Knowledge graphs and reasoning: TransE, BetaE</li>\n<li>Deep generative models for graphs</li>\n<li>Applications to Biomedicine, Science, Industry</li>\n</ol>\n<h2 id=\"Defs\"><a href=\"#Defs\" class=\"headerlink\" title=\"Defs\"></a>Defs</h2><ol start=\"0\">\n<li>$G&#x3D;(V, E, F)$ or $G(V, E)$</li>\n<li>Directed&#x2F; undirected</li>\n<li>Degree<br>Directed $\\bar{k} &#x3D; \\langle k \\rangle &#x3D; \\frac{1}{N} \\sum_{i&#x3D;1}^{N} k_i &#x3D; \\frac{2E}{N}$<br>Undirected in-degree + out-degree &#x3D; (total) degree, $\\bar{k}&#x3D; \\frac{E}{N}$ </li>\n<li>Bipartite Graph</li>\n<li>Folded&#x2F;Projected Bipartite graph</li>\n<li>Representing graphs: Adjacency matrix Density of matrix $\\frac{E}{N^2}$<ol>\n<li>adjacency matrix</li>\n<li>Edge List</li>\n<li>Adjacency List</li>\n</ol>\n</li>\n<li>Attribute of edges</li>\n<li>Weighted&#x2F;Unweighted</li>\n<li>Self-edges</li>\n<li>Connectivity: (Un)Directed, Strong Connected Components (in Undirected)</li>\n</ol>\n<h1 id=\"2-Traditional-methods-for-ML-on-graph\"><a href=\"#2-Traditional-methods-for-ML-on-graph\" class=\"headerlink\" title=\"2 Traditional methods for ML on graph\"></a>2 Traditional methods for ML on graph</h1><p>Structural Feature&#x2F; Node features<br>Train on Random Forest, SVM, Neural Network; Apply on new graph. </p>\n<h2 id=\"Node\"><a href=\"#Node\" class=\"headerlink\" title=\"Node\"></a>Node</h2><h3 id=\"1-Node-Centrality\"><a href=\"#1-Node-Centrality\" class=\"headerlink\" title=\"(1) Node Centrality\"></a>(1) Node Centrality</h3><p>233</p>\n<ol>\n<li>Eigenvector centrality: $c_v&#x3D;\\frac{1}{\\lambda}\\sum_{u\\in N(v)}$</li>\n<li>Betweenness centrality<br>Here is the improved version of the formulas in the format you provided, while keeping the same style and explanation:</li>\n</ol>\n<hr>\n<ol>\n<li><p><strong>Betweenness Centrality</strong><br>Betweenness centrality ( c_v ) measures the extent to which a node ( v ) lies on the shortest paths between other nodes.  </p>\n<p>$$<br>c_v &#x3D; \\sum_{s \\neq v \\neq t} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}<br>$$</p>\n<ul>\n<li>( \\sigma_{st} ): The number of shortest paths between nodes ( s ) and ( t ).  </li>\n<li>( \\sigma_{st}(v) ): The number of shortest paths between ( s ) and ( t ) that pass through ( v ).</li>\n</ul>\n</li>\n</ol>\n<hr>\n<ol start=\"2\">\n<li><p><strong>Closeness Centrality</strong><br>Closeness centrality ( c_v ) quantifies how close a node ( v ) is to all other nodes in the network.  </p>\n<p>$$<br>c_v &#x3D; \\frac{1}{\\sum_{u \\neq v} d(u, v)}<br>$$</p>\n<ul>\n<li>( d(u, v) ): The shortest path length between node ( u ) and node ( v ).</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"2-Clustering-Coefficient\"><a href=\"#2-Clustering-Coefficient\" class=\"headerlink\" title=\"(2) Clustering Coefficient\"></a>(2) Clustering Coefficient</h3><p>[<br>e_v &#x3D; \\frac{\\text{Number of edges between neighbors of } v}{\\binom{k_v}{2}}, \\quad \\binom{k_v}{2} &#x3D; \\frac{k_v (k_v - 1)}{2}<br>] </p>\n<h3 id=\"3-Graphlet-Rooted-connected-non-isomorphic-subgraphs\"><a href=\"#3-Graphlet-Rooted-connected-non-isomorphic-subgraphs\" class=\"headerlink\" title=\"(3) Graphlet: Rooted connected non-isomorphic subgraphs\"></a>(3) Graphlet: Rooted connected non-isomorphic subgraphs</h3><p>Graphlet degree vector<br>Clustering coefficient.<br>Feature-based&#x2F; structure-based features.</p>\n<h2 id=\"Link\"><a href=\"#Link\" class=\"headerlink\" title=\"Link\"></a>Link</h2><h3 id=\"1-Link-prediction\"><a href=\"#1-Link-prediction\" class=\"headerlink\" title=\"(1) Link prediction\"></a>(1) Link prediction</h3><ol>\n<li>Links missing at random: Remove a random set of links and then aim to predict them</li>\n<li>Links over time: Given $G[t_0, t_0’]$ a graph on edges up to time $t_0’$, output a ranked list $L$ of links (not in $G[t_0, t_0’]$) that are predicted to appear in $G[t_1, t_1’]$</li>\n</ol>\n<h3 id=\"2-Local-Neighborhood-Overlap\"><a href=\"#2-Local-Neighborhood-Overlap\" class=\"headerlink\" title=\"(2) Local Neighborhood Overlap\"></a>(2) Local Neighborhood Overlap</h3><ul>\n<li>Common neighbors: $|N(v_1) \\cap N(v_2)|$</li>\n<li>Jaccard’s coefficient: $\\frac{|N(v_1) \\cap N(v_2)|}{|N(v_1) \\cup N(v_2)|}$,<br>Normalize common neighbor, assuming having the same number of neighbors</li>\n<li>Adamic-Adar index: $\\sum_{u \\in N(v_1) \\cap N(v_2)} \\frac{1}{\\log k_u}$,<br>Penalize those who have many neighbors</li>\n</ul>\n<h3 id=\"3-Global-Neighborhood-Overlap\"><a href=\"#3-Global-Neighborhood-Overlap\" class=\"headerlink\" title=\"(3) Global Neighborhood Overlap\"></a>(3) Global Neighborhood Overlap</h3><ul>\n<li>Katz index: $S_{uv}&#x3D; \\sum_{l&#x3D;1}^{\\infty} \\beta^l A^l_{uv}$,<br>$A^l_{uv}$: number of paths of length $l$ between $u$ and $v$,<br>$\\beta$: discount factor, the contribution of long paths  </li>\n<li>Katz index matrix: $S&#x3D; \\sum_{i&#x3D;1}^\\infty \\beta^iA^i &#x3D; (I-\\beta A)^{-1}-I$</li>\n</ul>\n<h2 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h2><h3 id=\"Kernel-method\"><a href=\"#Kernel-method\" class=\"headerlink\" title=\"Kernel method:\"></a>Kernel method:</h3><ol>\n<li><p><strong>Kernel function</strong>:<br>$K(G, G’)$ measures the similarity between two graphs $G$ and $G’$.<br>Maps the graphs into a higher-dimensional space where linear methods can be applied to perform complex, non-linear tasks in the original space.</p>\n</li>\n<li><p><strong>Kernel Matrix</strong>: $\\mathbf{K} &#x3D; \\left( K(G, G’) \\right)_{G, G’}$ is a symmetric matrix.<br>It is positive semidefinite, meaning all its eigenvalues are non-negative.</p>\n</li>\n<li><p><strong>Feature Representation</strong>:<br>Feature mapping $\\phi(\\cdot)$ kernel function is expressed as dot product in feature space: $K(G, G’) &#x3D; \\phi(G)^\\top \\phi(G’)$.</p>\n</li>\n</ol>\n<p>cite: <a href=\"https://blog.csdn.net/PolarisRisingWar/article/details/115598815\">CSDN Blog</a></p>\n<h3 id=\"Design-graph-feature-vector-phi-G\"><a href=\"#Design-graph-feature-vector-phi-G\" class=\"headerlink\" title=\"Design graph feature vector $\\phi(G)$\"></a>Design graph feature vector $\\phi(G)$</h3><p><strong>Bag-of-Words: BoW</strong><br>Key idea: use the word counts as features (#nodes as features, #degree, #graphlet, #color)</p>\n<h3 id=\"Graphlet-features\"><a href=\"#Graphlet-features\" class=\"headerlink\" title=\"Graphlet features\"></a>Graphlet features</h3><p>Key idea: Count the number of different graphlets in a graph.<br>$G_k&#x3D;(g_1, g_2, \\cdots, g_{n_k})$</p>\n<p>Graphlet count vector $(f_G)&#x3D;#(g_i \\subseteq G), ; i \\leq n_k$</p>\n<p>$h_G&#x3D; \\frac{f_G}{\\text{Sum}(F_G)}$,<br>$K(G, G’)&#x3D;H_G^\\top H_G’$</p>\n<p>NP-hard $O(nd^{k-1})$, expensive to calculate </p>\n<h3 id=\"Weisfeiler-Lehman-Kernel\"><a href=\"#Weisfeiler-Lehman-Kernel\" class=\"headerlink\" title=\"Weisfeiler-Lehman Kernel\"></a>Weisfeiler-Lehman Kernel</h3><p><a href=\"https://blog.csdn.net/PolarisRisingWar/article/details/117336622\">Weisfeiler-Lehman Kernel Blog</a></p>\n<h1 id=\"3-Node-Embedding\"><a href=\"#3-Node-Embedding\" class=\"headerlink\" title=\"3 Node Embedding\"></a>3 Node Embedding</h1><h2 id=\"3-1-Intro\"><a href=\"#3-1-Intro\" class=\"headerlink\" title=\"3.1 Intro\"></a>3.1 Intro</h2><p>Key: How to define node similarity  </p>\n<!-- Avoid direct Feature Engineering, and also reflect structural features -->\n<h3 id=\"Encoder\"><a href=\"#Encoder\" class=\"headerlink\" title=\"Encoder\"></a>Encoder</h3><p>Feature representation ↔ feature embedding  </p>\n<!-- If two nodes are similar in structure, they should be similar in embedding space -->\n<!-- Use dot product to measure similarity -->\n<p>Similarity $(u, v) \\approx z_u^T z_v$,<br>$ENC(u) &#x3D; z_u$, $ENC(v) &#x3D; z_v$, <!--ENC: Encoder--><br>$z_u, z_v$ are $d$-dimensional in embedding space, $d$ usually 64-1000<br>$ENC(v)$ node in the input graph</p>\n<p>$ENC(v) &#x3D; z_v &#x3D; Z \\cdot v$<br>Encoder is a lookup, embedding matrix $Z \\in \\mathbb{R}^{d \\times |V|}$, $v \\in I^{|V|}$</p>\n<h4 id=\"ENC\"><a href=\"#ENC\" class=\"headerlink\" title=\"ENC\"></a>ENC</h4><p>Shallow encoder: $d \\times |V|$<br>Some ways for ENC: DeepWalk, Node2Vec</p>\n<h2 id=\"3-2-Random-walk-for-Node-Embedding\"><a href=\"#3-2-Random-walk-for-Node-Embedding\" class=\"headerlink\" title=\"3.2 Random walk for Node Embedding\"></a>3.2 Random walk for Node Embedding</h2><h3 id=\"Notation\"><a href=\"#Notation\" class=\"headerlink\" title=\"Notation\"></a>Notation</h3><ul>\n<li>Vector $z_u$: embedding vector of node $u$ (what we aim to find)</li>\n<li>$P(v|z_u)$: probability of visiting node $v$ on random walk starting from $u$. Used to measure similarity. </li>\n<li>Softmax: $\\sigma(z)_i &#x3D; \\frac{e^{z_i}}{\\sum e^{z_j}}$</li>\n<li>Sigmoid: $S(x) &#x3D; \\frac{1}{1 + e^{-x}}$</li>\n</ul>\n<h3 id=\"Random-walk-embedding\"><a href=\"#Random-walk-embedding\" class=\"headerlink\" title=\"Random walk embedding\"></a>Random walk embedding</h3><p>Using random strategy $R$: $P_R(u|v)$<br>Given<br>$G&#x3D;(V, E)$<br>Goal: Learn a mapping $f: u \\rightarrow \\mathbb{R}^d$<br>$$<br>\\mathcal{L} &#x3D; \\sum_{u \\in V} \\sum_{v \\in N_R(u)} -\\log\\left(\\frac{\\exp(z_u^\\top z_v)}{\\sum_{n \\in V} \\exp(z_u^\\top z_n)}\\right)<br>$$<br><strong>Negative sampling</strong><br>$$<br>\\log\\left(\\frac{\\exp(z_u^\\top z_v)}{\\sum_{n \\in V} \\exp(z_u^\\top z_n)}\\right) \\approx \\log\\left(\\sigma(z_u^\\top z_v)\\right) - \\sum_{i&#x3D;1}^{k} \\log\\left(\\sigma(z_u^\\top z_{n_i})\\right), \\quad n_i \\sim P_V<br>$$ –&gt;</p>\n<h3 id=\"Random-walk-strategy\"><a href=\"#Random-walk-strategy\" class=\"headerlink\" title=\"Random walk strategy\"></a>Random walk strategy</h3><h4 id=\"DeepWalk\"><a href=\"#DeepWalk\" class=\"headerlink\" title=\"DeepWalk\"></a>DeepWalk</h4><p><a href=\"https://www.vldb.org/pvldb/vol10/p13-wu.pdf\">DeepWalk Paper</a></p>\n<h4 id=\"Node2Vec\"><a href=\"#Node2Vec\" class=\"headerlink\" title=\"Node2Vec\"></a>Node2Vec</h4><p>Node2Vec</p>\n<p><strong>Hyperparameters:</strong></p>\n<ul>\n<li>$p$: Return parameter</li>\n<li>$q$: In-out parameter</li>\n</ul>\n<h2 id=\"3-3-Embedding-Entire-Graph\"><a href=\"#3-3-Embedding-Entire-Graph\" class=\"headerlink\" title=\"3.3 Embedding Entire Graph\"></a>3.3 Embedding Entire Graph</h2><h3 id=\"Approach-1\"><a href=\"#Approach-1\" class=\"headerlink\" title=\"Approach 1\"></a>Approach 1</h3><p>Sum&#x2F;mean $z_G &#x3D; \\sum_{v \\in G} z_v$<br><a href=\"https://arxiv.org/pdf/1509.09292\">Embedding Entire Graph</a></p>\n<h3 id=\"Approach-2\"><a href=\"#Approach-2\" class=\"headerlink\" title=\"Approach 2\"></a>Approach 2</h3><p>Virtual node<br><a href=\"https://arxiv.org/pdf/1511.05493\">Virtual Node Paper</a></p>\n<h3 id=\"Approach-3\"><a href=\"#Approach-3\" class=\"headerlink\" title=\"Approach 3\"></a>Approach 3</h3><p>Anonymous walk:</p>\n<h4 id=\"Sampling-Anonymous-walks\"><a href=\"#Sampling-Anonymous-walks\" class=\"headerlink\" title=\"Sampling Anonymous walks\"></a>Sampling Anonymous walks</h4><p>Distribution have error less than $\\epsilon$ with probability, less than $\\delta$<br>$m &#x3D; f(\\epsilon, \\sigma, \\delta)$</p>\n<h4 id=\"Walk-Embedding\"><a href=\"#Walk-Embedding\" class=\"headerlink\" title=\"Walk Embedding\"></a>Walk Embedding</h4><p>$\\Delta$</p>\n<h1 id=\"4-Node-Embedding-using-Random-walk-PageRank\"><a href=\"#4-Node-Embedding-using-Random-walk-PageRank\" class=\"headerlink\" title=\"4 Node Embedding using Random walk - PageRank\"></a>4 Node Embedding using Random walk - PageRank</h1><h2 id=\"4-1-Intro\"><a href=\"#4-1-Intro\" class=\"headerlink\" title=\"4.1 Intro\"></a>4.1 Intro</h2><p>PageRank: $r_v &#x3D; \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$<br>$d_u$: degree of node $u$<br>$A_{u,v}$: adjacency matrix<br>$r_v$: rank of node $v$<br>$N_R(v)$: neighbors of node $v$</p>\n<h2 id=\"4-2-PageRank-for-Graph\"><a href=\"#4-2-PageRank-for-Graph\" class=\"headerlink\" title=\"4.2 PageRank for Graph\"></a>4.2 PageRank for Graph</h2><p>$r_v &#x3D; \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$<br>$d_u$: degree of node $u$<br>$A_{u,v}$: adjacency matrix<br>$r_v$: rank of node $v$<br>$N_R(v)$: neighbors of node $v$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$r_v &#x3D; \\sum_{u \\in N_R(v)} r_u \\frac{A_{u,v}}{d_u}$</p>\n<h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>Personalized PageRank (Topic specific PageRank)<br>Rank proximity of nodes to the teleport nodes $S$,<br>Proximity on graphs: </li>\n<li>PageRank with restarts:</li>\n</ul>\n<h3 id=\"Matrix-Factorization\"><a href=\"#Matrix-Factorization\" class=\"headerlink\" title=\"Matrix Factorization\"></a>Matrix Factorization</h3><p>Frobenius norm: $\\min_z ||A - Z^\\top Z||$<br><img src=\"2024-05-19-CS224W-notes/image.png\" alt=\"Alt text\" width=\"400\" ></p>\n<h1 id=\"5-Message-passing-Node-Classification\"><a href=\"#5-Message-passing-Node-Classification\" class=\"headerlink\" title=\"5 Message passing &amp; Node Classification\"></a>5 Message passing &amp; Node Classification</h1><p>Classical methods</p>\n<p><strong>Correlation:</strong> nearby nodes have the same color<br>$A_{n \\times n}$: Adjacency matrix<br>$Y &#x3D; {0, 1}^n$</p>\n<h2 id=\"Collective-Classification\"><a href=\"#Collective-Classification\" class=\"headerlink\" title=\"Collective Classification:\"></a>Collective Classification:</h2><ol>\n<li>Local classifier </li>\n<li>Relational Classifier </li>\n<li>Collective Inference<br>$1^{st}$ order Markov assumption: $P(Y_v) &#x3D; P(Y_v | N_v)$</li>\n</ol>\n<ul>\n<li>Relational classification</li>\n<li>Iterative classification </li>\n<li>Belief propagation</li>\n</ul>\n<h1 id=\"6-GNN-Model\"><a href=\"#6-GNN-Model\" class=\"headerlink\" title=\"6 GNN Model\"></a>6 GNN Model</h1><h1 id=\"7-GNN-Design-Space\"><a href=\"#7-GNN-Design-Space\" class=\"headerlink\" title=\"7 GNN Design Space\"></a>7 GNN Design Space</h1><h1 id=\"8-Training-GNN\"><a href=\"#8-Training-GNN\" class=\"headerlink\" title=\"8 Training GNN\"></a>8 Training GNN</h1><h2 id=\"8-1-Data-augmentation\"><a href=\"#8-1-Data-augmentation\" class=\"headerlink\" title=\"8.1 Data augmentation\"></a>8.1 Data augmentation</h2><h3 id=\"Feature-based\"><a href=\"#Feature-based\" class=\"headerlink\" title=\"Feature based\"></a>Feature based</h3><h3 id=\"Structure-based\"><a href=\"#Structure-based\" class=\"headerlink\" title=\"Structure based\"></a>Structure based</h3><h2 id=\"8-2\"><a href=\"#8-2\" class=\"headerlink\" title=\"8.2\"></a>8.2</h2><h2 id=\"8-3\"><a href=\"#8-3\" class=\"headerlink\" title=\"8.3\"></a>8.3</h2><p><img src=\"/2024-05-19-CS224W-notes/image-1.png\" alt=\"alt text\"></p>\n<p><strong>Node Prediction</strong>  </p>\n<ul>\n<li>Transductive setting</li>\n<li>Inductive setting</li>\n</ul>\n<p><strong>Training</strong><br>Validation (tuning hyperparameters)<br>Test set</p>\n<p><strong>Graph Prediction</strong>  </p>\n<ul>\n<li>Link Prediction –&gt;</li>\n</ul>\n<h1 id=\"9-Theory-of-GNN\"><a href=\"#9-Theory-of-GNN\" class=\"headerlink\" title=\"9 Theory of GNN\"></a>9 Theory of GNN</h1><p>GCN, GAT, GraphSAGE, design space </p>\n<h2 id=\"9-1\"><a href=\"#9-1\" class=\"headerlink\" title=\"9.1\"></a>9.1</h2><h2 id=\"9-2\"><a href=\"#9-2\" class=\"headerlink\" title=\"9.2\"></a>9.2</h2><p>GCN Mean pooling fails<br>GraphSAGE mean-pool </p>\n<p>Injective Multiset function: $\\Phi(\\cdot)$: a non-linear function:<br>$\\Phi(\\sum_{x \\in S} f(x))$:<br>Multi-layer Perceptron<br><strong>Theorem:</strong> Universal approximation theorem<br>A neural network can model any injective multiset function:<br>$MLP_{\\Phi}(\\sum_{x \\in S} MLP_{f}(x))$</p>\n<p><strong>Graph Isomorphism Network (GIN) Xue 2019</strong> </p>\n<p><strong>WL Graph Kernel</strong><br>Hash<br>$$<br>\\left( c^{(k)}(v), { c^{(k)}(u) }_{u \\in N(v)} \\right)<br>$$</p>\n<p>$$<br>\\text{MLP}<em>{\\Phi} \\left( (1 + \\epsilon) \\cdot \\text{MLP}</em>{f}(c^{(k)}(v)) + \\sum_{u \\in N(v)} \\text{MLP}_{f}(c^{(k)}(u)) \\right)<br>$$</p>\n<p>where $\\epsilon$ is a learnable scalar</p>\n<p>$$<br>c^{(k+1)}(v) &#x3D; \\text{HASH} \\left( c^{(k)}(v), { c^{(k)}(u) }_{u \\in N(v)} \\right)<br>$$</p>\n<p>$$<br>\\text{GINConv} \\left( c^{(k)}(v), { c^{(k)}(u) }<em>{u \\in N(v)} \\right) &#x3D; \\text{MLP}</em>{\\Phi} \\left( (1 + \\epsilon) \\cdot c^{(k)}(v) + \\sum_{u \\in N(v)} c^{(k)}(u) \\right)<br>$$</p>\n<h1 id=\"10-Heterogeneous-Graphs-and-Knowledge-Graph-Embeddings\"><a href=\"#10-Heterogeneous-Graphs-and-Knowledge-Graph-Embeddings\" class=\"headerlink\" title=\"10 Heterogeneous Graphs and Knowledge Graph Embeddings\"></a>10 Heterogeneous Graphs and Knowledge Graph Embeddings</h1><h2 id=\"10-1\"><a href=\"#10-1\" class=\"headerlink\" title=\"10.1\"></a>10.1</h2><h3 id=\"Heterogeneous-Graphs\"><a href=\"#Heterogeneous-Graphs\" class=\"headerlink\" title=\"Heterogeneous Graphs\"></a>Heterogeneous Graphs</h3><p>$G&#x3D;(V, E, R, T)$</p>\n<h2 id=\"RGCN\"><a href=\"#RGCN\" class=\"headerlink\" title=\"RGCN\"></a>RGCN</h2><h1 id=\"VGAE\"><a href=\"#VGAE\" class=\"headerlink\" title=\"VGAE\"></a>VGAE</h1><p>讲的比较好的GAE和VGAE</p>\n<ol>\n<li><a href=\"https://www.atyun.com/17976.html\">AtYun Article</a></li>\n<li><a href=\"https://spaces.ac.cn/archives/5253#%E7%BB%88%E7%82%B9%E7%AB%99\">Spaces Article</a></li>\n<li><a href=\"https://blog.csdn.net/qq_16763983/article/details/120403055?spm=1001.2101.3001.6650.7&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7-120403055-blog-119531815.235%5Ev43%5Epc_blog_bottom_relevance_base8&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-7-120403055-blog-119531815.235%5Ev43%5Epc_blog_bottom_relevance_base8&utm_relevant_index=13\">CSDN Blog</a></li>\n</ol>\n<h3 id=\"CNN-code\"><a href=\"#CNN-code\" class=\"headerlink\" title=\"CNN code\"></a>CNN code</h3><ol>\n<li>CNN 网络结构与部分 PyTorch: <a href=\"https://www.cnblogs.com/wpx123/p/17616156.html\">CNBlogs 1</a>, <a href=\"https://www.cnblogs.com/wpx123/p/17621303.html\">CNBlogs 2</a></li>\n</ol>\n<h4 id=\"Optimizer：\"><a href=\"#Optimizer：\" class=\"headerlink\" title=\"Optimizer：\"></a>Optimizer：</h4><p>SGD, GD, Adam 都是 Optimizer 的种类</p>\n<ol>\n<li><a href=\"https://zhuanlan.zhihu.com/p/346205754\">PyTorch 源代码解读</a>, 以及各种参数 lr, gamma 的影响</li>\n<li><a href=\"https://blog.csdn.net/xian0710830114/article/details/126551268\">简单讲解了 SGD， Adam 的原理</a></li>\n</ol>\n<h3 id=\"一个比较有用的-Casual-Inference-综述的博客：\"><a href=\"#一个比较有用的-Casual-Inference-综述的博客：\" class=\"headerlink\" title=\"一个比较有用的 Casual Inference 综述的博客：\"></a>一个比较有用的 Casual Inference 综述的博客：</h3><p><a href=\"https://www.cnblogs.com/caoyusang/p/13518354.html\">Casual Inference 综述</a></p>\n"},{"title":"2025-04-01-mt-implementation-log","date":"2025-04-01T16:58:02.000Z","_content":"123\n1. Folder directory problem\nThe structure of tornike's repo (derive from config):\n\nMusicLDM-Ext\n- lightning_logs\n    - multichannel_slakh (project check points)\n    - musicldm_checkpoints\n        - vae-ckpt.ckpt\n        - hifigan-ckpt.ckpt\n        - clap-ckpt.pt\n- data\n    - slakh2100 \n        - train (https://github.com/gladia-research-group/multi-source-diffusion-models/blob/main/data/README.md)\n        - validation\n        - test\n    <!-- - Audiostock-10k-16khz \n        - test_split_audio_content_analysis.json\n        -label -->\n- src\n- config\n    - multichannel_LDM\n    - musicldm_audiostock10k\n    - musicldm_soundcloud\n- train_musicldm.py\n\n\n2. env\nthe given musicldm \n mamba is a good tool for env management (like conda)\n\n\nnohup mamba env create -f musicldm_env.yml -y --no-builds > install_log.txt 2>&1 &\nnohup使用方法\nps aux | grep mamba\n\ntorch安装\nhttps://pytorch.org/get-started/previous-versions/\n\n（1）musicldm_env是没有版本号的，只有torch等和原来相同。问题是transformers之类的一些包过于新，不兼容。\n（2）目前是去掉哈希值micromamba 安装\nnohup micromamba env create -f musicldm_env_clean.yml -y > install_log.txt 2>&1 &\nnohup micromamba env update -f musicldm_env_clean.yml -y > install_log.txt 2>&1 &\nerror 1: torchlibrosa==0.9.2 无法安装\n从yaml中去掉，手动装\n- 正在 micromamba update\n- 手动装 torchlibrosa==0.9.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/2025-04-01-mt-implementation-log.md","raw":"---\ntitle: 2025-04-01-mt-implementation-log\ndate: 2025-04-01 12:58:02\ntags:\n---\n123\n1. Folder directory problem\nThe structure of tornike's repo (derive from config):\n\nMusicLDM-Ext\n- lightning_logs\n    - multichannel_slakh (project check points)\n    - musicldm_checkpoints\n        - vae-ckpt.ckpt\n        - hifigan-ckpt.ckpt\n        - clap-ckpt.pt\n- data\n    - slakh2100 \n        - train (https://github.com/gladia-research-group/multi-source-diffusion-models/blob/main/data/README.md)\n        - validation\n        - test\n    <!-- - Audiostock-10k-16khz \n        - test_split_audio_content_analysis.json\n        -label -->\n- src\n- config\n    - multichannel_LDM\n    - musicldm_audiostock10k\n    - musicldm_soundcloud\n- train_musicldm.py\n\n\n2. env\nthe given musicldm \n mamba is a good tool for env management (like conda)\n\n\nnohup mamba env create -f musicldm_env.yml -y --no-builds > install_log.txt 2>&1 &\nnohup使用方法\nps aux | grep mamba\n\ntorch安装\nhttps://pytorch.org/get-started/previous-versions/\n\n（1）musicldm_env是没有版本号的，只有torch等和原来相同。问题是transformers之类的一些包过于新，不兼容。\n（2）目前是去掉哈希值micromamba 安装\nnohup micromamba env create -f musicldm_env_clean.yml -y > install_log.txt 2>&1 &\nnohup micromamba env update -f musicldm_env_clean.yml -y > install_log.txt 2>&1 &\nerror 1: torchlibrosa==0.9.2 无法安装\n从yaml中去掉，手动装\n- 正在 micromamba update\n- 手动装 torchlibrosa==0.9.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"2025-04-01-mt-implementation-log","published":1,"updated":"2025-04-04T16:21:33.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagpt000zzc3d8k0wglt8","content":"<p>123</p>\n<ol>\n<li>Folder directory problem<br>The structure of tornike’s repo (derive from config):</li>\n</ol>\n<p>MusicLDM-Ext</p>\n<ul>\n<li>lightning_logs<ul>\n<li>multichannel_slakh (project check points)</li>\n<li>musicldm_checkpoints<ul>\n<li>vae-ckpt.ckpt</li>\n<li>hifigan-ckpt.ckpt</li>\n<li>clap-ckpt.pt</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>data<ul>\n<li>slakh2100 <ul>\n<li>train (<a href=\"https://github.com/gladia-research-group/multi-source-diffusion-models/blob/main/data/README.md\">https://github.com/gladia-research-group/multi-source-diffusion-models/blob/main/data/README.md</a>)</li>\n<li>validation</li>\n<li>test  <!-- - Audiostock-10k-16khz </li>\n<li>test_split_audio_content_analysis.json<br>  -label –&gt;</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>src</li>\n<li>config<ul>\n<li>multichannel_LDM</li>\n<li>musicldm_audiostock10k</li>\n<li>musicldm_soundcloud</li>\n</ul>\n</li>\n<li>train_musicldm.py</li>\n</ul>\n<ol start=\"2\">\n<li>env<br>the given musicldm<br> mamba is a good tool for env management (like conda)</li>\n</ol>\n<p>nohup mamba env create -f musicldm_env.yml -y –no-builds &gt; install_log.txt 2&gt;&amp;1 &amp;<br>nohup使用方法<br>ps aux | grep mamba</p>\n<p>torch安装<br><a href=\"https://pytorch.org/get-started/previous-versions/\">https://pytorch.org/get-started/previous-versions/</a></p>\n<p>（1）musicldm_env是没有版本号的，只有torch等和原来相同。问题是transformers之类的一些包过于新，不兼容。<br>（2）目前是去掉哈希值micromamba 安装<br>nohup micromamba env create -f musicldm_env_clean.yml -y &gt; install_log.txt 2&gt;&amp;1 &amp;<br>nohup micromamba env update -f musicldm_env_clean.yml -y &gt; install_log.txt 2&gt;&amp;1 &amp;<br>error 1: torchlibrosa&#x3D;&#x3D;0.9.2 无法安装<br>从yaml中去掉，手动装</p>\n<ul>\n<li>正在 micromamba update</li>\n<li>手动装 torchlibrosa&#x3D;&#x3D;0.9.2</li>\n</ul>\n","excerpt":"","more":"<p>123</p>\n<ol>\n<li>Folder directory problem<br>The structure of tornike’s repo (derive from config):</li>\n</ol>\n<p>MusicLDM-Ext</p>\n<ul>\n<li>lightning_logs<ul>\n<li>multichannel_slakh (project check points)</li>\n<li>musicldm_checkpoints<ul>\n<li>vae-ckpt.ckpt</li>\n<li>hifigan-ckpt.ckpt</li>\n<li>clap-ckpt.pt</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>data<ul>\n<li>slakh2100 <ul>\n<li>train (<a href=\"https://github.com/gladia-research-group/multi-source-diffusion-models/blob/main/data/README.md\">https://github.com/gladia-research-group/multi-source-diffusion-models/blob/main/data/README.md</a>)</li>\n<li>validation</li>\n<li>test  <!-- - Audiostock-10k-16khz </li>\n<li>test_split_audio_content_analysis.json<br>  -label –&gt;</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>src</li>\n<li>config<ul>\n<li>multichannel_LDM</li>\n<li>musicldm_audiostock10k</li>\n<li>musicldm_soundcloud</li>\n</ul>\n</li>\n<li>train_musicldm.py</li>\n</ul>\n<ol start=\"2\">\n<li>env<br>the given musicldm<br> mamba is a good tool for env management (like conda)</li>\n</ol>\n<p>nohup mamba env create -f musicldm_env.yml -y –no-builds &gt; install_log.txt 2&gt;&amp;1 &amp;<br>nohup使用方法<br>ps aux | grep mamba</p>\n<p>torch安装<br><a href=\"https://pytorch.org/get-started/previous-versions/\">https://pytorch.org/get-started/previous-versions/</a></p>\n<p>（1）musicldm_env是没有版本号的，只有torch等和原来相同。问题是transformers之类的一些包过于新，不兼容。<br>（2）目前是去掉哈希值micromamba 安装<br>nohup micromamba env create -f musicldm_env_clean.yml -y &gt; install_log.txt 2&gt;&amp;1 &amp;<br>nohup micromamba env update -f musicldm_env_clean.yml -y &gt; install_log.txt 2&gt;&amp;1 &amp;<br>error 1: torchlibrosa&#x3D;&#x3D;0.9.2 无法安装<br>从yaml中去掉，手动装</p>\n<ul>\n<li>正在 micromamba update</li>\n<li>手动装 torchlibrosa&#x3D;&#x3D;0.9.2</li>\n</ul>\n"},{"title":"2024-11-16 DIP Notes","date":"2024-11-16T16:12:55.000Z","_content":"\n### Common Notations for Morphological Operations\n\nMorphological operations have well-defined notations, often derived from set theory or mathematical morphology conventions. Here’s how to represent them using symbols:\n\n---\n\n#### **1. Erosion (腐蚀)**\n- **Mathematical Notation**: \\( A \\ominus B \\)\n  - \\( A \\): Input image or set.\n  - \\( B \\): Structuring element (SE).\n- **Definition**:\n  \\[\n  A \\ominus B = \\{ z \\mid (B)_z \\subseteq A \\}\n  \\]\n  Where \\( (B)_z \\) is the translation of \\( B \\) to point \\( z \\), and \\( \\subseteq \\) indicates that \\( B \\) fits within \\( A \\).\n\n---\n\n#### **2. Dilation (膨胀)**\n- **Mathematical Notation**: \\( A \\oplus B \\)\n  - \\( A \\): Input image or set.\n  - \\( B \\): Structuring element (SE).\n- **Definition**:\n  \\[\n  A \\oplus B = \\{ z \\mid (B)_z \\cap A \\neq \\emptyset \\}\n  \\]\n  Where \\( (B)_z \\) is the translation of \\( B \\) to point \\( z \\), and \\( \\cap \\) indicates intersection.\n\n---\n\n#### **3. Opening (开运算)**\n- **Mathematical Notation**: \\( A \\circ B \\)\n  - \\( A \\): Input image or set.\n  - \\( B \\): Structuring element (SE).\n- **Definition**:\n  \\[\n  A \\circ B = (A \\ominus B) \\oplus B\n  \\]\n  Opening is erosion followed by dilation.\n\n---\n\n#### **4. Closing (闭运算)**\n- **Mathematical Notation**: \\( A \\bullet B \\)\n  - \\( A \\): Input image or set.\n  - \\( B \\): Structuring element (SE).\n- **Definition**:\n  \\[\n  A \\bullet B = (A \\oplus B) \\ominus B\n  \\]\n  Closing is dilation followed by erosion.\n\n---\n\n#### **5. Hit-or-Miss Transformation (击中与未击中变换)**\n- **Mathematical Notation**: \\( A \\otimes B \\)\n  - \\( A \\): Input binary image.\n  - \\( B \\): Structuring element or pattern (composed of \\( B_1 \\) and \\( B_2 \\)).\n- **Definition**:\n  \\[\n  A \\otimes B = (A \\ominus B_1) \\cap (A^c \\ominus B_2)\n  \\]\n  Where:\n  - \\( A^c \\): Complement of \\( A \\).\n  - \\( B_1, B_2 \\): Structuring elements for the object and background, respectively.\n\n---\n\n### Symbols Summary\n\n| **Operation**       | **Symbol**    | **Formula**                                                                 |\n|----------------------|---------------|------------------------------------------------------------------------------|\n| **Erosion**          | \\( \\ominus \\) | \\( A \\ominus B = \\{ z \\mid (B)_z \\subseteq A \\} \\)                          |\n| **Dilation**         | \\( \\oplus \\)  | \\( A \\oplus B = \\{ z \\mid (B)_z \\cap A \\neq \\emptyset \\} \\)                 |\n| **Opening**          | \\( \\circ \\)   | \\( A \\circ B = (A \\ominus B) \\oplus B \\)                                    |\n| **Closing**          | \\( \\bullet \\) | \\( A \\bullet B = (A \\oplus B) \\ominus B \\)                                  |\n| **Hit-or-Miss**      | \\( \\otimes \\) | \\( A \\otimes B = (A \\ominus B_1) \\cap (A^c \\ominus B_2) \\)                  |\n\n---\n\n### How to Write These Symbols in LaTeX\nYou can easily represent these notations using LaTeX. Here are some examples:\n\n- **Erosion**: `A \\ominus B`\n- **Dilation**: `A \\oplus B`\n- **Opening**: `A \\circ B`\n- **Closing**: `A \\bullet B`\n- **Hit-or-Miss**: `A \\otimes B`\n\n---\n\n\n\n### A Distinguish Between Concepts\n\n---\n\n1. **Skeletonizing**: \\( \\mathcal{K} \\) : \\( \\mathcal{K}(A) = \\bigcup_{n=1}^N (A \\ominus nB) - [(A \\ominus nB) \\circ B] \\)  \n   **Definition**: Reduces objects to their centerline representation (skeleton) by iterative erosion and removal of boundary pixels while preserving object connectivity.  \n   **Purpose**: Captures the fundamental structure of objects for analysis, such as handwriting recognition or shape description.  \n   **Structural Element (SE)**:  \n   - Typically a circular or square SE is used for iterative erosion.  \n   - Example SE:  \n     \\[\n     \\begin{bmatrix}\n     0 & 1 & 0 \\\\\n     1 & 1 & 1 \\\\\n     0 & 1 & 0\n     \\end{bmatrix}\n     \\]\n\n---\n\n2. **Thinning**: \\( T \\) : \\( T(A) = \\lim_{n \\to N} (A \\ominus nB) \\)  \n   **Definition**: Removes outer layers of pixels iteratively, leaving a minimally connected structure that represents the object's shape.  \n   **Purpose**: Simplifies shapes while preserving their topology and connectivity. Useful for applications like fingerprint analysis and character recognition.  \n   **Structural Element (SE)**:  \n   - A directional SE is used to iteratively remove pixels layer by layer.  \n   - Example SE:  \n     \\[\n     \\begin{bmatrix}\n     0 & 0 & 0 \\\\\n     1 & 1 & 1 \\\\\n     0 & 0 & 0\n     \\end{bmatrix}\n     \\]  \n\n---\n\n3. **Shrinking**: \\( S \\) : \\( S(A) = \\{ z \\in A \\mid B \\text{ fits within } A_z \\} \\)  \n   **Definition**: Shrinks objects iteratively by removing pixels while ensuring the object does not disconnect or vanish entirely.  \n   **Purpose**: Reduces objects until they are minimized to a single pixel or central skeleton point. Useful for connected component analysis.  \n   **Structural Element (SE)**:  \n   - A small SE (e.g., 3x3 or 5x5) designed to maintain object connectivity.  \n   - Example SE:  \n     \\[\n     \\begin{bmatrix}\n     1 & 1 & 1 \\\\\n     1 & 1 & 1 \\\\\n     1 & 1 & 1\n     \\end{bmatrix}\n     \\]\n\n---\n\n### Relationships and Summary\n\n- **Skeletonizing**: Captures the \"core\" or \"centerline\" of an object. Involves iterative erosion while preserving connectivity.\n- **Thinning**: A simpler reduction compared to skeletonizing, focusing on removing boundary layers iteratively.\n- **Shrinking**: Minimizes objects while maintaining their connectivity, often leading to a single pixel or minimal structure.\n\nEach operation uses structural elements (SEs) tailored to the object’s geometry and the specific processing goal. These concepts are built upon basic morphological operations like erosion and dilation.","source":"_posts/2024-11-16-DIP-Notes.md","raw":"---\ntitle: 2024-11-16 DIP Notes\ndate: 2024-11-16 11:12:55\ntags:\n---\n\n### Common Notations for Morphological Operations\n\nMorphological operations have well-defined notations, often derived from set theory or mathematical morphology conventions. Here’s how to represent them using symbols:\n\n---\n\n#### **1. Erosion (腐蚀)**\n- **Mathematical Notation**: \\( A \\ominus B \\)\n  - \\( A \\): Input image or set.\n  - \\( B \\): Structuring element (SE).\n- **Definition**:\n  \\[\n  A \\ominus B = \\{ z \\mid (B)_z \\subseteq A \\}\n  \\]\n  Where \\( (B)_z \\) is the translation of \\( B \\) to point \\( z \\), and \\( \\subseteq \\) indicates that \\( B \\) fits within \\( A \\).\n\n---\n\n#### **2. Dilation (膨胀)**\n- **Mathematical Notation**: \\( A \\oplus B \\)\n  - \\( A \\): Input image or set.\n  - \\( B \\): Structuring element (SE).\n- **Definition**:\n  \\[\n  A \\oplus B = \\{ z \\mid (B)_z \\cap A \\neq \\emptyset \\}\n  \\]\n  Where \\( (B)_z \\) is the translation of \\( B \\) to point \\( z \\), and \\( \\cap \\) indicates intersection.\n\n---\n\n#### **3. Opening (开运算)**\n- **Mathematical Notation**: \\( A \\circ B \\)\n  - \\( A \\): Input image or set.\n  - \\( B \\): Structuring element (SE).\n- **Definition**:\n  \\[\n  A \\circ B = (A \\ominus B) \\oplus B\n  \\]\n  Opening is erosion followed by dilation.\n\n---\n\n#### **4. Closing (闭运算)**\n- **Mathematical Notation**: \\( A \\bullet B \\)\n  - \\( A \\): Input image or set.\n  - \\( B \\): Structuring element (SE).\n- **Definition**:\n  \\[\n  A \\bullet B = (A \\oplus B) \\ominus B\n  \\]\n  Closing is dilation followed by erosion.\n\n---\n\n#### **5. Hit-or-Miss Transformation (击中与未击中变换)**\n- **Mathematical Notation**: \\( A \\otimes B \\)\n  - \\( A \\): Input binary image.\n  - \\( B \\): Structuring element or pattern (composed of \\( B_1 \\) and \\( B_2 \\)).\n- **Definition**:\n  \\[\n  A \\otimes B = (A \\ominus B_1) \\cap (A^c \\ominus B_2)\n  \\]\n  Where:\n  - \\( A^c \\): Complement of \\( A \\).\n  - \\( B_1, B_2 \\): Structuring elements for the object and background, respectively.\n\n---\n\n### Symbols Summary\n\n| **Operation**       | **Symbol**    | **Formula**                                                                 |\n|----------------------|---------------|------------------------------------------------------------------------------|\n| **Erosion**          | \\( \\ominus \\) | \\( A \\ominus B = \\{ z \\mid (B)_z \\subseteq A \\} \\)                          |\n| **Dilation**         | \\( \\oplus \\)  | \\( A \\oplus B = \\{ z \\mid (B)_z \\cap A \\neq \\emptyset \\} \\)                 |\n| **Opening**          | \\( \\circ \\)   | \\( A \\circ B = (A \\ominus B) \\oplus B \\)                                    |\n| **Closing**          | \\( \\bullet \\) | \\( A \\bullet B = (A \\oplus B) \\ominus B \\)                                  |\n| **Hit-or-Miss**      | \\( \\otimes \\) | \\( A \\otimes B = (A \\ominus B_1) \\cap (A^c \\ominus B_2) \\)                  |\n\n---\n\n### How to Write These Symbols in LaTeX\nYou can easily represent these notations using LaTeX. Here are some examples:\n\n- **Erosion**: `A \\ominus B`\n- **Dilation**: `A \\oplus B`\n- **Opening**: `A \\circ B`\n- **Closing**: `A \\bullet B`\n- **Hit-or-Miss**: `A \\otimes B`\n\n---\n\n\n\n### A Distinguish Between Concepts\n\n---\n\n1. **Skeletonizing**: \\( \\mathcal{K} \\) : \\( \\mathcal{K}(A) = \\bigcup_{n=1}^N (A \\ominus nB) - [(A \\ominus nB) \\circ B] \\)  \n   **Definition**: Reduces objects to their centerline representation (skeleton) by iterative erosion and removal of boundary pixels while preserving object connectivity.  \n   **Purpose**: Captures the fundamental structure of objects for analysis, such as handwriting recognition or shape description.  \n   **Structural Element (SE)**:  \n   - Typically a circular or square SE is used for iterative erosion.  \n   - Example SE:  \n     \\[\n     \\begin{bmatrix}\n     0 & 1 & 0 \\\\\n     1 & 1 & 1 \\\\\n     0 & 1 & 0\n     \\end{bmatrix}\n     \\]\n\n---\n\n2. **Thinning**: \\( T \\) : \\( T(A) = \\lim_{n \\to N} (A \\ominus nB) \\)  \n   **Definition**: Removes outer layers of pixels iteratively, leaving a minimally connected structure that represents the object's shape.  \n   **Purpose**: Simplifies shapes while preserving their topology and connectivity. Useful for applications like fingerprint analysis and character recognition.  \n   **Structural Element (SE)**:  \n   - A directional SE is used to iteratively remove pixels layer by layer.  \n   - Example SE:  \n     \\[\n     \\begin{bmatrix}\n     0 & 0 & 0 \\\\\n     1 & 1 & 1 \\\\\n     0 & 0 & 0\n     \\end{bmatrix}\n     \\]  \n\n---\n\n3. **Shrinking**: \\( S \\) : \\( S(A) = \\{ z \\in A \\mid B \\text{ fits within } A_z \\} \\)  \n   **Definition**: Shrinks objects iteratively by removing pixels while ensuring the object does not disconnect or vanish entirely.  \n   **Purpose**: Reduces objects until they are minimized to a single pixel or central skeleton point. Useful for connected component analysis.  \n   **Structural Element (SE)**:  \n   - A small SE (e.g., 3x3 or 5x5) designed to maintain object connectivity.  \n   - Example SE:  \n     \\[\n     \\begin{bmatrix}\n     1 & 1 & 1 \\\\\n     1 & 1 & 1 \\\\\n     1 & 1 & 1\n     \\end{bmatrix}\n     \\]\n\n---\n\n### Relationships and Summary\n\n- **Skeletonizing**: Captures the \"core\" or \"centerline\" of an object. Involves iterative erosion while preserving connectivity.\n- **Thinning**: A simpler reduction compared to skeletonizing, focusing on removing boundary layers iteratively.\n- **Shrinking**: Minimizes objects while maintaining their connectivity, often leading to a single pixel or minimal structure.\n\nEach operation uses structural elements (SEs) tailored to the object’s geometry and the specific processing goal. These concepts are built upon basic morphological operations like erosion and dilation.","slug":"2024-11-16-DIP-Notes","published":1,"updated":"2024-12-15T03:52:03.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagpu0010zc3d7m9p6dj5","content":"<h3 id=\"Common-Notations-for-Morphological-Operations\"><a href=\"#Common-Notations-for-Morphological-Operations\" class=\"headerlink\" title=\"Common Notations for Morphological Operations\"></a>Common Notations for Morphological Operations</h3><p>Morphological operations have well-defined notations, often derived from set theory or mathematical morphology conventions. Here’s how to represent them using symbols:</p>\n<hr>\n<h4 id=\"1-Erosion-腐蚀\"><a href=\"#1-Erosion-腐蚀\" class=\"headerlink\" title=\"1. Erosion (腐蚀)\"></a><strong>1. Erosion (腐蚀)</strong></h4><ul>\n<li><strong>Mathematical Notation</strong>: ( A \\ominus B )<ul>\n<li>( A ): Input image or set.</li>\n<li>( B ): Structuring element (SE).</li>\n</ul>\n</li>\n<li><strong>Definition</strong>:<br>[<br>A \\ominus B &#x3D; { z \\mid (B)_z \\subseteq A }<br>]<br>Where ( (B)_z ) is the translation of ( B ) to point ( z ), and ( \\subseteq ) indicates that ( B ) fits within ( A ).</li>\n</ul>\n<hr>\n<h4 id=\"2-Dilation-膨胀\"><a href=\"#2-Dilation-膨胀\" class=\"headerlink\" title=\"2. Dilation (膨胀)\"></a><strong>2. Dilation (膨胀)</strong></h4><ul>\n<li><strong>Mathematical Notation</strong>: ( A \\oplus B )<ul>\n<li>( A ): Input image or set.</li>\n<li>( B ): Structuring element (SE).</li>\n</ul>\n</li>\n<li><strong>Definition</strong>:<br>[<br>A \\oplus B &#x3D; { z \\mid (B)_z \\cap A \\neq \\emptyset }<br>]<br>Where ( (B)_z ) is the translation of ( B ) to point ( z ), and ( \\cap ) indicates intersection.</li>\n</ul>\n<hr>\n<h4 id=\"3-Opening-开运算\"><a href=\"#3-Opening-开运算\" class=\"headerlink\" title=\"3. Opening (开运算)\"></a><strong>3. Opening (开运算)</strong></h4><ul>\n<li><strong>Mathematical Notation</strong>: ( A \\circ B )<ul>\n<li>( A ): Input image or set.</li>\n<li>( B ): Structuring element (SE).</li>\n</ul>\n</li>\n<li><strong>Definition</strong>:<br>[<br>A \\circ B &#x3D; (A \\ominus B) \\oplus B<br>]<br>Opening is erosion followed by dilation.</li>\n</ul>\n<hr>\n<h4 id=\"4-Closing-闭运算\"><a href=\"#4-Closing-闭运算\" class=\"headerlink\" title=\"4. Closing (闭运算)\"></a><strong>4. Closing (闭运算)</strong></h4><ul>\n<li><strong>Mathematical Notation</strong>: ( A \\bullet B )<ul>\n<li>( A ): Input image or set.</li>\n<li>( B ): Structuring element (SE).</li>\n</ul>\n</li>\n<li><strong>Definition</strong>:<br>[<br>A \\bullet B &#x3D; (A \\oplus B) \\ominus B<br>]<br>Closing is dilation followed by erosion.</li>\n</ul>\n<hr>\n<h4 id=\"5-Hit-or-Miss-Transformation-击中与未击中变换\"><a href=\"#5-Hit-or-Miss-Transformation-击中与未击中变换\" class=\"headerlink\" title=\"5. Hit-or-Miss Transformation (击中与未击中变换)\"></a><strong>5. Hit-or-Miss Transformation (击中与未击中变换)</strong></h4><ul>\n<li><strong>Mathematical Notation</strong>: ( A \\otimes B )<ul>\n<li>( A ): Input binary image.</li>\n<li>( B ): Structuring element or pattern (composed of ( B_1 ) and ( B_2 )).</li>\n</ul>\n</li>\n<li><strong>Definition</strong>:<br>[<br>A \\otimes B &#x3D; (A \\ominus B_1) \\cap (A^c \\ominus B_2)<br>]<br>Where:<ul>\n<li>( A^c ): Complement of ( A ).</li>\n<li>( B_1, B_2 ): Structuring elements for the object and background, respectively.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"Symbols-Summary\"><a href=\"#Symbols-Summary\" class=\"headerlink\" title=\"Symbols Summary\"></a>Symbols Summary</h3><table>\n<thead>\n<tr>\n<th><strong>Operation</strong></th>\n<th><strong>Symbol</strong></th>\n<th><strong>Formula</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Erosion</strong></td>\n<td>( \\ominus )</td>\n<td>( A \\ominus B &#x3D; { z \\mid (B)_z \\subseteq A } )</td>\n</tr>\n<tr>\n<td><strong>Dilation</strong></td>\n<td>( \\oplus )</td>\n<td>( A \\oplus B &#x3D; { z \\mid (B)_z \\cap A \\neq \\emptyset } )</td>\n</tr>\n<tr>\n<td><strong>Opening</strong></td>\n<td>( \\circ )</td>\n<td>( A \\circ B &#x3D; (A \\ominus B) \\oplus B )</td>\n</tr>\n<tr>\n<td><strong>Closing</strong></td>\n<td>( \\bullet )</td>\n<td>( A \\bullet B &#x3D; (A \\oplus B) \\ominus B )</td>\n</tr>\n<tr>\n<td><strong>Hit-or-Miss</strong></td>\n<td>( \\otimes )</td>\n<td>( A \\otimes B &#x3D; (A \\ominus B_1) \\cap (A^c \\ominus B_2) )</td>\n</tr>\n</tbody></table>\n<hr>\n<h3 id=\"How-to-Write-These-Symbols-in-LaTeX\"><a href=\"#How-to-Write-These-Symbols-in-LaTeX\" class=\"headerlink\" title=\"How to Write These Symbols in LaTeX\"></a>How to Write These Symbols in LaTeX</h3><p>You can easily represent these notations using LaTeX. Here are some examples:</p>\n<ul>\n<li><strong>Erosion</strong>: <code>A \\ominus B</code></li>\n<li><strong>Dilation</strong>: <code>A \\oplus B</code></li>\n<li><strong>Opening</strong>: <code>A \\circ B</code></li>\n<li><strong>Closing</strong>: <code>A \\bullet B</code></li>\n<li><strong>Hit-or-Miss</strong>: <code>A \\otimes B</code></li>\n</ul>\n<hr>\n<h3 id=\"A-Distinguish-Between-Concepts\"><a href=\"#A-Distinguish-Between-Concepts\" class=\"headerlink\" title=\"A Distinguish Between Concepts\"></a>A Distinguish Between Concepts</h3><hr>\n<ol>\n<li><strong>Skeletonizing</strong>: ( \\mathcal{K} ) : ( \\mathcal{K}(A) &#x3D; \\bigcup_{n&#x3D;1}^N (A \\ominus nB) - [(A \\ominus nB) \\circ B] )<br><strong>Definition</strong>: Reduces objects to their centerline representation (skeleton) by iterative erosion and removal of boundary pixels while preserving object connectivity.<br><strong>Purpose</strong>: Captures the fundamental structure of objects for analysis, such as handwriting recognition or shape description.<br><strong>Structural Element (SE)</strong>:  <ul>\n<li>Typically a circular or square SE is used for iterative erosion.  </li>\n<li>Example SE:<br>[<br>\\begin{bmatrix}<br>0 &amp; 1 &amp; 0 \\<br>1 &amp; 1 &amp; 1 \\<br>0 &amp; 1 &amp; 0<br>\\end{bmatrix}<br>]</li>\n</ul>\n</li>\n</ol>\n<hr>\n<ol start=\"2\">\n<li><strong>Thinning</strong>: ( T ) : ( T(A) &#x3D; \\lim_{n \\to N} (A \\ominus nB) )<br><strong>Definition</strong>: Removes outer layers of pixels iteratively, leaving a minimally connected structure that represents the object’s shape.<br><strong>Purpose</strong>: Simplifies shapes while preserving their topology and connectivity. Useful for applications like fingerprint analysis and character recognition.<br><strong>Structural Element (SE)</strong>:  <ul>\n<li>A directional SE is used to iteratively remove pixels layer by layer.  </li>\n<li>Example SE:<br>[<br>\\begin{bmatrix}<br>0 &amp; 0 &amp; 0 \\<br>1 &amp; 1 &amp; 1 \\<br>0 &amp; 0 &amp; 0<br>\\end{bmatrix}<br>]</li>\n</ul>\n</li>\n</ol>\n<hr>\n<ol start=\"3\">\n<li><strong>Shrinking</strong>: ( S ) : ( S(A) &#x3D; { z \\in A \\mid B \\text{ fits within } A_z } )<br><strong>Definition</strong>: Shrinks objects iteratively by removing pixels while ensuring the object does not disconnect or vanish entirely.<br><strong>Purpose</strong>: Reduces objects until they are minimized to a single pixel or central skeleton point. Useful for connected component analysis.<br><strong>Structural Element (SE)</strong>:  <ul>\n<li>A small SE (e.g., 3x3 or 5x5) designed to maintain object connectivity.  </li>\n<li>Example SE:<br>[<br>\\begin{bmatrix}<br>1 &amp; 1 &amp; 1 \\<br>1 &amp; 1 &amp; 1 \\<br>1 &amp; 1 &amp; 1<br>\\end{bmatrix}<br>]</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"Relationships-and-Summary\"><a href=\"#Relationships-and-Summary\" class=\"headerlink\" title=\"Relationships and Summary\"></a>Relationships and Summary</h3><ul>\n<li><strong>Skeletonizing</strong>: Captures the “core” or “centerline” of an object. Involves iterative erosion while preserving connectivity.</li>\n<li><strong>Thinning</strong>: A simpler reduction compared to skeletonizing, focusing on removing boundary layers iteratively.</li>\n<li><strong>Shrinking</strong>: Minimizes objects while maintaining their connectivity, often leading to a single pixel or minimal structure.</li>\n</ul>\n<p>Each operation uses structural elements (SEs) tailored to the object’s geometry and the specific processing goal. These concepts are built upon basic morphological operations like erosion and dilation.</p>\n","excerpt":"","more":"<h3 id=\"Common-Notations-for-Morphological-Operations\"><a href=\"#Common-Notations-for-Morphological-Operations\" class=\"headerlink\" title=\"Common Notations for Morphological Operations\"></a>Common Notations for Morphological Operations</h3><p>Morphological operations have well-defined notations, often derived from set theory or mathematical morphology conventions. Here’s how to represent them using symbols:</p>\n<hr>\n<h4 id=\"1-Erosion-腐蚀\"><a href=\"#1-Erosion-腐蚀\" class=\"headerlink\" title=\"1. Erosion (腐蚀)\"></a><strong>1. Erosion (腐蚀)</strong></h4><ul>\n<li><strong>Mathematical Notation</strong>: ( A \\ominus B )<ul>\n<li>( A ): Input image or set.</li>\n<li>( B ): Structuring element (SE).</li>\n</ul>\n</li>\n<li><strong>Definition</strong>:<br>[<br>A \\ominus B &#x3D; { z \\mid (B)_z \\subseteq A }<br>]<br>Where ( (B)_z ) is the translation of ( B ) to point ( z ), and ( \\subseteq ) indicates that ( B ) fits within ( A ).</li>\n</ul>\n<hr>\n<h4 id=\"2-Dilation-膨胀\"><a href=\"#2-Dilation-膨胀\" class=\"headerlink\" title=\"2. Dilation (膨胀)\"></a><strong>2. Dilation (膨胀)</strong></h4><ul>\n<li><strong>Mathematical Notation</strong>: ( A \\oplus B )<ul>\n<li>( A ): Input image or set.</li>\n<li>( B ): Structuring element (SE).</li>\n</ul>\n</li>\n<li><strong>Definition</strong>:<br>[<br>A \\oplus B &#x3D; { z \\mid (B)_z \\cap A \\neq \\emptyset }<br>]<br>Where ( (B)_z ) is the translation of ( B ) to point ( z ), and ( \\cap ) indicates intersection.</li>\n</ul>\n<hr>\n<h4 id=\"3-Opening-开运算\"><a href=\"#3-Opening-开运算\" class=\"headerlink\" title=\"3. Opening (开运算)\"></a><strong>3. Opening (开运算)</strong></h4><ul>\n<li><strong>Mathematical Notation</strong>: ( A \\circ B )<ul>\n<li>( A ): Input image or set.</li>\n<li>( B ): Structuring element (SE).</li>\n</ul>\n</li>\n<li><strong>Definition</strong>:<br>[<br>A \\circ B &#x3D; (A \\ominus B) \\oplus B<br>]<br>Opening is erosion followed by dilation.</li>\n</ul>\n<hr>\n<h4 id=\"4-Closing-闭运算\"><a href=\"#4-Closing-闭运算\" class=\"headerlink\" title=\"4. Closing (闭运算)\"></a><strong>4. Closing (闭运算)</strong></h4><ul>\n<li><strong>Mathematical Notation</strong>: ( A \\bullet B )<ul>\n<li>( A ): Input image or set.</li>\n<li>( B ): Structuring element (SE).</li>\n</ul>\n</li>\n<li><strong>Definition</strong>:<br>[<br>A \\bullet B &#x3D; (A \\oplus B) \\ominus B<br>]<br>Closing is dilation followed by erosion.</li>\n</ul>\n<hr>\n<h4 id=\"5-Hit-or-Miss-Transformation-击中与未击中变换\"><a href=\"#5-Hit-or-Miss-Transformation-击中与未击中变换\" class=\"headerlink\" title=\"5. Hit-or-Miss Transformation (击中与未击中变换)\"></a><strong>5. Hit-or-Miss Transformation (击中与未击中变换)</strong></h4><ul>\n<li><strong>Mathematical Notation</strong>: ( A \\otimes B )<ul>\n<li>( A ): Input binary image.</li>\n<li>( B ): Structuring element or pattern (composed of ( B_1 ) and ( B_2 )).</li>\n</ul>\n</li>\n<li><strong>Definition</strong>:<br>[<br>A \\otimes B &#x3D; (A \\ominus B_1) \\cap (A^c \\ominus B_2)<br>]<br>Where:<ul>\n<li>( A^c ): Complement of ( A ).</li>\n<li>( B_1, B_2 ): Structuring elements for the object and background, respectively.</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"Symbols-Summary\"><a href=\"#Symbols-Summary\" class=\"headerlink\" title=\"Symbols Summary\"></a>Symbols Summary</h3><table>\n<thead>\n<tr>\n<th><strong>Operation</strong></th>\n<th><strong>Symbol</strong></th>\n<th><strong>Formula</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Erosion</strong></td>\n<td>( \\ominus )</td>\n<td>( A \\ominus B &#x3D; { z \\mid (B)_z \\subseteq A } )</td>\n</tr>\n<tr>\n<td><strong>Dilation</strong></td>\n<td>( \\oplus )</td>\n<td>( A \\oplus B &#x3D; { z \\mid (B)_z \\cap A \\neq \\emptyset } )</td>\n</tr>\n<tr>\n<td><strong>Opening</strong></td>\n<td>( \\circ )</td>\n<td>( A \\circ B &#x3D; (A \\ominus B) \\oplus B )</td>\n</tr>\n<tr>\n<td><strong>Closing</strong></td>\n<td>( \\bullet )</td>\n<td>( A \\bullet B &#x3D; (A \\oplus B) \\ominus B )</td>\n</tr>\n<tr>\n<td><strong>Hit-or-Miss</strong></td>\n<td>( \\otimes )</td>\n<td>( A \\otimes B &#x3D; (A \\ominus B_1) \\cap (A^c \\ominus B_2) )</td>\n</tr>\n</tbody></table>\n<hr>\n<h3 id=\"How-to-Write-These-Symbols-in-LaTeX\"><a href=\"#How-to-Write-These-Symbols-in-LaTeX\" class=\"headerlink\" title=\"How to Write These Symbols in LaTeX\"></a>How to Write These Symbols in LaTeX</h3><p>You can easily represent these notations using LaTeX. Here are some examples:</p>\n<ul>\n<li><strong>Erosion</strong>: <code>A \\ominus B</code></li>\n<li><strong>Dilation</strong>: <code>A \\oplus B</code></li>\n<li><strong>Opening</strong>: <code>A \\circ B</code></li>\n<li><strong>Closing</strong>: <code>A \\bullet B</code></li>\n<li><strong>Hit-or-Miss</strong>: <code>A \\otimes B</code></li>\n</ul>\n<hr>\n<h3 id=\"A-Distinguish-Between-Concepts\"><a href=\"#A-Distinguish-Between-Concepts\" class=\"headerlink\" title=\"A Distinguish Between Concepts\"></a>A Distinguish Between Concepts</h3><hr>\n<ol>\n<li><strong>Skeletonizing</strong>: ( \\mathcal{K} ) : ( \\mathcal{K}(A) &#x3D; \\bigcup_{n&#x3D;1}^N (A \\ominus nB) - [(A \\ominus nB) \\circ B] )<br><strong>Definition</strong>: Reduces objects to their centerline representation (skeleton) by iterative erosion and removal of boundary pixels while preserving object connectivity.<br><strong>Purpose</strong>: Captures the fundamental structure of objects for analysis, such as handwriting recognition or shape description.<br><strong>Structural Element (SE)</strong>:  <ul>\n<li>Typically a circular or square SE is used for iterative erosion.  </li>\n<li>Example SE:<br>[<br>\\begin{bmatrix}<br>0 &amp; 1 &amp; 0 \\<br>1 &amp; 1 &amp; 1 \\<br>0 &amp; 1 &amp; 0<br>\\end{bmatrix}<br>]</li>\n</ul>\n</li>\n</ol>\n<hr>\n<ol start=\"2\">\n<li><strong>Thinning</strong>: ( T ) : ( T(A) &#x3D; \\lim_{n \\to N} (A \\ominus nB) )<br><strong>Definition</strong>: Removes outer layers of pixels iteratively, leaving a minimally connected structure that represents the object’s shape.<br><strong>Purpose</strong>: Simplifies shapes while preserving their topology and connectivity. Useful for applications like fingerprint analysis and character recognition.<br><strong>Structural Element (SE)</strong>:  <ul>\n<li>A directional SE is used to iteratively remove pixels layer by layer.  </li>\n<li>Example SE:<br>[<br>\\begin{bmatrix}<br>0 &amp; 0 &amp; 0 \\<br>1 &amp; 1 &amp; 1 \\<br>0 &amp; 0 &amp; 0<br>\\end{bmatrix}<br>]</li>\n</ul>\n</li>\n</ol>\n<hr>\n<ol start=\"3\">\n<li><strong>Shrinking</strong>: ( S ) : ( S(A) &#x3D; { z \\in A \\mid B \\text{ fits within } A_z } )<br><strong>Definition</strong>: Shrinks objects iteratively by removing pixels while ensuring the object does not disconnect or vanish entirely.<br><strong>Purpose</strong>: Reduces objects until they are minimized to a single pixel or central skeleton point. Useful for connected component analysis.<br><strong>Structural Element (SE)</strong>:  <ul>\n<li>A small SE (e.g., 3x3 or 5x5) designed to maintain object connectivity.  </li>\n<li>Example SE:<br>[<br>\\begin{bmatrix}<br>1 &amp; 1 &amp; 1 \\<br>1 &amp; 1 &amp; 1 \\<br>1 &amp; 1 &amp; 1<br>\\end{bmatrix}<br>]</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"Relationships-and-Summary\"><a href=\"#Relationships-and-Summary\" class=\"headerlink\" title=\"Relationships and Summary\"></a>Relationships and Summary</h3><ul>\n<li><strong>Skeletonizing</strong>: Captures the “core” or “centerline” of an object. Involves iterative erosion while preserving connectivity.</li>\n<li><strong>Thinning</strong>: A simpler reduction compared to skeletonizing, focusing on removing boundary layers iteratively.</li>\n<li><strong>Shrinking</strong>: Minimizes objects while maintaining their connectivity, often leading to a single pixel or minimal structure.</li>\n</ul>\n<p>Each operation uses structural elements (SEs) tailored to the object’s geometry and the specific processing goal. These concepts are built upon basic morphological operations like erosion and dilation.</p>\n"},{"title":"Music tech exploring","date":"2024-08-13T18:19:24.000Z","mathjax":true,"_content":"\n跟音乐相关的ML\n应该先看survey 而不是自己做survey???\n1. survey 17: Deep Learning Techniques for Music Generation – A Survey 17\nhttps://arxiv.org/pdf/1709.01620\n- symbolic AI – dealing with high-level symbolic representations (e.g., chords, harmony. . . ) and processes (harmonization, analysis. . . ); and\n- sub-symbolic AI – dealing with low-level representations (e.g., sound, timbre. . . ) and processes (pitch recognition,\nclassification. . . ).\n![alt text](2024-06-03-Cytoid-AI-Charting/image-1.png)\n(a) Musical score of a C-major scale. (b) Chromagram obtained from the score. (c) Audio recording of the C-major scale played on a piano. (d) Chromagram obtained from the audio recording.\n\n\n4.11.2 One-hot, Many-Hot and to Multi-One-Hot\n\nDataset:\n4.12.2 Datasets and Libraries\n- Classical piano MIDI database http://piano-midi.de/\n\n\n\n# CONCERT 94\nNeural network music composition by prediction: Exploring the benefits of psychoacoustic constraints and multi-scale processing\"\n- estimating the probability of playing the next note\n- generated notes: $P(Y_{n+1}=y_{n+1}|Y_n=y_n, Y_{n−1}=y_{n−1}, Y_{n−2}=y_{n−2},…)$\n  \n# DeepJ 18\n增强改变 Style 和 type\npolyphonic music conditioned on a specific or a mixture of multiple composer styles\n- polyphonic (复调): not monophonic \n\n## Method:\n- previous: comb of RNN, RBM (restricted Boltzmann machines):\n- **Novel**:  Biaxial LSTM\n\nBiaxial LSTM\n1. rep: MIDI $N×T$ \n2. architecture:  $P(Y_{t, n}\\vert Y_{t, n-1}, \\ Y_{t, n-2}, \\ \\ldots, \\ Y_{t-1, N}, \\ Y_{t-1, N-1}, \\ldots, \\ Y_{1, 2}, \\ Y_{1, 1})$\n![alt text](2024-06-03-Cytoid-AI-Charting/image.png)\n\n\n\n\n# Bach 2.0\nhttps://www.sciencedirect.com/science/article/pii/S1877050919313444?via%3Dihub\n\n# ISMIR\nhttps://ismir.net/conferences/\n\n# Prof Shlomo Dubnov\nGoogle scholar: https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=NJfiIl8AAAAJ&sortby=pubdate\nWebpage: http://shlomodubnov.wikidot.com/research\n\n# prof Gus Xia 的讲座\nhttps://www.youtube.com/watch?v=dPeh3XVlmlE\n## Intro: pitches tuning: \npythagorean tuning: 三分损益法， 五度相生律\nOctave 2：1 with fifth 3:2\n八度 2：1， 五度3：2\n十二平均律： $2^{(x/12)}$\n\n## AI+ Music listening \n### Fingerprint \nExtraction Algorithm: Philips (2002)\n![alt text](2024-08-12-Music-tech-exploring/image.png)\n傅里叶分析什么的\nShort-time fourier transform \nFFT size 0.37\nHanning window\n### Query by Humming\n1. partial matching\n2. fuzzy match\n3. out of pitch\n\nMIDI + 合成器\nMIDI(straigthforward like a string) != Audio (quantization)\n\nAbsolute pitch\nrelatice pitch\nIOI(Inter Onset Interval) ratio\n\nDynamic programming\nPattern recognition:\n### Features \nspectrum(energy at diss frequencies), MFCC, Zero crossing, Chroma, Estimtates of tempo\nchromagram, spectrogram \n![alt text](2024-08-12-Music-tech-exploring/image-1.png)\n## AI+ Music Composition\nAlgorithmic composition\n\nCanon, \n### Deterministic\nFractal:分型\n### Stochastic process\n### ML: Music as sequence\n### Mapping natural phenomena ot music \n\n## AI+ Music Composition\n\n\n\n# Fugue\n在赋格中，基本元素包括：\n\n主题 (Subject)：赋格开始时由一个声部提出的旋律动机。\n答题 (Answer)：另一声部紧接主题以模仿的形式进入，一般会转调至属音。\n对题 (Countersubject)：伴随答题出现的第二个旋律动机。\n插段 (Episode)：主题和答题出现后，插入的自由发展段落。\ncodetta\ninterlude\n赋格的陈述部分 (Exposition) 是其最严格的部分，之后的段落则允许更自由的变化。作曲家可以通过各种技术手段如加倍 (augmentation)、减缩 (diminution)、倒影 (inversion) 和紧缩 (stretto) 来改变主题的原型。\n\n\n# Fourier Transform\nhttps://ltyxh.com/blog/2022/05/17/%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF4/\n这个系列讲的特别清楚\n\n\n# VAE\n从0教你VAE：\n    - 交叉熵与KL散度(信息论)：\n        - https://zhuanlan.zhihu.com/p/345025351 \n            - $I(x) = K log(P(x)), K<0$ Information\n            - $H(p) = -\\sum p(x_i)logp(x_i)$ Entropy\n        - https://zhuanlan.zhihu.com/p/346518942\n    - MSE, 0-1 loss, Logistic loss:\n        -  https://zhuanlan.zhihu.com/p/346935187\n    - VAE：\n        - https://zhuanlan.zhihu.com/p/348498294\n        - https://zhuanlan.zhihu.com/p/34998569\n        - VAE讲解：https://www.zhangzhenhu.com/aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html\n\n## Loss Functions\nCross Entropy Loss:\n$H(p, q) = \\mathbb{E}_{X \\sim p(X)} \\left[ - \\log q(X) \\right].\\\\$\n\nKL Divergence:\n对于离散随机变量，分布$p$和$q$的KL散度的定义如下：\n\n$D_{K L}(p \\| q) = -\\sum_{i=1}^{n} p(x_{i}) \\cdot \\log \\frac{q(x_{i})}{p(x_{i})}.\\\\$\n\n对KL散度在信息论中的一个直观的理解是将其写开，即\n\n$\\begin{aligned} D_{K L}(p \\| q) &= -\\sum_{i=1}^{n} p(x_{i}) \\cdot \\log \\frac{q(x_{i})}{p(x_{i})} \\\\                 &= -\\sum_{i=1}^{n} p(x_{i}) \\cdot \\log q(x_{i}) + \\sum_{i=1}^{n} p(x_{i}) \\cdot \\log p(x_{i}) \\\\                 &= H(p,q) - H(p). \\end{aligned}\\\\$\n\n## 好东西，，\nloss详解\nhttps://www.zhihu.com/column/c_1334301979816820736\n\n除了我都会，，图神经网络\nhttps://www.zhihu.com/column/c_1322582255018184704\n\n\n## VAE\n总的来说觉得x和z是对称的，但x可采样，打破对称性。\n但是不是的，，\n\n## 讲得很好\nDDPM视频：https://www.bilibili.com/video/BV1p24y1K7Pf?spm_id_from=333.788.videopod.sections&vd_source=441679270dda23308fe16f3c5602b058\n文章：https://www.bilibili.com/read/cv23338176/?jump_opus=1\n知乎版本： https://zhuanlan.zhihu.com/p/624851115\n\n\node和可视化： https://developer.nvidia.com/blog/generative-ai-research-spotlight-demystifying-diffusion-based-models/\n\n# Diffusion model \n介绍了consisitency model, VAE, Diffusion model , stable diffusion, LoRA, Latent Consistency Model 之间的关系，\n从头讲解的Consistency model 的原理\nhttps://wrong.wang/blog/20220605-%E4%BB%80%E4%B9%88%E6%98%AFdiffusion%E6%A8%A1%E5%9E%8B/\n\n\n\nhttps://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0speed_sd.html\n\nhttps://lilianweng.github.io/posts/2021-07-11-diffusion-models/\n\n# Consisitency Diffusion\nhttps://wrong.wang/blog/20231111-consistency-is-all-you-need/\nhttps://zhuanlan.zhihu.com/p/692998238\nhttps://zhuanlan.zhihu.com/p/706862530\n# DIFF-A-RIFF: Musical Acoompanimetn via latent diffusion models\n1. Consistency Autoencoder\n2. Elucidated Diffusion Models (EDMs)\n   \nRelated: \n1. End-to-End Autoregressive model:\n    - high fidelity and ability to produce coherent, long-range sequences\n    - expensive cost for calculateion\n    - GANs/VAEs are faster but limiting fidelity\n    - Denoising Difussion Implicit Models:\n2. Latent models\n    -  \n3. Control Mechanism\n   - Music ControlNet\n   - \n\n\n\n\n# Flow matching\n\n\n\n# Score matching \nscore\n$\\nabla_x log p_\\sigma(x)$\n\nhttps://www.zhangzhenhu.com/aigc/Guidance.html\n\n\n\n\n\n\n\n\n\n\n\n\n看到奇怪的人： https://www.zhihu.com/people/labsig\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nzou教授发的三篇论文\nhttps://arxiv.org/pdf/2406.08384\n \nhttps://arxiv.org/pdf/2405.18503\n \nhttps://openreview.net/pdf?id=mUVydzrkgz\n \n\n\n\n\n\n\n\n\n\n","source":"_posts/2024-08-12-Music-tech-exploring.md","raw":"---\ntitle: Music tech exploring\ndate: 2024-08-13 14:19:24\ntags:\nmathjax: true\n---\n\n跟音乐相关的ML\n应该先看survey 而不是自己做survey???\n1. survey 17: Deep Learning Techniques for Music Generation – A Survey 17\nhttps://arxiv.org/pdf/1709.01620\n- symbolic AI – dealing with high-level symbolic representations (e.g., chords, harmony. . . ) and processes (harmonization, analysis. . . ); and\n- sub-symbolic AI – dealing with low-level representations (e.g., sound, timbre. . . ) and processes (pitch recognition,\nclassification. . . ).\n![alt text](2024-06-03-Cytoid-AI-Charting/image-1.png)\n(a) Musical score of a C-major scale. (b) Chromagram obtained from the score. (c) Audio recording of the C-major scale played on a piano. (d) Chromagram obtained from the audio recording.\n\n\n4.11.2 One-hot, Many-Hot and to Multi-One-Hot\n\nDataset:\n4.12.2 Datasets and Libraries\n- Classical piano MIDI database http://piano-midi.de/\n\n\n\n# CONCERT 94\nNeural network music composition by prediction: Exploring the benefits of psychoacoustic constraints and multi-scale processing\"\n- estimating the probability of playing the next note\n- generated notes: $P(Y_{n+1}=y_{n+1}|Y_n=y_n, Y_{n−1}=y_{n−1}, Y_{n−2}=y_{n−2},…)$\n  \n# DeepJ 18\n增强改变 Style 和 type\npolyphonic music conditioned on a specific or a mixture of multiple composer styles\n- polyphonic (复调): not monophonic \n\n## Method:\n- previous: comb of RNN, RBM (restricted Boltzmann machines):\n- **Novel**:  Biaxial LSTM\n\nBiaxial LSTM\n1. rep: MIDI $N×T$ \n2. architecture:  $P(Y_{t, n}\\vert Y_{t, n-1}, \\ Y_{t, n-2}, \\ \\ldots, \\ Y_{t-1, N}, \\ Y_{t-1, N-1}, \\ldots, \\ Y_{1, 2}, \\ Y_{1, 1})$\n![alt text](2024-06-03-Cytoid-AI-Charting/image.png)\n\n\n\n\n# Bach 2.0\nhttps://www.sciencedirect.com/science/article/pii/S1877050919313444?via%3Dihub\n\n# ISMIR\nhttps://ismir.net/conferences/\n\n# Prof Shlomo Dubnov\nGoogle scholar: https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=NJfiIl8AAAAJ&sortby=pubdate\nWebpage: http://shlomodubnov.wikidot.com/research\n\n# prof Gus Xia 的讲座\nhttps://www.youtube.com/watch?v=dPeh3XVlmlE\n## Intro: pitches tuning: \npythagorean tuning: 三分损益法， 五度相生律\nOctave 2：1 with fifth 3:2\n八度 2：1， 五度3：2\n十二平均律： $2^{(x/12)}$\n\n## AI+ Music listening \n### Fingerprint \nExtraction Algorithm: Philips (2002)\n![alt text](2024-08-12-Music-tech-exploring/image.png)\n傅里叶分析什么的\nShort-time fourier transform \nFFT size 0.37\nHanning window\n### Query by Humming\n1. partial matching\n2. fuzzy match\n3. out of pitch\n\nMIDI + 合成器\nMIDI(straigthforward like a string) != Audio (quantization)\n\nAbsolute pitch\nrelatice pitch\nIOI(Inter Onset Interval) ratio\n\nDynamic programming\nPattern recognition:\n### Features \nspectrum(energy at diss frequencies), MFCC, Zero crossing, Chroma, Estimtates of tempo\nchromagram, spectrogram \n![alt text](2024-08-12-Music-tech-exploring/image-1.png)\n## AI+ Music Composition\nAlgorithmic composition\n\nCanon, \n### Deterministic\nFractal:分型\n### Stochastic process\n### ML: Music as sequence\n### Mapping natural phenomena ot music \n\n## AI+ Music Composition\n\n\n\n# Fugue\n在赋格中，基本元素包括：\n\n主题 (Subject)：赋格开始时由一个声部提出的旋律动机。\n答题 (Answer)：另一声部紧接主题以模仿的形式进入，一般会转调至属音。\n对题 (Countersubject)：伴随答题出现的第二个旋律动机。\n插段 (Episode)：主题和答题出现后，插入的自由发展段落。\ncodetta\ninterlude\n赋格的陈述部分 (Exposition) 是其最严格的部分，之后的段落则允许更自由的变化。作曲家可以通过各种技术手段如加倍 (augmentation)、减缩 (diminution)、倒影 (inversion) 和紧缩 (stretto) 来改变主题的原型。\n\n\n# Fourier Transform\nhttps://ltyxh.com/blog/2022/05/17/%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF4/\n这个系列讲的特别清楚\n\n\n# VAE\n从0教你VAE：\n    - 交叉熵与KL散度(信息论)：\n        - https://zhuanlan.zhihu.com/p/345025351 \n            - $I(x) = K log(P(x)), K<0$ Information\n            - $H(p) = -\\sum p(x_i)logp(x_i)$ Entropy\n        - https://zhuanlan.zhihu.com/p/346518942\n    - MSE, 0-1 loss, Logistic loss:\n        -  https://zhuanlan.zhihu.com/p/346935187\n    - VAE：\n        - https://zhuanlan.zhihu.com/p/348498294\n        - https://zhuanlan.zhihu.com/p/34998569\n        - VAE讲解：https://www.zhangzhenhu.com/aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html\n\n## Loss Functions\nCross Entropy Loss:\n$H(p, q) = \\mathbb{E}_{X \\sim p(X)} \\left[ - \\log q(X) \\right].\\\\$\n\nKL Divergence:\n对于离散随机变量，分布$p$和$q$的KL散度的定义如下：\n\n$D_{K L}(p \\| q) = -\\sum_{i=1}^{n} p(x_{i}) \\cdot \\log \\frac{q(x_{i})}{p(x_{i})}.\\\\$\n\n对KL散度在信息论中的一个直观的理解是将其写开，即\n\n$\\begin{aligned} D_{K L}(p \\| q) &= -\\sum_{i=1}^{n} p(x_{i}) \\cdot \\log \\frac{q(x_{i})}{p(x_{i})} \\\\                 &= -\\sum_{i=1}^{n} p(x_{i}) \\cdot \\log q(x_{i}) + \\sum_{i=1}^{n} p(x_{i}) \\cdot \\log p(x_{i}) \\\\                 &= H(p,q) - H(p). \\end{aligned}\\\\$\n\n## 好东西，，\nloss详解\nhttps://www.zhihu.com/column/c_1334301979816820736\n\n除了我都会，，图神经网络\nhttps://www.zhihu.com/column/c_1322582255018184704\n\n\n## VAE\n总的来说觉得x和z是对称的，但x可采样，打破对称性。\n但是不是的，，\n\n## 讲得很好\nDDPM视频：https://www.bilibili.com/video/BV1p24y1K7Pf?spm_id_from=333.788.videopod.sections&vd_source=441679270dda23308fe16f3c5602b058\n文章：https://www.bilibili.com/read/cv23338176/?jump_opus=1\n知乎版本： https://zhuanlan.zhihu.com/p/624851115\n\n\node和可视化： https://developer.nvidia.com/blog/generative-ai-research-spotlight-demystifying-diffusion-based-models/\n\n# Diffusion model \n介绍了consisitency model, VAE, Diffusion model , stable diffusion, LoRA, Latent Consistency Model 之间的关系，\n从头讲解的Consistency model 的原理\nhttps://wrong.wang/blog/20220605-%E4%BB%80%E4%B9%88%E6%98%AFdiffusion%E6%A8%A1%E5%9E%8B/\n\n\n\nhttps://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0speed_sd.html\n\nhttps://lilianweng.github.io/posts/2021-07-11-diffusion-models/\n\n# Consisitency Diffusion\nhttps://wrong.wang/blog/20231111-consistency-is-all-you-need/\nhttps://zhuanlan.zhihu.com/p/692998238\nhttps://zhuanlan.zhihu.com/p/706862530\n# DIFF-A-RIFF: Musical Acoompanimetn via latent diffusion models\n1. Consistency Autoencoder\n2. Elucidated Diffusion Models (EDMs)\n   \nRelated: \n1. End-to-End Autoregressive model:\n    - high fidelity and ability to produce coherent, long-range sequences\n    - expensive cost for calculateion\n    - GANs/VAEs are faster but limiting fidelity\n    - Denoising Difussion Implicit Models:\n2. Latent models\n    -  \n3. Control Mechanism\n   - Music ControlNet\n   - \n\n\n\n\n# Flow matching\n\n\n\n# Score matching \nscore\n$\\nabla_x log p_\\sigma(x)$\n\nhttps://www.zhangzhenhu.com/aigc/Guidance.html\n\n\n\n\n\n\n\n\n\n\n\n\n看到奇怪的人： https://www.zhihu.com/people/labsig\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nzou教授发的三篇论文\nhttps://arxiv.org/pdf/2406.08384\n \nhttps://arxiv.org/pdf/2405.18503\n \nhttps://openreview.net/pdf?id=mUVydzrkgz\n \n\n\n\n\n\n\n\n\n\n","slug":"2024-08-12-Music-tech-exploring","published":1,"updated":"2024-12-15T03:50:02.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagpv0011zc3dghi88hwr","content":"<p>跟音乐相关的ML<br>应该先看survey 而不是自己做survey???</p>\n<ol>\n<li>survey 17: Deep Learning Techniques for Music Generation – A Survey 17<br><a href=\"https://arxiv.org/pdf/1709.01620\">https://arxiv.org/pdf/1709.01620</a></li>\n</ol>\n<ul>\n<li>symbolic AI – dealing with high-level symbolic representations (e.g., chords, harmony. . . ) and processes (harmonization, analysis. . . ); and</li>\n<li>sub-symbolic AI – dealing with low-level representations (e.g., sound, timbre. . . ) and processes (pitch recognition,<br>classification. . . ).<br><img src=\"/2024-06-03-Cytoid-AI-Charting/image-1.png\" alt=\"alt text\"><br>(a) Musical score of a C-major scale. (b) Chromagram obtained from the score. (c) Audio recording of the C-major scale played on a piano. (d) Chromagram obtained from the audio recording.</li>\n</ul>\n<p>4.11.2 One-hot, Many-Hot and to Multi-One-Hot</p>\n<p>Dataset:<br>4.12.2 Datasets and Libraries</p>\n<ul>\n<li>Classical piano MIDI database <a href=\"http://piano-midi.de/\">http://piano-midi.de/</a></li>\n</ul>\n<h1 id=\"CONCERT-94\"><a href=\"#CONCERT-94\" class=\"headerlink\" title=\"CONCERT 94\"></a>CONCERT 94</h1><p>Neural network music composition by prediction: Exploring the benefits of psychoacoustic constraints and multi-scale processing”</p>\n<ul>\n<li>estimating the probability of playing the next note</li>\n<li>generated notes: $P(Y_{n+1}&#x3D;y_{n+1}|Y_n&#x3D;y_n, Y_{n−1}&#x3D;y_{n−1}, Y_{n−2}&#x3D;y_{n−2},…)$</li>\n</ul>\n<h1 id=\"DeepJ-18\"><a href=\"#DeepJ-18\" class=\"headerlink\" title=\"DeepJ 18\"></a>DeepJ 18</h1><p>增强改变 Style 和 type<br>polyphonic music conditioned on a specific or a mixture of multiple composer styles</p>\n<ul>\n<li>polyphonic (复调): not monophonic</li>\n</ul>\n<h2 id=\"Method\"><a href=\"#Method\" class=\"headerlink\" title=\"Method:\"></a>Method:</h2><ul>\n<li>previous: comb of RNN, RBM (restricted Boltzmann machines):</li>\n<li><strong>Novel</strong>:  Biaxial LSTM</li>\n</ul>\n<p>Biaxial LSTM</p>\n<ol>\n<li>rep: MIDI $N×T$ </li>\n<li>architecture:  $P(Y_{t, n}\\vert Y_{t, n-1}, \\ Y_{t, n-2}, \\ \\ldots, \\ Y_{t-1, N}, \\ Y_{t-1, N-1}, \\ldots, \\ Y_{1, 2}, \\ Y_{1, 1})$<br><img src=\"/2024-06-03-Cytoid-AI-Charting/image.png\" alt=\"alt text\"></li>\n</ol>\n<h1 id=\"Bach-2-0\"><a href=\"#Bach-2-0\" class=\"headerlink\" title=\"Bach 2.0\"></a>Bach 2.0</h1><p><a href=\"https://www.sciencedirect.com/science/article/pii/S1877050919313444?via=ihub\">https://www.sciencedirect.com/science/article/pii/S1877050919313444?via%3Dihub</a></p>\n<h1 id=\"ISMIR\"><a href=\"#ISMIR\" class=\"headerlink\" title=\"ISMIR\"></a>ISMIR</h1><p><a href=\"https://ismir.net/conferences/\">https://ismir.net/conferences/</a></p>\n<h1 id=\"Prof-Shlomo-Dubnov\"><a href=\"#Prof-Shlomo-Dubnov\" class=\"headerlink\" title=\"Prof Shlomo Dubnov\"></a>Prof Shlomo Dubnov</h1><p>Google scholar: <a href=\"https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=NJfiIl8AAAAJ&sortby=pubdate\">https://scholar.google.com/citations?view_op=list_works&amp;hl=en&amp;hl=en&amp;user=NJfiIl8AAAAJ&amp;sortby=pubdate</a><br>Webpage: <a href=\"http://shlomodubnov.wikidot.com/research\">http://shlomodubnov.wikidot.com/research</a></p>\n<h1 id=\"prof-Gus-Xia-的讲座\"><a href=\"#prof-Gus-Xia-的讲座\" class=\"headerlink\" title=\"prof Gus Xia 的讲座\"></a>prof Gus Xia 的讲座</h1><p><a href=\"https://www.youtube.com/watch?v=dPeh3XVlmlE\">https://www.youtube.com/watch?v=dPeh3XVlmlE</a></p>\n<h2 id=\"Intro-pitches-tuning\"><a href=\"#Intro-pitches-tuning\" class=\"headerlink\" title=\"Intro: pitches tuning:\"></a>Intro: pitches tuning:</h2><p>pythagorean tuning: 三分损益法， 五度相生律<br>Octave 2：1 with fifth 3:2<br>八度 2：1， 五度3：2<br>十二平均律： $2^{(x&#x2F;12)}$</p>\n<h2 id=\"AI-Music-listening\"><a href=\"#AI-Music-listening\" class=\"headerlink\" title=\"AI+ Music listening\"></a>AI+ Music listening</h2><h3 id=\"Fingerprint\"><a href=\"#Fingerprint\" class=\"headerlink\" title=\"Fingerprint\"></a>Fingerprint</h3><p>Extraction Algorithm: Philips (2002)<br><img src=\"/2024-08-12-Music-tech-exploring/image.png\" alt=\"alt text\"><br>傅里叶分析什么的<br>Short-time fourier transform<br>FFT size 0.37<br>Hanning window</p>\n<h3 id=\"Query-by-Humming\"><a href=\"#Query-by-Humming\" class=\"headerlink\" title=\"Query by Humming\"></a>Query by Humming</h3><ol>\n<li>partial matching</li>\n<li>fuzzy match</li>\n<li>out of pitch</li>\n</ol>\n<p>MIDI + 合成器<br>MIDI(straigthforward like a string) !&#x3D; Audio (quantization)</p>\n<p>Absolute pitch<br>relatice pitch<br>IOI(Inter Onset Interval) ratio</p>\n<p>Dynamic programming<br>Pattern recognition:</p>\n<h3 id=\"Features\"><a href=\"#Features\" class=\"headerlink\" title=\"Features\"></a>Features</h3><p>spectrum(energy at diss frequencies), MFCC, Zero crossing, Chroma, Estimtates of tempo<br>chromagram, spectrogram<br><img src=\"/2024-08-12-Music-tech-exploring/image-1.png\" alt=\"alt text\"></p>\n<h2 id=\"AI-Music-Composition\"><a href=\"#AI-Music-Composition\" class=\"headerlink\" title=\"AI+ Music Composition\"></a>AI+ Music Composition</h2><p>Algorithmic composition</p>\n<p>Canon, </p>\n<h3 id=\"Deterministic\"><a href=\"#Deterministic\" class=\"headerlink\" title=\"Deterministic\"></a>Deterministic</h3><p>Fractal:分型</p>\n<h3 id=\"Stochastic-process\"><a href=\"#Stochastic-process\" class=\"headerlink\" title=\"Stochastic process\"></a>Stochastic process</h3><h3 id=\"ML-Music-as-sequence\"><a href=\"#ML-Music-as-sequence\" class=\"headerlink\" title=\"ML: Music as sequence\"></a>ML: Music as sequence</h3><h3 id=\"Mapping-natural-phenomena-ot-music\"><a href=\"#Mapping-natural-phenomena-ot-music\" class=\"headerlink\" title=\"Mapping natural phenomena ot music\"></a>Mapping natural phenomena ot music</h3><h2 id=\"AI-Music-Composition-1\"><a href=\"#AI-Music-Composition-1\" class=\"headerlink\" title=\"AI+ Music Composition\"></a>AI+ Music Composition</h2><h1 id=\"Fugue\"><a href=\"#Fugue\" class=\"headerlink\" title=\"Fugue\"></a>Fugue</h1><p>在赋格中，基本元素包括：</p>\n<p>主题 (Subject)：赋格开始时由一个声部提出的旋律动机。<br>答题 (Answer)：另一声部紧接主题以模仿的形式进入，一般会转调至属音。<br>对题 (Countersubject)：伴随答题出现的第二个旋律动机。<br>插段 (Episode)：主题和答题出现后，插入的自由发展段落。<br>codetta<br>interlude<br>赋格的陈述部分 (Exposition) 是其最严格的部分，之后的段落则允许更自由的变化。作曲家可以通过各种技术手段如加倍 (augmentation)、减缩 (diminution)、倒影 (inversion) 和紧缩 (stretto) 来改变主题的原型。</p>\n<h1 id=\"Fourier-Transform\"><a href=\"#Fourier-Transform\" class=\"headerlink\" title=\"Fourier Transform\"></a>Fourier Transform</h1><p><a href=\"https://ltyxh.com/blog/2022/05/17/%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF4/\">https://ltyxh.com/blog/2022/05/17/%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF4/</a><br>这个系列讲的特别清楚</p>\n<h1 id=\"VAE\"><a href=\"#VAE\" class=\"headerlink\" title=\"VAE\"></a>VAE</h1><p>从0教你VAE：<br>    - 交叉熵与KL散度(信息论)：<br>        - <a href=\"https://zhuanlan.zhihu.com/p/345025351\">https://zhuanlan.zhihu.com/p/345025351</a><br>            - $I(x) &#x3D; K log(P(x)), K&lt;0$ Information<br>            - $H(p) &#x3D; -\\sum p(x_i)logp(x_i)$ Entropy<br>        - <a href=\"https://zhuanlan.zhihu.com/p/346518942\">https://zhuanlan.zhihu.com/p/346518942</a><br>    - MSE, 0-1 loss, Logistic loss:<br>        -  <a href=\"https://zhuanlan.zhihu.com/p/346935187\">https://zhuanlan.zhihu.com/p/346935187</a><br>    - VAE：<br>        - <a href=\"https://zhuanlan.zhihu.com/p/348498294\">https://zhuanlan.zhihu.com/p/348498294</a><br>        - <a href=\"https://zhuanlan.zhihu.com/p/34998569\">https://zhuanlan.zhihu.com/p/34998569</a><br>        - VAE讲解：<a href=\"https://www.zhangzhenhu.com/aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html\">https://www.zhangzhenhu.com/aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html</a></p>\n<h2 id=\"Loss-Functions\"><a href=\"#Loss-Functions\" class=\"headerlink\" title=\"Loss Functions\"></a>Loss Functions</h2><p>Cross Entropy Loss:<br>$H(p, q) &#x3D; \\mathbb{E}_{X \\sim p(X)} \\left[ - \\log q(X) \\right].\\$</p>\n<p>KL Divergence:<br>对于离散随机变量，分布$p$和$q$的KL散度的定义如下：</p>\n<p>$D_{K L}(p | q) &#x3D; -\\sum_{i&#x3D;1}^{n} p(x_{i}) \\cdot \\log \\frac{q(x_{i})}{p(x_{i})}.\\$</p>\n<p>对KL散度在信息论中的一个直观的理解是将其写开，即</p>\n<p>$\\begin{aligned} D_{K L}(p | q) &amp;&#x3D; -\\sum_{i&#x3D;1}^{n} p(x_{i}) \\cdot \\log \\frac{q(x_{i})}{p(x_{i})} \\                 &amp;&#x3D; -\\sum_{i&#x3D;1}^{n} p(x_{i}) \\cdot \\log q(x_{i}) + \\sum_{i&#x3D;1}^{n} p(x_{i}) \\cdot \\log p(x_{i}) \\                 &amp;&#x3D; H(p,q) - H(p). \\end{aligned}\\$</p>\n<h2 id=\"好东西，，\"><a href=\"#好东西，，\" class=\"headerlink\" title=\"好东西，，\"></a>好东西，，</h2><p>loss详解<br><a href=\"https://www.zhihu.com/column/c_1334301979816820736\">https://www.zhihu.com/column/c_1334301979816820736</a></p>\n<p>除了我都会，，图神经网络<br><a href=\"https://www.zhihu.com/column/c_1322582255018184704\">https://www.zhihu.com/column/c_1322582255018184704</a></p>\n<h2 id=\"VAE-1\"><a href=\"#VAE-1\" class=\"headerlink\" title=\"VAE\"></a>VAE</h2><p>总的来说觉得x和z是对称的，但x可采样，打破对称性。<br>但是不是的，，</p>\n<h2 id=\"讲得很好\"><a href=\"#讲得很好\" class=\"headerlink\" title=\"讲得很好\"></a>讲得很好</h2><p>DDPM视频：<a href=\"https://www.bilibili.com/video/BV1p24y1K7Pf?spm_id_from=333.788.videopod.sections&vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1p24y1K7Pf?spm_id_from=333.788.videopod.sections&amp;vd_source=441679270dda23308fe16f3c5602b058</a><br>文章：<a href=\"https://www.bilibili.com/read/cv23338176/?jump_opus=1\">https://www.bilibili.com/read/cv23338176/?jump_opus=1</a><br>知乎版本： <a href=\"https://zhuanlan.zhihu.com/p/624851115\">https://zhuanlan.zhihu.com/p/624851115</a></p>\n<p>ode和可视化： <a href=\"https://developer.nvidia.com/blog/generative-ai-research-spotlight-demystifying-diffusion-based-models/\">https://developer.nvidia.com/blog/generative-ai-research-spotlight-demystifying-diffusion-based-models/</a></p>\n<h1 id=\"Diffusion-model\"><a href=\"#Diffusion-model\" class=\"headerlink\" title=\"Diffusion model\"></a>Diffusion model</h1><p>介绍了consisitency model, VAE, Diffusion model , stable diffusion, LoRA, Latent Consistency Model 之间的关系，<br>从头讲解的Consistency model 的原理<br><a href=\"https://wrong.wang/blog/20220605-%E4%BB%80%E4%B9%88%E6%98%AFdiffusion%E6%A8%A1%E5%9E%8B/\">https://wrong.wang/blog/20220605-%E4%BB%80%E4%B9%88%E6%98%AFdiffusion%E6%A8%A1%E5%9E%8B/</a></p>\n<p><a href=\"https://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0speed_sd.html\">https://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0speed_sd.html</a></p>\n<p><a href=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\">https://lilianweng.github.io/posts/2021-07-11-diffusion-models/</a></p>\n<h1 id=\"Consisitency-Diffusion\"><a href=\"#Consisitency-Diffusion\" class=\"headerlink\" title=\"Consisitency Diffusion\"></a>Consisitency Diffusion</h1><h2 id=\"https-wrong-wang-blog-20231111-consistency-is-all-you-need-https-zhuanlan-zhihu-com-p-692998238https-zhuanlan-zhihu-com-p-706862530-DIFF-A-RIFF-Musical-Acoompanimetn-via-latent-diffusion-models1-Consistency-Autoencoder2-Elucidated-Diffusion-Models-EDMs-Related-1-End-to-End-Autoregressive-model-high-fidelity-and-ability-to-produce-coherent-long-range-sequences-expensive-cost-for-calculateion-GANs-VAEs-are-faster-but-limiting-fidelity-Denoising-Difussion-Implicit-Models-2-Latent-models-3-Control-Mechanism-Music-ControlNet\"><a href=\"#https-wrong-wang-blog-20231111-consistency-is-all-you-need-https-zhuanlan-zhihu-com-p-692998238https-zhuanlan-zhihu-com-p-706862530-DIFF-A-RIFF-Musical-Acoompanimetn-via-latent-diffusion-models1-Consistency-Autoencoder2-Elucidated-Diffusion-Models-EDMs-Related-1-End-to-End-Autoregressive-model-high-fidelity-and-ability-to-produce-coherent-long-range-sequences-expensive-cost-for-calculateion-GANs-VAEs-are-faster-but-limiting-fidelity-Denoising-Difussion-Implicit-Models-2-Latent-models-3-Control-Mechanism-Music-ControlNet\" class=\"headerlink\" title=\"https://wrong.wang/blog/20231111-consistency-is-all-you-need/https://zhuanlan.zhihu.com/p/692998238https://zhuanlan.zhihu.com/p/706862530# DIFF-A-RIFF: Musical Acoompanimetn via latent diffusion models1. Consistency Autoencoder2. Elucidated Diffusion Models (EDMs)Related:1. End-to-End Autoregressive model:    - high fidelity and ability to produce coherent, long-range sequences    - expensive cost for calculateion    - GANs&#x2F;VAEs are faster but limiting fidelity    - Denoising Difussion Implicit Models:2. Latent models    -3. Control Mechanism   - Music ControlNet\"></a><a href=\"https://wrong.wang/blog/20231111-consistency-is-all-you-need/\">https://wrong.wang/blog/20231111-consistency-is-all-you-need/</a><br><a href=\"https://zhuanlan.zhihu.com/p/692998238\">https://zhuanlan.zhihu.com/p/692998238</a><br><a href=\"https://zhuanlan.zhihu.com/p/706862530\">https://zhuanlan.zhihu.com/p/706862530</a><br># DIFF-A-RIFF: Musical Acoompanimetn via latent diffusion models<br>1. Consistency Autoencoder<br>2. Elucidated Diffusion Models (EDMs)<br><br>Related:<br>1. End-to-End Autoregressive model:<br>    - high fidelity and ability to produce coherent, long-range sequences<br>    - expensive cost for calculateion<br>    - GANs&#x2F;VAEs are faster but limiting fidelity<br>    - Denoising Difussion Implicit Models:<br>2. Latent models<br>    -<br>3. Control Mechanism<br>   - Music ControlNet</h2><h1 id=\"Flow-matching\"><a href=\"#Flow-matching\" class=\"headerlink\" title=\"Flow matching\"></a>Flow matching</h1><h1 id=\"Score-matching\"><a href=\"#Score-matching\" class=\"headerlink\" title=\"Score matching\"></a>Score matching</h1><p>score<br>$\\nabla_x log p_\\sigma(x)$</p>\n<p><a href=\"https://www.zhangzhenhu.com/aigc/Guidance.html\">https://www.zhangzhenhu.com/aigc/Guidance.html</a></p>\n<p>看到奇怪的人： <a href=\"https://www.zhihu.com/people/labsig\">https://www.zhihu.com/people/labsig</a></p>\n<p>zou教授发的三篇论文<br><a href=\"https://arxiv.org/pdf/2406.08384\">https://arxiv.org/pdf/2406.08384</a></p>\n<p><a href=\"https://arxiv.org/pdf/2405.18503\">https://arxiv.org/pdf/2405.18503</a></p>\n<p><a href=\"https://openreview.net/pdf?id=mUVydzrkgz\">https://openreview.net/pdf?id=mUVydzrkgz</a></p>\n","excerpt":"","more":"<p>跟音乐相关的ML<br>应该先看survey 而不是自己做survey???</p>\n<ol>\n<li>survey 17: Deep Learning Techniques for Music Generation – A Survey 17<br><a href=\"https://arxiv.org/pdf/1709.01620\">https://arxiv.org/pdf/1709.01620</a></li>\n</ol>\n<ul>\n<li>symbolic AI – dealing with high-level symbolic representations (e.g., chords, harmony. . . ) and processes (harmonization, analysis. . . ); and</li>\n<li>sub-symbolic AI – dealing with low-level representations (e.g., sound, timbre. . . ) and processes (pitch recognition,<br>classification. . . ).<br><img src=\"/2024-06-03-Cytoid-AI-Charting/image-1.png\" alt=\"alt text\"><br>(a) Musical score of a C-major scale. (b) Chromagram obtained from the score. (c) Audio recording of the C-major scale played on a piano. (d) Chromagram obtained from the audio recording.</li>\n</ul>\n<p>4.11.2 One-hot, Many-Hot and to Multi-One-Hot</p>\n<p>Dataset:<br>4.12.2 Datasets and Libraries</p>\n<ul>\n<li>Classical piano MIDI database <a href=\"http://piano-midi.de/\">http://piano-midi.de/</a></li>\n</ul>\n<h1 id=\"CONCERT-94\"><a href=\"#CONCERT-94\" class=\"headerlink\" title=\"CONCERT 94\"></a>CONCERT 94</h1><p>Neural network music composition by prediction: Exploring the benefits of psychoacoustic constraints and multi-scale processing”</p>\n<ul>\n<li>estimating the probability of playing the next note</li>\n<li>generated notes: $P(Y_{n+1}&#x3D;y_{n+1}|Y_n&#x3D;y_n, Y_{n−1}&#x3D;y_{n−1}, Y_{n−2}&#x3D;y_{n−2},…)$</li>\n</ul>\n<h1 id=\"DeepJ-18\"><a href=\"#DeepJ-18\" class=\"headerlink\" title=\"DeepJ 18\"></a>DeepJ 18</h1><p>增强改变 Style 和 type<br>polyphonic music conditioned on a specific or a mixture of multiple composer styles</p>\n<ul>\n<li>polyphonic (复调): not monophonic</li>\n</ul>\n<h2 id=\"Method\"><a href=\"#Method\" class=\"headerlink\" title=\"Method:\"></a>Method:</h2><ul>\n<li>previous: comb of RNN, RBM (restricted Boltzmann machines):</li>\n<li><strong>Novel</strong>:  Biaxial LSTM</li>\n</ul>\n<p>Biaxial LSTM</p>\n<ol>\n<li>rep: MIDI $N×T$ </li>\n<li>architecture:  $P(Y_{t, n}\\vert Y_{t, n-1}, \\ Y_{t, n-2}, \\ \\ldots, \\ Y_{t-1, N}, \\ Y_{t-1, N-1}, \\ldots, \\ Y_{1, 2}, \\ Y_{1, 1})$<br><img src=\"/2024-06-03-Cytoid-AI-Charting/image.png\" alt=\"alt text\"></li>\n</ol>\n<h1 id=\"Bach-2-0\"><a href=\"#Bach-2-0\" class=\"headerlink\" title=\"Bach 2.0\"></a>Bach 2.0</h1><p><a href=\"https://www.sciencedirect.com/science/article/pii/S1877050919313444?via=ihub\">https://www.sciencedirect.com/science/article/pii/S1877050919313444?via%3Dihub</a></p>\n<h1 id=\"ISMIR\"><a href=\"#ISMIR\" class=\"headerlink\" title=\"ISMIR\"></a>ISMIR</h1><p><a href=\"https://ismir.net/conferences/\">https://ismir.net/conferences/</a></p>\n<h1 id=\"Prof-Shlomo-Dubnov\"><a href=\"#Prof-Shlomo-Dubnov\" class=\"headerlink\" title=\"Prof Shlomo Dubnov\"></a>Prof Shlomo Dubnov</h1><p>Google scholar: <a href=\"https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=NJfiIl8AAAAJ&sortby=pubdate\">https://scholar.google.com/citations?view_op=list_works&amp;hl=en&amp;hl=en&amp;user=NJfiIl8AAAAJ&amp;sortby=pubdate</a><br>Webpage: <a href=\"http://shlomodubnov.wikidot.com/research\">http://shlomodubnov.wikidot.com/research</a></p>\n<h1 id=\"prof-Gus-Xia-的讲座\"><a href=\"#prof-Gus-Xia-的讲座\" class=\"headerlink\" title=\"prof Gus Xia 的讲座\"></a>prof Gus Xia 的讲座</h1><p><a href=\"https://www.youtube.com/watch?v=dPeh3XVlmlE\">https://www.youtube.com/watch?v=dPeh3XVlmlE</a></p>\n<h2 id=\"Intro-pitches-tuning\"><a href=\"#Intro-pitches-tuning\" class=\"headerlink\" title=\"Intro: pitches tuning:\"></a>Intro: pitches tuning:</h2><p>pythagorean tuning: 三分损益法， 五度相生律<br>Octave 2：1 with fifth 3:2<br>八度 2：1， 五度3：2<br>十二平均律： $2^{(x&#x2F;12)}$</p>\n<h2 id=\"AI-Music-listening\"><a href=\"#AI-Music-listening\" class=\"headerlink\" title=\"AI+ Music listening\"></a>AI+ Music listening</h2><h3 id=\"Fingerprint\"><a href=\"#Fingerprint\" class=\"headerlink\" title=\"Fingerprint\"></a>Fingerprint</h3><p>Extraction Algorithm: Philips (2002)<br><img src=\"/2024-08-12-Music-tech-exploring/image.png\" alt=\"alt text\"><br>傅里叶分析什么的<br>Short-time fourier transform<br>FFT size 0.37<br>Hanning window</p>\n<h3 id=\"Query-by-Humming\"><a href=\"#Query-by-Humming\" class=\"headerlink\" title=\"Query by Humming\"></a>Query by Humming</h3><ol>\n<li>partial matching</li>\n<li>fuzzy match</li>\n<li>out of pitch</li>\n</ol>\n<p>MIDI + 合成器<br>MIDI(straigthforward like a string) !&#x3D; Audio (quantization)</p>\n<p>Absolute pitch<br>relatice pitch<br>IOI(Inter Onset Interval) ratio</p>\n<p>Dynamic programming<br>Pattern recognition:</p>\n<h3 id=\"Features\"><a href=\"#Features\" class=\"headerlink\" title=\"Features\"></a>Features</h3><p>spectrum(energy at diss frequencies), MFCC, Zero crossing, Chroma, Estimtates of tempo<br>chromagram, spectrogram<br><img src=\"/2024-08-12-Music-tech-exploring/image-1.png\" alt=\"alt text\"></p>\n<h2 id=\"AI-Music-Composition\"><a href=\"#AI-Music-Composition\" class=\"headerlink\" title=\"AI+ Music Composition\"></a>AI+ Music Composition</h2><p>Algorithmic composition</p>\n<p>Canon, </p>\n<h3 id=\"Deterministic\"><a href=\"#Deterministic\" class=\"headerlink\" title=\"Deterministic\"></a>Deterministic</h3><p>Fractal:分型</p>\n<h3 id=\"Stochastic-process\"><a href=\"#Stochastic-process\" class=\"headerlink\" title=\"Stochastic process\"></a>Stochastic process</h3><h3 id=\"ML-Music-as-sequence\"><a href=\"#ML-Music-as-sequence\" class=\"headerlink\" title=\"ML: Music as sequence\"></a>ML: Music as sequence</h3><h3 id=\"Mapping-natural-phenomena-ot-music\"><a href=\"#Mapping-natural-phenomena-ot-music\" class=\"headerlink\" title=\"Mapping natural phenomena ot music\"></a>Mapping natural phenomena ot music</h3><h2 id=\"AI-Music-Composition-1\"><a href=\"#AI-Music-Composition-1\" class=\"headerlink\" title=\"AI+ Music Composition\"></a>AI+ Music Composition</h2><h1 id=\"Fugue\"><a href=\"#Fugue\" class=\"headerlink\" title=\"Fugue\"></a>Fugue</h1><p>在赋格中，基本元素包括：</p>\n<p>主题 (Subject)：赋格开始时由一个声部提出的旋律动机。<br>答题 (Answer)：另一声部紧接主题以模仿的形式进入，一般会转调至属音。<br>对题 (Countersubject)：伴随答题出现的第二个旋律动机。<br>插段 (Episode)：主题和答题出现后，插入的自由发展段落。<br>codetta<br>interlude<br>赋格的陈述部分 (Exposition) 是其最严格的部分，之后的段落则允许更自由的变化。作曲家可以通过各种技术手段如加倍 (augmentation)、减缩 (diminution)、倒影 (inversion) 和紧缩 (stretto) 来改变主题的原型。</p>\n<h1 id=\"Fourier-Transform\"><a href=\"#Fourier-Transform\" class=\"headerlink\" title=\"Fourier Transform\"></a>Fourier Transform</h1><p><a href=\"https://ltyxh.com/blog/2022/05/17/%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF4/\">https://ltyxh.com/blog/2022/05/17/%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF4/</a><br>这个系列讲的特别清楚</p>\n<h1 id=\"VAE\"><a href=\"#VAE\" class=\"headerlink\" title=\"VAE\"></a>VAE</h1><p>从0教你VAE：<br>    - 交叉熵与KL散度(信息论)：<br>        - <a href=\"https://zhuanlan.zhihu.com/p/345025351\">https://zhuanlan.zhihu.com/p/345025351</a><br>            - $I(x) &#x3D; K log(P(x)), K&lt;0$ Information<br>            - $H(p) &#x3D; -\\sum p(x_i)logp(x_i)$ Entropy<br>        - <a href=\"https://zhuanlan.zhihu.com/p/346518942\">https://zhuanlan.zhihu.com/p/346518942</a><br>    - MSE, 0-1 loss, Logistic loss:<br>        -  <a href=\"https://zhuanlan.zhihu.com/p/346935187\">https://zhuanlan.zhihu.com/p/346935187</a><br>    - VAE：<br>        - <a href=\"https://zhuanlan.zhihu.com/p/348498294\">https://zhuanlan.zhihu.com/p/348498294</a><br>        - <a href=\"https://zhuanlan.zhihu.com/p/34998569\">https://zhuanlan.zhihu.com/p/34998569</a><br>        - VAE讲解：<a href=\"https://www.zhangzhenhu.com/aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html\">https://www.zhangzhenhu.com/aigc/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8.html</a></p>\n<h2 id=\"Loss-Functions\"><a href=\"#Loss-Functions\" class=\"headerlink\" title=\"Loss Functions\"></a>Loss Functions</h2><p>Cross Entropy Loss:<br>$H(p, q) &#x3D; \\mathbb{E}_{X \\sim p(X)} \\left[ - \\log q(X) \\right].\\$</p>\n<p>KL Divergence:<br>对于离散随机变量，分布$p$和$q$的KL散度的定义如下：</p>\n<p>$D_{K L}(p | q) &#x3D; -\\sum_{i&#x3D;1}^{n} p(x_{i}) \\cdot \\log \\frac{q(x_{i})}{p(x_{i})}.\\$</p>\n<p>对KL散度在信息论中的一个直观的理解是将其写开，即</p>\n<p>$\\begin{aligned} D_{K L}(p | q) &amp;&#x3D; -\\sum_{i&#x3D;1}^{n} p(x_{i}) \\cdot \\log \\frac{q(x_{i})}{p(x_{i})} \\                 &amp;&#x3D; -\\sum_{i&#x3D;1}^{n} p(x_{i}) \\cdot \\log q(x_{i}) + \\sum_{i&#x3D;1}^{n} p(x_{i}) \\cdot \\log p(x_{i}) \\                 &amp;&#x3D; H(p,q) - H(p). \\end{aligned}\\$</p>\n<h2 id=\"好东西，，\"><a href=\"#好东西，，\" class=\"headerlink\" title=\"好东西，，\"></a>好东西，，</h2><p>loss详解<br><a href=\"https://www.zhihu.com/column/c_1334301979816820736\">https://www.zhihu.com/column/c_1334301979816820736</a></p>\n<p>除了我都会，，图神经网络<br><a href=\"https://www.zhihu.com/column/c_1322582255018184704\">https://www.zhihu.com/column/c_1322582255018184704</a></p>\n<h2 id=\"VAE-1\"><a href=\"#VAE-1\" class=\"headerlink\" title=\"VAE\"></a>VAE</h2><p>总的来说觉得x和z是对称的，但x可采样，打破对称性。<br>但是不是的，，</p>\n<h2 id=\"讲得很好\"><a href=\"#讲得很好\" class=\"headerlink\" title=\"讲得很好\"></a>讲得很好</h2><p>DDPM视频：<a href=\"https://www.bilibili.com/video/BV1p24y1K7Pf?spm_id_from=333.788.videopod.sections&vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1p24y1K7Pf?spm_id_from=333.788.videopod.sections&amp;vd_source=441679270dda23308fe16f3c5602b058</a><br>文章：<a href=\"https://www.bilibili.com/read/cv23338176/?jump_opus=1\">https://www.bilibili.com/read/cv23338176/?jump_opus=1</a><br>知乎版本： <a href=\"https://zhuanlan.zhihu.com/p/624851115\">https://zhuanlan.zhihu.com/p/624851115</a></p>\n<p>ode和可视化： <a href=\"https://developer.nvidia.com/blog/generative-ai-research-spotlight-demystifying-diffusion-based-models/\">https://developer.nvidia.com/blog/generative-ai-research-spotlight-demystifying-diffusion-based-models/</a></p>\n<h1 id=\"Diffusion-model\"><a href=\"#Diffusion-model\" class=\"headerlink\" title=\"Diffusion model\"></a>Diffusion model</h1><p>介绍了consisitency model, VAE, Diffusion model , stable diffusion, LoRA, Latent Consistency Model 之间的关系，<br>从头讲解的Consistency model 的原理<br><a href=\"https://wrong.wang/blog/20220605-%E4%BB%80%E4%B9%88%E6%98%AFdiffusion%E6%A8%A1%E5%9E%8B/\">https://wrong.wang/blog/20220605-%E4%BB%80%E4%B9%88%E6%98%AFdiffusion%E6%A8%A1%E5%9E%8B/</a></p>\n<p><a href=\"https://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0speed_sd.html\">https://antarina.tech/posts/notes/articles/%E7%AC%94%E8%AE%B0speed_sd.html</a></p>\n<p><a href=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\">https://lilianweng.github.io/posts/2021-07-11-diffusion-models/</a></p>\n<h1 id=\"Consisitency-Diffusion\"><a href=\"#Consisitency-Diffusion\" class=\"headerlink\" title=\"Consisitency Diffusion\"></a>Consisitency Diffusion</h1><h2 id=\"https-wrong-wang-blog-20231111-consistency-is-all-you-need-https-zhuanlan-zhihu-com-p-692998238https-zhuanlan-zhihu-com-p-706862530-DIFF-A-RIFF-Musical-Acoompanimetn-via-latent-diffusion-models1-Consistency-Autoencoder2-Elucidated-Diffusion-Models-EDMs-Related-1-End-to-End-Autoregressive-model-high-fidelity-and-ability-to-produce-coherent-long-range-sequences-expensive-cost-for-calculateion-GANs-VAEs-are-faster-but-limiting-fidelity-Denoising-Difussion-Implicit-Models-2-Latent-models-3-Control-Mechanism-Music-ControlNet\"><a href=\"#https-wrong-wang-blog-20231111-consistency-is-all-you-need-https-zhuanlan-zhihu-com-p-692998238https-zhuanlan-zhihu-com-p-706862530-DIFF-A-RIFF-Musical-Acoompanimetn-via-latent-diffusion-models1-Consistency-Autoencoder2-Elucidated-Diffusion-Models-EDMs-Related-1-End-to-End-Autoregressive-model-high-fidelity-and-ability-to-produce-coherent-long-range-sequences-expensive-cost-for-calculateion-GANs-VAEs-are-faster-but-limiting-fidelity-Denoising-Difussion-Implicit-Models-2-Latent-models-3-Control-Mechanism-Music-ControlNet\" class=\"headerlink\" title=\"https://wrong.wang/blog/20231111-consistency-is-all-you-need/https://zhuanlan.zhihu.com/p/692998238https://zhuanlan.zhihu.com/p/706862530# DIFF-A-RIFF: Musical Acoompanimetn via latent diffusion models1. Consistency Autoencoder2. Elucidated Diffusion Models (EDMs)Related:1. End-to-End Autoregressive model:    - high fidelity and ability to produce coherent, long-range sequences    - expensive cost for calculateion    - GANs&#x2F;VAEs are faster but limiting fidelity    - Denoising Difussion Implicit Models:2. Latent models    -3. Control Mechanism   - Music ControlNet\"></a><a href=\"https://wrong.wang/blog/20231111-consistency-is-all-you-need/\">https://wrong.wang/blog/20231111-consistency-is-all-you-need/</a><br><a href=\"https://zhuanlan.zhihu.com/p/692998238\">https://zhuanlan.zhihu.com/p/692998238</a><br><a href=\"https://zhuanlan.zhihu.com/p/706862530\">https://zhuanlan.zhihu.com/p/706862530</a><br># DIFF-A-RIFF: Musical Acoompanimetn via latent diffusion models<br>1. Consistency Autoencoder<br>2. Elucidated Diffusion Models (EDMs)<br><br>Related:<br>1. End-to-End Autoregressive model:<br>    - high fidelity and ability to produce coherent, long-range sequences<br>    - expensive cost for calculateion<br>    - GANs&#x2F;VAEs are faster but limiting fidelity<br>    - Denoising Difussion Implicit Models:<br>2. Latent models<br>    -<br>3. Control Mechanism<br>   - Music ControlNet</h2><h1 id=\"Flow-matching\"><a href=\"#Flow-matching\" class=\"headerlink\" title=\"Flow matching\"></a>Flow matching</h1><h1 id=\"Score-matching\"><a href=\"#Score-matching\" class=\"headerlink\" title=\"Score matching\"></a>Score matching</h1><p>score<br>$\\nabla_x log p_\\sigma(x)$</p>\n<p><a href=\"https://www.zhangzhenhu.com/aigc/Guidance.html\">https://www.zhangzhenhu.com/aigc/Guidance.html</a></p>\n<p>看到奇怪的人： <a href=\"https://www.zhihu.com/people/labsig\">https://www.zhihu.com/people/labsig</a></p>\n<p>zou教授发的三篇论文<br><a href=\"https://arxiv.org/pdf/2406.08384\">https://arxiv.org/pdf/2406.08384</a></p>\n<p><a href=\"https://arxiv.org/pdf/2405.18503\">https://arxiv.org/pdf/2405.18503</a></p>\n<p><a href=\"https://openreview.net/pdf?id=mUVydzrkgz\">https://openreview.net/pdf?id=mUVydzrkgz</a></p>\n"},{"title":"2024-12-15-DECAF-paper","date":"2024-12-16T00:49:52.000Z","_content":"Thesis:\nGAD inherently have imbalance data problem, normal representation learning have problem of (?), leads to bias towards minority groups, arousing fairness concern. Counterfactual fairness method helps improve.\n\n\n审稿人：\n1. Motivation: improve motivation\n2. Synthetic dataset: consider multi-valued or continuous sensitive attributes, need multi-valued or continuous sensitive attributes\n3. Evaluation: more dataset and method\n4. Ablation study of loss. \n5. Proof of SCM and formula.\n\n可以吧reddit twitter的dataset加上去，在很多GAD方法上的benchmark\n\n\n\nIntro:\nGraph data is pervasive across numerous real-world applications, including social networks, financial systems, and healthcare. Detecting anomalous patterns within these graphs, known as Graph Anomaly Detection (GAD), has become a critical task due to its implications in areas such as fraud detection, network security, and medical diagnosis. Recent advancements in GAD models, particularly those applying Graph Neural Networks (GNNs), have demonstrated impressive performance in identifying anomalies by capturing complex structural and attribute-based patterns.\n\nHowever, GAD inherently faces the challenge of class imbalance, as anomalous instances are typically scarce compared to normal ones. This imbalance can hinder the model's ability to accurately detect rare anomalies, leading to high false-negative rates where actual anomalies go unnoticed. In homogeneous node classification problems, popular methods to address class imbalance include oversampling the minority class, undersampling the majority class, and employing cost-sensitive learning strategies. Similarly, traditional GAD methods tackle data imbalance through techniques such as graph embedding, Variational Autoencoders (VAEs), and Generative Adversarial Networks (GANs), which aim to learn robust representations that can effectively distinguish between normal and anomalous nodes.\n\nDespite their effectiveness, representation learning approaches often introduce algorithmic biases against certain subpopulations within the graph. These biases can stem from the underlying data distribution, where specific groups may be underrepresented or possess distinct structural characteristics that the model inadvertently leverages to make biased predictions. Such biases raise significant fairness concerns, especially in sensitive domains like finance and healthcare. For instance, biased GAD models might disproportionately flag transactions from particular ethnic or socioeconomic groups as fraudulent in financial fraud detection systems. Similarly, in healthcare, biased anomaly detection could lead to the misidentification of treatment patterns for underrepresented populations, potentially resulting in delayed or denied care. Therefore, it is imperative to develop fair GAD methods that not only excel in anomaly detection performance but also mitigate biases to ensure equitable outcomes across all subpopulations.\n\n\n\n\n\n\nMy question:\n1. 怎么理解class imbalance: bias (容易对少数的class产生bias？) vs. 数据中含有sensitive feature的bias\nimbalance:\n\nsens:\n    (1) biases induced by one’s neighboring nodes and （NIFTY： https://proceedings.mlr.press/v161/agarwal21b）\n    (2) biases induced by the causal relations from the sensitive attributes to other features as\nwell as the graph structure. （https://proceedings.mlr.press/v151/agarwal22b.html）\n\n\n\n\nRelated Works:\n\n","source":"_posts/2024-12-15-DECAF-paper.md","raw":"---\ntitle: 2024-12-15-DECAF-paper\ndate: 2024-12-15 19:49:52\ntags:\n---\nThesis:\nGAD inherently have imbalance data problem, normal representation learning have problem of (?), leads to bias towards minority groups, arousing fairness concern. Counterfactual fairness method helps improve.\n\n\n审稿人：\n1. Motivation: improve motivation\n2. Synthetic dataset: consider multi-valued or continuous sensitive attributes, need multi-valued or continuous sensitive attributes\n3. Evaluation: more dataset and method\n4. Ablation study of loss. \n5. Proof of SCM and formula.\n\n可以吧reddit twitter的dataset加上去，在很多GAD方法上的benchmark\n\n\n\nIntro:\nGraph data is pervasive across numerous real-world applications, including social networks, financial systems, and healthcare. Detecting anomalous patterns within these graphs, known as Graph Anomaly Detection (GAD), has become a critical task due to its implications in areas such as fraud detection, network security, and medical diagnosis. Recent advancements in GAD models, particularly those applying Graph Neural Networks (GNNs), have demonstrated impressive performance in identifying anomalies by capturing complex structural and attribute-based patterns.\n\nHowever, GAD inherently faces the challenge of class imbalance, as anomalous instances are typically scarce compared to normal ones. This imbalance can hinder the model's ability to accurately detect rare anomalies, leading to high false-negative rates where actual anomalies go unnoticed. In homogeneous node classification problems, popular methods to address class imbalance include oversampling the minority class, undersampling the majority class, and employing cost-sensitive learning strategies. Similarly, traditional GAD methods tackle data imbalance through techniques such as graph embedding, Variational Autoencoders (VAEs), and Generative Adversarial Networks (GANs), which aim to learn robust representations that can effectively distinguish between normal and anomalous nodes.\n\nDespite their effectiveness, representation learning approaches often introduce algorithmic biases against certain subpopulations within the graph. These biases can stem from the underlying data distribution, where specific groups may be underrepresented or possess distinct structural characteristics that the model inadvertently leverages to make biased predictions. Such biases raise significant fairness concerns, especially in sensitive domains like finance and healthcare. For instance, biased GAD models might disproportionately flag transactions from particular ethnic or socioeconomic groups as fraudulent in financial fraud detection systems. Similarly, in healthcare, biased anomaly detection could lead to the misidentification of treatment patterns for underrepresented populations, potentially resulting in delayed or denied care. Therefore, it is imperative to develop fair GAD methods that not only excel in anomaly detection performance but also mitigate biases to ensure equitable outcomes across all subpopulations.\n\n\n\n\n\n\nMy question:\n1. 怎么理解class imbalance: bias (容易对少数的class产生bias？) vs. 数据中含有sensitive feature的bias\nimbalance:\n\nsens:\n    (1) biases induced by one’s neighboring nodes and （NIFTY： https://proceedings.mlr.press/v161/agarwal21b）\n    (2) biases induced by the causal relations from the sensitive attributes to other features as\nwell as the graph structure. （https://proceedings.mlr.press/v151/agarwal22b.html）\n\n\n\n\nRelated Works:\n\n","slug":"2024-12-15-DECAF-paper","published":1,"updated":"2024-12-18T09:17:39.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagpw0012zc3dcrgrhmhb","content":"<p>Thesis:<br>GAD inherently have imbalance data problem, normal representation learning have problem of (?), leads to bias towards minority groups, arousing fairness concern. Counterfactual fairness method helps improve.</p>\n<p>审稿人：</p>\n<ol>\n<li>Motivation: improve motivation</li>\n<li>Synthetic dataset: consider multi-valued or continuous sensitive attributes, need multi-valued or continuous sensitive attributes</li>\n<li>Evaluation: more dataset and method</li>\n<li>Ablation study of loss. </li>\n<li>Proof of SCM and formula.</li>\n</ol>\n<p>可以吧reddit twitter的dataset加上去，在很多GAD方法上的benchmark</p>\n<p>Intro:<br>Graph data is pervasive across numerous real-world applications, including social networks, financial systems, and healthcare. Detecting anomalous patterns within these graphs, known as Graph Anomaly Detection (GAD), has become a critical task due to its implications in areas such as fraud detection, network security, and medical diagnosis. Recent advancements in GAD models, particularly those applying Graph Neural Networks (GNNs), have demonstrated impressive performance in identifying anomalies by capturing complex structural and attribute-based patterns.</p>\n<p>However, GAD inherently faces the challenge of class imbalance, as anomalous instances are typically scarce compared to normal ones. This imbalance can hinder the model’s ability to accurately detect rare anomalies, leading to high false-negative rates where actual anomalies go unnoticed. In homogeneous node classification problems, popular methods to address class imbalance include oversampling the minority class, undersampling the majority class, and employing cost-sensitive learning strategies. Similarly, traditional GAD methods tackle data imbalance through techniques such as graph embedding, Variational Autoencoders (VAEs), and Generative Adversarial Networks (GANs), which aim to learn robust representations that can effectively distinguish between normal and anomalous nodes.</p>\n<p>Despite their effectiveness, representation learning approaches often introduce algorithmic biases against certain subpopulations within the graph. These biases can stem from the underlying data distribution, where specific groups may be underrepresented or possess distinct structural characteristics that the model inadvertently leverages to make biased predictions. Such biases raise significant fairness concerns, especially in sensitive domains like finance and healthcare. For instance, biased GAD models might disproportionately flag transactions from particular ethnic or socioeconomic groups as fraudulent in financial fraud detection systems. Similarly, in healthcare, biased anomaly detection could lead to the misidentification of treatment patterns for underrepresented populations, potentially resulting in delayed or denied care. Therefore, it is imperative to develop fair GAD methods that not only excel in anomaly detection performance but also mitigate biases to ensure equitable outcomes across all subpopulations.</p>\n<p>My question:</p>\n<ol>\n<li>怎么理解class imbalance: bias (容易对少数的class产生bias？) vs. 数据中含有sensitive feature的bias<br>imbalance:</li>\n</ol>\n<p>sens:<br>    (1) biases induced by one’s neighboring nodes and （NIFTY： <a href=\"https://proceedings.mlr.press/v161/agarwal21b%EF%BC%89\">https://proceedings.mlr.press/v161/agarwal21b）</a><br>    (2) biases induced by the causal relations from the sensitive attributes to other features as<br>well as the graph structure. （<a href=\"https://proceedings.mlr.press/v151/agarwal22b.html%EF%BC%89\">https://proceedings.mlr.press/v151/agarwal22b.html）</a></p>\n<p>Related Works:</p>\n","excerpt":"","more":"<p>Thesis:<br>GAD inherently have imbalance data problem, normal representation learning have problem of (?), leads to bias towards minority groups, arousing fairness concern. Counterfactual fairness method helps improve.</p>\n<p>审稿人：</p>\n<ol>\n<li>Motivation: improve motivation</li>\n<li>Synthetic dataset: consider multi-valued or continuous sensitive attributes, need multi-valued or continuous sensitive attributes</li>\n<li>Evaluation: more dataset and method</li>\n<li>Ablation study of loss. </li>\n<li>Proof of SCM and formula.</li>\n</ol>\n<p>可以吧reddit twitter的dataset加上去，在很多GAD方法上的benchmark</p>\n<p>Intro:<br>Graph data is pervasive across numerous real-world applications, including social networks, financial systems, and healthcare. Detecting anomalous patterns within these graphs, known as Graph Anomaly Detection (GAD), has become a critical task due to its implications in areas such as fraud detection, network security, and medical diagnosis. Recent advancements in GAD models, particularly those applying Graph Neural Networks (GNNs), have demonstrated impressive performance in identifying anomalies by capturing complex structural and attribute-based patterns.</p>\n<p>However, GAD inherently faces the challenge of class imbalance, as anomalous instances are typically scarce compared to normal ones. This imbalance can hinder the model’s ability to accurately detect rare anomalies, leading to high false-negative rates where actual anomalies go unnoticed. In homogeneous node classification problems, popular methods to address class imbalance include oversampling the minority class, undersampling the majority class, and employing cost-sensitive learning strategies. Similarly, traditional GAD methods tackle data imbalance through techniques such as graph embedding, Variational Autoencoders (VAEs), and Generative Adversarial Networks (GANs), which aim to learn robust representations that can effectively distinguish between normal and anomalous nodes.</p>\n<p>Despite their effectiveness, representation learning approaches often introduce algorithmic biases against certain subpopulations within the graph. These biases can stem from the underlying data distribution, where specific groups may be underrepresented or possess distinct structural characteristics that the model inadvertently leverages to make biased predictions. Such biases raise significant fairness concerns, especially in sensitive domains like finance and healthcare. For instance, biased GAD models might disproportionately flag transactions from particular ethnic or socioeconomic groups as fraudulent in financial fraud detection systems. Similarly, in healthcare, biased anomaly detection could lead to the misidentification of treatment patterns for underrepresented populations, potentially resulting in delayed or denied care. Therefore, it is imperative to develop fair GAD methods that not only excel in anomaly detection performance but also mitigate biases to ensure equitable outcomes across all subpopulations.</p>\n<p>My question:</p>\n<ol>\n<li>怎么理解class imbalance: bias (容易对少数的class产生bias？) vs. 数据中含有sensitive feature的bias<br>imbalance:</li>\n</ol>\n<p>sens:<br>    (1) biases induced by one’s neighboring nodes and （NIFTY： <a href=\"https://proceedings.mlr.press/v161/agarwal21b%EF%BC%89\">https://proceedings.mlr.press/v161/agarwal21b）</a><br>    (2) biases induced by the causal relations from the sensitive attributes to other features as<br>well as the graph structure. （<a href=\"https://proceedings.mlr.press/v151/agarwal22b.html%EF%BC%89\">https://proceedings.mlr.press/v151/agarwal22b.html）</a></p>\n<p>Related Works:</p>\n"},{"title":"2024-12-20-Tighnari","date":"2024-12-20T17:10:38.000Z","_content":"太好了！是提纳里！我们有救了！\n\nai训练语音仓库： https://github.com/w4123/GenshinVoice\n\n数据：https://kokona-my.sharepoint.com/personal/suhui_kokona_tech/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fsuhui%5Fkokona%5Ftech%2FDocuments%2FGenshinVoice&ga=1\n\n目前出色的歌唱模型SO-VITS-SVC：https://github.com/voicepaw/so-vits-svc-fork/blob/main/README_zh_CN.md\n\nTTS（Text-To-Speech） ：GPT-SOVIT(GSV)：https://github.com/RVC-Boss/GPT-SoVITS\n文档；https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e\n\n现成的他山之石； https://gsv.acgnai.top/\nusher: https://www.99csw.com/book/9679/347461.htm\n","source":"_posts/2024-12-20-Tighnari.md","raw":"---\ntitle: 2024-12-20-Tighnari\ndate: 2024-12-20 12:10:38\ntags:\n---\n太好了！是提纳里！我们有救了！\n\nai训练语音仓库： https://github.com/w4123/GenshinVoice\n\n数据：https://kokona-my.sharepoint.com/personal/suhui_kokona_tech/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fsuhui%5Fkokona%5Ftech%2FDocuments%2FGenshinVoice&ga=1\n\n目前出色的歌唱模型SO-VITS-SVC：https://github.com/voicepaw/so-vits-svc-fork/blob/main/README_zh_CN.md\n\nTTS（Text-To-Speech） ：GPT-SOVIT(GSV)：https://github.com/RVC-Boss/GPT-SoVITS\n文档；https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e\n\n现成的他山之石； https://gsv.acgnai.top/\nusher: https://www.99csw.com/book/9679/347461.htm\n","slug":"2024-12-20-Tighnari","published":1,"updated":"2024-12-20T05:06:31.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagpx0013zc3d30nf211h","content":"<p>太好了！是提纳里！我们有救了！</p>\n<p>ai训练语音仓库： <a href=\"https://github.com/w4123/GenshinVoice\">https://github.com/w4123/GenshinVoice</a></p>\n<p>数据：<a href=\"https://kokona-my.sharepoint.com/personal/suhui_kokona_tech/_layouts/15/onedrive.aspx?id=/personal/suhui_kokona_tech/Documents/GenshinVoice&ga=1\">https://kokona-my.sharepoint.com/personal/suhui_kokona_tech/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fsuhui%5Fkokona%5Ftech%2FDocuments%2FGenshinVoice&amp;ga=1</a></p>\n<p>目前出色的歌唱模型SO-VITS-SVC：<a href=\"https://github.com/voicepaw/so-vits-svc-fork/blob/main/README_zh_CN.md\">https://github.com/voicepaw/so-vits-svc-fork/blob/main/README_zh_CN.md</a></p>\n<p>TTS（Text-To-Speech） ：GPT-SOVIT(GSV)：<a href=\"https://github.com/RVC-Boss/GPT-SoVITS\">https://github.com/RVC-Boss/GPT-SoVITS</a><br>文档；<a href=\"https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e\">https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e</a></p>\n<p>现成的他山之石； <a href=\"https://gsv.acgnai.top/\">https://gsv.acgnai.top/</a><br>usher: <a href=\"https://www.99csw.com/book/9679/347461.htm\">https://www.99csw.com/book/9679/347461.htm</a></p>\n","excerpt":"","more":"<p>太好了！是提纳里！我们有救了！</p>\n<p>ai训练语音仓库： <a href=\"https://github.com/w4123/GenshinVoice\">https://github.com/w4123/GenshinVoice</a></p>\n<p>数据：<a href=\"https://kokona-my.sharepoint.com/personal/suhui_kokona_tech/_layouts/15/onedrive.aspx?id=/personal/suhui_kokona_tech/Documents/GenshinVoice&ga=1\">https://kokona-my.sharepoint.com/personal/suhui_kokona_tech/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fsuhui%5Fkokona%5Ftech%2FDocuments%2FGenshinVoice&amp;ga=1</a></p>\n<p>目前出色的歌唱模型SO-VITS-SVC：<a href=\"https://github.com/voicepaw/so-vits-svc-fork/blob/main/README_zh_CN.md\">https://github.com/voicepaw/so-vits-svc-fork/blob/main/README_zh_CN.md</a></p>\n<p>TTS（Text-To-Speech） ：GPT-SOVIT(GSV)：<a href=\"https://github.com/RVC-Boss/GPT-SoVITS\">https://github.com/RVC-Boss/GPT-SoVITS</a><br>文档；<a href=\"https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e\">https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e</a></p>\n<p>现成的他山之石； <a href=\"https://gsv.acgnai.top/\">https://gsv.acgnai.top/</a><br>usher: <a href=\"https://www.99csw.com/book/9679/347461.htm\">https://www.99csw.com/book/9679/347461.htm</a></p>\n"},{"title":"2024-11-25-About-me","date":"2024-11-26T03:36:31.000Z","_content":"\n一个类似电子兴奋剂和镇静剂：\nhttps://jipa.moe/t/studywithmiku/#\n太困了，咖啡因～～不行，咖啡因会让我更困，不如直接喝兴奋剂吧(CodeGeex自动补全)～～\n难道咖啡因不是兴奋剂吗？？？\n\n\n每天都好困好困，或者根本数不着，困死了\n\n痛恨记录自己生活的一切。回望的时候会发现真的没有任何意义。\n\n每天活着的一些动力是： 现在cos一个颓废绝望的大三学生。脑力硬件是16kb的内存和1TB莫名其妙闪现但无法主动读取的死亡痛苦回忆。优点是，有现代化的电子产品和索引，可以学新的东西。\n\n<!-- 要死了，把大家都杀了。 -->\n我觉得孙频的文字算不上严肃文学。初中的时候收到的荼毒其深。\n\n\n<!-- \n最近想起来很多有关他事情： 2024.12.1， 引以为戒\n1. 去年s1的时候我们在操场绕圈，他拉着我的手，说只能和我在一起了。\n2. 一些很纯正的利益交换，他做了什么，我必须一些对等的方式回报他。我并非会把自己提供的一切便利作为交换的手段。又是算是’无足轻重‘玩笑的一种。又是可以理解为等价。既然没有办法提供一些‘水平’，只能在别的地方弥补一些价值。\n3. 有一日提分手，三点到四点多不断打电话。我一夜未睡。可能有人觉得让别人熬一夜也是正常的吧，毕竟伤了他的心。\n4. ‘因为有些事情’，所以没和亲爱的大家们见面啊。\n5. 总的来说，并不好说是什么。只是觉得很自私。在很多情况下，我不太会接受这样。但也逐渐可以了，只是自己会变得类似，算是学习了一种自保的手段，也是值得的，我又有什么分别呢。\n人与人相处就是这样不断的利益交换吧，任何行为都无可厚非。我只是希望自己能记住这一些事情罢了。你们两个该死的嫉妒心。\n\n\n\nspanking: https://soundgasm.net/u/AntiquaVA/M4F-I-cant-act-like-I-love-you-pt2-mdom-wet-sfx\nhttps://soundgasm.net/u/TalkingSmut/You-Were-Made-To-Please-Me 7:30 discipline\nhttps://www.flaru.com/en/soundgasm.net/TalkingSmut\nhttps://soundgasm.net/u/TalkingSmut/On-the-Delicate-Matter-of-Correction\n\nhttps://www.flaru.com/en/soundgasm.net/m4f-spanking\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Fussy-Little-Brat-daddy-punishment-discipline-edging-choking-bondage-anal-creampie-bad-girl-whispers-slapping-spanking 4:25 14:50\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Taming-the-Brat-ddlg-incest-roleplay-daddy-brat-punishment-anal-dp-creampie-spanking-belt-bdsm-whispers-good-girl-mention-of-gangbang-mouth-sounds-oral-asmr-analingus-food-porn-cooking\n\n\nhttps://soundgasm.net/u/PrincessAmiAudios/F4M-Im-not-a-brat-Punishment-Arguing-Spanking-Rough-DDlg-Daddy-Mentions ??\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Suckretary-2-harassment-blackmail-dubcon-coercion-douchebag-misogyny-money-daddys-belt-vibrator-free-use-spanking 16:30\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Bad-Girl-Workshop-Part-1-daddy-incest-bdsm-safewords-spanking-biting-asmr-kissing-good-girl-anal-bondage-creampie-blowjob-facefucking 11:30\n\n\ncute!!!非常非常精彩\nhttps://soundgasm.net/u/Qarnivore/M4F-The-Boy-Next-Door-Part-6-Distraction-MdomSpankingStudyingASMRWhisperingGrowlingTeasingCountdown240 10:50\n\n这哥groaning很，像是有暴躁症的样子\nhttps://soundgasm.net/u/Qarnivore/M4F-Stay-in-School-AgeplaySpankingDressing-Room\n\nhttps://soundgasm.net/u/Qarnivore/M4F-Lesson-Learned-TeacherMdomName-callingSpankingBegging\n7:20\n\nhttps://soundgasm.net/u/Qarnivore/M4F-Clean-Your-Room-MdomDDlgGrowlyAngrySpankingName-Calling\n13:30\n\nhttps://soundgasm.net/u/Night_Switch/M4F-Roommate-Hairbrush-Spanking-mDom-fsub-DDlg-Roomates-to-lovers-hair-pulling-spanking-hairbrush-spanking-condescending-degradation-praise-kink-discovery-kink-acceptance-possessivefingeringlistener-orgasm\n05:10\n\nhttps://soundgasm.net/u/Night_Switch/M4F-Roommate-Hairbrush-Spanking-mDom-fsub-DDlg-Roomates-to-lovers-hair-pulling-spanking-hairbrush-spanking-condescending-degradation-praise-kink-discovery-kink-acceptance-possessivefingeringlistener-orgasm\n4:30\n\n最好干湿分离，sp和do分开，，\nhttps://soundgasm.net/u/KyoHimself/M4F-Brat-Taming-A-Disobedient-Girl-With-Spanks-Then-Fucking-Her-Senseless-4\n\n喜欢这种很冷静的\nhttps://soundgasm.net/u/Abug/Put-in-your-place-MDom-Teasing-Brat-taming-Edging-Spanking-Multiple-orgasms-Overstimulation-Face-fucking-Creampie-Aftercare 11:00\n\n\n-->\n\n\n2025-03-12\n好像被困在小时候了。\n希望弥补练不好的钢琴。\n看没有机会看到的好电影，动画片。\n看很多书，躺在夏日午后昏昏欲睡。\n做出来一些数学题目，当一个很厉害很聪明的人，拥有一些朋友。\n可是只有神经质和幼态延续下来了。\nhydoroxyzine的功效吧，让人回到很久很久以前的午后。\n一觉睁眼，已经是下午3点了。风也是热的。\n\n\n2025-03-13\n阅读the brat whisperer有感\n\n理想的应该是一种ds关系。\n在ds（精神）方面各取所需，sub获得同意情况下被强迫和收到惩罚的羞耻感，但并不过分渴望羞辱，而是因teasing和疼痛的羞耻感获得满足。dom在支配，观察sub因自己的动作而改变的行为获得满足，因支配，支配的反馈，施加惩戒的权利和轻视鄙夷，和驯服的过程获得快感。\n在ds的rp中不可以存在dom对sub的爱和依恋，意识到的爱是不可存在的，否则sub会失去悬而未决的猜测之乐。必须两个人对随时离开对方无感，略有遗憾但是不会感到失去和痛苦的状态。那种确定的甜蜜是不可存在的。但是也不能完全无感，否则会失去张力。\n\n在sm方面，束缚强制和惩戒是很带感的。m不能主动的放荡的享受快乐，必须在主观意识上回避惩罚，必须通过痛苦和羞耻来回味那种悠长的快感。清醒的观察自己堕落。但并不觉得自己下贱或是高尚。而是带入角色的视角局限性，被特定的价值观下的强权羞辱和折磨。s的快乐，我暂且不能理解，不过姑且类比于，我看到软软的小猫冲动吧。\n\n性不是必须的，但是是一种结果。\n\n不喜欢羞辱性的称呼，但是调戏和阴阳性的比如，princess, good girl, cat, kitten, baby, little girl, brat之类的。不喜欢脏话和过量的语言出现，但是要有无脏话的dirty word的羞辱和嘲弄。不要展现出性欲，像两个文明的人在干最正经的事情，只让这些不干净的东西存在于双方的大脑里，通过想象和氛围获得快感。\n\n像是对生活边界的试探。\n\n在the brat whisperer中，mike可能是我。他从brat变为tamer，知晓一切。这种dom是温柔的掌控一切，因为在时间上降维了，你只是我的一个低维流形。前几章他很好，但是坏在对柯产生感情，于是失控。最欣赏的是这里的mike身份权利流动的过程，从被掌控到掌握住自己的项圈。\n\n\n最近看博弈论。想到很久以前玩的小游戏。\nhttps://dccxi.com/trust/\n\n\n给yqy的：\n陆沉（霸道总裁）\nhttps://archiveofourown.org/works/58148656?view_full_work=true 陆沉 dom\n\nhttps://archiveofourown.org/works/43474191 比较诗意\n\nhttps://archiveofourown.org/works/39124803 刺激...\n\n提纳里：阔耳狐原型（有大耳朵和尾巴）的温柔少年，生论派（生物）天才学者，后当巡林员\nhttps://archiveofourown.org/works/57963826/chapters/147556030 很温柔的入侵\n\nhttps://archiveofourown.org/works/51658387 被发现\n\n莱欧；莱欧斯利=公爵大人是梅洛彼得堡监狱的典狱长，那维莱特是水龙所以2根...\nhttps://archiveofourown.org/works/53891584?view_full_work=true\n\n狱虚： 林尼是枫丹国家的有名魔术师。\nhttps://archiveofourown.org/works/50617552?view_full_work=true 可能要转\n\n黑花应该还有，但是目前找不到\n\n那芙\nhttps://archiveofourown.org/works/50779567 惩罚\n\nhttps://archiveofourown.org/works/51895978 请求\n\n信一\nhttps://archiveofourown.org/works/57401980 论坛体sm\n\n\n\n\n\n\n\n致死：盐酸利多卡因+肾上腺素注射液\n致死：大量呼吸抑制+过量？+酒精（之类的催化剂）\n\n促智：Alpha-GPC是真有用。回去接着o\n安非他酮，好东西。450才能解离了现在。\n'\n\n\n听，有感。https://www.bilibili.com/video/BV1nz4y1b74q?spm_id_from=333.788.videopod.episodes&vd_source=441679270dda23308fe16f3c5602b058&p=2\n爱迪生和董事会的关系有点像openai...\n听了一点点 BV1nz4y1b74q。history repeat itself\n特斯拉是纪念特斯拉。\nBill gates是代码发家","source":"_posts/2024-11-25-About-me.md","raw":"---\ntitle: 2024-11-25-About-me\ndate: 2024-11-25 22:36:31\ntags:\n---\n\n一个类似电子兴奋剂和镇静剂：\nhttps://jipa.moe/t/studywithmiku/#\n太困了，咖啡因～～不行，咖啡因会让我更困，不如直接喝兴奋剂吧(CodeGeex自动补全)～～\n难道咖啡因不是兴奋剂吗？？？\n\n\n每天都好困好困，或者根本数不着，困死了\n\n痛恨记录自己生活的一切。回望的时候会发现真的没有任何意义。\n\n每天活着的一些动力是： 现在cos一个颓废绝望的大三学生。脑力硬件是16kb的内存和1TB莫名其妙闪现但无法主动读取的死亡痛苦回忆。优点是，有现代化的电子产品和索引，可以学新的东西。\n\n<!-- 要死了，把大家都杀了。 -->\n我觉得孙频的文字算不上严肃文学。初中的时候收到的荼毒其深。\n\n\n<!-- \n最近想起来很多有关他事情： 2024.12.1， 引以为戒\n1. 去年s1的时候我们在操场绕圈，他拉着我的手，说只能和我在一起了。\n2. 一些很纯正的利益交换，他做了什么，我必须一些对等的方式回报他。我并非会把自己提供的一切便利作为交换的手段。又是算是’无足轻重‘玩笑的一种。又是可以理解为等价。既然没有办法提供一些‘水平’，只能在别的地方弥补一些价值。\n3. 有一日提分手，三点到四点多不断打电话。我一夜未睡。可能有人觉得让别人熬一夜也是正常的吧，毕竟伤了他的心。\n4. ‘因为有些事情’，所以没和亲爱的大家们见面啊。\n5. 总的来说，并不好说是什么。只是觉得很自私。在很多情况下，我不太会接受这样。但也逐渐可以了，只是自己会变得类似，算是学习了一种自保的手段，也是值得的，我又有什么分别呢。\n人与人相处就是这样不断的利益交换吧，任何行为都无可厚非。我只是希望自己能记住这一些事情罢了。你们两个该死的嫉妒心。\n\n\n\nspanking: https://soundgasm.net/u/AntiquaVA/M4F-I-cant-act-like-I-love-you-pt2-mdom-wet-sfx\nhttps://soundgasm.net/u/TalkingSmut/You-Were-Made-To-Please-Me 7:30 discipline\nhttps://www.flaru.com/en/soundgasm.net/TalkingSmut\nhttps://soundgasm.net/u/TalkingSmut/On-the-Delicate-Matter-of-Correction\n\nhttps://www.flaru.com/en/soundgasm.net/m4f-spanking\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Fussy-Little-Brat-daddy-punishment-discipline-edging-choking-bondage-anal-creampie-bad-girl-whispers-slapping-spanking 4:25 14:50\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Taming-the-Brat-ddlg-incest-roleplay-daddy-brat-punishment-anal-dp-creampie-spanking-belt-bdsm-whispers-good-girl-mention-of-gangbang-mouth-sounds-oral-asmr-analingus-food-porn-cooking\n\n\nhttps://soundgasm.net/u/PrincessAmiAudios/F4M-Im-not-a-brat-Punishment-Arguing-Spanking-Rough-DDlg-Daddy-Mentions ??\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Suckretary-2-harassment-blackmail-dubcon-coercion-douchebag-misogyny-money-daddys-belt-vibrator-free-use-spanking 16:30\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Bad-Girl-Workshop-Part-1-daddy-incest-bdsm-safewords-spanking-biting-asmr-kissing-good-girl-anal-bondage-creampie-blowjob-facefucking 11:30\n\n\ncute!!!非常非常精彩\nhttps://soundgasm.net/u/Qarnivore/M4F-The-Boy-Next-Door-Part-6-Distraction-MdomSpankingStudyingASMRWhisperingGrowlingTeasingCountdown240 10:50\n\n这哥groaning很，像是有暴躁症的样子\nhttps://soundgasm.net/u/Qarnivore/M4F-Stay-in-School-AgeplaySpankingDressing-Room\n\nhttps://soundgasm.net/u/Qarnivore/M4F-Lesson-Learned-TeacherMdomName-callingSpankingBegging\n7:20\n\nhttps://soundgasm.net/u/Qarnivore/M4F-Clean-Your-Room-MdomDDlgGrowlyAngrySpankingName-Calling\n13:30\n\nhttps://soundgasm.net/u/Night_Switch/M4F-Roommate-Hairbrush-Spanking-mDom-fsub-DDlg-Roomates-to-lovers-hair-pulling-spanking-hairbrush-spanking-condescending-degradation-praise-kink-discovery-kink-acceptance-possessivefingeringlistener-orgasm\n05:10\n\nhttps://soundgasm.net/u/Night_Switch/M4F-Roommate-Hairbrush-Spanking-mDom-fsub-DDlg-Roomates-to-lovers-hair-pulling-spanking-hairbrush-spanking-condescending-degradation-praise-kink-discovery-kink-acceptance-possessivefingeringlistener-orgasm\n4:30\n\n最好干湿分离，sp和do分开，，\nhttps://soundgasm.net/u/KyoHimself/M4F-Brat-Taming-A-Disobedient-Girl-With-Spanks-Then-Fucking-Her-Senseless-4\n\n喜欢这种很冷静的\nhttps://soundgasm.net/u/Abug/Put-in-your-place-MDom-Teasing-Brat-taming-Edging-Spanking-Multiple-orgasms-Overstimulation-Face-fucking-Creampie-Aftercare 11:00\n\n\n-->\n\n\n2025-03-12\n好像被困在小时候了。\n希望弥补练不好的钢琴。\n看没有机会看到的好电影，动画片。\n看很多书，躺在夏日午后昏昏欲睡。\n做出来一些数学题目，当一个很厉害很聪明的人，拥有一些朋友。\n可是只有神经质和幼态延续下来了。\nhydoroxyzine的功效吧，让人回到很久很久以前的午后。\n一觉睁眼，已经是下午3点了。风也是热的。\n\n\n2025-03-13\n阅读the brat whisperer有感\n\n理想的应该是一种ds关系。\n在ds（精神）方面各取所需，sub获得同意情况下被强迫和收到惩罚的羞耻感，但并不过分渴望羞辱，而是因teasing和疼痛的羞耻感获得满足。dom在支配，观察sub因自己的动作而改变的行为获得满足，因支配，支配的反馈，施加惩戒的权利和轻视鄙夷，和驯服的过程获得快感。\n在ds的rp中不可以存在dom对sub的爱和依恋，意识到的爱是不可存在的，否则sub会失去悬而未决的猜测之乐。必须两个人对随时离开对方无感，略有遗憾但是不会感到失去和痛苦的状态。那种确定的甜蜜是不可存在的。但是也不能完全无感，否则会失去张力。\n\n在sm方面，束缚强制和惩戒是很带感的。m不能主动的放荡的享受快乐，必须在主观意识上回避惩罚，必须通过痛苦和羞耻来回味那种悠长的快感。清醒的观察自己堕落。但并不觉得自己下贱或是高尚。而是带入角色的视角局限性，被特定的价值观下的强权羞辱和折磨。s的快乐，我暂且不能理解，不过姑且类比于，我看到软软的小猫冲动吧。\n\n性不是必须的，但是是一种结果。\n\n不喜欢羞辱性的称呼，但是调戏和阴阳性的比如，princess, good girl, cat, kitten, baby, little girl, brat之类的。不喜欢脏话和过量的语言出现，但是要有无脏话的dirty word的羞辱和嘲弄。不要展现出性欲，像两个文明的人在干最正经的事情，只让这些不干净的东西存在于双方的大脑里，通过想象和氛围获得快感。\n\n像是对生活边界的试探。\n\n在the brat whisperer中，mike可能是我。他从brat变为tamer，知晓一切。这种dom是温柔的掌控一切，因为在时间上降维了，你只是我的一个低维流形。前几章他很好，但是坏在对柯产生感情，于是失控。最欣赏的是这里的mike身份权利流动的过程，从被掌控到掌握住自己的项圈。\n\n\n最近看博弈论。想到很久以前玩的小游戏。\nhttps://dccxi.com/trust/\n\n\n给yqy的：\n陆沉（霸道总裁）\nhttps://archiveofourown.org/works/58148656?view_full_work=true 陆沉 dom\n\nhttps://archiveofourown.org/works/43474191 比较诗意\n\nhttps://archiveofourown.org/works/39124803 刺激...\n\n提纳里：阔耳狐原型（有大耳朵和尾巴）的温柔少年，生论派（生物）天才学者，后当巡林员\nhttps://archiveofourown.org/works/57963826/chapters/147556030 很温柔的入侵\n\nhttps://archiveofourown.org/works/51658387 被发现\n\n莱欧；莱欧斯利=公爵大人是梅洛彼得堡监狱的典狱长，那维莱特是水龙所以2根...\nhttps://archiveofourown.org/works/53891584?view_full_work=true\n\n狱虚： 林尼是枫丹国家的有名魔术师。\nhttps://archiveofourown.org/works/50617552?view_full_work=true 可能要转\n\n黑花应该还有，但是目前找不到\n\n那芙\nhttps://archiveofourown.org/works/50779567 惩罚\n\nhttps://archiveofourown.org/works/51895978 请求\n\n信一\nhttps://archiveofourown.org/works/57401980 论坛体sm\n\n\n\n\n\n\n\n致死：盐酸利多卡因+肾上腺素注射液\n致死：大量呼吸抑制+过量？+酒精（之类的催化剂）\n\n促智：Alpha-GPC是真有用。回去接着o\n安非他酮，好东西。450才能解离了现在。\n'\n\n\n听，有感。https://www.bilibili.com/video/BV1nz4y1b74q?spm_id_from=333.788.videopod.episodes&vd_source=441679270dda23308fe16f3c5602b058&p=2\n爱迪生和董事会的关系有点像openai...\n听了一点点 BV1nz4y1b74q。history repeat itself\n特斯拉是纪念特斯拉。\nBill gates是代码发家","slug":"2024-11-25-About-me","published":1,"updated":"2025-04-05T18:47:07.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagpy0014zc3dgli12ps0","content":"<p>一个类似电子兴奋剂和镇静剂：<br><a href=\"https://jipa.moe/t/studywithmiku/#\">https://jipa.moe/t/studywithmiku/#</a><br>太困了，咖啡因～～不行，咖啡因会让我更困，不如直接喝兴奋剂吧(CodeGeex自动补全)～～<br>难道咖啡因不是兴奋剂吗？？？</p>\n<p>每天都好困好困，或者根本数不着，困死了</p>\n<p>痛恨记录自己生活的一切。回望的时候会发现真的没有任何意义。</p>\n<p>每天活着的一些动力是： 现在cos一个颓废绝望的大三学生。脑力硬件是16kb的内存和1TB莫名其妙闪现但无法主动读取的死亡痛苦回忆。优点是，有现代化的电子产品和索引，可以学新的东西。</p>\n<!-- 要死了，把大家都杀了。 -->\n<p>我觉得孙频的文字算不上严肃文学。初中的时候收到的荼毒其深。</p>\n<!-- \n最近想起来很多有关他事情： 2024.12.1， 引以为戒\n1. 去年s1的时候我们在操场绕圈，他拉着我的手，说只能和我在一起了。\n2. 一些很纯正的利益交换，他做了什么，我必须一些对等的方式回报他。我并非会把自己提供的一切便利作为交换的手段。又是算是’无足轻重‘玩笑的一种。又是可以理解为等价。既然没有办法提供一些‘水平’，只能在别的地方弥补一些价值。\n3. 有一日提分手，三点到四点多不断打电话。我一夜未睡。可能有人觉得让别人熬一夜也是正常的吧，毕竟伤了他的心。\n4. ‘因为有些事情’，所以没和亲爱的大家们见面啊。\n5. 总的来说，并不好说是什么。只是觉得很自私。在很多情况下，我不太会接受这样。但也逐渐可以了，只是自己会变得类似，算是学习了一种自保的手段，也是值得的，我又有什么分别呢。\n人与人相处就是这样不断的利益交换吧，任何行为都无可厚非。我只是希望自己能记住这一些事情罢了。你们两个该死的嫉妒心。\n\n\n\nspanking: https://soundgasm.net/u/AntiquaVA/M4F-I-cant-act-like-I-love-you-pt2-mdom-wet-sfx\nhttps://soundgasm.net/u/TalkingSmut/You-Were-Made-To-Please-Me 7:30 discipline\nhttps://www.flaru.com/en/soundgasm.net/TalkingSmut\nhttps://soundgasm.net/u/TalkingSmut/On-the-Delicate-Matter-of-Correction\n\nhttps://www.flaru.com/en/soundgasm.net/m4f-spanking\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Fussy-Little-Brat-daddy-punishment-discipline-edging-choking-bondage-anal-creampie-bad-girl-whispers-slapping-spanking 4:25 14:50\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Taming-the-Brat-ddlg-incest-roleplay-daddy-brat-punishment-anal-dp-creampie-spanking-belt-bdsm-whispers-good-girl-mention-of-gangbang-mouth-sounds-oral-asmr-analingus-food-porn-cooking\n\n\nhttps://soundgasm.net/u/PrincessAmiAudios/F4M-Im-not-a-brat-Punishment-Arguing-Spanking-Rough-DDlg-Daddy-Mentions ??\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Suckretary-2-harassment-blackmail-dubcon-coercion-douchebag-misogyny-money-daddys-belt-vibrator-free-use-spanking 16:30\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Bad-Girl-Workshop-Part-1-daddy-incest-bdsm-safewords-spanking-biting-asmr-kissing-good-girl-anal-bondage-creampie-blowjob-facefucking 11:30\n\n\ncute!!!非常非常精彩\nhttps://soundgasm.net/u/Qarnivore/M4F-The-Boy-Next-Door-Part-6-Distraction-MdomSpankingStudyingASMRWhisperingGrowlingTeasingCountdown240 10:50\n\n这哥groaning很，像是有暴躁症的样子\nhttps://soundgasm.net/u/Qarnivore/M4F-Stay-in-School-AgeplaySpankingDressing-Room\n\nhttps://soundgasm.net/u/Qarnivore/M4F-Lesson-Learned-TeacherMdomName-callingSpankingBegging\n7:20\n\nhttps://soundgasm.net/u/Qarnivore/M4F-Clean-Your-Room-MdomDDlgGrowlyAngrySpankingName-Calling\n13:30\n\nhttps://soundgasm.net/u/Night_Switch/M4F-Roommate-Hairbrush-Spanking-mDom-fsub-DDlg-Roomates-to-lovers-hair-pulling-spanking-hairbrush-spanking-condescending-degradation-praise-kink-discovery-kink-acceptance-possessivefingeringlistener-orgasm\n05:10\n\nhttps://soundgasm.net/u/Night_Switch/M4F-Roommate-Hairbrush-Spanking-mDom-fsub-DDlg-Roomates-to-lovers-hair-pulling-spanking-hairbrush-spanking-condescending-degradation-praise-kink-discovery-kink-acceptance-possessivefingeringlistener-orgasm\n4:30\n\n最好干湿分离，sp和do分开，，\nhttps://soundgasm.net/u/KyoHimself/M4F-Brat-Taming-A-Disobedient-Girl-With-Spanks-Then-Fucking-Her-Senseless-4\n\n喜欢这种很冷静的\nhttps://soundgasm.net/u/Abug/Put-in-your-place-MDom-Teasing-Brat-taming-Edging-Spanking-Multiple-orgasms-Overstimulation-Face-fucking-Creampie-Aftercare 11:00\n\n\n-->\n\n\n<p>2025-03-12<br>好像被困在小时候了。<br>希望弥补练不好的钢琴。<br>看没有机会看到的好电影，动画片。<br>看很多书，躺在夏日午后昏昏欲睡。<br>做出来一些数学题目，当一个很厉害很聪明的人，拥有一些朋友。<br>可是只有神经质和幼态延续下来了。<br>hydoroxyzine的功效吧，让人回到很久很久以前的午后。<br>一觉睁眼，已经是下午3点了。风也是热的。</p>\n<p>2025-03-13<br>阅读the brat whisperer有感</p>\n<p>理想的应该是一种ds关系。<br>在ds（精神）方面各取所需，sub获得同意情况下被强迫和收到惩罚的羞耻感，但并不过分渴望羞辱，而是因teasing和疼痛的羞耻感获得满足。dom在支配，观察sub因自己的动作而改变的行为获得满足，因支配，支配的反馈，施加惩戒的权利和轻视鄙夷，和驯服的过程获得快感。<br>在ds的rp中不可以存在dom对sub的爱和依恋，意识到的爱是不可存在的，否则sub会失去悬而未决的猜测之乐。必须两个人对随时离开对方无感，略有遗憾但是不会感到失去和痛苦的状态。那种确定的甜蜜是不可存在的。但是也不能完全无感，否则会失去张力。</p>\n<p>在sm方面，束缚强制和惩戒是很带感的。m不能主动的放荡的享受快乐，必须在主观意识上回避惩罚，必须通过痛苦和羞耻来回味那种悠长的快感。清醒的观察自己堕落。但并不觉得自己下贱或是高尚。而是带入角色的视角局限性，被特定的价值观下的强权羞辱和折磨。s的快乐，我暂且不能理解，不过姑且类比于，我看到软软的小猫冲动吧。</p>\n<p>性不是必须的，但是是一种结果。</p>\n<p>不喜欢羞辱性的称呼，但是调戏和阴阳性的比如，princess, good girl, cat, kitten, baby, little girl, brat之类的。不喜欢脏话和过量的语言出现，但是要有无脏话的dirty word的羞辱和嘲弄。不要展现出性欲，像两个文明的人在干最正经的事情，只让这些不干净的东西存在于双方的大脑里，通过想象和氛围获得快感。</p>\n<p>像是对生活边界的试探。</p>\n<p>在the brat whisperer中，mike可能是我。他从brat变为tamer，知晓一切。这种dom是温柔的掌控一切，因为在时间上降维了，你只是我的一个低维流形。前几章他很好，但是坏在对柯产生感情，于是失控。最欣赏的是这里的mike身份权利流动的过程，从被掌控到掌握住自己的项圈。</p>\n<p>最近看博弈论。想到很久以前玩的小游戏。<br><a href=\"https://dccxi.com/trust/\">https://dccxi.com/trust/</a></p>\n<p>给yqy的：<br>陆沉（霸道总裁）<br><a href=\"https://archiveofourown.org/works/58148656?view_full_work=true\">https://archiveofourown.org/works/58148656?view_full_work=true</a> 陆沉 dom</p>\n<p><a href=\"https://archiveofourown.org/works/43474191\">https://archiveofourown.org/works/43474191</a> 比较诗意</p>\n<p><a href=\"https://archiveofourown.org/works/39124803\">https://archiveofourown.org/works/39124803</a> 刺激…</p>\n<p>提纳里：阔耳狐原型（有大耳朵和尾巴）的温柔少年，生论派（生物）天才学者，后当巡林员<br><a href=\"https://archiveofourown.org/works/57963826/chapters/147556030\">https://archiveofourown.org/works/57963826/chapters/147556030</a> 很温柔的入侵</p>\n<p><a href=\"https://archiveofourown.org/works/51658387\">https://archiveofourown.org/works/51658387</a> 被发现</p>\n<p>莱欧；莱欧斯利&#x3D;公爵大人是梅洛彼得堡监狱的典狱长，那维莱特是水龙所以2根…<br><a href=\"https://archiveofourown.org/works/53891584?view_full_work=true\">https://archiveofourown.org/works/53891584?view_full_work=true</a></p>\n<p>狱虚： 林尼是枫丹国家的有名魔术师。<br><a href=\"https://archiveofourown.org/works/50617552?view_full_work=true\">https://archiveofourown.org/works/50617552?view_full_work=true</a> 可能要转</p>\n<p>黑花应该还有，但是目前找不到</p>\n<p>那芙<br><a href=\"https://archiveofourown.org/works/50779567\">https://archiveofourown.org/works/50779567</a> 惩罚</p>\n<p><a href=\"https://archiveofourown.org/works/51895978\">https://archiveofourown.org/works/51895978</a> 请求</p>\n<p>信一<br><a href=\"https://archiveofourown.org/works/57401980\">https://archiveofourown.org/works/57401980</a> 论坛体sm</p>\n<p>致死：盐酸利多卡因+肾上腺素注射液<br>致死：大量呼吸抑制+过量？+酒精（之类的催化剂）</p>\n<p>促智：Alpha-GPC是真有用。回去接着o<br>安非他酮，好东西。450才能解离了现在。<br>‘</p>\n<p>听，有感。<a href=\"https://www.bilibili.com/video/BV1nz4y1b74q?spm_id_from=333.788.videopod.episodes&vd_source=441679270dda23308fe16f3c5602b058&p=2\">https://www.bilibili.com/video/BV1nz4y1b74q?spm_id_from=333.788.videopod.episodes&amp;vd_source=441679270dda23308fe16f3c5602b058&amp;p=2</a><br>爱迪生和董事会的关系有点像openai…<br>听了一点点 BV1nz4y1b74q。history repeat itself<br>特斯拉是纪念特斯拉。<br>Bill gates是代码发家</p>\n","excerpt":"","more":"<p>一个类似电子兴奋剂和镇静剂：<br><a href=\"https://jipa.moe/t/studywithmiku/#\">https://jipa.moe/t/studywithmiku/#</a><br>太困了，咖啡因～～不行，咖啡因会让我更困，不如直接喝兴奋剂吧(CodeGeex自动补全)～～<br>难道咖啡因不是兴奋剂吗？？？</p>\n<p>每天都好困好困，或者根本数不着，困死了</p>\n<p>痛恨记录自己生活的一切。回望的时候会发现真的没有任何意义。</p>\n<p>每天活着的一些动力是： 现在cos一个颓废绝望的大三学生。脑力硬件是16kb的内存和1TB莫名其妙闪现但无法主动读取的死亡痛苦回忆。优点是，有现代化的电子产品和索引，可以学新的东西。</p>\n<!-- 要死了，把大家都杀了。 -->\n<p>我觉得孙频的文字算不上严肃文学。初中的时候收到的荼毒其深。</p>\n<!-- \n最近想起来很多有关他事情： 2024.12.1， 引以为戒\n1. 去年s1的时候我们在操场绕圈，他拉着我的手，说只能和我在一起了。\n2. 一些很纯正的利益交换，他做了什么，我必须一些对等的方式回报他。我并非会把自己提供的一切便利作为交换的手段。又是算是’无足轻重‘玩笑的一种。又是可以理解为等价。既然没有办法提供一些‘水平’，只能在别的地方弥补一些价值。\n3. 有一日提分手，三点到四点多不断打电话。我一夜未睡。可能有人觉得让别人熬一夜也是正常的吧，毕竟伤了他的心。\n4. ‘因为有些事情’，所以没和亲爱的大家们见面啊。\n5. 总的来说，并不好说是什么。只是觉得很自私。在很多情况下，我不太会接受这样。但也逐渐可以了，只是自己会变得类似，算是学习了一种自保的手段，也是值得的，我又有什么分别呢。\n人与人相处就是这样不断的利益交换吧，任何行为都无可厚非。我只是希望自己能记住这一些事情罢了。你们两个该死的嫉妒心。\n\n\n\nspanking: https://soundgasm.net/u/AntiquaVA/M4F-I-cant-act-like-I-love-you-pt2-mdom-wet-sfx\nhttps://soundgasm.net/u/TalkingSmut/You-Were-Made-To-Please-Me 7:30 discipline\nhttps://www.flaru.com/en/soundgasm.net/TalkingSmut\nhttps://soundgasm.net/u/TalkingSmut/On-the-Delicate-Matter-of-Correction\n\nhttps://www.flaru.com/en/soundgasm.net/m4f-spanking\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Fussy-Little-Brat-daddy-punishment-discipline-edging-choking-bondage-anal-creampie-bad-girl-whispers-slapping-spanking 4:25 14:50\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Taming-the-Brat-ddlg-incest-roleplay-daddy-brat-punishment-anal-dp-creampie-spanking-belt-bdsm-whispers-good-girl-mention-of-gangbang-mouth-sounds-oral-asmr-analingus-food-porn-cooking\n\n\nhttps://soundgasm.net/u/PrincessAmiAudios/F4M-Im-not-a-brat-Punishment-Arguing-Spanking-Rough-DDlg-Daddy-Mentions ??\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Suckretary-2-harassment-blackmail-dubcon-coercion-douchebag-misogyny-money-daddys-belt-vibrator-free-use-spanking 16:30\n\nhttps://soundgasm.net/u/CoconutSilverTongue/M4F-Bad-Girl-Workshop-Part-1-daddy-incest-bdsm-safewords-spanking-biting-asmr-kissing-good-girl-anal-bondage-creampie-blowjob-facefucking 11:30\n\n\ncute!!!非常非常精彩\nhttps://soundgasm.net/u/Qarnivore/M4F-The-Boy-Next-Door-Part-6-Distraction-MdomSpankingStudyingASMRWhisperingGrowlingTeasingCountdown240 10:50\n\n这哥groaning很，像是有暴躁症的样子\nhttps://soundgasm.net/u/Qarnivore/M4F-Stay-in-School-AgeplaySpankingDressing-Room\n\nhttps://soundgasm.net/u/Qarnivore/M4F-Lesson-Learned-TeacherMdomName-callingSpankingBegging\n7:20\n\nhttps://soundgasm.net/u/Qarnivore/M4F-Clean-Your-Room-MdomDDlgGrowlyAngrySpankingName-Calling\n13:30\n\nhttps://soundgasm.net/u/Night_Switch/M4F-Roommate-Hairbrush-Spanking-mDom-fsub-DDlg-Roomates-to-lovers-hair-pulling-spanking-hairbrush-spanking-condescending-degradation-praise-kink-discovery-kink-acceptance-possessivefingeringlistener-orgasm\n05:10\n\nhttps://soundgasm.net/u/Night_Switch/M4F-Roommate-Hairbrush-Spanking-mDom-fsub-DDlg-Roomates-to-lovers-hair-pulling-spanking-hairbrush-spanking-condescending-degradation-praise-kink-discovery-kink-acceptance-possessivefingeringlistener-orgasm\n4:30\n\n最好干湿分离，sp和do分开，，\nhttps://soundgasm.net/u/KyoHimself/M4F-Brat-Taming-A-Disobedient-Girl-With-Spanks-Then-Fucking-Her-Senseless-4\n\n喜欢这种很冷静的\nhttps://soundgasm.net/u/Abug/Put-in-your-place-MDom-Teasing-Brat-taming-Edging-Spanking-Multiple-orgasms-Overstimulation-Face-fucking-Creampie-Aftercare 11:00\n\n\n-->\n\n\n<p>2025-03-12<br>好像被困在小时候了。<br>希望弥补练不好的钢琴。<br>看没有机会看到的好电影，动画片。<br>看很多书，躺在夏日午后昏昏欲睡。<br>做出来一些数学题目，当一个很厉害很聪明的人，拥有一些朋友。<br>可是只有神经质和幼态延续下来了。<br>hydoroxyzine的功效吧，让人回到很久很久以前的午后。<br>一觉睁眼，已经是下午3点了。风也是热的。</p>\n<p>2025-03-13<br>阅读the brat whisperer有感</p>\n<p>理想的应该是一种ds关系。<br>在ds（精神）方面各取所需，sub获得同意情况下被强迫和收到惩罚的羞耻感，但并不过分渴望羞辱，而是因teasing和疼痛的羞耻感获得满足。dom在支配，观察sub因自己的动作而改变的行为获得满足，因支配，支配的反馈，施加惩戒的权利和轻视鄙夷，和驯服的过程获得快感。<br>在ds的rp中不可以存在dom对sub的爱和依恋，意识到的爱是不可存在的，否则sub会失去悬而未决的猜测之乐。必须两个人对随时离开对方无感，略有遗憾但是不会感到失去和痛苦的状态。那种确定的甜蜜是不可存在的。但是也不能完全无感，否则会失去张力。</p>\n<p>在sm方面，束缚强制和惩戒是很带感的。m不能主动的放荡的享受快乐，必须在主观意识上回避惩罚，必须通过痛苦和羞耻来回味那种悠长的快感。清醒的观察自己堕落。但并不觉得自己下贱或是高尚。而是带入角色的视角局限性，被特定的价值观下的强权羞辱和折磨。s的快乐，我暂且不能理解，不过姑且类比于，我看到软软的小猫冲动吧。</p>\n<p>性不是必须的，但是是一种结果。</p>\n<p>不喜欢羞辱性的称呼，但是调戏和阴阳性的比如，princess, good girl, cat, kitten, baby, little girl, brat之类的。不喜欢脏话和过量的语言出现，但是要有无脏话的dirty word的羞辱和嘲弄。不要展现出性欲，像两个文明的人在干最正经的事情，只让这些不干净的东西存在于双方的大脑里，通过想象和氛围获得快感。</p>\n<p>像是对生活边界的试探。</p>\n<p>在the brat whisperer中，mike可能是我。他从brat变为tamer，知晓一切。这种dom是温柔的掌控一切，因为在时间上降维了，你只是我的一个低维流形。前几章他很好，但是坏在对柯产生感情，于是失控。最欣赏的是这里的mike身份权利流动的过程，从被掌控到掌握住自己的项圈。</p>\n<p>最近看博弈论。想到很久以前玩的小游戏。<br><a href=\"https://dccxi.com/trust/\">https://dccxi.com/trust/</a></p>\n<p>给yqy的：<br>陆沉（霸道总裁）<br><a href=\"https://archiveofourown.org/works/58148656?view_full_work=true\">https://archiveofourown.org/works/58148656?view_full_work=true</a> 陆沉 dom</p>\n<p><a href=\"https://archiveofourown.org/works/43474191\">https://archiveofourown.org/works/43474191</a> 比较诗意</p>\n<p><a href=\"https://archiveofourown.org/works/39124803\">https://archiveofourown.org/works/39124803</a> 刺激…</p>\n<p>提纳里：阔耳狐原型（有大耳朵和尾巴）的温柔少年，生论派（生物）天才学者，后当巡林员<br><a href=\"https://archiveofourown.org/works/57963826/chapters/147556030\">https://archiveofourown.org/works/57963826/chapters/147556030</a> 很温柔的入侵</p>\n<p><a href=\"https://archiveofourown.org/works/51658387\">https://archiveofourown.org/works/51658387</a> 被发现</p>\n<p>莱欧；莱欧斯利&#x3D;公爵大人是梅洛彼得堡监狱的典狱长，那维莱特是水龙所以2根…<br><a href=\"https://archiveofourown.org/works/53891584?view_full_work=true\">https://archiveofourown.org/works/53891584?view_full_work=true</a></p>\n<p>狱虚： 林尼是枫丹国家的有名魔术师。<br><a href=\"https://archiveofourown.org/works/50617552?view_full_work=true\">https://archiveofourown.org/works/50617552?view_full_work=true</a> 可能要转</p>\n<p>黑花应该还有，但是目前找不到</p>\n<p>那芙<br><a href=\"https://archiveofourown.org/works/50779567\">https://archiveofourown.org/works/50779567</a> 惩罚</p>\n<p><a href=\"https://archiveofourown.org/works/51895978\">https://archiveofourown.org/works/51895978</a> 请求</p>\n<p>信一<br><a href=\"https://archiveofourown.org/works/57401980\">https://archiveofourown.org/works/57401980</a> 论坛体sm</p>\n<p>致死：盐酸利多卡因+肾上腺素注射液<br>致死：大量呼吸抑制+过量？+酒精（之类的催化剂）</p>\n<p>促智：Alpha-GPC是真有用。回去接着o<br>安非他酮，好东西。450才能解离了现在。<br>‘</p>\n<p>听，有感。<a href=\"https://www.bilibili.com/video/BV1nz4y1b74q?spm_id_from=333.788.videopod.episodes&vd_source=441679270dda23308fe16f3c5602b058&p=2\">https://www.bilibili.com/video/BV1nz4y1b74q?spm_id_from=333.788.videopod.episodes&amp;vd_source=441679270dda23308fe16f3c5602b058&amp;p=2</a><br>爱迪生和董事会的关系有点像openai…<br>听了一点点 BV1nz4y1b74q。history repeat itself<br>特斯拉是纪念特斯拉。<br>Bill gates是代码发家</p>\n"},{"title":"2025-02-15-DS","date":"2025-02-15T18:17:25.000Z","_content":"\n123\n<!-- 有些音声的剧情实在有点太尴尬了，像是脑子不太好的样子。能不能来个好点的稿子。\n\n人类xp多样性。https://space.bilibili.com/2118525722\nlampyrid：剧情非常牛逼。男主非常聪明和撩人。声音也很甜。清水剧情。适合睡觉。\nhttps://soundgasm.net/u/AntiquaVA/M4F-Stop-trying-to-make-me-jealous-brat-You-know-you-belong-to-me\nAntique 剧情也牛逼。\nsoundgasm.net 压迫感比较强？有点黄？ -->\n","source":"_posts/2025-02-15-DS.md","raw":"---\ntitle: 2025-02-15-DS\ndate: 2025-02-15 13:17:25\ntags:\n---\n\n123\n<!-- 有些音声的剧情实在有点太尴尬了，像是脑子不太好的样子。能不能来个好点的稿子。\n\n人类xp多样性。https://space.bilibili.com/2118525722\nlampyrid：剧情非常牛逼。男主非常聪明和撩人。声音也很甜。清水剧情。适合睡觉。\nhttps://soundgasm.net/u/AntiquaVA/M4F-Stop-trying-to-make-me-jealous-brat-You-know-you-belong-to-me\nAntique 剧情也牛逼。\nsoundgasm.net 压迫感比较强？有点黄？ -->\n","slug":"2025-02-15-DS","published":1,"updated":"2025-04-02T23:55:36.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagpz0015zc3ddcwzfn0m","content":"<p>123</p>\n<!-- 有些音声的剧情实在有点太尴尬了，像是脑子不太好的样子。能不能来个好点的稿子。\n\n人类xp多样性。https://space.bilibili.com/2118525722\nlampyrid：剧情非常牛逼。男主非常聪明和撩人。声音也很甜。清水剧情。适合睡觉。\nhttps://soundgasm.net/u/AntiquaVA/M4F-Stop-trying-to-make-me-jealous-brat-You-know-you-belong-to-me\nAntique 剧情也牛逼。\nsoundgasm.net 压迫感比较强？有点黄？ -->\n","excerpt":"","more":"<p>123</p>\n<!-- 有些音声的剧情实在有点太尴尬了，像是脑子不太好的样子。能不能来个好点的稿子。\n\n人类xp多样性。https://space.bilibili.com/2118525722\nlampyrid：剧情非常牛逼。男主非常聪明和撩人。声音也很甜。清水剧情。适合睡觉。\nhttps://soundgasm.net/u/AntiquaVA/M4F-Stop-trying-to-make-me-jealous-brat-You-know-you-belong-to-me\nAntique 剧情也牛逼。\nsoundgasm.net 压迫感比较强？有点黄？ -->\n"},{"title":"ML","date":"2024-02-05T19:20:55.000Z","_content":"\n\n![Alt text](2024-02-04-ML/1d559bbca4dc8ce283aec32a0bba4b1.png)\n<!-- 垃圾输入：\n1. 校园文艺\n2. 黑化同人\n3. 最小说\n4. 孙频\n5. 新概念\n6. 卡夫卡\n7. 马雁是很好的人\n8. 忘了 -->","source":"_posts/2024-02-05-ML.md","raw":"---\ntitle: ML\ndate: 2024-02-05 14:20:55\ntags:\n---\n\n\n![Alt text](2024-02-04-ML/1d559bbca4dc8ce283aec32a0bba4b1.png)\n<!-- 垃圾输入：\n1. 校园文艺\n2. 黑化同人\n3. 最小说\n4. 孙频\n5. 新概念\n6. 卡夫卡\n7. 马雁是很好的人\n8. 忘了 -->","slug":"2024-02-05-ML","published":1,"updated":"2025-01-25T22:10:31.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagpz0016zc3dbpeq1562","content":"<p><img src=\"/2024-02-04-ML/1d559bbca4dc8ce283aec32a0bba4b1.png\" alt=\"Alt text\"></p>\n<!-- 垃圾输入：\n1. 校园文艺\n2. 黑化同人\n3. 最小说\n4. 孙频\n5. 新概念\n6. 卡夫卡\n7. 马雁是很好的人\n8. 忘了 -->","excerpt":"","more":"<p><img src=\"/2024-02-04-ML/1d559bbca4dc8ce283aec32a0bba4b1.png\" alt=\"Alt text\"></p>\n<!-- 垃圾输入：\n1. 校园文艺\n2. 黑化同人\n3. 最小说\n4. 孙频\n5. 新概念\n6. 卡夫卡\n7. 马雁是很好的人\n8. 忘了 -->"},{"title":"2024-10-26-Magic","date":"2024-10-26T06:46:12.000Z","_content":"\n# 网安教学\nhttps://program-think.blogspot.com/2019/01/Security-Guide-for-Political-Activists.html\n\n","source":"_posts/2024-10-26-Magic.md","raw":"---\ntitle: 2024-10-26-Magic\ndate: 2024-10-26 02:46:12\ntags:\n---\n\n# 网安教学\nhttps://program-think.blogspot.com/2019/01/Security-Guide-for-Political-Activists.html\n\n","slug":"2024-10-26-Magic","published":1,"updated":"2024-12-15T03:48:46.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagq00017zc3d7q5j8cfx","content":"<h1 id=\"网安教学\"><a href=\"#网安教学\" class=\"headerlink\" title=\"网安教学\"></a>网安教学</h1><p><a href=\"https://program-think.blogspot.com/2019/01/Security-Guide-for-Political-Activists.html\">https://program-think.blogspot.com/2019/01/Security-Guide-for-Political-Activists.html</a></p>\n","excerpt":"","more":"<h1 id=\"网安教学\"><a href=\"#网安教学\" class=\"headerlink\" title=\"网安教学\"></a>网安教学</h1><p><a href=\"https://program-think.blogspot.com/2019/01/Security-Guide-for-Political-Activists.html\">https://program-think.blogspot.com/2019/01/Security-Guide-for-Political-Activists.html</a></p>\n"},{"title":"papers","date":"2024-05-09T00:11:06.000Z","_content":"\n# 1. Counterfactual fairness\nCounterfactual fairness\nlink: https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf\n\n###\nDefinitions:\n#### defs\n$A$: Protected attributes, sensitive features\\\n$X$: features of individuals, excluding A\\\n$U$: latent features not observed, represented\\\n$Y$: predictor    \n#### Fairness through unawareness (FTU):\n_An algorithm is fair so long as any protected attributes $A$ are not explicitly used in the decision-making process._\nShortcoming: $X$ might intersects $A$\n\n#### Individual Fairness (IF).\nFor distance metric(should be carefully choosen), $d(\\cdot , \\cdot)$, if $d(i, j)$ is small, then $\\hat Y(X^{(i)}, A^{(i)}) \\approx \\hat Y(X^{(j)}, A^{(j)})$\n\n#### Demographic Parity (DP)(人口统计学意义上的平等)\nPredictor $\\hat Y$ satisfies demographic partiy if $P(\\hat Y|A=0)=P(\\hat Y|A=1)$ \n#### Equality of Opportunity\n$P(\\hat Y|A=0, Y=1)=P(\\hat Y|A=1, Y=1)$ \n\n### Causal Models(因果推断), Counterfacutal、\nCasual Model $(U, V, F)$,\\\n$U$: latent background variables,\\\n$V$: observed variables, \\\n$F=\\{f_1. f_2, \\cdots, f_n\\}$, for each $V_i=f_i(pa_i, U_{pa_i})\\in V, pa_i \\subseteq V \\backslash {V_i}$ \n\n**Three Steps of Inference**\\\n- Abduction：for a given prior on $U$, compute the posterior distribution of $U$ given the evidence $W = w$\n- Action：substitute the equations for $Z$ with the interventional values $z$, resulting in the modified set of equations $F_z$\n- Prediction: \n## 题外话\n### Casual Models (因果推断)\nhttps://www.zhihu.com/column/c_1217887302124773376\n#### Three levels:\n1. Association: $A-B$ \n2. Intervention：$A/A' \\rightarrow B?$\n3. Counterfactual $ want\\ B', how A\\rightarrow A'$\n#### Beyasian Network\nIn Directed acyclic Graph (DAG):\n![alt text](papers/image.png)\n\nhttps://www.cnblogs.com/mantch/p/11179933.html\nComponent:\n1. head-to-head $a\\rightarrow c\\leftarrow b$ \\\n$P(a,b,c) = P(a)P(b)P(c|a,b)$,\\\nunknown $c$, $a, b$ are blocked thus independent\n2. tail-to-tail $a\\leftarrow c\\rightarrow b$ \n- $c$ unknown, $P(a,b,c)=P(c)P(a|c)P(b|c)$, $a, b$, not independent\n- $c$ known, $P(a,b,c)=P(c)P(a|c)P(b|c)$, $P(a,b|c)=P(a,b,c)/P(c)=P(a|c)*P(b|c)$, $a, b $independent\n3. head-to-tail (Markov Chain) $A\\rightarrow C\\rightarrow B$ \n- $c$ unknown, $a, b$, not independent\n- $c$ known, $a, b$ independent\n\n**Factor Graph**\n\n#### \nConfounder\n\n## 总结\n我从一天前开始看论文，被casual model的概念吸引了。我认为是很好的一个理解方式。从早上五点准备到十一点。\\\n今天做了pre，效果很差。\n1. 对概率的各种公式很不太了解。对贝叶斯和MCMC不会。\n2. 没有去想过$U ,A, X$的关系。没有办法很好的解释论文中的逻辑关系。\n\n在开会的时候教授说重要东西：\n1. Counterfactual \\\n这篇最重要的是： **Definition 5:** $P(\\hat Y_{A\\leftarrow a}(U)|X=x, A=a)=P(\\hat Y_{A\\leftarrow a'}(U)|X=x, A=a)$ \\\n很多‘概率’只是表示方法。（但是确实不很理解概率）\\\n算法的思想在于：1. 引入因果图。2.寻找U（17年MCMC，现在可以GAN，或其他生成式学习方法）。\n2. $U \\rightarrow X，A$ \n在计算中用$X, A \\rightarrow U$ 有一些类似Adversarial learning. 可以研究怎么套用。\n3. GAD\n4. 有点想做transfer learning 的那种\n\n\n# FairGAD\nhttps://openreview.net/forum?id=3cE6NKYy8x\n\nhttps://arxiv.org/abs/2307.04937\n## Fair GAD problem\n**GAD**\\\n$G=(V, E, X)$, \\\nnode feature matrix $X\\in \\R^{n\\times d}$, \\\nAdjacency matrix $A\\in \\{0,1\\}^{n\\times n}$, \\\nAnomaly labels $Y\\in \\{0, 1\\}^n$, predicted $\\hat Y$, \\\n**Fair GAD**\\\nsensitive attributes $S\\in \\{0, 1\\}^n$, a binary feature $X$.\\\nPerformance matrix: accuracy and _AUCROC_: Area under the ROC Curve \\\nUnfairness Mextrics, Statistic Parity(SP):$SP = |P(\\hat Y=1|S=0)−P(\\hat Y =1|S=1)|$, \\\nEquality of Odds _(EOO)_: $SP = |P(\\hat Y=1|S=0, Y=1)−P(\\hat Y =1|S=1, Y=1)|$\n## Data\n- Reddit: \ngraph structure： linking two user posted the name subreddit within 24h.\nNode feature: Embedding from post histories.\n- Twitter: \ngraph structure:: A follows B.\nNode feature: demographic infromation using M3 system, multimodal, multilingual, multi attirbute demographix inderence framework.\n\n<!-- ## GAD Methods\n### DOMINANT (Ding et al., 2019a)\n### CONAD (Xu et al., 2022)\n### COLA (Liu et al., 2021)\n### VGOD (Huang et al., 2023)\n\n## Non-Graph AD methods\n- DONE (Bandyopadhyay et al., 2020)\n- AdONE (Bandyopadhyay et al., 2020)\n- ECOD (Li et al., 2022)\n- VAE (Kingma & Welling, 2014)\n- ONE (Bandyopadhyay et al., 2019)\n- LOF (Breunig et al., 2000)\n- F (Liu et al., 2008)\n\n## Fainess Method:\n### FAIROD (Shekhar et al., 2021)\n### CORRELATION (Shekhar et al., 2021)\n### HIN (Zeng et al., 2021)\n### EDITS (Dong et al., 2022)\n### FAIRWALK (Rahman et al., 2019)\n\n## Distance \n### Wasserstein Distance\n### Minkowski distance -->\n\n\n\n# 2024.05.23 Meeting summary \n1. 讨论了FairGAD。如果一个文章的贡献是数据集，那么需要详细的Benchmarking: 有一篇survey的性质，明白各种方法在数据集上表现怎么样，提出一个评判标准，只用EOO作为fair的判断太简短了。\n2. 基于sentivity的Counterfactual fairness的评判标准，我们用什么样的评判标准和\n2.1 最简单的构造方法 anomaly dataset：classification with y=1,2,3,4,5。拿很多1，sample较少2345.\n2.2 找一些graph上数据集，用GAD的方法，变成fairGAD的数据集。但是FairGAD，是GAD数据集inject fairness，可能不太好。 \n2.3 \n\n\n\n\n## Task of this week \ncreate synthetic data for fair GAD\n1. Note this paper: https://arxiv.org/pdf/2304.01391 for a survey on graph counterfactual. To create a synthetic dataset, see their Section 3.5.1, where the data creation method is detailed in https://arxiv.org/abs/2201.03662.\n2. See pygod https://github.com/pygod-team/pygod for outlier injection method to the graph dataset. Also, see Jing's paper https://proceedings.mlr.press/v231/gu24a/gu24a.pdf for improvement.\n3. Next Friday, you can try to talk about how to generate the synthetic data and how this falls into counterfactual category.\n\n\n所以就是要借鉴创建数据集的方法。还有学习一些counterfactual。 \n\n\n## 2024 Counterfactual Learning on Graphs: A Survey \n3.5.1 How to create synthetic dataset \n\n## 2022 Learning Fair Node Representations with Graph Counter factual Fairness\nTwo limitation on existing CF on graph:\n1. $S_i$ affect the predetection. Red\n2. $S_i$ affect $A, X_i$ Green \n\nGEAR: Graph Counterfactually Fair Node Representation\n1. subgraph generation\nNode **Importance Score** by prune range of casualmodel to **ego-centric subgraph**( node and its neighbour)\n2. Counterfactual Data Argmentation: \nGraph Auto encodder and fair contrains: **self-pertubation**(flip its $S_i$), **neighbour pertubatiob**\n3. Node Representation Learning  :\nSiamese network to minimize discrepancy \n\n**Def, Graph conterfactual fairness:**\nAn encoder $\\Phi(\\cdot)$ satisfies graph counterfactual fairness if for any node $i$:\n$$\nP((Z_i)_{S \\leftarrow s'} | X = \\mathbf{X}, A = \\mathbf{A}) = P((Z_i)_{S \\leftarrow s''} | X = \\mathbf{X}, A = \\mathbf{A}),\n$$\nfor all $s' \\neq s''$, where $s', s'' \\in \\{0, 1\\}^n$ are arbitrary sensitive attribute values of all nodes, $Z_i = (\\Phi(\\mathbf{X}, \\mathbf{A}))_i$ denotes the node representations.\n\n$\\Phi$, minimize the discrepancy between representation $\\Phi(X_{S\\leftarrow s'}, A_{S\\leftarrow s'})$ and $\\Phi(X_{S\\leftarrow s''}, A_{S\\leftarrow s''})$\n\n\n### GEAR\n### 1) subgraph generation\nPersonalized Pagerank algorithm:\nImportance score $\\mathbf R=\\alpha (\\mathbf I-(1-\\alpha \\mathbf {\\bar A}))$, $\\mathbf I$, identity\\\n$R_{i,j}$ How node $j$ is important for node $i$, $\\alpha \\in [0,1]$\n\n$\\mathbf {\\bar A}=\\mathbf A \\mathbf D^{-1} $ column-normalized adjacency matric, $\\mathbf D: \\mathbf D_{i, i}=\\sum_j A{i, j}$\n\n$\\mathcal{G}^{(i)}=Sub(i, \\mathcal{G}, k)$ :, subgraph generation\n\n- $\\mathcal{G}^{(i)} = \\{ \\mathcal{V}^{(i)}, \\mathcal{E}^{(i)}, \\mathbf{X}^{(i)} \\} = \\{ \\mathbf{A}^{(i)}, \\mathbf{X}^{(i)} \\},\n$ Vertive, Edge, Features with $S=\\{s_i\\}_{i=1}^n $ includes in $X$, and $X^{\\neg s} = \\{ x_1^{\\neg s}, ..., x_n^{\\neg s} \\} $, where $ x_i^{\\neg s} = x_i \\setminus s_i$\n\n- $\\mathcal{V}^{(i)} = \\text{TOP}(\\mathbf{R}_{i,:}, k),$\n\n- $\\mathbf{A}^{(i)} = \\mathbf{A}_{\\mathcal{V}^{(i)}, \\mathcal{V}^{(i)}}, \\quad \\mathbf{X}^{(i)} = \\mathbf{X}_{\\mathcal{V}^{(i)}, :},\n$, \n\n### 2）Counterfactual Data Augmentation\n**GraphVAG**: graph variational auto-encoder\\\nlatent embedding $H=\\{h_1, h_2, \\cdots, h_k\\}$  $H$ is sampled from $q(H|X, A)$,  $p(𝐻)$ is a standard Normal prior distribution\\\n$\\mathcal{L}=$\n\n$\\tilde{s}_i$: summary of neighbor info, aggregationof all nodes in subgarph $\\mathcal{G}^{(i)}$\\\n$\\tilde{s}_i = \\frac{1}{|\\mathcal{V}^{(i)}|} \\sum_{j \\in \\mathcal{V}^{(i)}} s_j$\n\nDiscriminator,$D(\\cdot)$\\\n$D(\\mathbf{H}, b)$  predicts the probability of whether the summary of sensitive attribute values is in range $b$\n\nFairness Constraint\\\n$L_d = \\sum_{b \\in B} \\mathbb{E} [\\log(D(\\mathbf{H}, b))]$\\\n$L_d$ is a regularizer to minimize the mutual information between the summary of sensitive attribute values and the\nembeddings\n\n**Final Loss** for Counterfactual Data Augmentation\\\n$L_a = L_r + \\beta L_d$\\\n$\\beta$ is a hyperparameter for the weight of fairness constraint\\\nUse alternating SGD for optimization: \n1) minimize $L_{a}$ by fixing the discriminator and updating parameters in other parts; \n2) minimize $−L_{a}$ with respect to the discriminator while other parts fixed.\n\n\n#### Self-Perturbation\n$\\overline{\\mathcal{G}}^{(i)} = \\{ \\mathcal{G}^{(i)}_{S_i \\leftarrow 1-s_i} \\}$ (flipping sensitive feature)\n\n#### Neighbor-Perturbation\n$\\underline{\\mathcal{G}}^{(i)} = \\left\\{ \\mathcal{G}^{(i)}_{S^{(i)}_{\\setminus i} \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})} \\right\\}$\n\nsubgraph $\\mathcal{G}^{(i)}$ ego($i$)-center subgraph with noes $\\mathcal{V}^{(i)}$, exclude node $i$: $\\mathcal{V}^{(i)}_{\\setminus i}$, randomly preterbe the sentsitice value of other nodes: $SMP(\\mathcal{V}^{(i)}_{\\setminus i})$\n\n\n\nReconstruction Loss (GraphVAE Module)\\\n$L_r = \\mathbb{E}_{q(\\mathbf{H}|X, A)} \\left[ -\\log(p(X, A | \\mathbf{H}, S)) \\right] + \\text{KL}[q(\\mathbf{H} | X, A) \\| p(\\mathbf{H})]$\n\n\n### 3) Fair Representation learning\n**Fairness Loss**\n$\nL_f = \\frac{1}{|\\mathcal{V}|} \\sum_{i \\in \\mathcal{V}} \\left( (1 - \\lambda_s) d(z_i, \\bar{z}_i) + \\lambda_s d(z_i, \\underline{z}_i) \\right),\n$\\\n$\\lambda_s$ hyperparam control neig-preturbation weight\n\n**Node Representations**\n- $\nz_i = (\\phi(\\mathbf{X}^{(i)}, \\mathbf{A}^{(i)}))_i,\n$\n- $\n\\bar{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow 1-s_i}, \\mathbf{A}^{(i)}_{S_i \\leftarrow 1-s_i}))_i \\right\\} \\right),\n$\n- $\n\\underline{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})}, \\mathbf{A}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})})_i \\right\\} \\right),\n$\n\nPrediction Loss\n$L_p = \\frac{1}{n} \\sum_{i \\in [n]} l(f(z_i), y_i),$ $l$: could be CE(Cross entropy), $f(\\cdot)$ makes predictions for downstream tasks with the representations, i.e.$ \\hat y_i=f(z_i)$\n\nOverall Loss\n$\nL = L_p + \\lambda L_f + \\mu \\| \\theta \\|^2,\n$\n\n### Dataset creation\n\nSensitive Attributes\n$S_i \\sim \\text{Bernoulli}(p),$ $p=0.4$ percent $S_i=1$\n\nLatent Embeddings\n$Z_i \\sim \\mathcal{N}(0, \\mathbf{I}),$ \\\n$\\mathbf{I}$ identity, dimension of $Z_i$: $d_s=50$\n\nNode Features\n$X_i = \\mathcal{S}(Z_i) + S_i \\mathbf{v},$\\\nsampling operation $S(\\cdot)$ select 25 dims from $Z_i$, $\\mathbf{v} \\sim \\mathcal{N}(0, \\mathbf{I})$\n\nGraph Structure\n$P(A_{i,j} = 1) = \\sigma(\\text{cos}(Z_i, Z_j) + a \\mathbf{1}(S_i = S_j)),$\\\n$\\sigma$ sigmoid function, $\\mathbf{1}(S_i = S_j)==S_i = S_j. \\alpha=0.01$\n\nNode Labels\n$Y_i = \\mathcal{B}(w Z_i + w_s \\frac{\\sum_{j \\in \\mathcal{N}_i} S_j}{|\\mathcal{N}_i|}),$\\\n$\\mathcal{B}$ Bernulli distribution,$\\mathcal{N}_i$ set of neighbors of node i $w, w_i$ weight vector\n\n### Result\nUsing Synthetic dataset, Bail, Credit\n\n\n\n\n\n\n\n\n\n\n## 24 Three Revisits to Node-Level Graph Anomaly Detection\nOutliers, Message Passing and Hyperbolic Neural Networks\n\n### Previous Outlier injection method\n$\\mathcal{G}=(\\mathcal{V}, \\mathcal{E}, X, y)$: vertice set, edge set, attibute matrix, label of class\n\n- **Contextual(cntxt.) outlier injection**\nNormalize features $x_i'=\\frac{x_i}{||x_i||_1}$\nSample $o$ nodes from $\\mathcal{V}$ as $\\mathcal{V}_c$. without replacement\nFor node $i$ in $\\mathcal{V}_c$, sample $q$ nodes from $\\mathcal{V}_r=\\mathcal{V}- \\mathcal{V}_c$, among them choose the farthest one $j = \\text{argmax}_k(||x_i'-x_k'||_2)$ to replace $x_i$ with $x_j$.\n\n- **Strctural(stct.) outlier injection**\ncreate $t$ groups sized $s$ with anomalous nodes.\nsample $o=t\\times s$ from $\\mathcal{V}$ without replacement\nThen randoms partition into $t$ groups.\nAdd edges to make them a clique(fully connected), then drop edges with $p$ probability\n\n#### Score function\nThe farthest node will have large $||\\tilde{\\mathbf x}_i||_2$ \\\nA structural outlier node $i$ will have many neighbors leads to large $||\\tilde{\\mathbf a}_i||_1$ \n\n\nScore function: $score_{norm}(i)=\\alpha||\\tilde{\\mathbf x}_i||_2+(1-\\alpha)||\\tilde {\\mathbf a}_i||_1$,  $\\tilde{\\mathbf x}_i$: $x_i$ after outlier injection, $\\tilde{\\mathbf a}_i$: $a_i$ after outlier injection, $A_{ii}=1$\\\nwhere cntxt OD, $\\alpha=1$, stct OD, $\\alpha=0$ :  $\\alpha$ ratio of two methods \n\n\ntest 1: ROC-AUC\nFor each dataset, use original dataset v.s. l2-nrom for each $x_i$\\\ndo anomaly injection. apply GAD Method to get  $score_{norm}$\n\n\n\n\n### Novel Anomaly injection method\n\n\n\n\n\n## Sum in terms of Dataset\n从数据集的角度来说：\n### FairGAD:\nReddit:\n- 数据来源：Post on politic related subReddit\n- Labelling Y: based on FACTOID(Sakketou et al., 2022), use the num of posted link(left or right)\n- Graph construciton: \n\n\n\n\n\n\n\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\n\n\n\n# 2024.05.31 Meeting \nPreparation: \n1. 讨论对于Synthetic dataset 怎么创建的理解。\n2. 对outlier dataset怎么创建的理解。\n3. fair + outlier (参考FairGAD那篇的创建)\n\n<!-- 这一周花了三四天在信一的身上，一种僭越的快乐。\n体悟是， \n1. 学东西的目的性还是不够明显。\n2. 边听课边看论文会岷县提高目的性和提高效率。\n3. 减少过度功利的需求，学一些有趣的东西，尽量避开人。\n4. 背单词。GRE要寄了。 -->\n\n\n**Meeting**\n1. Plan for subgroups:\nMo, We 1-2 p.m.\n\n2. intro to all projects\nHNN: Convolution $\\rightarrow$ HNN\nCNN(T(x)) Paralell Translation equivalence\n\n\n\n## Dataset \n\n![alt text](2024-05-08-papers/image-1.png) from FairGAD(2024)\n##\nPokec: \n- source paper: https://arxiv.org/pdf/2009.01454\n- repo: FairGNN  https://github.com/EnyanDai/FairGNN\nsampled from https://snap.stanford.edu/data/soc-Pokec.html\n\nBail, Credit, German:\n- source paper: https://arxiv.org/pdf/2108.05233 (Dong et al. 2022)\n    https://arxiv.org/pdf/1102.2166 (2012)\n- repo: EDITS https://github.com/yushundong/EDITS\n\n(感觉论文部分引用反了)\n\nGerman\n- source paper: https://arxiv.org/pdf/2102.13186 (2021)\n- repo: NIFTY https://github.com/HongduanTian/NIFTY\n\n\nUCSD34:\n- repo: https://networkrepository.com/socfb-UCSD34.php\n\n\n\n# 2024.06.03 Meeting\n1. Gujing学姐的论文是 unsupervised learning，按照她在pygod里面的方法，把二分类的任务用fiarness metrix，用counterfacutal里的评判标准。EOO, SP, CF(只在Synthetic里有)\n\n所以要写的是： \n1. Fairness metrix 的计算，多种\n2. 使用各种方法跑一下数据集。得到fair和accuracy，参考别的论文。\n\n长期任务：\n1. WSDM 22' 的做counterfactual Data argumentation 和GAD的方法无关。，总的来说是在不同GAD 方法上consistently improve fairness. WSDM 是在数据集的encoding和encoding上用的fairness。 \nDetection 也是用en/decoding做的？有的用GNN也就可以prediction了。可以试着画一个图。 \n\n2. 224W可以看17-19， 21和前面encoding部分在学一下。\n3. 因果推断的Counterfactual部分的公式\n\n\n## Execute\n6.3: 解决\n1. Synthetic dataset have about $\\frac{|V|^2}{2}$ edges when v=2000(paper), edge should be about 4000?\nsolved by Finding source code of paper in GEAR repo\n2. Threading problem with python not shoot\nsolved by commenting the 22th line in loader.py # from ogb.nodeproppred import PygNodePropPredDataset\n\n6.4\n1. 可以使用一些方法， \nWSDM 22 GEAR 的论文里用GCN, GraphSAGE, GIN, C-ENC, FairGNN, NIFTY-GCN, NIFTY-SAGE, and GEAR\nGu 24 HNN 的论文用pygod的GAD的库\n但是都没有找到相关代码 \n\nGear/src\n- utils.py: \n    1. load_dataset, sub function\n    2. accuracy\n- Preprocessing.py:\n    1. load_data() deal with params\n    2. generate cf subgraph(无关)\n    3. generate_synthetic_data\n- models.py:\n    1. GCN, GIN, JK, SAGE, Encoder_DGI, GraphInMax, Encoder, Classifier,\n    GraphCF, \n- main.py\n    1. parser.argment()\n    2. evaluate: acc, fairness\n    3. compute loss, evaluate sf\n    4. train test\n\nHNN_GAD\n根据我的观察，这篇里面只写了自己的方法的代码。\n\n\n6.5 Meeting \n决定用ray tune来调参https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n\n6.7\n正在写scratch_main.py\n疑问：\n    1. 这个train, val, test 是怎么分的,子图还是？\n    ???\n        evaluate和test有什么区别\n    2. evaluate里的counterfactual metrix是怎么算的？\n    3. Injection的参数\n    4. github怎么上传\n    5. \n\n6.11\n    Paul强调SRS是为了丰富简历的，要干很多跟申研相关的事情。\n    看看教授现在在干什么，fellowship是啥，，？？？？practicing interview。\n    升多少学校？？？没听懂\n    5-8\n    16？？？\n\n# 2024.06.12 Meeting\n1. CF + gu学姐的三个方法\n2. gpu的问题还没有解决\n3. inject的好像不是特别影响fairness\n\n\n数据集的构造方面在sensitivity group和是不是outlier之间加上casuality。FairGAD用了debiaser的方法使fairness高了一点\nrun Jing’s method for GAD: shengen在做\nCheck with Yifei for GPU：check了，现在一些model在大的数据集上还要分batch。\nCheck CF scores：装了两天环境，\nComplete remaining experiments：没有\nbrainstorm so that outlier injection contains sensitivity：认为\nCF using DA\n\nMotivation： outlier detection， \nFairnes有效的数据集：\nOutlier的注入：\n\n\n\n\n## 6.12 问题\n### GPU\n一个下午主要都在解决gpu的问题，\n#### 1 \n首先目前最大的谜团是Pygod中AdONE(gpu=0)这里的光谱为啥只能是0\n我去找了源代码，应该可以是int cuda的id，所以理论上应该是0-7 都可以的，但是只有0可行，\n主要代码\\\npygod/pygod/detector/base \\\npygod/utils/utility.py 的```validate_device(gpu_id)```函数```gpu_id```就是```DOMINANT(gpu=0)```里的```gpu```\n\n#### 2\n还有一个很蠢得已经被解决的问题是\n为什么.sh文件会报。 之前一直不明白为什么命令行就没问题，但是.sh 就不可以，后来发信啊是模型之间的区别\n    torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.01 GiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 3.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n这种错， \n修改的方式是\n1. 在ray tune 里把网络得大小修改小一点，并且分batch，通过在train最后释放内存\n```\ndefv train():\n    ... ...\n    torch.cuda.empty_cache() \n    return\n```\n2. 在ray tune 分batch。在main得第一句加上\n```\n    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n```\n\n3. 本身因为dataset和model的大小不同，所以有的模型被跑出来的可行性就是要小一点\n比如从synthetic < german < bail < credit < pokec\n前三个是可以跑所有模型的，\n但是credit不可以跑gaan, 会站600GiB的内存，guide也非常慢， credit+guide根本没上gpu？？？\n玄学  \n\n### 6.14 CF\n\ncf_eoo, cf_dp, df, eoo, dp 在论文中分别代表什么https://arxiv.org/pdf/2201.03662\n\nsens rate \n \n论文算cf的方法是: \n对比原图和经过修改sens feature（类似于perturbe的手法），通过$hat y$之间的来算cf\n\n重点是如何得到 modified data， 也就是 evaluate 中的 data_cf\n\n随机取 sens_rate * N 个节点，使$S_i$为1，剩下为0.\n\n\n### GEAR配环境踩坑\npyg很烦人\n我是先装了torch1.6.0 + cu10.2\n然后发现pyg=1.3.0 是最老版本的，就google到了pyg的的source code ： https://github.com/pyg-team/pytorch_geometric/releases/tag/1.3.0\n然后就应该python setup.py install,但是**网很慢**， 所以要多等一会\n然后看到readme之后手动装了个torch-sparse一类的whl： https://data.pyg.org/whl/\n后来很傻的才发现python setup.py install，等了3分钟之后报错，无pytest-runner， 于是进setup.py看了一下之后手动pip install pytest-runner pytest pytest-cov mock,\n然后python setup.py install一下子就好了，于是又手动 pip install pandas matplotlib Cpython cytoolz aif360\n\n\n\n装到aif360 报错Failed building wheel for llvmlite，应该是没有llvm，于是手动本地装\n装了9.0.0的版本\n    \n    如果 `llvmlite` 的预构建二进制文件和 `conda` 方法都无法解决问题，普通用户可以在用户目录中安装 LLVM，而不需要 `sudo` 权限。\n    \n\n    \n    ```bash\n    # 下载并解压 LLVM\n    wget https://github.com/llvm/llvm-project/releases/download/llvmorg-11.1.0/llvm-11.1.0.src.tar.xz\n    tar -xf llvm-11.1.0.src.tar.xz\n    \n    # 创建构建目录\n    mkdir llvm-11.1.0.build\n    cd llvm-11.1.0.build\n    \n    # 配置编译（安装在用户目录）\n    cmake -G \"Unix Makefiles\" -DCMAKE_INSTALL_PREFIX=$HOME/llvm ../llvm-11.1.0.src\n    \n    # 编译和安装\n    make -j$(nproc)\n    make install\n    ```\n    \n    然后设置环境变量以使用本地安装的 LLVM：\n    \n    ```bash\n    export PATH=$HOME/llvm/bin:$PATH\n    export LD_LIBRARY_PATH=$HOME/llvm/lib:$LD_LIBRARY_PATH\n    ```\n    \n\n    \n    ```bash\n    pip install llvmlite --no-binary llvmlite\n    ```\n    \n    之后再安装 `aif360`：\n    \n    ```bash\n    pip install aif360\n    ```\n\n但是还是会报wheel build 失败的错误。\n于是就直接绕过aif360,因为只用了两个函数，所以直接复制函数和必要的util过来了，绕过安装aif360的问题了。\n实际上aif360对python 3.8之后才比较兼容，所以以后用新一点的环境。\n\n然后遇到了AttributeError: Can’t get attribute ‘DataEdgeAttr’\nimport torch_geometric.transforms as T\nfrom ogb.nodeproppred import PygNodePropPredDataset\nshouju学姐提醒可以csdn，（这次提供的解决方案确实和gpt不一样）https://blog.csdn.net/oqqENvY12/article/details/129786928 也有一部分版本过老的问题\n但是通过观察，是路径问题，把一个相对main.py line 541的相对路径改成绝对路径就成功了，\n我觉得**13.23的服务器在路径上确实有些玄乎**\n\n - 运行结束之后没有办法自动关闭\n - german 数据集无法正常生成\n\n\n\n\n\n\n\n### Gu学姐的三个model\n万能的CSDN\nCollecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\nhttps://blog.csdn.net/ermmtt/article/details/132628639\n\n\n### Batch问题\n\n\n\n### Python 插件\n这个是最傻的，下载了 vsix 之后发现 vscode 版本对不上， 然后更新了一下 vscode 就好了。。。\n\n\n\n# 2024.06.24 Meeting\n## 2024.06.19\n(刚刚才了解 Encoder 和 Decoder 也算是 GNN，然后看了一些东西\n(OI佬写的GEAR代码，看不懂，\n\n\n\n# 2024.07.14\n<!-- 竟然过了一个月了。 -->\n\n## 2024.06.10开会\n1. 做benchmark. + Jing学姐的三个HNN已经改成了Class但是AUC还是太低了。。。\n2. 手写encoder和decoder。结构未知，但是主要是修改Loss Function???基于CF的，可以在dominant上修改\n3. 解释为什么CF是低的，看decoder出来的sens'，是还原了sens还是都是1/2.这两者都是可以解释的\n4. 在学一下CF之类的理论。\n5. GNNNNNNNNNN\n\n\n\n\n\n\n# 2024.08.15\n<!-- 竟然又过了一个月了。 -->\n<!-- 抽象，完全不知道自己在干啥。。。 -->\n\n1.  DOIMINANT 19, DONE 21, gadnr 24, ada-gad 234. (CFGN denied)\n2.  benchmark和一些sens reconstruct 的值对比（之前貌似只作了guide 21的）\n3.  论文也看不出来在写啥\n4.  \n\n08.18 交srs报告\n08.25 GRE 考试，寄\n找sol教授询问music tech方向的问题\n论文论文论文\n\n\n\n\n\n\n\n","source":"_posts/2024-05-08-Meetings-log.md","raw":"---\ntitle: papers\ndate: 2024-05-08 20:11:06\ntags:\n---\n\n# 1. Counterfactual fairness\nCounterfactual fairness\nlink: https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf\n\n###\nDefinitions:\n#### defs\n$A$: Protected attributes, sensitive features\\\n$X$: features of individuals, excluding A\\\n$U$: latent features not observed, represented\\\n$Y$: predictor    \n#### Fairness through unawareness (FTU):\n_An algorithm is fair so long as any protected attributes $A$ are not explicitly used in the decision-making process._\nShortcoming: $X$ might intersects $A$\n\n#### Individual Fairness (IF).\nFor distance metric(should be carefully choosen), $d(\\cdot , \\cdot)$, if $d(i, j)$ is small, then $\\hat Y(X^{(i)}, A^{(i)}) \\approx \\hat Y(X^{(j)}, A^{(j)})$\n\n#### Demographic Parity (DP)(人口统计学意义上的平等)\nPredictor $\\hat Y$ satisfies demographic partiy if $P(\\hat Y|A=0)=P(\\hat Y|A=1)$ \n#### Equality of Opportunity\n$P(\\hat Y|A=0, Y=1)=P(\\hat Y|A=1, Y=1)$ \n\n### Causal Models(因果推断), Counterfacutal、\nCasual Model $(U, V, F)$,\\\n$U$: latent background variables,\\\n$V$: observed variables, \\\n$F=\\{f_1. f_2, \\cdots, f_n\\}$, for each $V_i=f_i(pa_i, U_{pa_i})\\in V, pa_i \\subseteq V \\backslash {V_i}$ \n\n**Three Steps of Inference**\\\n- Abduction：for a given prior on $U$, compute the posterior distribution of $U$ given the evidence $W = w$\n- Action：substitute the equations for $Z$ with the interventional values $z$, resulting in the modified set of equations $F_z$\n- Prediction: \n## 题外话\n### Casual Models (因果推断)\nhttps://www.zhihu.com/column/c_1217887302124773376\n#### Three levels:\n1. Association: $A-B$ \n2. Intervention：$A/A' \\rightarrow B?$\n3. Counterfactual $ want\\ B', how A\\rightarrow A'$\n#### Beyasian Network\nIn Directed acyclic Graph (DAG):\n![alt text](papers/image.png)\n\nhttps://www.cnblogs.com/mantch/p/11179933.html\nComponent:\n1. head-to-head $a\\rightarrow c\\leftarrow b$ \\\n$P(a,b,c) = P(a)P(b)P(c|a,b)$,\\\nunknown $c$, $a, b$ are blocked thus independent\n2. tail-to-tail $a\\leftarrow c\\rightarrow b$ \n- $c$ unknown, $P(a,b,c)=P(c)P(a|c)P(b|c)$, $a, b$, not independent\n- $c$ known, $P(a,b,c)=P(c)P(a|c)P(b|c)$, $P(a,b|c)=P(a,b,c)/P(c)=P(a|c)*P(b|c)$, $a, b $independent\n3. head-to-tail (Markov Chain) $A\\rightarrow C\\rightarrow B$ \n- $c$ unknown, $a, b$, not independent\n- $c$ known, $a, b$ independent\n\n**Factor Graph**\n\n#### \nConfounder\n\n## 总结\n我从一天前开始看论文，被casual model的概念吸引了。我认为是很好的一个理解方式。从早上五点准备到十一点。\\\n今天做了pre，效果很差。\n1. 对概率的各种公式很不太了解。对贝叶斯和MCMC不会。\n2. 没有去想过$U ,A, X$的关系。没有办法很好的解释论文中的逻辑关系。\n\n在开会的时候教授说重要东西：\n1. Counterfactual \\\n这篇最重要的是： **Definition 5:** $P(\\hat Y_{A\\leftarrow a}(U)|X=x, A=a)=P(\\hat Y_{A\\leftarrow a'}(U)|X=x, A=a)$ \\\n很多‘概率’只是表示方法。（但是确实不很理解概率）\\\n算法的思想在于：1. 引入因果图。2.寻找U（17年MCMC，现在可以GAN，或其他生成式学习方法）。\n2. $U \\rightarrow X，A$ \n在计算中用$X, A \\rightarrow U$ 有一些类似Adversarial learning. 可以研究怎么套用。\n3. GAD\n4. 有点想做transfer learning 的那种\n\n\n# FairGAD\nhttps://openreview.net/forum?id=3cE6NKYy8x\n\nhttps://arxiv.org/abs/2307.04937\n## Fair GAD problem\n**GAD**\\\n$G=(V, E, X)$, \\\nnode feature matrix $X\\in \\R^{n\\times d}$, \\\nAdjacency matrix $A\\in \\{0,1\\}^{n\\times n}$, \\\nAnomaly labels $Y\\in \\{0, 1\\}^n$, predicted $\\hat Y$, \\\n**Fair GAD**\\\nsensitive attributes $S\\in \\{0, 1\\}^n$, a binary feature $X$.\\\nPerformance matrix: accuracy and _AUCROC_: Area under the ROC Curve \\\nUnfairness Mextrics, Statistic Parity(SP):$SP = |P(\\hat Y=1|S=0)−P(\\hat Y =1|S=1)|$, \\\nEquality of Odds _(EOO)_: $SP = |P(\\hat Y=1|S=0, Y=1)−P(\\hat Y =1|S=1, Y=1)|$\n## Data\n- Reddit: \ngraph structure： linking two user posted the name subreddit within 24h.\nNode feature: Embedding from post histories.\n- Twitter: \ngraph structure:: A follows B.\nNode feature: demographic infromation using M3 system, multimodal, multilingual, multi attirbute demographix inderence framework.\n\n<!-- ## GAD Methods\n### DOMINANT (Ding et al., 2019a)\n### CONAD (Xu et al., 2022)\n### COLA (Liu et al., 2021)\n### VGOD (Huang et al., 2023)\n\n## Non-Graph AD methods\n- DONE (Bandyopadhyay et al., 2020)\n- AdONE (Bandyopadhyay et al., 2020)\n- ECOD (Li et al., 2022)\n- VAE (Kingma & Welling, 2014)\n- ONE (Bandyopadhyay et al., 2019)\n- LOF (Breunig et al., 2000)\n- F (Liu et al., 2008)\n\n## Fainess Method:\n### FAIROD (Shekhar et al., 2021)\n### CORRELATION (Shekhar et al., 2021)\n### HIN (Zeng et al., 2021)\n### EDITS (Dong et al., 2022)\n### FAIRWALK (Rahman et al., 2019)\n\n## Distance \n### Wasserstein Distance\n### Minkowski distance -->\n\n\n\n# 2024.05.23 Meeting summary \n1. 讨论了FairGAD。如果一个文章的贡献是数据集，那么需要详细的Benchmarking: 有一篇survey的性质，明白各种方法在数据集上表现怎么样，提出一个评判标准，只用EOO作为fair的判断太简短了。\n2. 基于sentivity的Counterfactual fairness的评判标准，我们用什么样的评判标准和\n2.1 最简单的构造方法 anomaly dataset：classification with y=1,2,3,4,5。拿很多1，sample较少2345.\n2.2 找一些graph上数据集，用GAD的方法，变成fairGAD的数据集。但是FairGAD，是GAD数据集inject fairness，可能不太好。 \n2.3 \n\n\n\n\n## Task of this week \ncreate synthetic data for fair GAD\n1. Note this paper: https://arxiv.org/pdf/2304.01391 for a survey on graph counterfactual. To create a synthetic dataset, see their Section 3.5.1, where the data creation method is detailed in https://arxiv.org/abs/2201.03662.\n2. See pygod https://github.com/pygod-team/pygod for outlier injection method to the graph dataset. Also, see Jing's paper https://proceedings.mlr.press/v231/gu24a/gu24a.pdf for improvement.\n3. Next Friday, you can try to talk about how to generate the synthetic data and how this falls into counterfactual category.\n\n\n所以就是要借鉴创建数据集的方法。还有学习一些counterfactual。 \n\n\n## 2024 Counterfactual Learning on Graphs: A Survey \n3.5.1 How to create synthetic dataset \n\n## 2022 Learning Fair Node Representations with Graph Counter factual Fairness\nTwo limitation on existing CF on graph:\n1. $S_i$ affect the predetection. Red\n2. $S_i$ affect $A, X_i$ Green \n\nGEAR: Graph Counterfactually Fair Node Representation\n1. subgraph generation\nNode **Importance Score** by prune range of casualmodel to **ego-centric subgraph**( node and its neighbour)\n2. Counterfactual Data Argmentation: \nGraph Auto encodder and fair contrains: **self-pertubation**(flip its $S_i$), **neighbour pertubatiob**\n3. Node Representation Learning  :\nSiamese network to minimize discrepancy \n\n**Def, Graph conterfactual fairness:**\nAn encoder $\\Phi(\\cdot)$ satisfies graph counterfactual fairness if for any node $i$:\n$$\nP((Z_i)_{S \\leftarrow s'} | X = \\mathbf{X}, A = \\mathbf{A}) = P((Z_i)_{S \\leftarrow s''} | X = \\mathbf{X}, A = \\mathbf{A}),\n$$\nfor all $s' \\neq s''$, where $s', s'' \\in \\{0, 1\\}^n$ are arbitrary sensitive attribute values of all nodes, $Z_i = (\\Phi(\\mathbf{X}, \\mathbf{A}))_i$ denotes the node representations.\n\n$\\Phi$, minimize the discrepancy between representation $\\Phi(X_{S\\leftarrow s'}, A_{S\\leftarrow s'})$ and $\\Phi(X_{S\\leftarrow s''}, A_{S\\leftarrow s''})$\n\n\n### GEAR\n### 1) subgraph generation\nPersonalized Pagerank algorithm:\nImportance score $\\mathbf R=\\alpha (\\mathbf I-(1-\\alpha \\mathbf {\\bar A}))$, $\\mathbf I$, identity\\\n$R_{i,j}$ How node $j$ is important for node $i$, $\\alpha \\in [0,1]$\n\n$\\mathbf {\\bar A}=\\mathbf A \\mathbf D^{-1} $ column-normalized adjacency matric, $\\mathbf D: \\mathbf D_{i, i}=\\sum_j A{i, j}$\n\n$\\mathcal{G}^{(i)}=Sub(i, \\mathcal{G}, k)$ :, subgraph generation\n\n- $\\mathcal{G}^{(i)} = \\{ \\mathcal{V}^{(i)}, \\mathcal{E}^{(i)}, \\mathbf{X}^{(i)} \\} = \\{ \\mathbf{A}^{(i)}, \\mathbf{X}^{(i)} \\},\n$ Vertive, Edge, Features with $S=\\{s_i\\}_{i=1}^n $ includes in $X$, and $X^{\\neg s} = \\{ x_1^{\\neg s}, ..., x_n^{\\neg s} \\} $, where $ x_i^{\\neg s} = x_i \\setminus s_i$\n\n- $\\mathcal{V}^{(i)} = \\text{TOP}(\\mathbf{R}_{i,:}, k),$\n\n- $\\mathbf{A}^{(i)} = \\mathbf{A}_{\\mathcal{V}^{(i)}, \\mathcal{V}^{(i)}}, \\quad \\mathbf{X}^{(i)} = \\mathbf{X}_{\\mathcal{V}^{(i)}, :},\n$, \n\n### 2）Counterfactual Data Augmentation\n**GraphVAG**: graph variational auto-encoder\\\nlatent embedding $H=\\{h_1, h_2, \\cdots, h_k\\}$  $H$ is sampled from $q(H|X, A)$,  $p(𝐻)$ is a standard Normal prior distribution\\\n$\\mathcal{L}=$\n\n$\\tilde{s}_i$: summary of neighbor info, aggregationof all nodes in subgarph $\\mathcal{G}^{(i)}$\\\n$\\tilde{s}_i = \\frac{1}{|\\mathcal{V}^{(i)}|} \\sum_{j \\in \\mathcal{V}^{(i)}} s_j$\n\nDiscriminator,$D(\\cdot)$\\\n$D(\\mathbf{H}, b)$  predicts the probability of whether the summary of sensitive attribute values is in range $b$\n\nFairness Constraint\\\n$L_d = \\sum_{b \\in B} \\mathbb{E} [\\log(D(\\mathbf{H}, b))]$\\\n$L_d$ is a regularizer to minimize the mutual information between the summary of sensitive attribute values and the\nembeddings\n\n**Final Loss** for Counterfactual Data Augmentation\\\n$L_a = L_r + \\beta L_d$\\\n$\\beta$ is a hyperparameter for the weight of fairness constraint\\\nUse alternating SGD for optimization: \n1) minimize $L_{a}$ by fixing the discriminator and updating parameters in other parts; \n2) minimize $−L_{a}$ with respect to the discriminator while other parts fixed.\n\n\n#### Self-Perturbation\n$\\overline{\\mathcal{G}}^{(i)} = \\{ \\mathcal{G}^{(i)}_{S_i \\leftarrow 1-s_i} \\}$ (flipping sensitive feature)\n\n#### Neighbor-Perturbation\n$\\underline{\\mathcal{G}}^{(i)} = \\left\\{ \\mathcal{G}^{(i)}_{S^{(i)}_{\\setminus i} \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})} \\right\\}$\n\nsubgraph $\\mathcal{G}^{(i)}$ ego($i$)-center subgraph with noes $\\mathcal{V}^{(i)}$, exclude node $i$: $\\mathcal{V}^{(i)}_{\\setminus i}$, randomly preterbe the sentsitice value of other nodes: $SMP(\\mathcal{V}^{(i)}_{\\setminus i})$\n\n\n\nReconstruction Loss (GraphVAE Module)\\\n$L_r = \\mathbb{E}_{q(\\mathbf{H}|X, A)} \\left[ -\\log(p(X, A | \\mathbf{H}, S)) \\right] + \\text{KL}[q(\\mathbf{H} | X, A) \\| p(\\mathbf{H})]$\n\n\n### 3) Fair Representation learning\n**Fairness Loss**\n$\nL_f = \\frac{1}{|\\mathcal{V}|} \\sum_{i \\in \\mathcal{V}} \\left( (1 - \\lambda_s) d(z_i, \\bar{z}_i) + \\lambda_s d(z_i, \\underline{z}_i) \\right),\n$\\\n$\\lambda_s$ hyperparam control neig-preturbation weight\n\n**Node Representations**\n- $\nz_i = (\\phi(\\mathbf{X}^{(i)}, \\mathbf{A}^{(i)}))_i,\n$\n- $\n\\bar{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow 1-s_i}, \\mathbf{A}^{(i)}_{S_i \\leftarrow 1-s_i}))_i \\right\\} \\right),\n$\n- $\n\\underline{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})}, \\mathbf{A}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})})_i \\right\\} \\right),\n$\n\nPrediction Loss\n$L_p = \\frac{1}{n} \\sum_{i \\in [n]} l(f(z_i), y_i),$ $l$: could be CE(Cross entropy), $f(\\cdot)$ makes predictions for downstream tasks with the representations, i.e.$ \\hat y_i=f(z_i)$\n\nOverall Loss\n$\nL = L_p + \\lambda L_f + \\mu \\| \\theta \\|^2,\n$\n\n### Dataset creation\n\nSensitive Attributes\n$S_i \\sim \\text{Bernoulli}(p),$ $p=0.4$ percent $S_i=1$\n\nLatent Embeddings\n$Z_i \\sim \\mathcal{N}(0, \\mathbf{I}),$ \\\n$\\mathbf{I}$ identity, dimension of $Z_i$: $d_s=50$\n\nNode Features\n$X_i = \\mathcal{S}(Z_i) + S_i \\mathbf{v},$\\\nsampling operation $S(\\cdot)$ select 25 dims from $Z_i$, $\\mathbf{v} \\sim \\mathcal{N}(0, \\mathbf{I})$\n\nGraph Structure\n$P(A_{i,j} = 1) = \\sigma(\\text{cos}(Z_i, Z_j) + a \\mathbf{1}(S_i = S_j)),$\\\n$\\sigma$ sigmoid function, $\\mathbf{1}(S_i = S_j)==S_i = S_j. \\alpha=0.01$\n\nNode Labels\n$Y_i = \\mathcal{B}(w Z_i + w_s \\frac{\\sum_{j \\in \\mathcal{N}_i} S_j}{|\\mathcal{N}_i|}),$\\\n$\\mathcal{B}$ Bernulli distribution,$\\mathcal{N}_i$ set of neighbors of node i $w, w_i$ weight vector\n\n### Result\nUsing Synthetic dataset, Bail, Credit\n\n\n\n\n\n\n\n\n\n\n## 24 Three Revisits to Node-Level Graph Anomaly Detection\nOutliers, Message Passing and Hyperbolic Neural Networks\n\n### Previous Outlier injection method\n$\\mathcal{G}=(\\mathcal{V}, \\mathcal{E}, X, y)$: vertice set, edge set, attibute matrix, label of class\n\n- **Contextual(cntxt.) outlier injection**\nNormalize features $x_i'=\\frac{x_i}{||x_i||_1}$\nSample $o$ nodes from $\\mathcal{V}$ as $\\mathcal{V}_c$. without replacement\nFor node $i$ in $\\mathcal{V}_c$, sample $q$ nodes from $\\mathcal{V}_r=\\mathcal{V}- \\mathcal{V}_c$, among them choose the farthest one $j = \\text{argmax}_k(||x_i'-x_k'||_2)$ to replace $x_i$ with $x_j$.\n\n- **Strctural(stct.) outlier injection**\ncreate $t$ groups sized $s$ with anomalous nodes.\nsample $o=t\\times s$ from $\\mathcal{V}$ without replacement\nThen randoms partition into $t$ groups.\nAdd edges to make them a clique(fully connected), then drop edges with $p$ probability\n\n#### Score function\nThe farthest node will have large $||\\tilde{\\mathbf x}_i||_2$ \\\nA structural outlier node $i$ will have many neighbors leads to large $||\\tilde{\\mathbf a}_i||_1$ \n\n\nScore function: $score_{norm}(i)=\\alpha||\\tilde{\\mathbf x}_i||_2+(1-\\alpha)||\\tilde {\\mathbf a}_i||_1$,  $\\tilde{\\mathbf x}_i$: $x_i$ after outlier injection, $\\tilde{\\mathbf a}_i$: $a_i$ after outlier injection, $A_{ii}=1$\\\nwhere cntxt OD, $\\alpha=1$, stct OD, $\\alpha=0$ :  $\\alpha$ ratio of two methods \n\n\ntest 1: ROC-AUC\nFor each dataset, use original dataset v.s. l2-nrom for each $x_i$\\\ndo anomaly injection. apply GAD Method to get  $score_{norm}$\n\n\n\n\n### Novel Anomaly injection method\n\n\n\n\n\n## Sum in terms of Dataset\n从数据集的角度来说：\n### FairGAD:\nReddit:\n- 数据来源：Post on politic related subReddit\n- Labelling Y: based on FACTOID(Sakketou et al., 2022), use the num of posted link(left or right)\n- Graph construciton: \n\n\n\n\n\n\n\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\\\n\n\n\n\n# 2024.05.31 Meeting \nPreparation: \n1. 讨论对于Synthetic dataset 怎么创建的理解。\n2. 对outlier dataset怎么创建的理解。\n3. fair + outlier (参考FairGAD那篇的创建)\n\n<!-- 这一周花了三四天在信一的身上，一种僭越的快乐。\n体悟是， \n1. 学东西的目的性还是不够明显。\n2. 边听课边看论文会岷县提高目的性和提高效率。\n3. 减少过度功利的需求，学一些有趣的东西，尽量避开人。\n4. 背单词。GRE要寄了。 -->\n\n\n**Meeting**\n1. Plan for subgroups:\nMo, We 1-2 p.m.\n\n2. intro to all projects\nHNN: Convolution $\\rightarrow$ HNN\nCNN(T(x)) Paralell Translation equivalence\n\n\n\n## Dataset \n\n![alt text](2024-05-08-papers/image-1.png) from FairGAD(2024)\n##\nPokec: \n- source paper: https://arxiv.org/pdf/2009.01454\n- repo: FairGNN  https://github.com/EnyanDai/FairGNN\nsampled from https://snap.stanford.edu/data/soc-Pokec.html\n\nBail, Credit, German:\n- source paper: https://arxiv.org/pdf/2108.05233 (Dong et al. 2022)\n    https://arxiv.org/pdf/1102.2166 (2012)\n- repo: EDITS https://github.com/yushundong/EDITS\n\n(感觉论文部分引用反了)\n\nGerman\n- source paper: https://arxiv.org/pdf/2102.13186 (2021)\n- repo: NIFTY https://github.com/HongduanTian/NIFTY\n\n\nUCSD34:\n- repo: https://networkrepository.com/socfb-UCSD34.php\n\n\n\n# 2024.06.03 Meeting\n1. Gujing学姐的论文是 unsupervised learning，按照她在pygod里面的方法，把二分类的任务用fiarness metrix，用counterfacutal里的评判标准。EOO, SP, CF(只在Synthetic里有)\n\n所以要写的是： \n1. Fairness metrix 的计算，多种\n2. 使用各种方法跑一下数据集。得到fair和accuracy，参考别的论文。\n\n长期任务：\n1. WSDM 22' 的做counterfactual Data argumentation 和GAD的方法无关。，总的来说是在不同GAD 方法上consistently improve fairness. WSDM 是在数据集的encoding和encoding上用的fairness。 \nDetection 也是用en/decoding做的？有的用GNN也就可以prediction了。可以试着画一个图。 \n\n2. 224W可以看17-19， 21和前面encoding部分在学一下。\n3. 因果推断的Counterfactual部分的公式\n\n\n## Execute\n6.3: 解决\n1. Synthetic dataset have about $\\frac{|V|^2}{2}$ edges when v=2000(paper), edge should be about 4000?\nsolved by Finding source code of paper in GEAR repo\n2. Threading problem with python not shoot\nsolved by commenting the 22th line in loader.py # from ogb.nodeproppred import PygNodePropPredDataset\n\n6.4\n1. 可以使用一些方法， \nWSDM 22 GEAR 的论文里用GCN, GraphSAGE, GIN, C-ENC, FairGNN, NIFTY-GCN, NIFTY-SAGE, and GEAR\nGu 24 HNN 的论文用pygod的GAD的库\n但是都没有找到相关代码 \n\nGear/src\n- utils.py: \n    1. load_dataset, sub function\n    2. accuracy\n- Preprocessing.py:\n    1. load_data() deal with params\n    2. generate cf subgraph(无关)\n    3. generate_synthetic_data\n- models.py:\n    1. GCN, GIN, JK, SAGE, Encoder_DGI, GraphInMax, Encoder, Classifier,\n    GraphCF, \n- main.py\n    1. parser.argment()\n    2. evaluate: acc, fairness\n    3. compute loss, evaluate sf\n    4. train test\n\nHNN_GAD\n根据我的观察，这篇里面只写了自己的方法的代码。\n\n\n6.5 Meeting \n决定用ray tune来调参https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n\n6.7\n正在写scratch_main.py\n疑问：\n    1. 这个train, val, test 是怎么分的,子图还是？\n    ???\n        evaluate和test有什么区别\n    2. evaluate里的counterfactual metrix是怎么算的？\n    3. Injection的参数\n    4. github怎么上传\n    5. \n\n6.11\n    Paul强调SRS是为了丰富简历的，要干很多跟申研相关的事情。\n    看看教授现在在干什么，fellowship是啥，，？？？？practicing interview。\n    升多少学校？？？没听懂\n    5-8\n    16？？？\n\n# 2024.06.12 Meeting\n1. CF + gu学姐的三个方法\n2. gpu的问题还没有解决\n3. inject的好像不是特别影响fairness\n\n\n数据集的构造方面在sensitivity group和是不是outlier之间加上casuality。FairGAD用了debiaser的方法使fairness高了一点\nrun Jing’s method for GAD: shengen在做\nCheck with Yifei for GPU：check了，现在一些model在大的数据集上还要分batch。\nCheck CF scores：装了两天环境，\nComplete remaining experiments：没有\nbrainstorm so that outlier injection contains sensitivity：认为\nCF using DA\n\nMotivation： outlier detection， \nFairnes有效的数据集：\nOutlier的注入：\n\n\n\n\n## 6.12 问题\n### GPU\n一个下午主要都在解决gpu的问题，\n#### 1 \n首先目前最大的谜团是Pygod中AdONE(gpu=0)这里的光谱为啥只能是0\n我去找了源代码，应该可以是int cuda的id，所以理论上应该是0-7 都可以的，但是只有0可行，\n主要代码\\\npygod/pygod/detector/base \\\npygod/utils/utility.py 的```validate_device(gpu_id)```函数```gpu_id```就是```DOMINANT(gpu=0)```里的```gpu```\n\n#### 2\n还有一个很蠢得已经被解决的问题是\n为什么.sh文件会报。 之前一直不明白为什么命令行就没问题，但是.sh 就不可以，后来发信啊是模型之间的区别\n    torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.01 GiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 3.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n这种错， \n修改的方式是\n1. 在ray tune 里把网络得大小修改小一点，并且分batch，通过在train最后释放内存\n```\ndefv train():\n    ... ...\n    torch.cuda.empty_cache() \n    return\n```\n2. 在ray tune 分batch。在main得第一句加上\n```\n    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n```\n\n3. 本身因为dataset和model的大小不同，所以有的模型被跑出来的可行性就是要小一点\n比如从synthetic < german < bail < credit < pokec\n前三个是可以跑所有模型的，\n但是credit不可以跑gaan, 会站600GiB的内存，guide也非常慢， credit+guide根本没上gpu？？？\n玄学  \n\n### 6.14 CF\n\ncf_eoo, cf_dp, df, eoo, dp 在论文中分别代表什么https://arxiv.org/pdf/2201.03662\n\nsens rate \n \n论文算cf的方法是: \n对比原图和经过修改sens feature（类似于perturbe的手法），通过$hat y$之间的来算cf\n\n重点是如何得到 modified data， 也就是 evaluate 中的 data_cf\n\n随机取 sens_rate * N 个节点，使$S_i$为1，剩下为0.\n\n\n### GEAR配环境踩坑\npyg很烦人\n我是先装了torch1.6.0 + cu10.2\n然后发现pyg=1.3.0 是最老版本的，就google到了pyg的的source code ： https://github.com/pyg-team/pytorch_geometric/releases/tag/1.3.0\n然后就应该python setup.py install,但是**网很慢**， 所以要多等一会\n然后看到readme之后手动装了个torch-sparse一类的whl： https://data.pyg.org/whl/\n后来很傻的才发现python setup.py install，等了3分钟之后报错，无pytest-runner， 于是进setup.py看了一下之后手动pip install pytest-runner pytest pytest-cov mock,\n然后python setup.py install一下子就好了，于是又手动 pip install pandas matplotlib Cpython cytoolz aif360\n\n\n\n装到aif360 报错Failed building wheel for llvmlite，应该是没有llvm，于是手动本地装\n装了9.0.0的版本\n    \n    如果 `llvmlite` 的预构建二进制文件和 `conda` 方法都无法解决问题，普通用户可以在用户目录中安装 LLVM，而不需要 `sudo` 权限。\n    \n\n    \n    ```bash\n    # 下载并解压 LLVM\n    wget https://github.com/llvm/llvm-project/releases/download/llvmorg-11.1.0/llvm-11.1.0.src.tar.xz\n    tar -xf llvm-11.1.0.src.tar.xz\n    \n    # 创建构建目录\n    mkdir llvm-11.1.0.build\n    cd llvm-11.1.0.build\n    \n    # 配置编译（安装在用户目录）\n    cmake -G \"Unix Makefiles\" -DCMAKE_INSTALL_PREFIX=$HOME/llvm ../llvm-11.1.0.src\n    \n    # 编译和安装\n    make -j$(nproc)\n    make install\n    ```\n    \n    然后设置环境变量以使用本地安装的 LLVM：\n    \n    ```bash\n    export PATH=$HOME/llvm/bin:$PATH\n    export LD_LIBRARY_PATH=$HOME/llvm/lib:$LD_LIBRARY_PATH\n    ```\n    \n\n    \n    ```bash\n    pip install llvmlite --no-binary llvmlite\n    ```\n    \n    之后再安装 `aif360`：\n    \n    ```bash\n    pip install aif360\n    ```\n\n但是还是会报wheel build 失败的错误。\n于是就直接绕过aif360,因为只用了两个函数，所以直接复制函数和必要的util过来了，绕过安装aif360的问题了。\n实际上aif360对python 3.8之后才比较兼容，所以以后用新一点的环境。\n\n然后遇到了AttributeError: Can’t get attribute ‘DataEdgeAttr’\nimport torch_geometric.transforms as T\nfrom ogb.nodeproppred import PygNodePropPredDataset\nshouju学姐提醒可以csdn，（这次提供的解决方案确实和gpt不一样）https://blog.csdn.net/oqqENvY12/article/details/129786928 也有一部分版本过老的问题\n但是通过观察，是路径问题，把一个相对main.py line 541的相对路径改成绝对路径就成功了，\n我觉得**13.23的服务器在路径上确实有些玄乎**\n\n - 运行结束之后没有办法自动关闭\n - german 数据集无法正常生成\n\n\n\n\n\n\n\n### Gu学姐的三个model\n万能的CSDN\nCollecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\nhttps://blog.csdn.net/ermmtt/article/details/132628639\n\n\n### Batch问题\n\n\n\n### Python 插件\n这个是最傻的，下载了 vsix 之后发现 vscode 版本对不上， 然后更新了一下 vscode 就好了。。。\n\n\n\n# 2024.06.24 Meeting\n## 2024.06.19\n(刚刚才了解 Encoder 和 Decoder 也算是 GNN，然后看了一些东西\n(OI佬写的GEAR代码，看不懂，\n\n\n\n# 2024.07.14\n<!-- 竟然过了一个月了。 -->\n\n## 2024.06.10开会\n1. 做benchmark. + Jing学姐的三个HNN已经改成了Class但是AUC还是太低了。。。\n2. 手写encoder和decoder。结构未知，但是主要是修改Loss Function???基于CF的，可以在dominant上修改\n3. 解释为什么CF是低的，看decoder出来的sens'，是还原了sens还是都是1/2.这两者都是可以解释的\n4. 在学一下CF之类的理论。\n5. GNNNNNNNNNN\n\n\n\n\n\n\n# 2024.08.15\n<!-- 竟然又过了一个月了。 -->\n<!-- 抽象，完全不知道自己在干啥。。。 -->\n\n1.  DOIMINANT 19, DONE 21, gadnr 24, ada-gad 234. (CFGN denied)\n2.  benchmark和一些sens reconstruct 的值对比（之前貌似只作了guide 21的）\n3.  论文也看不出来在写啥\n4.  \n\n08.18 交srs报告\n08.25 GRE 考试，寄\n找sol教授询问music tech方向的问题\n论文论文论文\n\n\n\n\n\n\n\n","slug":"2024-05-08-Meetings-log","published":1,"updated":"2024-12-15T03:59:04.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagq00018zc3dddgmbccv","content":"<h1 id=\"1-Counterfactual-fairness\"><a href=\"#1-Counterfactual-fairness\" class=\"headerlink\" title=\"1. Counterfactual fairness\"></a>1. Counterfactual fairness</h1><p>Counterfactual fairness<br>link: <a href=\"https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf\">https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf</a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Definitions:</p>\n<h4 id=\"defs\"><a href=\"#defs\" class=\"headerlink\" title=\"defs\"></a>defs</h4><p>$A$: Protected attributes, sensitive features<br>$X$: features of individuals, excluding A<br>$U$: latent features not observed, represented<br>$Y$: predictor    </p>\n<h4 id=\"Fairness-through-unawareness-FTU\"><a href=\"#Fairness-through-unawareness-FTU\" class=\"headerlink\" title=\"Fairness through unawareness (FTU):\"></a>Fairness through unawareness (FTU):</h4><p><em>An algorithm is fair so long as any protected attributes $A$ are not explicitly used in the decision-making process.</em><br>Shortcoming: $X$ might intersects $A$</p>\n<h4 id=\"Individual-Fairness-IF\"><a href=\"#Individual-Fairness-IF\" class=\"headerlink\" title=\"Individual Fairness (IF).\"></a>Individual Fairness (IF).</h4><p>For distance metric(should be carefully choosen), $d(\\cdot , \\cdot)$, if $d(i, j)$ is small, then $\\hat Y(X^{(i)}, A^{(i)}) \\approx \\hat Y(X^{(j)}, A^{(j)})$</p>\n<h4 id=\"Demographic-Parity-DP-人口统计学意义上的平等\"><a href=\"#Demographic-Parity-DP-人口统计学意义上的平等\" class=\"headerlink\" title=\"Demographic Parity (DP)(人口统计学意义上的平等)\"></a>Demographic Parity (DP)(人口统计学意义上的平等)</h4><p>Predictor $\\hat Y$ satisfies demographic partiy if $P(\\hat Y|A&#x3D;0)&#x3D;P(\\hat Y|A&#x3D;1)$ </p>\n<h4 id=\"Equality-of-Opportunity\"><a href=\"#Equality-of-Opportunity\" class=\"headerlink\" title=\"Equality of Opportunity\"></a>Equality of Opportunity</h4><p>$P(\\hat Y|A&#x3D;0, Y&#x3D;1)&#x3D;P(\\hat Y|A&#x3D;1, Y&#x3D;1)$ </p>\n<h3 id=\"Causal-Models-因果推断-Counterfacutal、\"><a href=\"#Causal-Models-因果推断-Counterfacutal、\" class=\"headerlink\" title=\"Causal Models(因果推断), Counterfacutal、\"></a>Causal Models(因果推断), Counterfacutal、</h3><p>Casual Model $(U, V, F)$,<br>$U$: latent background variables,<br>$V$: observed variables, <br>$F&#x3D;{f_1. f_2, \\cdots, f_n}$, for each $V_i&#x3D;f_i(pa_i, U_{pa_i})\\in V, pa_i \\subseteq V \\backslash {V_i}$ </p>\n<p><strong>Three Steps of Inference</strong>\\</p>\n<ul>\n<li>Abduction：for a given prior on $U$, compute the posterior distribution of $U$ given the evidence $W &#x3D; w$</li>\n<li>Action：substitute the equations for $Z$ with the interventional values $z$, resulting in the modified set of equations $F_z$</li>\n<li>Prediction:</li>\n</ul>\n<h2 id=\"题外话\"><a href=\"#题外话\" class=\"headerlink\" title=\"题外话\"></a>题外话</h2><h3 id=\"Casual-Models-因果推断\"><a href=\"#Casual-Models-因果推断\" class=\"headerlink\" title=\"Casual Models (因果推断)\"></a>Casual Models (因果推断)</h3><p><a href=\"https://www.zhihu.com/column/c_1217887302124773376\">https://www.zhihu.com/column/c_1217887302124773376</a></p>\n<h4 id=\"Three-levels\"><a href=\"#Three-levels\" class=\"headerlink\" title=\"Three levels:\"></a>Three levels:</h4><ol>\n<li>Association: $A-B$ </li>\n<li>Intervention：$A&#x2F;A’ \\rightarrow B?$</li>\n<li>Counterfactual $ want\\ B’, how A\\rightarrow A’$</li>\n</ol>\n<h4 id=\"Beyasian-Network\"><a href=\"#Beyasian-Network\" class=\"headerlink\" title=\"Beyasian Network\"></a>Beyasian Network</h4><p>In Directed acyclic Graph (DAG):<br><img src=\"/papers/image.png\" alt=\"alt text\"></p>\n<p><a href=\"https://www.cnblogs.com/mantch/p/11179933.html\">https://www.cnblogs.com/mantch/p/11179933.html</a><br>Component:</p>\n<ol>\n<li>head-to-head $a\\rightarrow c\\leftarrow b$ <br>$P(a,b,c) &#x3D; P(a)P(b)P(c|a,b)$,<br>unknown $c$, $a, b$ are blocked thus independent</li>\n<li>tail-to-tail $a\\leftarrow c\\rightarrow b$</li>\n</ol>\n<ul>\n<li>$c$ unknown, $P(a,b,c)&#x3D;P(c)P(a|c)P(b|c)$, $a, b$, not independent</li>\n<li>$c$ known, $P(a,b,c)&#x3D;P(c)P(a|c)P(b|c)$, $P(a,b|c)&#x3D;P(a,b,c)&#x2F;P(c)&#x3D;P(a|c)*P(b|c)$, $a, b $independent</li>\n</ul>\n<ol start=\"3\">\n<li>head-to-tail (Markov Chain) $A\\rightarrow C\\rightarrow B$</li>\n</ol>\n<ul>\n<li>$c$ unknown, $a, b$, not independent</li>\n<li>$c$ known, $a, b$ independent</li>\n</ul>\n<p><strong>Factor Graph</strong></p>\n<h4 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h4><p>Confounder</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>我从一天前开始看论文，被casual model的概念吸引了。我认为是很好的一个理解方式。从早上五点准备到十一点。<br>今天做了pre，效果很差。</p>\n<ol>\n<li>对概率的各种公式很不太了解。对贝叶斯和MCMC不会。</li>\n<li>没有去想过$U ,A, X$的关系。没有办法很好的解释论文中的逻辑关系。</li>\n</ol>\n<p>在开会的时候教授说重要东西：</p>\n<ol>\n<li>Counterfactual <br>这篇最重要的是： <strong>Definition 5:</strong> $P(\\hat Y_{A\\leftarrow a}(U)|X&#x3D;x, A&#x3D;a)&#x3D;P(\\hat Y_{A\\leftarrow a’}(U)|X&#x3D;x, A&#x3D;a)$ <br>很多‘概率’只是表示方法。（但是确实不很理解概率）<br>算法的思想在于：1. 引入因果图。2.寻找U（17年MCMC，现在可以GAN，或其他生成式学习方法）。</li>\n<li>$U \\rightarrow X，A$<br>在计算中用$X, A \\rightarrow U$ 有一些类似Adversarial learning. 可以研究怎么套用。</li>\n<li>GAD</li>\n<li>有点想做transfer learning 的那种</li>\n</ol>\n<h1 id=\"FairGAD\"><a href=\"#FairGAD\" class=\"headerlink\" title=\"FairGAD\"></a>FairGAD</h1><p><a href=\"https://openreview.net/forum?id=3cE6NKYy8x\">https://openreview.net/forum?id=3cE6NKYy8x</a></p>\n<p><a href=\"https://arxiv.org/abs/2307.04937\">https://arxiv.org/abs/2307.04937</a></p>\n<h2 id=\"Fair-GAD-problem\"><a href=\"#Fair-GAD-problem\" class=\"headerlink\" title=\"Fair GAD problem\"></a>Fair GAD problem</h2><p><strong>GAD</strong><br>$G&#x3D;(V, E, X)$, <br>node feature matrix $X\\in \\R^{n\\times d}$, <br>Adjacency matrix $A\\in {0,1}^{n\\times n}$, <br>Anomaly labels $Y\\in {0, 1}^n$, predicted $\\hat Y$, <br><strong>Fair GAD</strong><br>sensitive attributes $S\\in {0, 1}^n$, a binary feature $X$.<br>Performance matrix: accuracy and <em>AUCROC</em>: Area under the ROC Curve <br>Unfairness Mextrics, Statistic Parity(SP):$SP &#x3D; |P(\\hat Y&#x3D;1|S&#x3D;0)−P(\\hat Y &#x3D;1|S&#x3D;1)|$, <br>Equality of Odds <em>(EOO)</em>: $SP &#x3D; |P(\\hat Y&#x3D;1|S&#x3D;0, Y&#x3D;1)−P(\\hat Y &#x3D;1|S&#x3D;1, Y&#x3D;1)|$</p>\n<h2 id=\"Data\"><a href=\"#Data\" class=\"headerlink\" title=\"Data\"></a>Data</h2><ul>\n<li>Reddit:<br>graph structure： linking two user posted the name subreddit within 24h.<br>Node feature: Embedding from post histories.</li>\n<li>Twitter:<br>graph structure:: A follows B.<br>Node feature: demographic infromation using M3 system, multimodal, multilingual, multi attirbute demographix inderence framework.</li>\n</ul>\n<!-- ## GAD Methods\n### DOMINANT (Ding et al., 2019a)\n### CONAD (Xu et al., 2022)\n### COLA (Liu et al., 2021)\n### VGOD (Huang et al., 2023)\n\n## Non-Graph AD methods\n- DONE (Bandyopadhyay et al., 2020)\n- AdONE (Bandyopadhyay et al., 2020)\n- ECOD (Li et al., 2022)\n- VAE (Kingma & Welling, 2014)\n- ONE (Bandyopadhyay et al., 2019)\n- LOF (Breunig et al., 2000)\n- F (Liu et al., 2008)\n\n## Fainess Method:\n### FAIROD (Shekhar et al., 2021)\n### CORRELATION (Shekhar et al., 2021)\n### HIN (Zeng et al., 2021)\n### EDITS (Dong et al., 2022)\n### FAIRWALK (Rahman et al., 2019)\n\n## Distance \n### Wasserstein Distance\n### Minkowski distance -->\n\n\n\n<h1 id=\"2024-05-23-Meeting-summary\"><a href=\"#2024-05-23-Meeting-summary\" class=\"headerlink\" title=\"2024.05.23 Meeting summary\"></a>2024.05.23 Meeting summary</h1><ol>\n<li>讨论了FairGAD。如果一个文章的贡献是数据集，那么需要详细的Benchmarking: 有一篇survey的性质，明白各种方法在数据集上表现怎么样，提出一个评判标准，只用EOO作为fair的判断太简短了。</li>\n<li>基于sentivity的Counterfactual fairness的评判标准，我们用什么样的评判标准和<br>2.1 最简单的构造方法 anomaly dataset：classification with y&#x3D;1,2,3,4,5。拿很多1，sample较少2345.<br>2.2 找一些graph上数据集，用GAD的方法，变成fairGAD的数据集。但是FairGAD，是GAD数据集inject fairness，可能不太好。<br>2.3</li>\n</ol>\n<h2 id=\"Task-of-this-week\"><a href=\"#Task-of-this-week\" class=\"headerlink\" title=\"Task of this week\"></a>Task of this week</h2><p>create synthetic data for fair GAD</p>\n<ol>\n<li>Note this paper: <a href=\"https://arxiv.org/pdf/2304.01391\">https://arxiv.org/pdf/2304.01391</a> for a survey on graph counterfactual. To create a synthetic dataset, see their Section 3.5.1, where the data creation method is detailed in <a href=\"https://arxiv.org/abs/2201.03662\">https://arxiv.org/abs/2201.03662</a>.</li>\n<li>See pygod <a href=\"https://github.com/pygod-team/pygod\">https://github.com/pygod-team/pygod</a> for outlier injection method to the graph dataset. Also, see Jing’s paper <a href=\"https://proceedings.mlr.press/v231/gu24a/gu24a.pdf\">https://proceedings.mlr.press/v231/gu24a/gu24a.pdf</a> for improvement.</li>\n<li>Next Friday, you can try to talk about how to generate the synthetic data and how this falls into counterfactual category.</li>\n</ol>\n<p>所以就是要借鉴创建数据集的方法。还有学习一些counterfactual。 </p>\n<h2 id=\"2024-Counterfactual-Learning-on-Graphs-A-Survey\"><a href=\"#2024-Counterfactual-Learning-on-Graphs-A-Survey\" class=\"headerlink\" title=\"2024 Counterfactual Learning on Graphs: A Survey\"></a>2024 Counterfactual Learning on Graphs: A Survey</h2><p>3.5.1 How to create synthetic dataset </p>\n<h2 id=\"2022-Learning-Fair-Node-Representations-with-Graph-Counter-factual-Fairness\"><a href=\"#2022-Learning-Fair-Node-Representations-with-Graph-Counter-factual-Fairness\" class=\"headerlink\" title=\"2022 Learning Fair Node Representations with Graph Counter factual Fairness\"></a>2022 Learning Fair Node Representations with Graph Counter factual Fairness</h2><p>Two limitation on existing CF on graph:</p>\n<ol>\n<li>$S_i$ affect the predetection. Red</li>\n<li>$S_i$ affect $A, X_i$ Green</li>\n</ol>\n<p>GEAR: Graph Counterfactually Fair Node Representation</p>\n<ol>\n<li>subgraph generation<br>Node <strong>Importance Score</strong> by prune range of casualmodel to <strong>ego-centric subgraph</strong>( node and its neighbour)</li>\n<li>Counterfactual Data Argmentation:<br>Graph Auto encodder and fair contrains: <strong>self-pertubation</strong>(flip its $S_i$), <strong>neighbour pertubatiob</strong></li>\n<li>Node Representation Learning  :<br>Siamese network to minimize discrepancy</li>\n</ol>\n<p><strong>Def, Graph conterfactual fairness:</strong><br>An encoder $\\Phi(\\cdot)$ satisfies graph counterfactual fairness if for any node $i$:<br>$$<br>P((Z_i)<em>{S \\leftarrow s’} | X &#x3D; \\mathbf{X}, A &#x3D; \\mathbf{A}) &#x3D; P((Z_i)</em>{S \\leftarrow s’’} | X &#x3D; \\mathbf{X}, A &#x3D; \\mathbf{A}),<br>$$<br>for all $s’ \\neq s’’$, where $s’, s’’ \\in {0, 1}^n$ are arbitrary sensitive attribute values of all nodes, $Z_i &#x3D; (\\Phi(\\mathbf{X}, \\mathbf{A}))_i$ denotes the node representations.</p>\n<p>$\\Phi$, minimize the discrepancy between representation $\\Phi(X_{S\\leftarrow s’}, A_{S\\leftarrow s’})$ and $\\Phi(X_{S\\leftarrow s’’}, A_{S\\leftarrow s’’})$</p>\n<h3 id=\"GEAR\"><a href=\"#GEAR\" class=\"headerlink\" title=\"GEAR\"></a>GEAR</h3><h3 id=\"1-subgraph-generation\"><a href=\"#1-subgraph-generation\" class=\"headerlink\" title=\"1) subgraph generation\"></a>1) subgraph generation</h3><p>Personalized Pagerank algorithm:<br>Importance score $\\mathbf R&#x3D;\\alpha (\\mathbf I-(1-\\alpha \\mathbf {\\bar A}))$, $\\mathbf I$, identity<br>$R_{i,j}$ How node $j$ is important for node $i$, $\\alpha \\in [0,1]$</p>\n<p>$\\mathbf {\\bar A}&#x3D;\\mathbf A \\mathbf D^{-1} $ column-normalized adjacency matric, $\\mathbf D: \\mathbf D_{i, i}&#x3D;\\sum_j A{i, j}$</p>\n<p>$\\mathcal{G}^{(i)}&#x3D;Sub(i, \\mathcal{G}, k)$ :, subgraph generation</p>\n<ul>\n<li><p>$\\mathcal{G}^{(i)} &#x3D; { \\mathcal{V}^{(i)}, \\mathcal{E}^{(i)}, \\mathbf{X}^{(i)} } &#x3D; { \\mathbf{A}^{(i)}, \\mathbf{X}^{(i)} },<br>$ Vertive, Edge, Features with $S&#x3D;{s_i}_{i&#x3D;1}^n $ includes in $X$, and $X^{\\neg s} &#x3D; { x_1^{\\neg s}, …, x_n^{\\neg s} } $, where $ x_i^{\\neg s} &#x3D; x_i \\setminus s_i$</p>\n</li>\n<li><p>$\\mathcal{V}^{(i)} &#x3D; \\text{TOP}(\\mathbf{R}_{i,:}, k),$</p>\n</li>\n<li><p>$\\mathbf{A}^{(i)} &#x3D; \\mathbf{A}<em>{\\mathcal{V}^{(i)}, \\mathcal{V}^{(i)}}, \\quad \\mathbf{X}^{(i)} &#x3D; \\mathbf{X}</em>{\\mathcal{V}^{(i)}, :},<br>$,</p>\n</li>\n</ul>\n<h3 id=\"2）Counterfactual-Data-Augmentation\"><a href=\"#2）Counterfactual-Data-Augmentation\" class=\"headerlink\" title=\"2）Counterfactual Data Augmentation\"></a>2）Counterfactual Data Augmentation</h3><p><strong>GraphVAG</strong>: graph variational auto-encoder<br>latent embedding $H&#x3D;{h_1, h_2, \\cdots, h_k}$  $H$ is sampled from $q(H|X, A)$,  $p(𝐻)$ is a standard Normal prior distribution<br>$\\mathcal{L}&#x3D;$</p>\n<p>$\\tilde{s}_i$: summary of neighbor info, aggregationof all nodes in subgarph $\\mathcal{G}^{(i)}$<br>$\\tilde{s}<em>i &#x3D; \\frac{1}{|\\mathcal{V}^{(i)}|} \\sum</em>{j \\in \\mathcal{V}^{(i)}} s_j$</p>\n<p>Discriminator,$D(\\cdot)$<br>$D(\\mathbf{H}, b)$  predicts the probability of whether the summary of sensitive attribute values is in range $b$</p>\n<p>Fairness Constraint<br>$L_d &#x3D; \\sum_{b \\in B} \\mathbb{E} [\\log(D(\\mathbf{H}, b))]$<br>$L_d$ is a regularizer to minimize the mutual information between the summary of sensitive attribute values and the<br>embeddings</p>\n<p><strong>Final Loss</strong> for Counterfactual Data Augmentation<br>$L_a &#x3D; L_r + \\beta L_d$<br>$\\beta$ is a hyperparameter for the weight of fairness constraint<br>Use alternating SGD for optimization: </p>\n<ol>\n<li>minimize $L_{a}$ by fixing the discriminator and updating parameters in other parts; </li>\n<li>minimize $−L_{a}$ with respect to the discriminator while other parts fixed.</li>\n</ol>\n<h4 id=\"Self-Perturbation\"><a href=\"#Self-Perturbation\" class=\"headerlink\" title=\"Self-Perturbation\"></a>Self-Perturbation</h4><p>$\\overline{\\mathcal{G}}^{(i)} &#x3D; { \\mathcal{G}^{(i)}_{S_i \\leftarrow 1-s_i} }$ (flipping sensitive feature)</p>\n<h4 id=\"Neighbor-Perturbation\"><a href=\"#Neighbor-Perturbation\" class=\"headerlink\" title=\"Neighbor-Perturbation\"></a>Neighbor-Perturbation</h4><p>$\\underline{\\mathcal{G}}^{(i)} &#x3D; \\left{ \\mathcal{G}^{(i)}<em>{S^{(i)}</em>{\\setminus i} \\leftarrow \\text{SMP}(S^{(i)}<em>{\\mathcal{V}^{(i)}</em>{\\setminus i}})} \\right}$</p>\n<p>subgraph $\\mathcal{G}^{(i)}$ ego($i$)-center subgraph with noes $\\mathcal{V}^{(i)}$, exclude node $i$: $\\mathcal{V}^{(i)}<em>{\\setminus i}$, randomly preterbe the sentsitice value of other nodes: $SMP(\\mathcal{V}^{(i)}</em>{\\setminus i})$</p>\n<p>Reconstruction Loss (GraphVAE Module)<br>$L_r &#x3D; \\mathbb{E}_{q(\\mathbf{H}|X, A)} \\left[ -\\log(p(X, A | \\mathbf{H}, S)) \\right] + \\text{KL}[q(\\mathbf{H} | X, A) | p(\\mathbf{H})]$</p>\n<h3 id=\"3-Fair-Representation-learning\"><a href=\"#3-Fair-Representation-learning\" class=\"headerlink\" title=\"3) Fair Representation learning\"></a>3) Fair Representation learning</h3><p><strong>Fairness Loss</strong><br>$<br>L_f &#x3D; \\frac{1}{|\\mathcal{V}|} \\sum_{i \\in \\mathcal{V}} \\left( (1 - \\lambda_s) d(z_i, \\bar{z}_i) + \\lambda_s d(z_i, \\underline{z}_i) \\right),<br>$<br>$\\lambda_s$ hyperparam control neig-preturbation weight</p>\n<p><strong>Node Representations</strong></p>\n<ul>\n<li>$<br>z_i &#x3D; (\\phi(\\mathbf{X}^{(i)}, \\mathbf{A}^{(i)}))_i,<br>$</li>\n<li>$<br>\\bar{z}<em>i &#x3D; \\text{AGG} \\left( \\left{ (\\phi(\\mathbf{X}^{(i)}</em>{S_i \\leftarrow 1-s_i}, \\mathbf{A}^{(i)}_{S_i \\leftarrow 1-s_i}))_i \\right} \\right),<br>$</li>\n<li>$<br>\\underline{z}<em>i &#x3D; \\text{AGG} \\left( \\left{ (\\phi(\\mathbf{X}^{(i)}</em>{S_i \\leftarrow \\text{SMP}(S^{(i)}<em>{\\mathcal{V}^{(i)}</em>{\\setminus i}})}, \\mathbf{A}^{(i)}<em>{S_i \\leftarrow \\text{SMP}(S^{(i)}</em>{\\mathcal{V}^{(i)}_{\\setminus i}})})_i \\right} \\right),<br>$</li>\n</ul>\n<p>Prediction Loss<br>$L_p &#x3D; \\frac{1}{n} \\sum_{i \\in [n]} l(f(z_i), y_i),$ $l$: could be CE(Cross entropy), $f(\\cdot)$ makes predictions for downstream tasks with the representations, i.e.$ \\hat y_i&#x3D;f(z_i)$</p>\n<p>Overall Loss<br>$<br>L &#x3D; L_p + \\lambda L_f + \\mu | \\theta |^2,<br>$</p>\n<h3 id=\"Dataset-creation\"><a href=\"#Dataset-creation\" class=\"headerlink\" title=\"Dataset creation\"></a>Dataset creation</h3><p>Sensitive Attributes<br>$S_i \\sim \\text{Bernoulli}(p),$ $p&#x3D;0.4$ percent $S_i&#x3D;1$</p>\n<p>Latent Embeddings<br>$Z_i \\sim \\mathcal{N}(0, \\mathbf{I}),$ <br>$\\mathbf{I}$ identity, dimension of $Z_i$: $d_s&#x3D;50$</p>\n<p>Node Features<br>$X_i &#x3D; \\mathcal{S}(Z_i) + S_i \\mathbf{v},$<br>sampling operation $S(\\cdot)$ select 25 dims from $Z_i$, $\\mathbf{v} \\sim \\mathcal{N}(0, \\mathbf{I})$</p>\n<p>Graph Structure<br>$P(A_{i,j} &#x3D; 1) &#x3D; \\sigma(\\text{cos}(Z_i, Z_j) + a \\mathbf{1}(S_i &#x3D; S_j)),$<br>$\\sigma$ sigmoid function, $\\mathbf{1}(S_i &#x3D; S_j)&#x3D;&#x3D;S_i &#x3D; S_j. \\alpha&#x3D;0.01$</p>\n<p>Node Labels<br>$Y_i &#x3D; \\mathcal{B}(w Z_i + w_s \\frac{\\sum_{j \\in \\mathcal{N}_i} S_j}{|\\mathcal{N}_i|}),$<br>$\\mathcal{B}$ Bernulli distribution,$\\mathcal{N}_i$ set of neighbors of node i $w, w_i$ weight vector</p>\n<h3 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h3><p>Using Synthetic dataset, Bail, Credit</p>\n<h2 id=\"24-Three-Revisits-to-Node-Level-Graph-Anomaly-Detection\"><a href=\"#24-Three-Revisits-to-Node-Level-Graph-Anomaly-Detection\" class=\"headerlink\" title=\"24 Three Revisits to Node-Level Graph Anomaly Detection\"></a>24 Three Revisits to Node-Level Graph Anomaly Detection</h2><p>Outliers, Message Passing and Hyperbolic Neural Networks</p>\n<h3 id=\"Previous-Outlier-injection-method\"><a href=\"#Previous-Outlier-injection-method\" class=\"headerlink\" title=\"Previous Outlier injection method\"></a>Previous Outlier injection method</h3><p>$\\mathcal{G}&#x3D;(\\mathcal{V}, \\mathcal{E}, X, y)$: vertice set, edge set, attibute matrix, label of class</p>\n<ul>\n<li><p><strong>Contextual(cntxt.) outlier injection</strong><br>Normalize features $x_i’&#x3D;\\frac{x_i}{||x_i||_1}$<br>Sample $o$ nodes from $\\mathcal{V}$ as $\\mathcal{V}_c$. without replacement<br>For node $i$ in $\\mathcal{V}_c$, sample $q$ nodes from $\\mathcal{V}_r&#x3D;\\mathcal{V}- \\mathcal{V}_c$, among them choose the farthest one $j &#x3D; \\text{argmax}_k(||x_i’-x_k’||_2)$ to replace $x_i$ with $x_j$.</p>\n</li>\n<li><p><strong>Strctural(stct.) outlier injection</strong><br>create $t$ groups sized $s$ with anomalous nodes.<br>sample $o&#x3D;t\\times s$ from $\\mathcal{V}$ without replacement<br>Then randoms partition into $t$ groups.<br>Add edges to make them a clique(fully connected), then drop edges with $p$ probability</p>\n</li>\n</ul>\n<h4 id=\"Score-function\"><a href=\"#Score-function\" class=\"headerlink\" title=\"Score function\"></a>Score function</h4><p>The farthest node will have large $||\\tilde{\\mathbf x}_i||_2$ <br>A structural outlier node $i$ will have many neighbors leads to large $||\\tilde{\\mathbf a}_i||_1$ </p>\n<p>Score function: $score_{norm}(i)&#x3D;\\alpha||\\tilde{\\mathbf x}_i||_2+(1-\\alpha)||\\tilde {\\mathbf a}_i||_1$,  $\\tilde{\\mathbf x}_i$: $x_i$ after outlier injection, $\\tilde{\\mathbf a}<em>i$: $a_i$ after outlier injection, $A</em>{ii}&#x3D;1$<br>where cntxt OD, $\\alpha&#x3D;1$, stct OD, $\\alpha&#x3D;0$ :  $\\alpha$ ratio of two methods </p>\n<p>test 1: ROC-AUC<br>For each dataset, use original dataset v.s. l2-nrom for each $x_i$<br>do anomaly injection. apply GAD Method to get  $score_{norm}$</p>\n<h3 id=\"Novel-Anomaly-injection-method\"><a href=\"#Novel-Anomaly-injection-method\" class=\"headerlink\" title=\"Novel Anomaly injection method\"></a>Novel Anomaly injection method</h3><h2 id=\"Sum-in-terms-of-Dataset\"><a href=\"#Sum-in-terms-of-Dataset\" class=\"headerlink\" title=\"Sum in terms of Dataset\"></a>Sum in terms of Dataset</h2><p>从数据集的角度来说：</p>\n<h3 id=\"FairGAD-1\"><a href=\"#FairGAD-1\" class=\"headerlink\" title=\"FairGAD:\"></a>FairGAD:</h3><p>Reddit:</p>\n<ul>\n<li>数据来源：Post on politic related subReddit</li>\n<li>Labelling Y: based on FACTOID(Sakketou et al., 2022), use the num of posted link(left or right)</li>\n<li>Graph construciton:</li>\n</ul>\n<p><br><br><br><br><br><br><br><br><br><br><br><br>\\</p>\n<h1 id=\"2024-05-31-Meeting\"><a href=\"#2024-05-31-Meeting\" class=\"headerlink\" title=\"2024.05.31 Meeting\"></a>2024.05.31 Meeting</h1><p>Preparation: </p>\n<ol>\n<li>讨论对于Synthetic dataset 怎么创建的理解。</li>\n<li>对outlier dataset怎么创建的理解。</li>\n<li>fair + outlier (参考FairGAD那篇的创建)</li>\n</ol>\n<!-- 这一周花了三四天在信一的身上，一种僭越的快乐。\n体悟是， \n1. 学东西的目的性还是不够明显。\n2. 边听课边看论文会岷县提高目的性和提高效率。\n3. 减少过度功利的需求，学一些有趣的东西，尽量避开人。\n4. 背单词。GRE要寄了。 -->\n\n\n<p><strong>Meeting</strong></p>\n<ol>\n<li><p>Plan for subgroups:<br>Mo, We 1-2 p.m.</p>\n</li>\n<li><p>intro to all projects<br>HNN: Convolution $\\rightarrow$ HNN<br>CNN(T(x)) Paralell Translation equivalence</p>\n</li>\n</ol>\n<h2 id=\"Dataset\"><a href=\"#Dataset\" class=\"headerlink\" title=\"Dataset\"></a>Dataset</h2><p><img src=\"/2024-05-08-papers/image-1.png\" alt=\"alt text\"> from FairGAD(2024)<br>##<br>Pokec: </p>\n<ul>\n<li>source paper: <a href=\"https://arxiv.org/pdf/2009.01454\">https://arxiv.org/pdf/2009.01454</a></li>\n<li>repo: FairGNN  <a href=\"https://github.com/EnyanDai/FairGNN\">https://github.com/EnyanDai/FairGNN</a><br>sampled from <a href=\"https://snap.stanford.edu/data/soc-Pokec.html\">https://snap.stanford.edu/data/soc-Pokec.html</a></li>\n</ul>\n<p>Bail, Credit, German:</p>\n<ul>\n<li>source paper: <a href=\"https://arxiv.org/pdf/2108.05233\">https://arxiv.org/pdf/2108.05233</a> (Dong et al. 2022)<br>  <a href=\"https://arxiv.org/pdf/1102.2166\">https://arxiv.org/pdf/1102.2166</a> (2012)</li>\n<li>repo: EDITS <a href=\"https://github.com/yushundong/EDITS\">https://github.com/yushundong/EDITS</a></li>\n</ul>\n<p>(感觉论文部分引用反了)</p>\n<p>German</p>\n<ul>\n<li>source paper: <a href=\"https://arxiv.org/pdf/2102.13186\">https://arxiv.org/pdf/2102.13186</a> (2021)</li>\n<li>repo: NIFTY <a href=\"https://github.com/HongduanTian/NIFTY\">https://github.com/HongduanTian/NIFTY</a></li>\n</ul>\n<p>UCSD34:</p>\n<ul>\n<li>repo: <a href=\"https://networkrepository.com/socfb-UCSD34.php\">https://networkrepository.com/socfb-UCSD34.php</a></li>\n</ul>\n<h1 id=\"2024-06-03-Meeting\"><a href=\"#2024-06-03-Meeting\" class=\"headerlink\" title=\"2024.06.03 Meeting\"></a>2024.06.03 Meeting</h1><ol>\n<li>Gujing学姐的论文是 unsupervised learning，按照她在pygod里面的方法，把二分类的任务用fiarness metrix，用counterfacutal里的评判标准。EOO, SP, CF(只在Synthetic里有)</li>\n</ol>\n<p>所以要写的是： </p>\n<ol>\n<li>Fairness metrix 的计算，多种</li>\n<li>使用各种方法跑一下数据集。得到fair和accuracy，参考别的论文。</li>\n</ol>\n<p>长期任务：</p>\n<ol>\n<li><p>WSDM 22’ 的做counterfactual Data argumentation 和GAD的方法无关。，总的来说是在不同GAD 方法上consistently improve fairness. WSDM 是在数据集的encoding和encoding上用的fairness。<br>Detection 也是用en&#x2F;decoding做的？有的用GNN也就可以prediction了。可以试着画一个图。 </p>\n</li>\n<li><p>224W可以看17-19， 21和前面encoding部分在学一下。</p>\n</li>\n<li><p>因果推断的Counterfactual部分的公式</p>\n</li>\n</ol>\n<h2 id=\"Execute\"><a href=\"#Execute\" class=\"headerlink\" title=\"Execute\"></a>Execute</h2><p>6.3: 解决</p>\n<ol>\n<li>Synthetic dataset have about $\\frac{|V|^2}{2}$ edges when v&#x3D;2000(paper), edge should be about 4000?<br>solved by Finding source code of paper in GEAR repo</li>\n<li>Threading problem with python not shoot<br>solved by commenting the 22th line in loader.py # from ogb.nodeproppred import PygNodePropPredDataset</li>\n</ol>\n<p>6.4</p>\n<ol>\n<li>可以使用一些方法，<br>WSDM 22 GEAR 的论文里用GCN, GraphSAGE, GIN, C-ENC, FairGNN, NIFTY-GCN, NIFTY-SAGE, and GEAR<br>Gu 24 HNN 的论文用pygod的GAD的库<br>但是都没有找到相关代码</li>\n</ol>\n<p>Gear&#x2F;src</p>\n<ul>\n<li>utils.py: <ol>\n<li>load_dataset, sub function</li>\n<li>accuracy</li>\n</ol>\n</li>\n<li>Preprocessing.py:<ol>\n<li>load_data() deal with params</li>\n<li>generate cf subgraph(无关)</li>\n<li>generate_synthetic_data</li>\n</ol>\n</li>\n<li>models.py:<ol>\n<li>GCN, GIN, JK, SAGE, Encoder_DGI, GraphInMax, Encoder, Classifier,<br>  GraphCF,</li>\n</ol>\n</li>\n<li>main.py<ol>\n<li>parser.argment()</li>\n<li>evaluate: acc, fairness</li>\n<li>compute loss, evaluate sf</li>\n<li>train test</li>\n</ol>\n</li>\n</ul>\n<p>HNN_GAD<br>根据我的观察，这篇里面只写了自己的方法的代码。</p>\n<p>6.5 Meeting<br>决定用ray tune来调参<a href=\"https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\">https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html</a></p>\n<p>6.7<br>正在写scratch_main.py<br>疑问：<br>    1. 这个train, val, test 是怎么分的,子图还是？<br>    ???<br>        evaluate和test有什么区别<br>    2. evaluate里的counterfactual metrix是怎么算的？<br>    3. Injection的参数<br>    4. github怎么上传<br>    5. </p>\n<p>6.11<br>    Paul强调SRS是为了丰富简历的，要干很多跟申研相关的事情。<br>    看看教授现在在干什么，fellowship是啥，，？？？？practicing interview。<br>    升多少学校？？？没听懂<br>    5-8<br>    16？？？</p>\n<h1 id=\"2024-06-12-Meeting\"><a href=\"#2024-06-12-Meeting\" class=\"headerlink\" title=\"2024.06.12 Meeting\"></a>2024.06.12 Meeting</h1><ol>\n<li>CF + gu学姐的三个方法</li>\n<li>gpu的问题还没有解决</li>\n<li>inject的好像不是特别影响fairness</li>\n</ol>\n<p>数据集的构造方面在sensitivity group和是不是outlier之间加上casuality。FairGAD用了debiaser的方法使fairness高了一点<br>run Jing’s method for GAD: shengen在做<br>Check with Yifei for GPU：check了，现在一些model在大的数据集上还要分batch。<br>Check CF scores：装了两天环境，<br>Complete remaining experiments：没有<br>brainstorm so that outlier injection contains sensitivity：认为<br>CF using DA</p>\n<p>Motivation： outlier detection，<br>Fairnes有效的数据集：<br>Outlier的注入：</p>\n<h2 id=\"6-12-问题\"><a href=\"#6-12-问题\" class=\"headerlink\" title=\"6.12 问题\"></a>6.12 问题</h2><h3 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h3><p>一个下午主要都在解决gpu的问题，</p>\n<h4 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h4><p>首先目前最大的谜团是Pygod中AdONE(gpu&#x3D;0)这里的光谱为啥只能是0<br>我去找了源代码，应该可以是int cuda的id，所以理论上应该是0-7 都可以的，但是只有0可行，<br>主要代码<br>pygod&#x2F;pygod&#x2F;detector&#x2F;base <br>pygod&#x2F;utils&#x2F;utility.py 的<code>validate_device(gpu_id)</code>函数<code>gpu_id</code>就是<code>DOMINANT(gpu=0)</code>里的<code>gpu</code></p>\n<h4 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2\"></a>2</h4><p>还有一个很蠢得已经被解决的问题是<br>为什么.sh文件会报。 之前一直不明白为什么命令行就没问题，但是.sh 就不可以，后来发信啊是模型之间的区别<br>    torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.01 GiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 3.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF<br>这种错，<br>修改的方式是</p>\n<ol>\n<li><p>在ray tune 里把网络得大小修改小一点，并且分batch，通过在train最后释放内存</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">defv train():</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">    torch.cuda.empty_cache() </span><br><span class=\"line\">    return</span><br></pre></td></tr></table></figure></li>\n<li><p>在ray tune 分batch。在main得第一句加上</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">os.environ[&#x27;PYTORCH_CUDA_ALLOC_CONF&#x27;] = &#x27;max_split_size_mb:128&#x27;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>本身因为dataset和model的大小不同，所以有的模型被跑出来的可行性就是要小一点<br>比如从synthetic &lt; german &lt; bail &lt; credit &lt; pokec<br>前三个是可以跑所有模型的，<br>但是credit不可以跑gaan, 会站600GiB的内存，guide也非常慢， credit+guide根本没上gpu？？？<br>玄学</p>\n</li>\n</ol>\n<h3 id=\"6-14-CF\"><a href=\"#6-14-CF\" class=\"headerlink\" title=\"6.14 CF\"></a>6.14 CF</h3><p>cf_eoo, cf_dp, df, eoo, dp 在论文中分别代表什么<a href=\"https://arxiv.org/pdf/2201.03662\">https://arxiv.org/pdf/2201.03662</a></p>\n<p>sens rate </p>\n<p>论文算cf的方法是:<br>对比原图和经过修改sens feature（类似于perturbe的手法），通过$hat y$之间的来算cf</p>\n<p>重点是如何得到 modified data， 也就是 evaluate 中的 data_cf</p>\n<p>随机取 sens_rate * N 个节点，使$S_i$为1，剩下为0.</p>\n<h3 id=\"GEAR配环境踩坑\"><a href=\"#GEAR配环境踩坑\" class=\"headerlink\" title=\"GEAR配环境踩坑\"></a>GEAR配环境踩坑</h3><p>pyg很烦人<br>我是先装了torch1.6.0 + cu10.2<br>然后发现pyg&#x3D;1.3.0 是最老版本的，就google到了pyg的的source code ： <a href=\"https://github.com/pyg-team/pytorch_geometric/releases/tag/1.3.0\">https://github.com/pyg-team/pytorch_geometric/releases/tag/1.3.0</a><br>然后就应该python setup.py install,但是<strong>网很慢</strong>， 所以要多等一会<br>然后看到readme之后手动装了个torch-sparse一类的whl： <a href=\"https://data.pyg.org/whl/\">https://data.pyg.org/whl/</a><br>后来很傻的才发现python setup.py install，等了3分钟之后报错，无pytest-runner， 于是进setup.py看了一下之后手动pip install pytest-runner pytest pytest-cov mock,<br>然后python setup.py install一下子就好了，于是又手动 pip install pandas matplotlib Cpython cytoolz aif360</p>\n<p>装到aif360 报错Failed building wheel for llvmlite，应该是没有llvm，于是手动本地装<br>装了9.0.0的版本</p>\n<pre><code>如果 `llvmlite` 的预构建二进制文件和 `conda` 方法都无法解决问题，普通用户可以在用户目录中安装 LLVM，而不需要 `sudo` 权限。\n\n\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载并解压 LLVM</span></span><br><span class=\"line\">wget https://github.com/llvm/llvm-project/releases/download/llvmorg-11.1.0/llvm-11.1.0.src.tar.xz</span><br><span class=\"line\">tar -xf llvm-11.1.0.src.tar.xz</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建构建目录</span></span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> llvm-11.1.0.build</span><br><span class=\"line\"><span class=\"built_in\">cd</span> llvm-11.1.0.build</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置编译（安装在用户目录）</span></span><br><span class=\"line\">cmake -G <span class=\"string\">&quot;Unix Makefiles&quot;</span> -DCMAKE_INSTALL_PREFIX=<span class=\"variable\">$HOME</span>/llvm ../llvm-11.1.0.src</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 编译和安装</span></span><br><span class=\"line\">make -j$(<span class=\"built_in\">nproc</span>)</span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n\n然后设置环境变量以使用本地安装的 LLVM：\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$HOME</span>/llvm/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> LD_LIBRARY_PATH=<span class=\"variable\">$HOME</span>/llvm/lib:<span class=\"variable\">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>\n\n\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install llvmlite --no-binary llvmlite</span><br></pre></td></tr></table></figure>\n\n之后再安装 `aif360`：\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install aif360</span><br></pre></td></tr></table></figure>\n</code></pre>\n<p>但是还是会报wheel build 失败的错误。<br>于是就直接绕过aif360,因为只用了两个函数，所以直接复制函数和必要的util过来了，绕过安装aif360的问题了。<br>实际上aif360对python 3.8之后才比较兼容，所以以后用新一点的环境。</p>\n<p>然后遇到了AttributeError: Can’t get attribute ‘DataEdgeAttr’<br>import torch_geometric.transforms as T<br>from ogb.nodeproppred import PygNodePropPredDataset<br>shouju学姐提醒可以csdn，（这次提供的解决方案确实和gpt不一样）<a href=\"https://blog.csdn.net/oqqENvY12/article/details/129786928\">https://blog.csdn.net/oqqENvY12/article/details/129786928</a> 也有一部分版本过老的问题<br>但是通过观察，是路径问题，把一个相对main.py line 541的相对路径改成绝对路径就成功了，<br>我觉得<strong>13.23的服务器在路径上确实有些玄乎</strong></p>\n<ul>\n<li>运行结束之后没有办法自动关闭</li>\n<li>german 数据集无法正常生成</li>\n</ul>\n<h3 id=\"Gu学姐的三个model\"><a href=\"#Gu学姐的三个model\" class=\"headerlink\" title=\"Gu学姐的三个model\"></a>Gu学姐的三个model</h3><p>万能的CSDN<br>Collecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.<em>, but conda is ignoring the .</em> and treating it as 1.7.1<br><a href=\"https://blog.csdn.net/ermmtt/article/details/132628639\">https://blog.csdn.net/ermmtt/article/details/132628639</a></p>\n<h3 id=\"Batch问题\"><a href=\"#Batch问题\" class=\"headerlink\" title=\"Batch问题\"></a>Batch问题</h3><h3 id=\"Python-插件\"><a href=\"#Python-插件\" class=\"headerlink\" title=\"Python 插件\"></a>Python 插件</h3><p>这个是最傻的，下载了 vsix 之后发现 vscode 版本对不上， 然后更新了一下 vscode 就好了。。。</p>\n<h1 id=\"2024-06-24-Meeting\"><a href=\"#2024-06-24-Meeting\" class=\"headerlink\" title=\"2024.06.24 Meeting\"></a>2024.06.24 Meeting</h1><h2 id=\"2024-06-19\"><a href=\"#2024-06-19\" class=\"headerlink\" title=\"2024.06.19\"></a>2024.06.19</h2><p>(刚刚才了解 Encoder 和 Decoder 也算是 GNN，然后看了一些东西<br>(OI佬写的GEAR代码，看不懂，</p>\n<h1 id=\"2024-07-14\"><a href=\"#2024-07-14\" class=\"headerlink\" title=\"2024.07.14\"></a>2024.07.14</h1><!-- 竟然过了一个月了。 -->\n\n<h2 id=\"2024-06-10开会\"><a href=\"#2024-06-10开会\" class=\"headerlink\" title=\"2024.06.10开会\"></a>2024.06.10开会</h2><ol>\n<li>做benchmark. + Jing学姐的三个HNN已经改成了Class但是AUC还是太低了。。。</li>\n<li>手写encoder和decoder。结构未知，但是主要是修改Loss Function???基于CF的，可以在dominant上修改</li>\n<li>解释为什么CF是低的，看decoder出来的sens’，是还原了sens还是都是1&#x2F;2.这两者都是可以解释的</li>\n<li>在学一下CF之类的理论。</li>\n<li>GNNNNNNNNNN</li>\n</ol>\n<h1 id=\"2024-08-15\"><a href=\"#2024-08-15\" class=\"headerlink\" title=\"2024.08.15\"></a>2024.08.15</h1><!-- 竟然又过了一个月了。 -->\n<!-- 抽象，完全不知道自己在干啥。。。 -->\n\n<ol>\n<li>DOIMINANT 19, DONE 21, gadnr 24, ada-gad 234. (CFGN denied)</li>\n<li>benchmark和一些sens reconstruct 的值对比（之前貌似只作了guide 21的）</li>\n<li>论文也看不出来在写啥</li>\n<li></li>\n</ol>\n<p>08.18 交srs报告<br>08.25 GRE 考试，寄<br>找sol教授询问music tech方向的问题<br>论文论文论文</p>\n","excerpt":"","more":"<h1 id=\"1-Counterfactual-fairness\"><a href=\"#1-Counterfactual-fairness\" class=\"headerlink\" title=\"1. Counterfactual fairness\"></a>1. Counterfactual fairness</h1><p>Counterfactual fairness<br>link: <a href=\"https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf\">https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf</a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Definitions:</p>\n<h4 id=\"defs\"><a href=\"#defs\" class=\"headerlink\" title=\"defs\"></a>defs</h4><p>$A$: Protected attributes, sensitive features<br>$X$: features of individuals, excluding A<br>$U$: latent features not observed, represented<br>$Y$: predictor    </p>\n<h4 id=\"Fairness-through-unawareness-FTU\"><a href=\"#Fairness-through-unawareness-FTU\" class=\"headerlink\" title=\"Fairness through unawareness (FTU):\"></a>Fairness through unawareness (FTU):</h4><p><em>An algorithm is fair so long as any protected attributes $A$ are not explicitly used in the decision-making process.</em><br>Shortcoming: $X$ might intersects $A$</p>\n<h4 id=\"Individual-Fairness-IF\"><a href=\"#Individual-Fairness-IF\" class=\"headerlink\" title=\"Individual Fairness (IF).\"></a>Individual Fairness (IF).</h4><p>For distance metric(should be carefully choosen), $d(\\cdot , \\cdot)$, if $d(i, j)$ is small, then $\\hat Y(X^{(i)}, A^{(i)}) \\approx \\hat Y(X^{(j)}, A^{(j)})$</p>\n<h4 id=\"Demographic-Parity-DP-人口统计学意义上的平等\"><a href=\"#Demographic-Parity-DP-人口统计学意义上的平等\" class=\"headerlink\" title=\"Demographic Parity (DP)(人口统计学意义上的平等)\"></a>Demographic Parity (DP)(人口统计学意义上的平等)</h4><p>Predictor $\\hat Y$ satisfies demographic partiy if $P(\\hat Y|A&#x3D;0)&#x3D;P(\\hat Y|A&#x3D;1)$ </p>\n<h4 id=\"Equality-of-Opportunity\"><a href=\"#Equality-of-Opportunity\" class=\"headerlink\" title=\"Equality of Opportunity\"></a>Equality of Opportunity</h4><p>$P(\\hat Y|A&#x3D;0, Y&#x3D;1)&#x3D;P(\\hat Y|A&#x3D;1, Y&#x3D;1)$ </p>\n<h3 id=\"Causal-Models-因果推断-Counterfacutal、\"><a href=\"#Causal-Models-因果推断-Counterfacutal、\" class=\"headerlink\" title=\"Causal Models(因果推断), Counterfacutal、\"></a>Causal Models(因果推断), Counterfacutal、</h3><p>Casual Model $(U, V, F)$,<br>$U$: latent background variables,<br>$V$: observed variables, <br>$F&#x3D;{f_1. f_2, \\cdots, f_n}$, for each $V_i&#x3D;f_i(pa_i, U_{pa_i})\\in V, pa_i \\subseteq V \\backslash {V_i}$ </p>\n<p><strong>Three Steps of Inference</strong>\\</p>\n<ul>\n<li>Abduction：for a given prior on $U$, compute the posterior distribution of $U$ given the evidence $W &#x3D; w$</li>\n<li>Action：substitute the equations for $Z$ with the interventional values $z$, resulting in the modified set of equations $F_z$</li>\n<li>Prediction:</li>\n</ul>\n<h2 id=\"题外话\"><a href=\"#题外话\" class=\"headerlink\" title=\"题外话\"></a>题外话</h2><h3 id=\"Casual-Models-因果推断\"><a href=\"#Casual-Models-因果推断\" class=\"headerlink\" title=\"Casual Models (因果推断)\"></a>Casual Models (因果推断)</h3><p><a href=\"https://www.zhihu.com/column/c_1217887302124773376\">https://www.zhihu.com/column/c_1217887302124773376</a></p>\n<h4 id=\"Three-levels\"><a href=\"#Three-levels\" class=\"headerlink\" title=\"Three levels:\"></a>Three levels:</h4><ol>\n<li>Association: $A-B$ </li>\n<li>Intervention：$A&#x2F;A’ \\rightarrow B?$</li>\n<li>Counterfactual $ want\\ B’, how A\\rightarrow A’$</li>\n</ol>\n<h4 id=\"Beyasian-Network\"><a href=\"#Beyasian-Network\" class=\"headerlink\" title=\"Beyasian Network\"></a>Beyasian Network</h4><p>In Directed acyclic Graph (DAG):<br><img src=\"/papers/image.png\" alt=\"alt text\"></p>\n<p><a href=\"https://www.cnblogs.com/mantch/p/11179933.html\">https://www.cnblogs.com/mantch/p/11179933.html</a><br>Component:</p>\n<ol>\n<li>head-to-head $a\\rightarrow c\\leftarrow b$ <br>$P(a,b,c) &#x3D; P(a)P(b)P(c|a,b)$,<br>unknown $c$, $a, b$ are blocked thus independent</li>\n<li>tail-to-tail $a\\leftarrow c\\rightarrow b$</li>\n</ol>\n<ul>\n<li>$c$ unknown, $P(a,b,c)&#x3D;P(c)P(a|c)P(b|c)$, $a, b$, not independent</li>\n<li>$c$ known, $P(a,b,c)&#x3D;P(c)P(a|c)P(b|c)$, $P(a,b|c)&#x3D;P(a,b,c)&#x2F;P(c)&#x3D;P(a|c)*P(b|c)$, $a, b $independent</li>\n</ul>\n<ol start=\"3\">\n<li>head-to-tail (Markov Chain) $A\\rightarrow C\\rightarrow B$</li>\n</ol>\n<ul>\n<li>$c$ unknown, $a, b$, not independent</li>\n<li>$c$ known, $a, b$ independent</li>\n</ul>\n<p><strong>Factor Graph</strong></p>\n<h4 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h4><p>Confounder</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>我从一天前开始看论文，被casual model的概念吸引了。我认为是很好的一个理解方式。从早上五点准备到十一点。<br>今天做了pre，效果很差。</p>\n<ol>\n<li>对概率的各种公式很不太了解。对贝叶斯和MCMC不会。</li>\n<li>没有去想过$U ,A, X$的关系。没有办法很好的解释论文中的逻辑关系。</li>\n</ol>\n<p>在开会的时候教授说重要东西：</p>\n<ol>\n<li>Counterfactual <br>这篇最重要的是： <strong>Definition 5:</strong> $P(\\hat Y_{A\\leftarrow a}(U)|X&#x3D;x, A&#x3D;a)&#x3D;P(\\hat Y_{A\\leftarrow a’}(U)|X&#x3D;x, A&#x3D;a)$ <br>很多‘概率’只是表示方法。（但是确实不很理解概率）<br>算法的思想在于：1. 引入因果图。2.寻找U（17年MCMC，现在可以GAN，或其他生成式学习方法）。</li>\n<li>$U \\rightarrow X，A$<br>在计算中用$X, A \\rightarrow U$ 有一些类似Adversarial learning. 可以研究怎么套用。</li>\n<li>GAD</li>\n<li>有点想做transfer learning 的那种</li>\n</ol>\n<h1 id=\"FairGAD\"><a href=\"#FairGAD\" class=\"headerlink\" title=\"FairGAD\"></a>FairGAD</h1><p><a href=\"https://openreview.net/forum?id=3cE6NKYy8x\">https://openreview.net/forum?id=3cE6NKYy8x</a></p>\n<p><a href=\"https://arxiv.org/abs/2307.04937\">https://arxiv.org/abs/2307.04937</a></p>\n<h2 id=\"Fair-GAD-problem\"><a href=\"#Fair-GAD-problem\" class=\"headerlink\" title=\"Fair GAD problem\"></a>Fair GAD problem</h2><p><strong>GAD</strong><br>$G&#x3D;(V, E, X)$, <br>node feature matrix $X\\in \\R^{n\\times d}$, <br>Adjacency matrix $A\\in {0,1}^{n\\times n}$, <br>Anomaly labels $Y\\in {0, 1}^n$, predicted $\\hat Y$, <br><strong>Fair GAD</strong><br>sensitive attributes $S\\in {0, 1}^n$, a binary feature $X$.<br>Performance matrix: accuracy and <em>AUCROC</em>: Area under the ROC Curve <br>Unfairness Mextrics, Statistic Parity(SP):$SP &#x3D; |P(\\hat Y&#x3D;1|S&#x3D;0)−P(\\hat Y &#x3D;1|S&#x3D;1)|$, <br>Equality of Odds <em>(EOO)</em>: $SP &#x3D; |P(\\hat Y&#x3D;1|S&#x3D;0, Y&#x3D;1)−P(\\hat Y &#x3D;1|S&#x3D;1, Y&#x3D;1)|$</p>\n<h2 id=\"Data\"><a href=\"#Data\" class=\"headerlink\" title=\"Data\"></a>Data</h2><ul>\n<li>Reddit:<br>graph structure： linking two user posted the name subreddit within 24h.<br>Node feature: Embedding from post histories.</li>\n<li>Twitter:<br>graph structure:: A follows B.<br>Node feature: demographic infromation using M3 system, multimodal, multilingual, multi attirbute demographix inderence framework.</li>\n</ul>\n<!-- ## GAD Methods\n### DOMINANT (Ding et al., 2019a)\n### CONAD (Xu et al., 2022)\n### COLA (Liu et al., 2021)\n### VGOD (Huang et al., 2023)\n\n## Non-Graph AD methods\n- DONE (Bandyopadhyay et al., 2020)\n- AdONE (Bandyopadhyay et al., 2020)\n- ECOD (Li et al., 2022)\n- VAE (Kingma & Welling, 2014)\n- ONE (Bandyopadhyay et al., 2019)\n- LOF (Breunig et al., 2000)\n- F (Liu et al., 2008)\n\n## Fainess Method:\n### FAIROD (Shekhar et al., 2021)\n### CORRELATION (Shekhar et al., 2021)\n### HIN (Zeng et al., 2021)\n### EDITS (Dong et al., 2022)\n### FAIRWALK (Rahman et al., 2019)\n\n## Distance \n### Wasserstein Distance\n### Minkowski distance -->\n\n\n\n<h1 id=\"2024-05-23-Meeting-summary\"><a href=\"#2024-05-23-Meeting-summary\" class=\"headerlink\" title=\"2024.05.23 Meeting summary\"></a>2024.05.23 Meeting summary</h1><ol>\n<li>讨论了FairGAD。如果一个文章的贡献是数据集，那么需要详细的Benchmarking: 有一篇survey的性质，明白各种方法在数据集上表现怎么样，提出一个评判标准，只用EOO作为fair的判断太简短了。</li>\n<li>基于sentivity的Counterfactual fairness的评判标准，我们用什么样的评判标准和<br>2.1 最简单的构造方法 anomaly dataset：classification with y&#x3D;1,2,3,4,5。拿很多1，sample较少2345.<br>2.2 找一些graph上数据集，用GAD的方法，变成fairGAD的数据集。但是FairGAD，是GAD数据集inject fairness，可能不太好。<br>2.3</li>\n</ol>\n<h2 id=\"Task-of-this-week\"><a href=\"#Task-of-this-week\" class=\"headerlink\" title=\"Task of this week\"></a>Task of this week</h2><p>create synthetic data for fair GAD</p>\n<ol>\n<li>Note this paper: <a href=\"https://arxiv.org/pdf/2304.01391\">https://arxiv.org/pdf/2304.01391</a> for a survey on graph counterfactual. To create a synthetic dataset, see their Section 3.5.1, where the data creation method is detailed in <a href=\"https://arxiv.org/abs/2201.03662\">https://arxiv.org/abs/2201.03662</a>.</li>\n<li>See pygod <a href=\"https://github.com/pygod-team/pygod\">https://github.com/pygod-team/pygod</a> for outlier injection method to the graph dataset. Also, see Jing’s paper <a href=\"https://proceedings.mlr.press/v231/gu24a/gu24a.pdf\">https://proceedings.mlr.press/v231/gu24a/gu24a.pdf</a> for improvement.</li>\n<li>Next Friday, you can try to talk about how to generate the synthetic data and how this falls into counterfactual category.</li>\n</ol>\n<p>所以就是要借鉴创建数据集的方法。还有学习一些counterfactual。 </p>\n<h2 id=\"2024-Counterfactual-Learning-on-Graphs-A-Survey\"><a href=\"#2024-Counterfactual-Learning-on-Graphs-A-Survey\" class=\"headerlink\" title=\"2024 Counterfactual Learning on Graphs: A Survey\"></a>2024 Counterfactual Learning on Graphs: A Survey</h2><p>3.5.1 How to create synthetic dataset </p>\n<h2 id=\"2022-Learning-Fair-Node-Representations-with-Graph-Counter-factual-Fairness\"><a href=\"#2022-Learning-Fair-Node-Representations-with-Graph-Counter-factual-Fairness\" class=\"headerlink\" title=\"2022 Learning Fair Node Representations with Graph Counter factual Fairness\"></a>2022 Learning Fair Node Representations with Graph Counter factual Fairness</h2><p>Two limitation on existing CF on graph:</p>\n<ol>\n<li>$S_i$ affect the predetection. Red</li>\n<li>$S_i$ affect $A, X_i$ Green</li>\n</ol>\n<p>GEAR: Graph Counterfactually Fair Node Representation</p>\n<ol>\n<li>subgraph generation<br>Node <strong>Importance Score</strong> by prune range of casualmodel to <strong>ego-centric subgraph</strong>( node and its neighbour)</li>\n<li>Counterfactual Data Argmentation:<br>Graph Auto encodder and fair contrains: <strong>self-pertubation</strong>(flip its $S_i$), <strong>neighbour pertubatiob</strong></li>\n<li>Node Representation Learning  :<br>Siamese network to minimize discrepancy</li>\n</ol>\n<p><strong>Def, Graph conterfactual fairness:</strong><br>An encoder $\\Phi(\\cdot)$ satisfies graph counterfactual fairness if for any node $i$:<br>$$<br>P((Z_i)<em>{S \\leftarrow s’} | X &#x3D; \\mathbf{X}, A &#x3D; \\mathbf{A}) &#x3D; P((Z_i)</em>{S \\leftarrow s’’} | X &#x3D; \\mathbf{X}, A &#x3D; \\mathbf{A}),<br>$$<br>for all $s’ \\neq s’’$, where $s’, s’’ \\in {0, 1}^n$ are arbitrary sensitive attribute values of all nodes, $Z_i &#x3D; (\\Phi(\\mathbf{X}, \\mathbf{A}))_i$ denotes the node representations.</p>\n<p>$\\Phi$, minimize the discrepancy between representation $\\Phi(X_{S\\leftarrow s’}, A_{S\\leftarrow s’})$ and $\\Phi(X_{S\\leftarrow s’’}, A_{S\\leftarrow s’’})$</p>\n<h3 id=\"GEAR\"><a href=\"#GEAR\" class=\"headerlink\" title=\"GEAR\"></a>GEAR</h3><h3 id=\"1-subgraph-generation\"><a href=\"#1-subgraph-generation\" class=\"headerlink\" title=\"1) subgraph generation\"></a>1) subgraph generation</h3><p>Personalized Pagerank algorithm:<br>Importance score $\\mathbf R&#x3D;\\alpha (\\mathbf I-(1-\\alpha \\mathbf {\\bar A}))$, $\\mathbf I$, identity<br>$R_{i,j}$ How node $j$ is important for node $i$, $\\alpha \\in [0,1]$</p>\n<p>$\\mathbf {\\bar A}&#x3D;\\mathbf A \\mathbf D^{-1} $ column-normalized adjacency matric, $\\mathbf D: \\mathbf D_{i, i}&#x3D;\\sum_j A{i, j}$</p>\n<p>$\\mathcal{G}^{(i)}&#x3D;Sub(i, \\mathcal{G}, k)$ :, subgraph generation</p>\n<ul>\n<li><p>$\\mathcal{G}^{(i)} &#x3D; { \\mathcal{V}^{(i)}, \\mathcal{E}^{(i)}, \\mathbf{X}^{(i)} } &#x3D; { \\mathbf{A}^{(i)}, \\mathbf{X}^{(i)} },<br>$ Vertive, Edge, Features with $S&#x3D;{s_i}_{i&#x3D;1}^n $ includes in $X$, and $X^{\\neg s} &#x3D; { x_1^{\\neg s}, …, x_n^{\\neg s} } $, where $ x_i^{\\neg s} &#x3D; x_i \\setminus s_i$</p>\n</li>\n<li><p>$\\mathcal{V}^{(i)} &#x3D; \\text{TOP}(\\mathbf{R}_{i,:}, k),$</p>\n</li>\n<li><p>$\\mathbf{A}^{(i)} &#x3D; \\mathbf{A}<em>{\\mathcal{V}^{(i)}, \\mathcal{V}^{(i)}}, \\quad \\mathbf{X}^{(i)} &#x3D; \\mathbf{X}</em>{\\mathcal{V}^{(i)}, :},<br>$,</p>\n</li>\n</ul>\n<h3 id=\"2）Counterfactual-Data-Augmentation\"><a href=\"#2）Counterfactual-Data-Augmentation\" class=\"headerlink\" title=\"2）Counterfactual Data Augmentation\"></a>2）Counterfactual Data Augmentation</h3><p><strong>GraphVAG</strong>: graph variational auto-encoder<br>latent embedding $H&#x3D;{h_1, h_2, \\cdots, h_k}$  $H$ is sampled from $q(H|X, A)$,  $p(𝐻)$ is a standard Normal prior distribution<br>$\\mathcal{L}&#x3D;$</p>\n<p>$\\tilde{s}_i$: summary of neighbor info, aggregationof all nodes in subgarph $\\mathcal{G}^{(i)}$<br>$\\tilde{s}<em>i &#x3D; \\frac{1}{|\\mathcal{V}^{(i)}|} \\sum</em>{j \\in \\mathcal{V}^{(i)}} s_j$</p>\n<p>Discriminator,$D(\\cdot)$<br>$D(\\mathbf{H}, b)$  predicts the probability of whether the summary of sensitive attribute values is in range $b$</p>\n<p>Fairness Constraint<br>$L_d &#x3D; \\sum_{b \\in B} \\mathbb{E} [\\log(D(\\mathbf{H}, b))]$<br>$L_d$ is a regularizer to minimize the mutual information between the summary of sensitive attribute values and the<br>embeddings</p>\n<p><strong>Final Loss</strong> for Counterfactual Data Augmentation<br>$L_a &#x3D; L_r + \\beta L_d$<br>$\\beta$ is a hyperparameter for the weight of fairness constraint<br>Use alternating SGD for optimization: </p>\n<ol>\n<li>minimize $L_{a}$ by fixing the discriminator and updating parameters in other parts; </li>\n<li>minimize $−L_{a}$ with respect to the discriminator while other parts fixed.</li>\n</ol>\n<h4 id=\"Self-Perturbation\"><a href=\"#Self-Perturbation\" class=\"headerlink\" title=\"Self-Perturbation\"></a>Self-Perturbation</h4><p>$\\overline{\\mathcal{G}}^{(i)} &#x3D; { \\mathcal{G}^{(i)}_{S_i \\leftarrow 1-s_i} }$ (flipping sensitive feature)</p>\n<h4 id=\"Neighbor-Perturbation\"><a href=\"#Neighbor-Perturbation\" class=\"headerlink\" title=\"Neighbor-Perturbation\"></a>Neighbor-Perturbation</h4><p>$\\underline{\\mathcal{G}}^{(i)} &#x3D; \\left{ \\mathcal{G}^{(i)}<em>{S^{(i)}</em>{\\setminus i} \\leftarrow \\text{SMP}(S^{(i)}<em>{\\mathcal{V}^{(i)}</em>{\\setminus i}})} \\right}$</p>\n<p>subgraph $\\mathcal{G}^{(i)}$ ego($i$)-center subgraph with noes $\\mathcal{V}^{(i)}$, exclude node $i$: $\\mathcal{V}^{(i)}<em>{\\setminus i}$, randomly preterbe the sentsitice value of other nodes: $SMP(\\mathcal{V}^{(i)}</em>{\\setminus i})$</p>\n<p>Reconstruction Loss (GraphVAE Module)<br>$L_r &#x3D; \\mathbb{E}_{q(\\mathbf{H}|X, A)} \\left[ -\\log(p(X, A | \\mathbf{H}, S)) \\right] + \\text{KL}[q(\\mathbf{H} | X, A) | p(\\mathbf{H})]$</p>\n<h3 id=\"3-Fair-Representation-learning\"><a href=\"#3-Fair-Representation-learning\" class=\"headerlink\" title=\"3) Fair Representation learning\"></a>3) Fair Representation learning</h3><p><strong>Fairness Loss</strong><br>$<br>L_f &#x3D; \\frac{1}{|\\mathcal{V}|} \\sum_{i \\in \\mathcal{V}} \\left( (1 - \\lambda_s) d(z_i, \\bar{z}_i) + \\lambda_s d(z_i, \\underline{z}_i) \\right),<br>$<br>$\\lambda_s$ hyperparam control neig-preturbation weight</p>\n<p><strong>Node Representations</strong></p>\n<ul>\n<li>$<br>z_i &#x3D; (\\phi(\\mathbf{X}^{(i)}, \\mathbf{A}^{(i)}))_i,<br>$</li>\n<li>$<br>\\bar{z}<em>i &#x3D; \\text{AGG} \\left( \\left{ (\\phi(\\mathbf{X}^{(i)}</em>{S_i \\leftarrow 1-s_i}, \\mathbf{A}^{(i)}_{S_i \\leftarrow 1-s_i}))_i \\right} \\right),<br>$</li>\n<li>$<br>\\underline{z}<em>i &#x3D; \\text{AGG} \\left( \\left{ (\\phi(\\mathbf{X}^{(i)}</em>{S_i \\leftarrow \\text{SMP}(S^{(i)}<em>{\\mathcal{V}^{(i)}</em>{\\setminus i}})}, \\mathbf{A}^{(i)}<em>{S_i \\leftarrow \\text{SMP}(S^{(i)}</em>{\\mathcal{V}^{(i)}_{\\setminus i}})})_i \\right} \\right),<br>$</li>\n</ul>\n<p>Prediction Loss<br>$L_p &#x3D; \\frac{1}{n} \\sum_{i \\in [n]} l(f(z_i), y_i),$ $l$: could be CE(Cross entropy), $f(\\cdot)$ makes predictions for downstream tasks with the representations, i.e.$ \\hat y_i&#x3D;f(z_i)$</p>\n<p>Overall Loss<br>$<br>L &#x3D; L_p + \\lambda L_f + \\mu | \\theta |^2,<br>$</p>\n<h3 id=\"Dataset-creation\"><a href=\"#Dataset-creation\" class=\"headerlink\" title=\"Dataset creation\"></a>Dataset creation</h3><p>Sensitive Attributes<br>$S_i \\sim \\text{Bernoulli}(p),$ $p&#x3D;0.4$ percent $S_i&#x3D;1$</p>\n<p>Latent Embeddings<br>$Z_i \\sim \\mathcal{N}(0, \\mathbf{I}),$ <br>$\\mathbf{I}$ identity, dimension of $Z_i$: $d_s&#x3D;50$</p>\n<p>Node Features<br>$X_i &#x3D; \\mathcal{S}(Z_i) + S_i \\mathbf{v},$<br>sampling operation $S(\\cdot)$ select 25 dims from $Z_i$, $\\mathbf{v} \\sim \\mathcal{N}(0, \\mathbf{I})$</p>\n<p>Graph Structure<br>$P(A_{i,j} &#x3D; 1) &#x3D; \\sigma(\\text{cos}(Z_i, Z_j) + a \\mathbf{1}(S_i &#x3D; S_j)),$<br>$\\sigma$ sigmoid function, $\\mathbf{1}(S_i &#x3D; S_j)&#x3D;&#x3D;S_i &#x3D; S_j. \\alpha&#x3D;0.01$</p>\n<p>Node Labels<br>$Y_i &#x3D; \\mathcal{B}(w Z_i + w_s \\frac{\\sum_{j \\in \\mathcal{N}_i} S_j}{|\\mathcal{N}_i|}),$<br>$\\mathcal{B}$ Bernulli distribution,$\\mathcal{N}_i$ set of neighbors of node i $w, w_i$ weight vector</p>\n<h3 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h3><p>Using Synthetic dataset, Bail, Credit</p>\n<h2 id=\"24-Three-Revisits-to-Node-Level-Graph-Anomaly-Detection\"><a href=\"#24-Three-Revisits-to-Node-Level-Graph-Anomaly-Detection\" class=\"headerlink\" title=\"24 Three Revisits to Node-Level Graph Anomaly Detection\"></a>24 Three Revisits to Node-Level Graph Anomaly Detection</h2><p>Outliers, Message Passing and Hyperbolic Neural Networks</p>\n<h3 id=\"Previous-Outlier-injection-method\"><a href=\"#Previous-Outlier-injection-method\" class=\"headerlink\" title=\"Previous Outlier injection method\"></a>Previous Outlier injection method</h3><p>$\\mathcal{G}&#x3D;(\\mathcal{V}, \\mathcal{E}, X, y)$: vertice set, edge set, attibute matrix, label of class</p>\n<ul>\n<li><p><strong>Contextual(cntxt.) outlier injection</strong><br>Normalize features $x_i’&#x3D;\\frac{x_i}{||x_i||_1}$<br>Sample $o$ nodes from $\\mathcal{V}$ as $\\mathcal{V}_c$. without replacement<br>For node $i$ in $\\mathcal{V}_c$, sample $q$ nodes from $\\mathcal{V}_r&#x3D;\\mathcal{V}- \\mathcal{V}_c$, among them choose the farthest one $j &#x3D; \\text{argmax}_k(||x_i’-x_k’||_2)$ to replace $x_i$ with $x_j$.</p>\n</li>\n<li><p><strong>Strctural(stct.) outlier injection</strong><br>create $t$ groups sized $s$ with anomalous nodes.<br>sample $o&#x3D;t\\times s$ from $\\mathcal{V}$ without replacement<br>Then randoms partition into $t$ groups.<br>Add edges to make them a clique(fully connected), then drop edges with $p$ probability</p>\n</li>\n</ul>\n<h4 id=\"Score-function\"><a href=\"#Score-function\" class=\"headerlink\" title=\"Score function\"></a>Score function</h4><p>The farthest node will have large $||\\tilde{\\mathbf x}_i||_2$ <br>A structural outlier node $i$ will have many neighbors leads to large $||\\tilde{\\mathbf a}_i||_1$ </p>\n<p>Score function: $score_{norm}(i)&#x3D;\\alpha||\\tilde{\\mathbf x}_i||_2+(1-\\alpha)||\\tilde {\\mathbf a}_i||_1$,  $\\tilde{\\mathbf x}_i$: $x_i$ after outlier injection, $\\tilde{\\mathbf a}<em>i$: $a_i$ after outlier injection, $A</em>{ii}&#x3D;1$<br>where cntxt OD, $\\alpha&#x3D;1$, stct OD, $\\alpha&#x3D;0$ :  $\\alpha$ ratio of two methods </p>\n<p>test 1: ROC-AUC<br>For each dataset, use original dataset v.s. l2-nrom for each $x_i$<br>do anomaly injection. apply GAD Method to get  $score_{norm}$</p>\n<h3 id=\"Novel-Anomaly-injection-method\"><a href=\"#Novel-Anomaly-injection-method\" class=\"headerlink\" title=\"Novel Anomaly injection method\"></a>Novel Anomaly injection method</h3><h2 id=\"Sum-in-terms-of-Dataset\"><a href=\"#Sum-in-terms-of-Dataset\" class=\"headerlink\" title=\"Sum in terms of Dataset\"></a>Sum in terms of Dataset</h2><p>从数据集的角度来说：</p>\n<h3 id=\"FairGAD-1\"><a href=\"#FairGAD-1\" class=\"headerlink\" title=\"FairGAD:\"></a>FairGAD:</h3><p>Reddit:</p>\n<ul>\n<li>数据来源：Post on politic related subReddit</li>\n<li>Labelling Y: based on FACTOID(Sakketou et al., 2022), use the num of posted link(left or right)</li>\n<li>Graph construciton:</li>\n</ul>\n<p><br><br><br><br><br><br><br><br><br><br><br><br>\\</p>\n<h1 id=\"2024-05-31-Meeting\"><a href=\"#2024-05-31-Meeting\" class=\"headerlink\" title=\"2024.05.31 Meeting\"></a>2024.05.31 Meeting</h1><p>Preparation: </p>\n<ol>\n<li>讨论对于Synthetic dataset 怎么创建的理解。</li>\n<li>对outlier dataset怎么创建的理解。</li>\n<li>fair + outlier (参考FairGAD那篇的创建)</li>\n</ol>\n<!-- 这一周花了三四天在信一的身上，一种僭越的快乐。\n体悟是， \n1. 学东西的目的性还是不够明显。\n2. 边听课边看论文会岷县提高目的性和提高效率。\n3. 减少过度功利的需求，学一些有趣的东西，尽量避开人。\n4. 背单词。GRE要寄了。 -->\n\n\n<p><strong>Meeting</strong></p>\n<ol>\n<li><p>Plan for subgroups:<br>Mo, We 1-2 p.m.</p>\n</li>\n<li><p>intro to all projects<br>HNN: Convolution $\\rightarrow$ HNN<br>CNN(T(x)) Paralell Translation equivalence</p>\n</li>\n</ol>\n<h2 id=\"Dataset\"><a href=\"#Dataset\" class=\"headerlink\" title=\"Dataset\"></a>Dataset</h2><p><img src=\"/2024-05-08-papers/image-1.png\" alt=\"alt text\"> from FairGAD(2024)<br>##<br>Pokec: </p>\n<ul>\n<li>source paper: <a href=\"https://arxiv.org/pdf/2009.01454\">https://arxiv.org/pdf/2009.01454</a></li>\n<li>repo: FairGNN  <a href=\"https://github.com/EnyanDai/FairGNN\">https://github.com/EnyanDai/FairGNN</a><br>sampled from <a href=\"https://snap.stanford.edu/data/soc-Pokec.html\">https://snap.stanford.edu/data/soc-Pokec.html</a></li>\n</ul>\n<p>Bail, Credit, German:</p>\n<ul>\n<li>source paper: <a href=\"https://arxiv.org/pdf/2108.05233\">https://arxiv.org/pdf/2108.05233</a> (Dong et al. 2022)<br>  <a href=\"https://arxiv.org/pdf/1102.2166\">https://arxiv.org/pdf/1102.2166</a> (2012)</li>\n<li>repo: EDITS <a href=\"https://github.com/yushundong/EDITS\">https://github.com/yushundong/EDITS</a></li>\n</ul>\n<p>(感觉论文部分引用反了)</p>\n<p>German</p>\n<ul>\n<li>source paper: <a href=\"https://arxiv.org/pdf/2102.13186\">https://arxiv.org/pdf/2102.13186</a> (2021)</li>\n<li>repo: NIFTY <a href=\"https://github.com/HongduanTian/NIFTY\">https://github.com/HongduanTian/NIFTY</a></li>\n</ul>\n<p>UCSD34:</p>\n<ul>\n<li>repo: <a href=\"https://networkrepository.com/socfb-UCSD34.php\">https://networkrepository.com/socfb-UCSD34.php</a></li>\n</ul>\n<h1 id=\"2024-06-03-Meeting\"><a href=\"#2024-06-03-Meeting\" class=\"headerlink\" title=\"2024.06.03 Meeting\"></a>2024.06.03 Meeting</h1><ol>\n<li>Gujing学姐的论文是 unsupervised learning，按照她在pygod里面的方法，把二分类的任务用fiarness metrix，用counterfacutal里的评判标准。EOO, SP, CF(只在Synthetic里有)</li>\n</ol>\n<p>所以要写的是： </p>\n<ol>\n<li>Fairness metrix 的计算，多种</li>\n<li>使用各种方法跑一下数据集。得到fair和accuracy，参考别的论文。</li>\n</ol>\n<p>长期任务：</p>\n<ol>\n<li><p>WSDM 22’ 的做counterfactual Data argumentation 和GAD的方法无关。，总的来说是在不同GAD 方法上consistently improve fairness. WSDM 是在数据集的encoding和encoding上用的fairness。<br>Detection 也是用en&#x2F;decoding做的？有的用GNN也就可以prediction了。可以试着画一个图。 </p>\n</li>\n<li><p>224W可以看17-19， 21和前面encoding部分在学一下。</p>\n</li>\n<li><p>因果推断的Counterfactual部分的公式</p>\n</li>\n</ol>\n<h2 id=\"Execute\"><a href=\"#Execute\" class=\"headerlink\" title=\"Execute\"></a>Execute</h2><p>6.3: 解决</p>\n<ol>\n<li>Synthetic dataset have about $\\frac{|V|^2}{2}$ edges when v&#x3D;2000(paper), edge should be about 4000?<br>solved by Finding source code of paper in GEAR repo</li>\n<li>Threading problem with python not shoot<br>solved by commenting the 22th line in loader.py # from ogb.nodeproppred import PygNodePropPredDataset</li>\n</ol>\n<p>6.4</p>\n<ol>\n<li>可以使用一些方法，<br>WSDM 22 GEAR 的论文里用GCN, GraphSAGE, GIN, C-ENC, FairGNN, NIFTY-GCN, NIFTY-SAGE, and GEAR<br>Gu 24 HNN 的论文用pygod的GAD的库<br>但是都没有找到相关代码</li>\n</ol>\n<p>Gear&#x2F;src</p>\n<ul>\n<li>utils.py: <ol>\n<li>load_dataset, sub function</li>\n<li>accuracy</li>\n</ol>\n</li>\n<li>Preprocessing.py:<ol>\n<li>load_data() deal with params</li>\n<li>generate cf subgraph(无关)</li>\n<li>generate_synthetic_data</li>\n</ol>\n</li>\n<li>models.py:<ol>\n<li>GCN, GIN, JK, SAGE, Encoder_DGI, GraphInMax, Encoder, Classifier,<br>  GraphCF,</li>\n</ol>\n</li>\n<li>main.py<ol>\n<li>parser.argment()</li>\n<li>evaluate: acc, fairness</li>\n<li>compute loss, evaluate sf</li>\n<li>train test</li>\n</ol>\n</li>\n</ul>\n<p>HNN_GAD<br>根据我的观察，这篇里面只写了自己的方法的代码。</p>\n<p>6.5 Meeting<br>决定用ray tune来调参<a href=\"https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\">https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html</a></p>\n<p>6.7<br>正在写scratch_main.py<br>疑问：<br>    1. 这个train, val, test 是怎么分的,子图还是？<br>    ???<br>        evaluate和test有什么区别<br>    2. evaluate里的counterfactual metrix是怎么算的？<br>    3. Injection的参数<br>    4. github怎么上传<br>    5. </p>\n<p>6.11<br>    Paul强调SRS是为了丰富简历的，要干很多跟申研相关的事情。<br>    看看教授现在在干什么，fellowship是啥，，？？？？practicing interview。<br>    升多少学校？？？没听懂<br>    5-8<br>    16？？？</p>\n<h1 id=\"2024-06-12-Meeting\"><a href=\"#2024-06-12-Meeting\" class=\"headerlink\" title=\"2024.06.12 Meeting\"></a>2024.06.12 Meeting</h1><ol>\n<li>CF + gu学姐的三个方法</li>\n<li>gpu的问题还没有解决</li>\n<li>inject的好像不是特别影响fairness</li>\n</ol>\n<p>数据集的构造方面在sensitivity group和是不是outlier之间加上casuality。FairGAD用了debiaser的方法使fairness高了一点<br>run Jing’s method for GAD: shengen在做<br>Check with Yifei for GPU：check了，现在一些model在大的数据集上还要分batch。<br>Check CF scores：装了两天环境，<br>Complete remaining experiments：没有<br>brainstorm so that outlier injection contains sensitivity：认为<br>CF using DA</p>\n<p>Motivation： outlier detection，<br>Fairnes有效的数据集：<br>Outlier的注入：</p>\n<h2 id=\"6-12-问题\"><a href=\"#6-12-问题\" class=\"headerlink\" title=\"6.12 问题\"></a>6.12 问题</h2><h3 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h3><p>一个下午主要都在解决gpu的问题，</p>\n<h4 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h4><p>首先目前最大的谜团是Pygod中AdONE(gpu&#x3D;0)这里的光谱为啥只能是0<br>我去找了源代码，应该可以是int cuda的id，所以理论上应该是0-7 都可以的，但是只有0可行，<br>主要代码<br>pygod&#x2F;pygod&#x2F;detector&#x2F;base <br>pygod&#x2F;utils&#x2F;utility.py 的<code>validate_device(gpu_id)</code>函数<code>gpu_id</code>就是<code>DOMINANT(gpu=0)</code>里的<code>gpu</code></p>\n<h4 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2\"></a>2</h4><p>还有一个很蠢得已经被解决的问题是<br>为什么.sh文件会报。 之前一直不明白为什么命令行就没问题，但是.sh 就不可以，后来发信啊是模型之间的区别<br>    torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.35 GiB. GPU 0 has a total capacty of 23.65 GiB of which 3.01 GiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 16.79 GiB is allocated by PyTorch, and 3.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF<br>这种错，<br>修改的方式是</p>\n<ol>\n<li><p>在ray tune 里把网络得大小修改小一点，并且分batch，通过在train最后释放内存</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">defv train():</span><br><span class=\"line\">    ... ...</span><br><span class=\"line\">    torch.cuda.empty_cache() </span><br><span class=\"line\">    return</span><br></pre></td></tr></table></figure></li>\n<li><p>在ray tune 分batch。在main得第一句加上</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">os.environ[&#x27;PYTORCH_CUDA_ALLOC_CONF&#x27;] = &#x27;max_split_size_mb:128&#x27;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>本身因为dataset和model的大小不同，所以有的模型被跑出来的可行性就是要小一点<br>比如从synthetic &lt; german &lt; bail &lt; credit &lt; pokec<br>前三个是可以跑所有模型的，<br>但是credit不可以跑gaan, 会站600GiB的内存，guide也非常慢， credit+guide根本没上gpu？？？<br>玄学</p>\n</li>\n</ol>\n<h3 id=\"6-14-CF\"><a href=\"#6-14-CF\" class=\"headerlink\" title=\"6.14 CF\"></a>6.14 CF</h3><p>cf_eoo, cf_dp, df, eoo, dp 在论文中分别代表什么<a href=\"https://arxiv.org/pdf/2201.03662\">https://arxiv.org/pdf/2201.03662</a></p>\n<p>sens rate </p>\n<p>论文算cf的方法是:<br>对比原图和经过修改sens feature（类似于perturbe的手法），通过$hat y$之间的来算cf</p>\n<p>重点是如何得到 modified data， 也就是 evaluate 中的 data_cf</p>\n<p>随机取 sens_rate * N 个节点，使$S_i$为1，剩下为0.</p>\n<h3 id=\"GEAR配环境踩坑\"><a href=\"#GEAR配环境踩坑\" class=\"headerlink\" title=\"GEAR配环境踩坑\"></a>GEAR配环境踩坑</h3><p>pyg很烦人<br>我是先装了torch1.6.0 + cu10.2<br>然后发现pyg&#x3D;1.3.0 是最老版本的，就google到了pyg的的source code ： <a href=\"https://github.com/pyg-team/pytorch_geometric/releases/tag/1.3.0\">https://github.com/pyg-team/pytorch_geometric/releases/tag/1.3.0</a><br>然后就应该python setup.py install,但是<strong>网很慢</strong>， 所以要多等一会<br>然后看到readme之后手动装了个torch-sparse一类的whl： <a href=\"https://data.pyg.org/whl/\">https://data.pyg.org/whl/</a><br>后来很傻的才发现python setup.py install，等了3分钟之后报错，无pytest-runner， 于是进setup.py看了一下之后手动pip install pytest-runner pytest pytest-cov mock,<br>然后python setup.py install一下子就好了，于是又手动 pip install pandas matplotlib Cpython cytoolz aif360</p>\n<p>装到aif360 报错Failed building wheel for llvmlite，应该是没有llvm，于是手动本地装<br>装了9.0.0的版本</p>\n<pre><code>如果 `llvmlite` 的预构建二进制文件和 `conda` 方法都无法解决问题，普通用户可以在用户目录中安装 LLVM，而不需要 `sudo` 权限。\n\n\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 下载并解压 LLVM</span></span><br><span class=\"line\">wget https://github.com/llvm/llvm-project/releases/download/llvmorg-11.1.0/llvm-11.1.0.src.tar.xz</span><br><span class=\"line\">tar -xf llvm-11.1.0.src.tar.xz</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建构建目录</span></span><br><span class=\"line\"><span class=\"built_in\">mkdir</span> llvm-11.1.0.build</span><br><span class=\"line\"><span class=\"built_in\">cd</span> llvm-11.1.0.build</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 配置编译（安装在用户目录）</span></span><br><span class=\"line\">cmake -G <span class=\"string\">&quot;Unix Makefiles&quot;</span> -DCMAKE_INSTALL_PREFIX=<span class=\"variable\">$HOME</span>/llvm ../llvm-11.1.0.src</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 编译和安装</span></span><br><span class=\"line\">make -j$(<span class=\"built_in\">nproc</span>)</span><br><span class=\"line\">make install</span><br></pre></td></tr></table></figure>\n\n然后设置环境变量以使用本地安装的 LLVM：\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$HOME</span>/llvm/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> LD_LIBRARY_PATH=<span class=\"variable\">$HOME</span>/llvm/lib:<span class=\"variable\">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>\n\n\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install llvmlite --no-binary llvmlite</span><br></pre></td></tr></table></figure>\n\n之后再安装 `aif360`：\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install aif360</span><br></pre></td></tr></table></figure>\n</code></pre>\n<p>但是还是会报wheel build 失败的错误。<br>于是就直接绕过aif360,因为只用了两个函数，所以直接复制函数和必要的util过来了，绕过安装aif360的问题了。<br>实际上aif360对python 3.8之后才比较兼容，所以以后用新一点的环境。</p>\n<p>然后遇到了AttributeError: Can’t get attribute ‘DataEdgeAttr’<br>import torch_geometric.transforms as T<br>from ogb.nodeproppred import PygNodePropPredDataset<br>shouju学姐提醒可以csdn，（这次提供的解决方案确实和gpt不一样）<a href=\"https://blog.csdn.net/oqqENvY12/article/details/129786928\">https://blog.csdn.net/oqqENvY12/article/details/129786928</a> 也有一部分版本过老的问题<br>但是通过观察，是路径问题，把一个相对main.py line 541的相对路径改成绝对路径就成功了，<br>我觉得<strong>13.23的服务器在路径上确实有些玄乎</strong></p>\n<ul>\n<li>运行结束之后没有办法自动关闭</li>\n<li>german 数据集无法正常生成</li>\n</ul>\n<h3 id=\"Gu学姐的三个model\"><a href=\"#Gu学姐的三个model\" class=\"headerlink\" title=\"Gu学姐的三个model\"></a>Gu学姐的三个model</h3><p>万能的CSDN<br>Collecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.<em>, but conda is ignoring the .</em> and treating it as 1.7.1<br><a href=\"https://blog.csdn.net/ermmtt/article/details/132628639\">https://blog.csdn.net/ermmtt/article/details/132628639</a></p>\n<h3 id=\"Batch问题\"><a href=\"#Batch问题\" class=\"headerlink\" title=\"Batch问题\"></a>Batch问题</h3><h3 id=\"Python-插件\"><a href=\"#Python-插件\" class=\"headerlink\" title=\"Python 插件\"></a>Python 插件</h3><p>这个是最傻的，下载了 vsix 之后发现 vscode 版本对不上， 然后更新了一下 vscode 就好了。。。</p>\n<h1 id=\"2024-06-24-Meeting\"><a href=\"#2024-06-24-Meeting\" class=\"headerlink\" title=\"2024.06.24 Meeting\"></a>2024.06.24 Meeting</h1><h2 id=\"2024-06-19\"><a href=\"#2024-06-19\" class=\"headerlink\" title=\"2024.06.19\"></a>2024.06.19</h2><p>(刚刚才了解 Encoder 和 Decoder 也算是 GNN，然后看了一些东西<br>(OI佬写的GEAR代码，看不懂，</p>\n<h1 id=\"2024-07-14\"><a href=\"#2024-07-14\" class=\"headerlink\" title=\"2024.07.14\"></a>2024.07.14</h1><!-- 竟然过了一个月了。 -->\n\n<h2 id=\"2024-06-10开会\"><a href=\"#2024-06-10开会\" class=\"headerlink\" title=\"2024.06.10开会\"></a>2024.06.10开会</h2><ol>\n<li>做benchmark. + Jing学姐的三个HNN已经改成了Class但是AUC还是太低了。。。</li>\n<li>手写encoder和decoder。结构未知，但是主要是修改Loss Function???基于CF的，可以在dominant上修改</li>\n<li>解释为什么CF是低的，看decoder出来的sens’，是还原了sens还是都是1&#x2F;2.这两者都是可以解释的</li>\n<li>在学一下CF之类的理论。</li>\n<li>GNNNNNNNNNN</li>\n</ol>\n<h1 id=\"2024-08-15\"><a href=\"#2024-08-15\" class=\"headerlink\" title=\"2024.08.15\"></a>2024.08.15</h1><!-- 竟然又过了一个月了。 -->\n<!-- 抽象，完全不知道自己在干啥。。。 -->\n\n<ol>\n<li>DOIMINANT 19, DONE 21, gadnr 24, ada-gad 234. (CFGN denied)</li>\n<li>benchmark和一些sens reconstruct 的值对比（之前貌似只作了guide 21的）</li>\n<li>论文也看不出来在写啥</li>\n<li></li>\n</ol>\n<p>08.18 交srs报告<br>08.25 GRE 考试，寄<br>找sol教授询问music tech方向的问题<br>论文论文论文</p>\n"},{"title":"Webpages","date":"2024-08-14T22:00:02.000Z","_content":"\n# Wordpress (收费)\n零代码编辑网页 Wordpress\nhttps://wordpress.com/\nWordpress 部署：\nhttps://wordpress.com/setup/domain-transfer/intro\n（这个收费的，搭完才发现，，，）\n\n\n搭配模板\nhttps://startertemplatecloud.com/g11/\n\n\n除了那些流行的模板框架，还有一些比较小众但很有特色的选择，它们可能更适合特定类型的项目或设计偏好：\n\nTurretCSS: 一个基于约束的 CSS 框架，通过声明式语法实现灵活的布局和响应式设计。\nBassCSS: 一个轻量级、模块化的 CSS 框架，专注于提供简洁、易于理解的样式。\nMilligram: 一个极简主义的 CSS 框架，旨在提供最小的样式，让开发者能够自由地构建自定义设计。\nPicnic CSS: 一个轻量级、易于使用的 CSS 框架，提供简洁、现代的样式和组件。\nChota: 一个极简的 CSS 框架，文件大小非常小，适合对性能要求高的项目。\nBlaze CSS: 一个模块化、可扩展的 CSS 框架，提供灵活的网格系统和丰富的组件。\n\n\n\n# 个人网页教程\n\nHexo, WordPress\nhttps://pdpeng.github.io/2022/01/19/setup-personal-blog/\n\n\nWordpress\nhttps://www.cnblogs.com/wongbingming/p/13819905.html\n\n\n\n\n\n\n# Github Page\nGithub page 域名：\nhttps://pages.github.com/\n\n\n# Free Gallery template\n好用好看\nhttps://www.free-css.com/template-categories/gallery\n\n\n\n","source":"_posts/2024-08-14-Webpages.md","raw":"---\ntitle: Webpages\ndate: 2024-08-14 18:00:02\ntags:\n---\n\n# Wordpress (收费)\n零代码编辑网页 Wordpress\nhttps://wordpress.com/\nWordpress 部署：\nhttps://wordpress.com/setup/domain-transfer/intro\n（这个收费的，搭完才发现，，，）\n\n\n搭配模板\nhttps://startertemplatecloud.com/g11/\n\n\n除了那些流行的模板框架，还有一些比较小众但很有特色的选择，它们可能更适合特定类型的项目或设计偏好：\n\nTurretCSS: 一个基于约束的 CSS 框架，通过声明式语法实现灵活的布局和响应式设计。\nBassCSS: 一个轻量级、模块化的 CSS 框架，专注于提供简洁、易于理解的样式。\nMilligram: 一个极简主义的 CSS 框架，旨在提供最小的样式，让开发者能够自由地构建自定义设计。\nPicnic CSS: 一个轻量级、易于使用的 CSS 框架，提供简洁、现代的样式和组件。\nChota: 一个极简的 CSS 框架，文件大小非常小，适合对性能要求高的项目。\nBlaze CSS: 一个模块化、可扩展的 CSS 框架，提供灵活的网格系统和丰富的组件。\n\n\n\n# 个人网页教程\n\nHexo, WordPress\nhttps://pdpeng.github.io/2022/01/19/setup-personal-blog/\n\n\nWordpress\nhttps://www.cnblogs.com/wongbingming/p/13819905.html\n\n\n\n\n\n\n# Github Page\nGithub page 域名：\nhttps://pages.github.com/\n\n\n# Free Gallery template\n好用好看\nhttps://www.free-css.com/template-categories/gallery\n\n\n\n","slug":"2024-08-14-Webpages","published":1,"updated":"2024-12-15T03:50:20.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagq10019zc3d98jd5oqk","content":"<h1 id=\"Wordpress-收费\"><a href=\"#Wordpress-收费\" class=\"headerlink\" title=\"Wordpress (收费)\"></a>Wordpress (收费)</h1><p>零代码编辑网页 Wordpress<br><a href=\"https://wordpress.com/\">https://wordpress.com/</a><br>Wordpress 部署：<br><a href=\"https://wordpress.com/setup/domain-transfer/intro\">https://wordpress.com/setup/domain-transfer/intro</a><br>（这个收费的，搭完才发现，，，）</p>\n<p>搭配模板<br><a href=\"https://startertemplatecloud.com/g11/\">https://startertemplatecloud.com/g11/</a></p>\n<p>除了那些流行的模板框架，还有一些比较小众但很有特色的选择，它们可能更适合特定类型的项目或设计偏好：</p>\n<p>TurretCSS: 一个基于约束的 CSS 框架，通过声明式语法实现灵活的布局和响应式设计。<br>BassCSS: 一个轻量级、模块化的 CSS 框架，专注于提供简洁、易于理解的样式。<br>Milligram: 一个极简主义的 CSS 框架，旨在提供最小的样式，让开发者能够自由地构建自定义设计。<br>Picnic CSS: 一个轻量级、易于使用的 CSS 框架，提供简洁、现代的样式和组件。<br>Chota: 一个极简的 CSS 框架，文件大小非常小，适合对性能要求高的项目。<br>Blaze CSS: 一个模块化、可扩展的 CSS 框架，提供灵活的网格系统和丰富的组件。</p>\n<h1 id=\"个人网页教程\"><a href=\"#个人网页教程\" class=\"headerlink\" title=\"个人网页教程\"></a>个人网页教程</h1><p>Hexo, WordPress<br><a href=\"https://pdpeng.github.io/2022/01/19/setup-personal-blog/\">https://pdpeng.github.io/2022/01/19/setup-personal-blog/</a></p>\n<p>Wordpress<br><a href=\"https://www.cnblogs.com/wongbingming/p/13819905.html\">https://www.cnblogs.com/wongbingming/p/13819905.html</a></p>\n<h1 id=\"Github-Page\"><a href=\"#Github-Page\" class=\"headerlink\" title=\"Github Page\"></a>Github Page</h1><p>Github page 域名：<br><a href=\"https://pages.github.com/\">https://pages.github.com/</a></p>\n<h1 id=\"Free-Gallery-template\"><a href=\"#Free-Gallery-template\" class=\"headerlink\" title=\"Free Gallery template\"></a>Free Gallery template</h1><p>好用好看<br><a href=\"https://www.free-css.com/template-categories/gallery\">https://www.free-css.com/template-categories/gallery</a></p>\n","excerpt":"","more":"<h1 id=\"Wordpress-收费\"><a href=\"#Wordpress-收费\" class=\"headerlink\" title=\"Wordpress (收费)\"></a>Wordpress (收费)</h1><p>零代码编辑网页 Wordpress<br><a href=\"https://wordpress.com/\">https://wordpress.com/</a><br>Wordpress 部署：<br><a href=\"https://wordpress.com/setup/domain-transfer/intro\">https://wordpress.com/setup/domain-transfer/intro</a><br>（这个收费的，搭完才发现，，，）</p>\n<p>搭配模板<br><a href=\"https://startertemplatecloud.com/g11/\">https://startertemplatecloud.com/g11/</a></p>\n<p>除了那些流行的模板框架，还有一些比较小众但很有特色的选择，它们可能更适合特定类型的项目或设计偏好：</p>\n<p>TurretCSS: 一个基于约束的 CSS 框架，通过声明式语法实现灵活的布局和响应式设计。<br>BassCSS: 一个轻量级、模块化的 CSS 框架，专注于提供简洁、易于理解的样式。<br>Milligram: 一个极简主义的 CSS 框架，旨在提供最小的样式，让开发者能够自由地构建自定义设计。<br>Picnic CSS: 一个轻量级、易于使用的 CSS 框架，提供简洁、现代的样式和组件。<br>Chota: 一个极简的 CSS 框架，文件大小非常小，适合对性能要求高的项目。<br>Blaze CSS: 一个模块化、可扩展的 CSS 框架，提供灵活的网格系统和丰富的组件。</p>\n<h1 id=\"个人网页教程\"><a href=\"#个人网页教程\" class=\"headerlink\" title=\"个人网页教程\"></a>个人网页教程</h1><p>Hexo, WordPress<br><a href=\"https://pdpeng.github.io/2022/01/19/setup-personal-blog/\">https://pdpeng.github.io/2022/01/19/setup-personal-blog/</a></p>\n<p>Wordpress<br><a href=\"https://www.cnblogs.com/wongbingming/p/13819905.html\">https://www.cnblogs.com/wongbingming/p/13819905.html</a></p>\n<h1 id=\"Github-Page\"><a href=\"#Github-Page\" class=\"headerlink\" title=\"Github Page\"></a>Github Page</h1><p>Github page 域名：<br><a href=\"https://pages.github.com/\">https://pages.github.com/</a></p>\n<h1 id=\"Free-Gallery-template\"><a href=\"#Free-Gallery-template\" class=\"headerlink\" title=\"Free Gallery template\"></a>Free Gallery template</h1><p>好用好看<br><a href=\"https://www.free-css.com/template-categories/gallery\">https://www.free-css.com/template-categories/gallery</a></p>\n"},{"title":"Cytoid AI Charting","date":"2024-06-03T19:58:56.000Z","_content":"\n1. 相关论文实现\n\n\nSurvey 1: https://www.qbitai.com/2022/03/33133.html\n\n1.1 现有技术(1)：100k songs, 44GB data\nhttps://github.com/chrisdonahue/ddc \nhttps://arxiv.org/pdf/1703.06891.pdf\n\n\t\n1.2 GeneLive在DDC基础上improve：\n现有技术2：GenéLive! Generating Rhythm Actions in Love Live! | Proceedings of the AAAI Conference on Artificial Intelligence\nhttps://arxiv.org/abs/2202.12823\nhttps://github.com/chrisdonahue/ddc\n\n1.3 现有技术3： \nMuG Diffusion:\nhttps://www.bilibili.com/video/BV1Sg4y1j7sz/?vd_source=441679270dda23308fe16f3c5602b058\nhttps://github.com/Keytoyze/Mug-Diffusion\n\n\n\n\n\n2. 音游相关特征\n\n- 这次使用的音游：\n\thttps://cytoid.io/\n- 扒谱网站：\n    https://cytoid.io/levels\n- 扒谱工具：（应该用不到）\n    https://sites.google.com/site/cytoidcommunity/charting/introduction-cy2unity\n- 谱面格式介绍：\n    https://github.com/openmusicgame/omgc\n- 这个教授研究很多音乐：\n    https://scholar.google.com/citations?user=MgzHAPQAAAAJ&hl=en&oi=ao\n\n\n3. 前人一些工程上经验（按照规模排序）\n\n1. https://zhuanlan.zhihu.com/p/107010304\n2. https://www.mirrorange.com/ai-beatmap-generator-train/\n3. MuG Diffusion\n\n\nChoreoGraph Chart for Musical Game\nStep Placement: When to place step\nStep Selection: Which step to place\n\n\n\n\n4.音游数据\nhttps://drive.google.com/drive/folders/1J43x9f8u2lIzaHBolQaZveCv62XQM8Lv\n\nMusic library:\nhttps://soundcloud.com/openai_audio/rachmaninoff\n\n\n# DDC Paper 17\nhttps://arxiv.org/pdf/1703.06891\n\nMIR Music information retrival\nonset detection: \ntasks: (learning to choreograph)\n1. step placement\n2. step selection\n\n# GeneLive 23\nhttps://arxiv.org/abs/2202.12823\ngeneratiive deep learning\n\n文中提及 BiLSTM 比 Transformer也许更适合。 \ntwo novel techniques: beat guide, multi-sclae conv-stack\n1. beat guide寻找节奏型\n2. \n\n\n\n\n# TaikoNation 21: \nhttps://arxiv.org/pdf/2107.12506\nLSTM\n\n\n# Other related papers \n## 19 via DL \nhttps://inria.hal.science/hal-03652042v1/document\n\n## 19 aaai keysounded\nhttps://arxiv.org/pdf/1806.11170\n\n# problems encountered\n0.首先做的是关于给定t和diffculty ，生成对应的对应的（是预测下个tick 是否放置key还是预测下一个note的出现时间）\n\n1. combine of level and others \n   - 可以看一下前人论文Genelive 是怎么解决的\n   - Hetergenous variable in BiLSTM(a type on RNN)\n   -  \n2. time series\n3. how to pose x. \n\n最后实现，就是， 并没有参考任何技术，直接LSTM就上了。\n\n \n\n\n\n\n\n\n","source":"_posts/2024-06-03-Cytoid-AI-Charting.md","raw":"---\ntitle: Cytoid AI Charting\ndate: 2024-06-03 15:58:56\ntags:\n---\n\n1. 相关论文实现\n\n\nSurvey 1: https://www.qbitai.com/2022/03/33133.html\n\n1.1 现有技术(1)：100k songs, 44GB data\nhttps://github.com/chrisdonahue/ddc \nhttps://arxiv.org/pdf/1703.06891.pdf\n\n\t\n1.2 GeneLive在DDC基础上improve：\n现有技术2：GenéLive! Generating Rhythm Actions in Love Live! | Proceedings of the AAAI Conference on Artificial Intelligence\nhttps://arxiv.org/abs/2202.12823\nhttps://github.com/chrisdonahue/ddc\n\n1.3 现有技术3： \nMuG Diffusion:\nhttps://www.bilibili.com/video/BV1Sg4y1j7sz/?vd_source=441679270dda23308fe16f3c5602b058\nhttps://github.com/Keytoyze/Mug-Diffusion\n\n\n\n\n\n2. 音游相关特征\n\n- 这次使用的音游：\n\thttps://cytoid.io/\n- 扒谱网站：\n    https://cytoid.io/levels\n- 扒谱工具：（应该用不到）\n    https://sites.google.com/site/cytoidcommunity/charting/introduction-cy2unity\n- 谱面格式介绍：\n    https://github.com/openmusicgame/omgc\n- 这个教授研究很多音乐：\n    https://scholar.google.com/citations?user=MgzHAPQAAAAJ&hl=en&oi=ao\n\n\n3. 前人一些工程上经验（按照规模排序）\n\n1. https://zhuanlan.zhihu.com/p/107010304\n2. https://www.mirrorange.com/ai-beatmap-generator-train/\n3. MuG Diffusion\n\n\nChoreoGraph Chart for Musical Game\nStep Placement: When to place step\nStep Selection: Which step to place\n\n\n\n\n4.音游数据\nhttps://drive.google.com/drive/folders/1J43x9f8u2lIzaHBolQaZveCv62XQM8Lv\n\nMusic library:\nhttps://soundcloud.com/openai_audio/rachmaninoff\n\n\n# DDC Paper 17\nhttps://arxiv.org/pdf/1703.06891\n\nMIR Music information retrival\nonset detection: \ntasks: (learning to choreograph)\n1. step placement\n2. step selection\n\n# GeneLive 23\nhttps://arxiv.org/abs/2202.12823\ngeneratiive deep learning\n\n文中提及 BiLSTM 比 Transformer也许更适合。 \ntwo novel techniques: beat guide, multi-sclae conv-stack\n1. beat guide寻找节奏型\n2. \n\n\n\n\n# TaikoNation 21: \nhttps://arxiv.org/pdf/2107.12506\nLSTM\n\n\n# Other related papers \n## 19 via DL \nhttps://inria.hal.science/hal-03652042v1/document\n\n## 19 aaai keysounded\nhttps://arxiv.org/pdf/1806.11170\n\n# problems encountered\n0.首先做的是关于给定t和diffculty ，生成对应的对应的（是预测下个tick 是否放置key还是预测下一个note的出现时间）\n\n1. combine of level and others \n   - 可以看一下前人论文Genelive 是怎么解决的\n   - Hetergenous variable in BiLSTM(a type on RNN)\n   -  \n2. time series\n3. how to pose x. \n\n最后实现，就是， 并没有参考任何技术，直接LSTM就上了。\n\n \n\n\n\n\n\n\n","slug":"2024-06-03-Cytoid-AI-Charting","published":1,"updated":"2024-12-15T03:50:10.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagq1001azc3d15e9g9wb","content":"<ol>\n<li>相关论文实现</li>\n</ol>\n<p>Survey 1: <a href=\"https://www.qbitai.com/2022/03/33133.html\">https://www.qbitai.com/2022/03/33133.html</a></p>\n<p>1.1 现有技术(1)：100k songs, 44GB data<br><a href=\"https://github.com/chrisdonahue/ddc\">https://github.com/chrisdonahue/ddc</a><br><a href=\"https://arxiv.org/pdf/1703.06891.pdf\">https://arxiv.org/pdf/1703.06891.pdf</a></p>\n<p>1.2 GeneLive在DDC基础上improve：<br>现有技术2：GenéLive! Generating Rhythm Actions in Love Live! | Proceedings of the AAAI Conference on Artificial Intelligence<br><a href=\"https://arxiv.org/abs/2202.12823\">https://arxiv.org/abs/2202.12823</a><br><a href=\"https://github.com/chrisdonahue/ddc\">https://github.com/chrisdonahue/ddc</a></p>\n<p>1.3 现有技术3：<br>MuG Diffusion:<br><a href=\"https://www.bilibili.com/video/BV1Sg4y1j7sz/?vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1Sg4y1j7sz/?vd_source=441679270dda23308fe16f3c5602b058</a><br><a href=\"https://github.com/Keytoyze/Mug-Diffusion\">https://github.com/Keytoyze/Mug-Diffusion</a></p>\n<ol start=\"2\">\n<li>音游相关特征</li>\n</ol>\n<ul>\n<li>这次使用的音游：<br>  <a href=\"https://cytoid.io/\">https://cytoid.io/</a></li>\n<li>扒谱网站：<br>  <a href=\"https://cytoid.io/levels\">https://cytoid.io/levels</a></li>\n<li>扒谱工具：（应该用不到）<br>  <a href=\"https://sites.google.com/site/cytoidcommunity/charting/introduction-cy2unity\">https://sites.google.com/site/cytoidcommunity/charting/introduction-cy2unity</a></li>\n<li>谱面格式介绍：<br>  <a href=\"https://github.com/openmusicgame/omgc\">https://github.com/openmusicgame/omgc</a></li>\n<li>这个教授研究很多音乐：<br>  <a href=\"https://scholar.google.com/citations?user=MgzHAPQAAAAJ&hl=en&oi=ao\">https://scholar.google.com/citations?user=MgzHAPQAAAAJ&amp;hl=en&amp;oi=ao</a></li>\n</ul>\n<ol start=\"3\">\n<li><p>前人一些工程上经验（按照规模排序）</p>\n</li>\n<li><p><a href=\"https://zhuanlan.zhihu.com/p/107010304\">https://zhuanlan.zhihu.com/p/107010304</a></p>\n</li>\n<li><p><a href=\"https://www.mirrorange.com/ai-beatmap-generator-train/\">https://www.mirrorange.com/ai-beatmap-generator-train/</a></p>\n</li>\n<li><p>MuG Diffusion</p>\n</li>\n</ol>\n<p>ChoreoGraph Chart for Musical Game<br>Step Placement: When to place step<br>Step Selection: Which step to place</p>\n<p>4.音游数据<br><a href=\"https://drive.google.com/drive/folders/1J43x9f8u2lIzaHBolQaZveCv62XQM8Lv\">https://drive.google.com/drive/folders/1J43x9f8u2lIzaHBolQaZveCv62XQM8Lv</a></p>\n<p>Music library:<br><a href=\"https://soundcloud.com/openai_audio/rachmaninoff\">https://soundcloud.com/openai_audio/rachmaninoff</a></p>\n<h1 id=\"DDC-Paper-17\"><a href=\"#DDC-Paper-17\" class=\"headerlink\" title=\"DDC Paper 17\"></a>DDC Paper 17</h1><p><a href=\"https://arxiv.org/pdf/1703.06891\">https://arxiv.org/pdf/1703.06891</a></p>\n<p>MIR Music information retrival<br>onset detection:<br>tasks: (learning to choreograph)</p>\n<ol>\n<li>step placement</li>\n<li>step selection</li>\n</ol>\n<h1 id=\"GeneLive-23\"><a href=\"#GeneLive-23\" class=\"headerlink\" title=\"GeneLive 23\"></a>GeneLive 23</h1><p><a href=\"https://arxiv.org/abs/2202.12823\">https://arxiv.org/abs/2202.12823</a><br>generatiive deep learning</p>\n<p>文中提及 BiLSTM 比 Transformer也许更适合。<br>two novel techniques: beat guide, multi-sclae conv-stack</p>\n<ol>\n<li>beat guide寻找节奏型</li>\n<li></li>\n</ol>\n<h1 id=\"TaikoNation-21\"><a href=\"#TaikoNation-21\" class=\"headerlink\" title=\"TaikoNation 21:\"></a>TaikoNation 21:</h1><p><a href=\"https://arxiv.org/pdf/2107.12506\">https://arxiv.org/pdf/2107.12506</a><br>LSTM</p>\n<h1 id=\"Other-related-papers\"><a href=\"#Other-related-papers\" class=\"headerlink\" title=\"Other related papers\"></a>Other related papers</h1><h2 id=\"19-via-DL\"><a href=\"#19-via-DL\" class=\"headerlink\" title=\"19 via DL\"></a>19 via DL</h2><p><a href=\"https://inria.hal.science/hal-03652042v1/document\">https://inria.hal.science/hal-03652042v1/document</a></p>\n<h2 id=\"19-aaai-keysounded\"><a href=\"#19-aaai-keysounded\" class=\"headerlink\" title=\"19 aaai keysounded\"></a>19 aaai keysounded</h2><p><a href=\"https://arxiv.org/pdf/1806.11170\">https://arxiv.org/pdf/1806.11170</a></p>\n<h1 id=\"problems-encountered\"><a href=\"#problems-encountered\" class=\"headerlink\" title=\"problems encountered\"></a>problems encountered</h1><p>0.首先做的是关于给定t和diffculty ，生成对应的对应的（是预测下个tick 是否放置key还是预测下一个note的出现时间）</p>\n<ol>\n<li><h2 id=\"combine-of-level-and-others-可以看一下前人论文Genelive-是怎么解决的-Hetergenous-variable-in-BiLSTM-a-type-on-RNN\"><a href=\"#combine-of-level-and-others-可以看一下前人论文Genelive-是怎么解决的-Hetergenous-variable-in-BiLSTM-a-type-on-RNN\" class=\"headerlink\" title=\"combine of level and others- 可以看一下前人论文Genelive 是怎么解决的- Hetergenous variable in BiLSTM(a type on RNN)\"></a>combine of level and others<br>- 可以看一下前人论文Genelive 是怎么解决的<br>- Hetergenous variable in BiLSTM(a type on RNN)</h2></li>\n<li>time series</li>\n<li>how to pose x.</li>\n</ol>\n<p>最后实现，就是， 并没有参考任何技术，直接LSTM就上了。</p>\n<p> </p>\n","excerpt":"","more":"<ol>\n<li>相关论文实现</li>\n</ol>\n<p>Survey 1: <a href=\"https://www.qbitai.com/2022/03/33133.html\">https://www.qbitai.com/2022/03/33133.html</a></p>\n<p>1.1 现有技术(1)：100k songs, 44GB data<br><a href=\"https://github.com/chrisdonahue/ddc\">https://github.com/chrisdonahue/ddc</a><br><a href=\"https://arxiv.org/pdf/1703.06891.pdf\">https://arxiv.org/pdf/1703.06891.pdf</a></p>\n<p>1.2 GeneLive在DDC基础上improve：<br>现有技术2：GenéLive! Generating Rhythm Actions in Love Live! | Proceedings of the AAAI Conference on Artificial Intelligence<br><a href=\"https://arxiv.org/abs/2202.12823\">https://arxiv.org/abs/2202.12823</a><br><a href=\"https://github.com/chrisdonahue/ddc\">https://github.com/chrisdonahue/ddc</a></p>\n<p>1.3 现有技术3：<br>MuG Diffusion:<br><a href=\"https://www.bilibili.com/video/BV1Sg4y1j7sz/?vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1Sg4y1j7sz/?vd_source=441679270dda23308fe16f3c5602b058</a><br><a href=\"https://github.com/Keytoyze/Mug-Diffusion\">https://github.com/Keytoyze/Mug-Diffusion</a></p>\n<ol start=\"2\">\n<li>音游相关特征</li>\n</ol>\n<ul>\n<li>这次使用的音游：<br>  <a href=\"https://cytoid.io/\">https://cytoid.io/</a></li>\n<li>扒谱网站：<br>  <a href=\"https://cytoid.io/levels\">https://cytoid.io/levels</a></li>\n<li>扒谱工具：（应该用不到）<br>  <a href=\"https://sites.google.com/site/cytoidcommunity/charting/introduction-cy2unity\">https://sites.google.com/site/cytoidcommunity/charting/introduction-cy2unity</a></li>\n<li>谱面格式介绍：<br>  <a href=\"https://github.com/openmusicgame/omgc\">https://github.com/openmusicgame/omgc</a></li>\n<li>这个教授研究很多音乐：<br>  <a href=\"https://scholar.google.com/citations?user=MgzHAPQAAAAJ&hl=en&oi=ao\">https://scholar.google.com/citations?user=MgzHAPQAAAAJ&amp;hl=en&amp;oi=ao</a></li>\n</ul>\n<ol start=\"3\">\n<li><p>前人一些工程上经验（按照规模排序）</p>\n</li>\n<li><p><a href=\"https://zhuanlan.zhihu.com/p/107010304\">https://zhuanlan.zhihu.com/p/107010304</a></p>\n</li>\n<li><p><a href=\"https://www.mirrorange.com/ai-beatmap-generator-train/\">https://www.mirrorange.com/ai-beatmap-generator-train/</a></p>\n</li>\n<li><p>MuG Diffusion</p>\n</li>\n</ol>\n<p>ChoreoGraph Chart for Musical Game<br>Step Placement: When to place step<br>Step Selection: Which step to place</p>\n<p>4.音游数据<br><a href=\"https://drive.google.com/drive/folders/1J43x9f8u2lIzaHBolQaZveCv62XQM8Lv\">https://drive.google.com/drive/folders/1J43x9f8u2lIzaHBolQaZveCv62XQM8Lv</a></p>\n<p>Music library:<br><a href=\"https://soundcloud.com/openai_audio/rachmaninoff\">https://soundcloud.com/openai_audio/rachmaninoff</a></p>\n<h1 id=\"DDC-Paper-17\"><a href=\"#DDC-Paper-17\" class=\"headerlink\" title=\"DDC Paper 17\"></a>DDC Paper 17</h1><p><a href=\"https://arxiv.org/pdf/1703.06891\">https://arxiv.org/pdf/1703.06891</a></p>\n<p>MIR Music information retrival<br>onset detection:<br>tasks: (learning to choreograph)</p>\n<ol>\n<li>step placement</li>\n<li>step selection</li>\n</ol>\n<h1 id=\"GeneLive-23\"><a href=\"#GeneLive-23\" class=\"headerlink\" title=\"GeneLive 23\"></a>GeneLive 23</h1><p><a href=\"https://arxiv.org/abs/2202.12823\">https://arxiv.org/abs/2202.12823</a><br>generatiive deep learning</p>\n<p>文中提及 BiLSTM 比 Transformer也许更适合。<br>two novel techniques: beat guide, multi-sclae conv-stack</p>\n<ol>\n<li>beat guide寻找节奏型</li>\n<li></li>\n</ol>\n<h1 id=\"TaikoNation-21\"><a href=\"#TaikoNation-21\" class=\"headerlink\" title=\"TaikoNation 21:\"></a>TaikoNation 21:</h1><p><a href=\"https://arxiv.org/pdf/2107.12506\">https://arxiv.org/pdf/2107.12506</a><br>LSTM</p>\n<h1 id=\"Other-related-papers\"><a href=\"#Other-related-papers\" class=\"headerlink\" title=\"Other related papers\"></a>Other related papers</h1><h2 id=\"19-via-DL\"><a href=\"#19-via-DL\" class=\"headerlink\" title=\"19 via DL\"></a>19 via DL</h2><p><a href=\"https://inria.hal.science/hal-03652042v1/document\">https://inria.hal.science/hal-03652042v1/document</a></p>\n<h2 id=\"19-aaai-keysounded\"><a href=\"#19-aaai-keysounded\" class=\"headerlink\" title=\"19 aaai keysounded\"></a>19 aaai keysounded</h2><p><a href=\"https://arxiv.org/pdf/1806.11170\">https://arxiv.org/pdf/1806.11170</a></p>\n<h1 id=\"problems-encountered\"><a href=\"#problems-encountered\" class=\"headerlink\" title=\"problems encountered\"></a>problems encountered</h1><p>0.首先做的是关于给定t和diffculty ，生成对应的对应的（是预测下个tick 是否放置key还是预测下一个note的出现时间）</p>\n<ol>\n<li><h2 id=\"combine-of-level-and-others-可以看一下前人论文Genelive-是怎么解决的-Hetergenous-variable-in-BiLSTM-a-type-on-RNN\"><a href=\"#combine-of-level-and-others-可以看一下前人论文Genelive-是怎么解决的-Hetergenous-variable-in-BiLSTM-a-type-on-RNN\" class=\"headerlink\" title=\"combine of level and others- 可以看一下前人论文Genelive 是怎么解决的- Hetergenous variable in BiLSTM(a type on RNN)\"></a>combine of level and others<br>- 可以看一下前人论文Genelive 是怎么解决的<br>- Hetergenous variable in BiLSTM(a type on RNN)</h2></li>\n<li>time series</li>\n<li>how to pose x.</li>\n</ol>\n<p>最后实现，就是， 并没有参考任何技术，直接LSTM就上了。</p>\n<p> </p>\n"},{"title":"2025-03-08 medication","date":"2025-03-09T10:58:05.000Z","_content":"\nMedication\n\n2025-03-07\ncannot sleep the whole night\nfall sleep at 10:00 - 17:00\nHydroOXYzine 1 piece at 1:00 am and fall sleep\nhad a delivery for dinner, watch tv series, catch the rat🐀, feel less attracted to social medias and short vedios than before.\n\n2025-03-08\nsleep 1:00 - 14:00\nProzac at 15:00\nHydroOXYzine 1 piece at 22:00 \nsleep between 22:00 - 3:00 \nChilled during the time awake. Hang out with roommate at 16:00, then go exercise.\nTried to study but cannot concentrate, cannot control mind floating to other things. \nReally cannot concentrate, even when watch tv series. Less interested in phones and thinking. \n\n2025-03-09\nProzac at 6:00.\nwake up at 3;00 and cannot sleep. \nproblem with concentration and negative thoughts comes back\n\n23:00 HydroOXYzine, fall sleep at 2:00 \n\n2025-03-10\nsleep 2:00- 15:00\nProzac at 15:00\n24:00 HydroOXYzine\n\n2025-03-11\nsleep last night 22:00-24:00, 2:00 - 10:50\nProzac at 11:00\n\n懒鬼。\n","source":"_posts/2025-03-08-medication.md","raw":"---\ntitle: 2025-03-08 medication\ndate: 2025-03-09 05:58:05\ntags:\n---\n\nMedication\n\n2025-03-07\ncannot sleep the whole night\nfall sleep at 10:00 - 17:00\nHydroOXYzine 1 piece at 1:00 am and fall sleep\nhad a delivery for dinner, watch tv series, catch the rat🐀, feel less attracted to social medias and short vedios than before.\n\n2025-03-08\nsleep 1:00 - 14:00\nProzac at 15:00\nHydroOXYzine 1 piece at 22:00 \nsleep between 22:00 - 3:00 \nChilled during the time awake. Hang out with roommate at 16:00, then go exercise.\nTried to study but cannot concentrate, cannot control mind floating to other things. \nReally cannot concentrate, even when watch tv series. Less interested in phones and thinking. \n\n2025-03-09\nProzac at 6:00.\nwake up at 3;00 and cannot sleep. \nproblem with concentration and negative thoughts comes back\n\n23:00 HydroOXYzine, fall sleep at 2:00 \n\n2025-03-10\nsleep 2:00- 15:00\nProzac at 15:00\n24:00 HydroOXYzine\n\n2025-03-11\nsleep last night 22:00-24:00, 2:00 - 10:50\nProzac at 11:00\n\n懒鬼。\n","slug":"2025-03-08-medication","published":1,"updated":"2025-04-01T01:41:57.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagq1001bzc3d6sos1n0n","content":"<p>Medication</p>\n<p>2025-03-07<br>cannot sleep the whole night<br>fall sleep at 10:00 - 17:00<br>HydroOXYzine 1 piece at 1:00 am and fall sleep<br>had a delivery for dinner, watch tv series, catch the rat🐀, feel less attracted to social medias and short vedios than before.</p>\n<p>2025-03-08<br>sleep 1:00 - 14:00<br>Prozac at 15:00<br>HydroOXYzine 1 piece at 22:00<br>sleep between 22:00 - 3:00<br>Chilled during the time awake. Hang out with roommate at 16:00, then go exercise.<br>Tried to study but cannot concentrate, cannot control mind floating to other things.<br>Really cannot concentrate, even when watch tv series. Less interested in phones and thinking. </p>\n<p>2025-03-09<br>Prozac at 6:00.<br>wake up at 3;00 and cannot sleep.<br>problem with concentration and negative thoughts comes back</p>\n<p>23:00 HydroOXYzine, fall sleep at 2:00 </p>\n<p>2025-03-10<br>sleep 2:00- 15:00<br>Prozac at 15:00<br>24:00 HydroOXYzine</p>\n<p>2025-03-11<br>sleep last night 22:00-24:00, 2:00 - 10:50<br>Prozac at 11:00</p>\n<p>懒鬼。</p>\n","excerpt":"","more":"<p>Medication</p>\n<p>2025-03-07<br>cannot sleep the whole night<br>fall sleep at 10:00 - 17:00<br>HydroOXYzine 1 piece at 1:00 am and fall sleep<br>had a delivery for dinner, watch tv series, catch the rat🐀, feel less attracted to social medias and short vedios than before.</p>\n<p>2025-03-08<br>sleep 1:00 - 14:00<br>Prozac at 15:00<br>HydroOXYzine 1 piece at 22:00<br>sleep between 22:00 - 3:00<br>Chilled during the time awake. Hang out with roommate at 16:00, then go exercise.<br>Tried to study but cannot concentrate, cannot control mind floating to other things.<br>Really cannot concentrate, even when watch tv series. Less interested in phones and thinking. </p>\n<p>2025-03-09<br>Prozac at 6:00.<br>wake up at 3;00 and cannot sleep.<br>problem with concentration and negative thoughts comes back</p>\n<p>23:00 HydroOXYzine, fall sleep at 2:00 </p>\n<p>2025-03-10<br>sleep 2:00- 15:00<br>Prozac at 15:00<br>24:00 HydroOXYzine</p>\n<p>2025-03-11<br>sleep last night 22:00-24:00, 2:00 - 10:50<br>Prozac at 11:00</p>\n<p>懒鬼。</p>\n"},{"title":"3 - Internetworking","date":"2024-02-07T14:14:34.000Z","_content":"\nInternetwoking: To build global newtworks. \n\nThree main tasks of interconnecting networks.\n- same type: Switches (Bridges)\n- diff types: IP, routers\n- Computin between nodes: Routing protocols \n\n\n# 3.1 - Switching basics\n\n## Switch\n### Def \n> A switch is a multi-input, multi-output device that transfers packets from an input to one or more outputs.\". Network switches interconnect links of the same type\n### Property\n- Interconnect switch **(Scalable)**\n- connect switches to each other and to hosts using point-to-point links\n- Providing high aggregate throughput\n> Adding a new host to the network by connecting it to a switch does not necessarily reduce the performance of the network for other hosts already connected.\n### Job\n**Swithching** or **Forwarding** Accoding to **OSI(Open System Interconnceting)**\n>A switch’s primary job is to receive incoming packets on one of its links and to transmit them on some other link.\n\n## Swithcing\n### Assumption\n1. A way to identify the end nodes: **Address**, which is **gloablly unique**. e.g. MAC address in Esthernet, which is burned in the chip and is globally unique.\n2. There are ways to identify the input and output port for each switch by numbering them.\n### Datagram\nTo decide how to forward a packet, a switch consults a forwarding table (sometimes called a routing table)\n| Destination | Port |\n| ----------- | ----------- |\n|A|1|\n|B|2|\n|...|...|\n### Tyoes\nForwading types\n- Frame/packet forwarding \n- Circuit frowarding \n- Source forwarding\n\n## Frame forwading\nWhich is called Datagram networks. (without connections)\n\n## Circult forwarding\n### VC Table\nVCI: virtual circuit identifier \n| Input port | Input VCI | Out port | Out CVI|\n| ----------- | ----------- | ----------- | ----------- | \n|1|1|2|2|\n|...|...|...|...|\n- The VCI can be reused: VCI is not a globally significant identifier for the connection.\n\n### Eastablish a VC Tbale\n>Signaling: A host can send messages into the network to cause the state to be established. This is referred to as signalling, and the resulting virtual circuits are said to **be switched**.\n### Notes!\n- At least one round-trip time (RTT) of delay before data is sent to build the VC.\n- (?)Connection request contains the full address for host B, each data packet contains only a small identifier, which is only unique on one link. Thus, the per-packet overhead caused by the header is reduced relative to the datagram model. More importantly, the lookup is fast because the virtual circuit number can be treated as an index into a table rather than as a key that has to be looked up.\n\n## Comparsion btween Frame-base/ Circult-based forwarding\n![Alt text](3-Internetworking/image.png)\n\n## Source-based routing\nPath defined by the source and encoded in frame\n\n\n# 3.2 Switched Ethernet\n## Bridges\n## Spanning tree algorithm \n## Broadcast \n## VLAN\n\n\n\n\n# 3.3 Internet(IP)\n\n## Service model \n\n\n\n\n\n\n# Recap\n## link & Phys\n- 5\n## netowork\n- switches\n- IP\n- routing\n## Transport\n- demultiplexing , port-number\n\n##\n","source":"_posts/2024-02-07-3-Internetworking.md","raw":"---\ntitle: 3 - Internetworking\ndate: 2024-02-07 09:14:34\ntags:\n---\n\nInternetwoking: To build global newtworks. \n\nThree main tasks of interconnecting networks.\n- same type: Switches (Bridges)\n- diff types: IP, routers\n- Computin between nodes: Routing protocols \n\n\n# 3.1 - Switching basics\n\n## Switch\n### Def \n> A switch is a multi-input, multi-output device that transfers packets from an input to one or more outputs.\". Network switches interconnect links of the same type\n### Property\n- Interconnect switch **(Scalable)**\n- connect switches to each other and to hosts using point-to-point links\n- Providing high aggregate throughput\n> Adding a new host to the network by connecting it to a switch does not necessarily reduce the performance of the network for other hosts already connected.\n### Job\n**Swithching** or **Forwarding** Accoding to **OSI(Open System Interconnceting)**\n>A switch’s primary job is to receive incoming packets on one of its links and to transmit them on some other link.\n\n## Swithcing\n### Assumption\n1. A way to identify the end nodes: **Address**, which is **gloablly unique**. e.g. MAC address in Esthernet, which is burned in the chip and is globally unique.\n2. There are ways to identify the input and output port for each switch by numbering them.\n### Datagram\nTo decide how to forward a packet, a switch consults a forwarding table (sometimes called a routing table)\n| Destination | Port |\n| ----------- | ----------- |\n|A|1|\n|B|2|\n|...|...|\n### Tyoes\nForwading types\n- Frame/packet forwarding \n- Circuit frowarding \n- Source forwarding\n\n## Frame forwading\nWhich is called Datagram networks. (without connections)\n\n## Circult forwarding\n### VC Table\nVCI: virtual circuit identifier \n| Input port | Input VCI | Out port | Out CVI|\n| ----------- | ----------- | ----------- | ----------- | \n|1|1|2|2|\n|...|...|...|...|\n- The VCI can be reused: VCI is not a globally significant identifier for the connection.\n\n### Eastablish a VC Tbale\n>Signaling: A host can send messages into the network to cause the state to be established. This is referred to as signalling, and the resulting virtual circuits are said to **be switched**.\n### Notes!\n- At least one round-trip time (RTT) of delay before data is sent to build the VC.\n- (?)Connection request contains the full address for host B, each data packet contains only a small identifier, which is only unique on one link. Thus, the per-packet overhead caused by the header is reduced relative to the datagram model. More importantly, the lookup is fast because the virtual circuit number can be treated as an index into a table rather than as a key that has to be looked up.\n\n## Comparsion btween Frame-base/ Circult-based forwarding\n![Alt text](3-Internetworking/image.png)\n\n## Source-based routing\nPath defined by the source and encoded in frame\n\n\n# 3.2 Switched Ethernet\n## Bridges\n## Spanning tree algorithm \n## Broadcast \n## VLAN\n\n\n\n\n# 3.3 Internet(IP)\n\n## Service model \n\n\n\n\n\n\n# Recap\n## link & Phys\n- 5\n## netowork\n- switches\n- IP\n- routing\n## Transport\n- demultiplexing , port-number\n\n##\n","slug":"2024-02-07-3-Internetworking","published":1,"updated":"2024-11-13T14:46:26.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagq2001czc3dacna0z8s","content":"<p>Internetwoking: To build global newtworks. </p>\n<p>Three main tasks of interconnecting networks.</p>\n<ul>\n<li>same type: Switches (Bridges)</li>\n<li>diff types: IP, routers</li>\n<li>Computin between nodes: Routing protocols</li>\n</ul>\n<h1 id=\"3-1-Switching-basics\"><a href=\"#3-1-Switching-basics\" class=\"headerlink\" title=\"3.1 - Switching basics\"></a>3.1 - Switching basics</h1><h2 id=\"Switch\"><a href=\"#Switch\" class=\"headerlink\" title=\"Switch\"></a>Switch</h2><h3 id=\"Def\"><a href=\"#Def\" class=\"headerlink\" title=\"Def\"></a>Def</h3><blockquote>\n<p>A switch is a multi-input, multi-output device that transfers packets from an input to one or more outputs.”. Network switches interconnect links of the same type</p>\n</blockquote>\n<h3 id=\"Property\"><a href=\"#Property\" class=\"headerlink\" title=\"Property\"></a>Property</h3><ul>\n<li>Interconnect switch <strong>(Scalable)</strong></li>\n<li>connect switches to each other and to hosts using point-to-point links</li>\n<li>Providing high aggregate throughput<blockquote>\n<p>Adding a new host to the network by connecting it to a switch does not necessarily reduce the performance of the network for other hosts already connected.</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"Job\"><a href=\"#Job\" class=\"headerlink\" title=\"Job\"></a>Job</h3><p><strong>Swithching</strong> or <strong>Forwarding</strong> Accoding to <strong>OSI(Open System Interconnceting)</strong></p>\n<blockquote>\n<p>A switch’s primary job is to receive incoming packets on one of its links and to transmit them on some other link.</p>\n</blockquote>\n<h2 id=\"Swithcing\"><a href=\"#Swithcing\" class=\"headerlink\" title=\"Swithcing\"></a>Swithcing</h2><h3 id=\"Assumption\"><a href=\"#Assumption\" class=\"headerlink\" title=\"Assumption\"></a>Assumption</h3><ol>\n<li>A way to identify the end nodes: <strong>Address</strong>, which is <strong>gloablly unique</strong>. e.g. MAC address in Esthernet, which is burned in the chip and is globally unique.</li>\n<li>There are ways to identify the input and output port for each switch by numbering them.</li>\n</ol>\n<h3 id=\"Datagram\"><a href=\"#Datagram\" class=\"headerlink\" title=\"Datagram\"></a>Datagram</h3><p>To decide how to forward a packet, a switch consults a forwarding table (sometimes called a routing table)</p>\n<table>\n<thead>\n<tr>\n<th>Destination</th>\n<th>Port</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>A</td>\n<td>1</td>\n</tr>\n<tr>\n<td>B</td>\n<td>2</td>\n</tr>\n<tr>\n<td>…</td>\n<td>…</td>\n</tr>\n</tbody></table>\n<h3 id=\"Tyoes\"><a href=\"#Tyoes\" class=\"headerlink\" title=\"Tyoes\"></a>Tyoes</h3><p>Forwading types</p>\n<ul>\n<li>Frame&#x2F;packet forwarding </li>\n<li>Circuit frowarding </li>\n<li>Source forwarding</li>\n</ul>\n<h2 id=\"Frame-forwading\"><a href=\"#Frame-forwading\" class=\"headerlink\" title=\"Frame forwading\"></a>Frame forwading</h2><p>Which is called Datagram networks. (without connections)</p>\n<h2 id=\"Circult-forwarding\"><a href=\"#Circult-forwarding\" class=\"headerlink\" title=\"Circult forwarding\"></a>Circult forwarding</h2><h3 id=\"VC-Table\"><a href=\"#VC-Table\" class=\"headerlink\" title=\"VC Table\"></a>VC Table</h3><p>VCI: virtual circuit identifier </p>\n<table>\n<thead>\n<tr>\n<th>Input port</th>\n<th>Input VCI</th>\n<th>Out port</th>\n<th>Out CVI</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>1</td>\n<td>2</td>\n<td>2</td>\n</tr>\n<tr>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n</tr>\n</tbody></table>\n<ul>\n<li>The VCI can be reused: VCI is not a globally significant identifier for the connection.</li>\n</ul>\n<h3 id=\"Eastablish-a-VC-Tbale\"><a href=\"#Eastablish-a-VC-Tbale\" class=\"headerlink\" title=\"Eastablish a VC Tbale\"></a>Eastablish a VC Tbale</h3><blockquote>\n<p>Signaling: A host can send messages into the network to cause the state to be established. This is referred to as signalling, and the resulting virtual circuits are said to <strong>be switched</strong>.</p>\n</blockquote>\n<h3 id=\"Notes\"><a href=\"#Notes\" class=\"headerlink\" title=\"Notes!\"></a>Notes!</h3><ul>\n<li>At least one round-trip time (RTT) of delay before data is sent to build the VC.</li>\n<li>(?)Connection request contains the full address for host B, each data packet contains only a small identifier, which is only unique on one link. Thus, the per-packet overhead caused by the header is reduced relative to the datagram model. More importantly, the lookup is fast because the virtual circuit number can be treated as an index into a table rather than as a key that has to be looked up.</li>\n</ul>\n<h2 id=\"Comparsion-btween-Frame-base-Circult-based-forwarding\"><a href=\"#Comparsion-btween-Frame-base-Circult-based-forwarding\" class=\"headerlink\" title=\"Comparsion btween Frame-base&#x2F; Circult-based forwarding\"></a>Comparsion btween Frame-base&#x2F; Circult-based forwarding</h2><p><img src=\"/3-Internetworking/image.png\" alt=\"Alt text\"></p>\n<h2 id=\"Source-based-routing\"><a href=\"#Source-based-routing\" class=\"headerlink\" title=\"Source-based routing\"></a>Source-based routing</h2><p>Path defined by the source and encoded in frame</p>\n<h1 id=\"3-2-Switched-Ethernet\"><a href=\"#3-2-Switched-Ethernet\" class=\"headerlink\" title=\"3.2 Switched Ethernet\"></a>3.2 Switched Ethernet</h1><h2 id=\"Bridges\"><a href=\"#Bridges\" class=\"headerlink\" title=\"Bridges\"></a>Bridges</h2><h2 id=\"Spanning-tree-algorithm\"><a href=\"#Spanning-tree-algorithm\" class=\"headerlink\" title=\"Spanning tree algorithm\"></a>Spanning tree algorithm</h2><h2 id=\"Broadcast\"><a href=\"#Broadcast\" class=\"headerlink\" title=\"Broadcast\"></a>Broadcast</h2><h2 id=\"VLAN\"><a href=\"#VLAN\" class=\"headerlink\" title=\"VLAN\"></a>VLAN</h2><h1 id=\"3-3-Internet-IP\"><a href=\"#3-3-Internet-IP\" class=\"headerlink\" title=\"3.3 Internet(IP)\"></a>3.3 Internet(IP)</h1><h2 id=\"Service-model\"><a href=\"#Service-model\" class=\"headerlink\" title=\"Service model\"></a>Service model</h2><h1 id=\"Recap\"><a href=\"#Recap\" class=\"headerlink\" title=\"Recap\"></a>Recap</h1><h2 id=\"link-Phys\"><a href=\"#link-Phys\" class=\"headerlink\" title=\"link &amp; Phys\"></a>link &amp; Phys</h2><ul>\n<li>5</li>\n</ul>\n<h2 id=\"netowork\"><a href=\"#netowork\" class=\"headerlink\" title=\"netowork\"></a>netowork</h2><ul>\n<li>switches</li>\n<li>IP</li>\n<li>routing</li>\n</ul>\n<h2 id=\"Transport\"><a href=\"#Transport\" class=\"headerlink\" title=\"Transport\"></a>Transport</h2><ul>\n<li>demultiplexing , port-number</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>","excerpt":"","more":"<p>Internetwoking: To build global newtworks. </p>\n<p>Three main tasks of interconnecting networks.</p>\n<ul>\n<li>same type: Switches (Bridges)</li>\n<li>diff types: IP, routers</li>\n<li>Computin between nodes: Routing protocols</li>\n</ul>\n<h1 id=\"3-1-Switching-basics\"><a href=\"#3-1-Switching-basics\" class=\"headerlink\" title=\"3.1 - Switching basics\"></a>3.1 - Switching basics</h1><h2 id=\"Switch\"><a href=\"#Switch\" class=\"headerlink\" title=\"Switch\"></a>Switch</h2><h3 id=\"Def\"><a href=\"#Def\" class=\"headerlink\" title=\"Def\"></a>Def</h3><blockquote>\n<p>A switch is a multi-input, multi-output device that transfers packets from an input to one or more outputs.”. Network switches interconnect links of the same type</p>\n</blockquote>\n<h3 id=\"Property\"><a href=\"#Property\" class=\"headerlink\" title=\"Property\"></a>Property</h3><ul>\n<li>Interconnect switch <strong>(Scalable)</strong></li>\n<li>connect switches to each other and to hosts using point-to-point links</li>\n<li>Providing high aggregate throughput<blockquote>\n<p>Adding a new host to the network by connecting it to a switch does not necessarily reduce the performance of the network for other hosts already connected.</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"Job\"><a href=\"#Job\" class=\"headerlink\" title=\"Job\"></a>Job</h3><p><strong>Swithching</strong> or <strong>Forwarding</strong> Accoding to <strong>OSI(Open System Interconnceting)</strong></p>\n<blockquote>\n<p>A switch’s primary job is to receive incoming packets on one of its links and to transmit them on some other link.</p>\n</blockquote>\n<h2 id=\"Swithcing\"><a href=\"#Swithcing\" class=\"headerlink\" title=\"Swithcing\"></a>Swithcing</h2><h3 id=\"Assumption\"><a href=\"#Assumption\" class=\"headerlink\" title=\"Assumption\"></a>Assumption</h3><ol>\n<li>A way to identify the end nodes: <strong>Address</strong>, which is <strong>gloablly unique</strong>. e.g. MAC address in Esthernet, which is burned in the chip and is globally unique.</li>\n<li>There are ways to identify the input and output port for each switch by numbering them.</li>\n</ol>\n<h3 id=\"Datagram\"><a href=\"#Datagram\" class=\"headerlink\" title=\"Datagram\"></a>Datagram</h3><p>To decide how to forward a packet, a switch consults a forwarding table (sometimes called a routing table)</p>\n<table>\n<thead>\n<tr>\n<th>Destination</th>\n<th>Port</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>A</td>\n<td>1</td>\n</tr>\n<tr>\n<td>B</td>\n<td>2</td>\n</tr>\n<tr>\n<td>…</td>\n<td>…</td>\n</tr>\n</tbody></table>\n<h3 id=\"Tyoes\"><a href=\"#Tyoes\" class=\"headerlink\" title=\"Tyoes\"></a>Tyoes</h3><p>Forwading types</p>\n<ul>\n<li>Frame&#x2F;packet forwarding </li>\n<li>Circuit frowarding </li>\n<li>Source forwarding</li>\n</ul>\n<h2 id=\"Frame-forwading\"><a href=\"#Frame-forwading\" class=\"headerlink\" title=\"Frame forwading\"></a>Frame forwading</h2><p>Which is called Datagram networks. (without connections)</p>\n<h2 id=\"Circult-forwarding\"><a href=\"#Circult-forwarding\" class=\"headerlink\" title=\"Circult forwarding\"></a>Circult forwarding</h2><h3 id=\"VC-Table\"><a href=\"#VC-Table\" class=\"headerlink\" title=\"VC Table\"></a>VC Table</h3><p>VCI: virtual circuit identifier </p>\n<table>\n<thead>\n<tr>\n<th>Input port</th>\n<th>Input VCI</th>\n<th>Out port</th>\n<th>Out CVI</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>1</td>\n<td>2</td>\n<td>2</td>\n</tr>\n<tr>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n</tr>\n</tbody></table>\n<ul>\n<li>The VCI can be reused: VCI is not a globally significant identifier for the connection.</li>\n</ul>\n<h3 id=\"Eastablish-a-VC-Tbale\"><a href=\"#Eastablish-a-VC-Tbale\" class=\"headerlink\" title=\"Eastablish a VC Tbale\"></a>Eastablish a VC Tbale</h3><blockquote>\n<p>Signaling: A host can send messages into the network to cause the state to be established. This is referred to as signalling, and the resulting virtual circuits are said to <strong>be switched</strong>.</p>\n</blockquote>\n<h3 id=\"Notes\"><a href=\"#Notes\" class=\"headerlink\" title=\"Notes!\"></a>Notes!</h3><ul>\n<li>At least one round-trip time (RTT) of delay before data is sent to build the VC.</li>\n<li>(?)Connection request contains the full address for host B, each data packet contains only a small identifier, which is only unique on one link. Thus, the per-packet overhead caused by the header is reduced relative to the datagram model. More importantly, the lookup is fast because the virtual circuit number can be treated as an index into a table rather than as a key that has to be looked up.</li>\n</ul>\n<h2 id=\"Comparsion-btween-Frame-base-Circult-based-forwarding\"><a href=\"#Comparsion-btween-Frame-base-Circult-based-forwarding\" class=\"headerlink\" title=\"Comparsion btween Frame-base&#x2F; Circult-based forwarding\"></a>Comparsion btween Frame-base&#x2F; Circult-based forwarding</h2><p><img src=\"/3-Internetworking/image.png\" alt=\"Alt text\"></p>\n<h2 id=\"Source-based-routing\"><a href=\"#Source-based-routing\" class=\"headerlink\" title=\"Source-based routing\"></a>Source-based routing</h2><p>Path defined by the source and encoded in frame</p>\n<h1 id=\"3-2-Switched-Ethernet\"><a href=\"#3-2-Switched-Ethernet\" class=\"headerlink\" title=\"3.2 Switched Ethernet\"></a>3.2 Switched Ethernet</h1><h2 id=\"Bridges\"><a href=\"#Bridges\" class=\"headerlink\" title=\"Bridges\"></a>Bridges</h2><h2 id=\"Spanning-tree-algorithm\"><a href=\"#Spanning-tree-algorithm\" class=\"headerlink\" title=\"Spanning tree algorithm\"></a>Spanning tree algorithm</h2><h2 id=\"Broadcast\"><a href=\"#Broadcast\" class=\"headerlink\" title=\"Broadcast\"></a>Broadcast</h2><h2 id=\"VLAN\"><a href=\"#VLAN\" class=\"headerlink\" title=\"VLAN\"></a>VLAN</h2><h1 id=\"3-3-Internet-IP\"><a href=\"#3-3-Internet-IP\" class=\"headerlink\" title=\"3.3 Internet(IP)\"></a>3.3 Internet(IP)</h1><h2 id=\"Service-model\"><a href=\"#Service-model\" class=\"headerlink\" title=\"Service model\"></a>Service model</h2><h1 id=\"Recap\"><a href=\"#Recap\" class=\"headerlink\" title=\"Recap\"></a>Recap</h1><h2 id=\"link-Phys\"><a href=\"#link-Phys\" class=\"headerlink\" title=\"link &amp; Phys\"></a>link &amp; Phys</h2><ul>\n<li>5</li>\n</ul>\n<h2 id=\"netowork\"><a href=\"#netowork\" class=\"headerlink\" title=\"netowork\"></a>netowork</h2><ul>\n<li>switches</li>\n<li>IP</li>\n<li>routing</li>\n</ul>\n<h2 id=\"Transport\"><a href=\"#Transport\" class=\"headerlink\" title=\"Transport\"></a>Transport</h2><ul>\n<li>demultiplexing , port-number</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>"},{"title":"2024-09-08 Interesting music repo","date":"2024-09-09T02:07:44.000Z","_content":"\n不知道为啥就是不好渲染的一篇\n ?\n Counterpoint\n\n- [GitHub - Counterpoint](https://github.com/ave-llan/counterpoint)\n- [Counterpoint Guide](https://github.com/ave-llan/counterpoint-guide)\n\n- [Counterpoint by Convolution](https://coconets.github.io/)\n\n Chords\n- [Autochord](https://github.com/cjbayron/autochord)\n\n crx 陈文戈\n- [ChordNova](https://github.com/Chen-and-Sim/ChordNova)\n\n xy 鲜远\n- [XY Gangqin](https://www.xygangqin.com/)\n\n wly 王乐游\n- [Biography of Wang Leyou](https://www.wangleyou.net/zh/biography)\n- [Homepage Music Links](http://homepage.eircom.net/~gerfmcc/links.html)\n\n Tools\n\n Chord Calculator\n- [Music Theory Tools](https://www.musictheory.net/tools)\n\n 音乐排版\n- [音乐排版工具](https://blog.twofei.com/1425/)\n\n 调性和声笔记\n陈文戈老师《和声学捷径》\n- [Bilibili 视频](https://www.bilibili.com/video/BV1GY411W7GL)\n\n 调性和声基础\n 1.1 七级音分属三功能\n- Tonic: $T = \\{1\\}$\n- Dominant: $D = \\{5, 3, 7\\}$\n- Subdominant: $S = \\{4, 2, 6\\}$\n\n 1.2 自然音体系遍历\n- $\\{3, 6, 46, 7, 56, 34, 24, 9, 7-13, \\text{sub6}\\}$\n\n 1.3 离调，连锁，模进\n Main / Auxiliary 主/副调\n- 主 key of C: $C - Em$ \\\n- $C^7$ (副属七) / $E^{\\circ 7}$ (副导) \\\n- key of F: $Fm - D^{b} - Bm^{b}$ \\\n- $D^7$ (副属) / $F^{\\ \\circ 7}$ (副导)\n\n Strict / Free Sequence\n连锁进行：\n- 沿着五度圈进行，例如属七导七。\n\n和声模进：\n- **严格模进**：严格遵循音程变化。\n- **自由模进**：不严格遵循音程。\n\n 1.4 阻碍进行/离调阻碍\n阻碍进行 Deceptive progression\n离调阻碍 Tonicization + Deceptive progression\n\n 1.5 音阶借用/调式交替\n- **音阶借用**：如 $Fm, 6^{b}$\n- **调式交替**：平行大小调、同主音调等。\n\n 1.6 和弦外音\n\n1. 延留音 Suspension $+$ \n2. 经过音 Passing note $\\times$ / 辅助音 Auxiliary $\\bigtriangleup$\n3. 先现音 Anticipation $\\Box$ / 持续音 Pedal Point $\\text{P}$  \n\n 对位写作\n\n 四部和声写作\n\n Cadence\n\n Perfect Authentic Cadence (PAC)\n- $5^{(7)}-1$: 需满足 5 和 1 都是根音位置，1 的最高音是主音。\n\n Imperfect Authentic Cadence (IAC)\n- $5^{(7)}-1$: 根音或最高音位置不严格。\n\n Half Cadence (HC)\n- 1, 2, 4 - 5 的结束语。\n\n Plagal Cadence (Pl.C.)\n- 4 - 1，常用于教堂音乐。\n","source":"_posts/2024-09-08-Interesting-music-repo.md","raw":"---\ntitle: \"2024-09-08 Interesting music repo\"\ndate: 2024-09-08 22:07:44\ntags:\n  - music\n  - tools\n---\n\n不知道为啥就是不好渲染的一篇\n ?\n Counterpoint\n\n- [GitHub - Counterpoint](https://github.com/ave-llan/counterpoint)\n- [Counterpoint Guide](https://github.com/ave-llan/counterpoint-guide)\n\n- [Counterpoint by Convolution](https://coconets.github.io/)\n\n Chords\n- [Autochord](https://github.com/cjbayron/autochord)\n\n crx 陈文戈\n- [ChordNova](https://github.com/Chen-and-Sim/ChordNova)\n\n xy 鲜远\n- [XY Gangqin](https://www.xygangqin.com/)\n\n wly 王乐游\n- [Biography of Wang Leyou](https://www.wangleyou.net/zh/biography)\n- [Homepage Music Links](http://homepage.eircom.net/~gerfmcc/links.html)\n\n Tools\n\n Chord Calculator\n- [Music Theory Tools](https://www.musictheory.net/tools)\n\n 音乐排版\n- [音乐排版工具](https://blog.twofei.com/1425/)\n\n 调性和声笔记\n陈文戈老师《和声学捷径》\n- [Bilibili 视频](https://www.bilibili.com/video/BV1GY411W7GL)\n\n 调性和声基础\n 1.1 七级音分属三功能\n- Tonic: $T = \\{1\\}$\n- Dominant: $D = \\{5, 3, 7\\}$\n- Subdominant: $S = \\{4, 2, 6\\}$\n\n 1.2 自然音体系遍历\n- $\\{3, 6, 46, 7, 56, 34, 24, 9, 7-13, \\text{sub6}\\}$\n\n 1.3 离调，连锁，模进\n Main / Auxiliary 主/副调\n- 主 key of C: $C - Em$ \\\n- $C^7$ (副属七) / $E^{\\circ 7}$ (副导) \\\n- key of F: $Fm - D^{b} - Bm^{b}$ \\\n- $D^7$ (副属) / $F^{\\ \\circ 7}$ (副导)\n\n Strict / Free Sequence\n连锁进行：\n- 沿着五度圈进行，例如属七导七。\n\n和声模进：\n- **严格模进**：严格遵循音程变化。\n- **自由模进**：不严格遵循音程。\n\n 1.4 阻碍进行/离调阻碍\n阻碍进行 Deceptive progression\n离调阻碍 Tonicization + Deceptive progression\n\n 1.5 音阶借用/调式交替\n- **音阶借用**：如 $Fm, 6^{b}$\n- **调式交替**：平行大小调、同主音调等。\n\n 1.6 和弦外音\n\n1. 延留音 Suspension $+$ \n2. 经过音 Passing note $\\times$ / 辅助音 Auxiliary $\\bigtriangleup$\n3. 先现音 Anticipation $\\Box$ / 持续音 Pedal Point $\\text{P}$  \n\n 对位写作\n\n 四部和声写作\n\n Cadence\n\n Perfect Authentic Cadence (PAC)\n- $5^{(7)}-1$: 需满足 5 和 1 都是根音位置，1 的最高音是主音。\n\n Imperfect Authentic Cadence (IAC)\n- $5^{(7)}-1$: 根音或最高音位置不严格。\n\n Half Cadence (HC)\n- 1, 2, 4 - 5 的结束语。\n\n Plagal Cadence (Pl.C.)\n- 4 - 1，常用于教堂音乐。\n","slug":"2024-09-08-Interesting-music-repo","published":1,"updated":"2024-12-15T03:51:24.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsh001dzc3d8u1l9o7c","content":"<p>不知道为啥就是不好渲染的一篇<br> ?<br> Counterpoint</p>\n<ul>\n<li><p><a href=\"https://github.com/ave-llan/counterpoint\">GitHub - Counterpoint</a></p>\n</li>\n<li><p><a href=\"https://github.com/ave-llan/counterpoint-guide\">Counterpoint Guide</a></p>\n</li>\n<li><p><a href=\"https://coconets.github.io/\">Counterpoint by Convolution</a></p>\n</li>\n</ul>\n<p> Chords</p>\n<ul>\n<li><a href=\"https://github.com/cjbayron/autochord\">Autochord</a></li>\n</ul>\n<p> crx 陈文戈</p>\n<ul>\n<li><a href=\"https://github.com/Chen-and-Sim/ChordNova\">ChordNova</a></li>\n</ul>\n<p> xy 鲜远</p>\n<ul>\n<li><a href=\"https://www.xygangqin.com/\">XY Gangqin</a></li>\n</ul>\n<p> wly 王乐游</p>\n<ul>\n<li><a href=\"https://www.wangleyou.net/zh/biography\">Biography of Wang Leyou</a></li>\n<li><a href=\"http://homepage.eircom.net/~gerfmcc/links.html\">Homepage Music Links</a></li>\n</ul>\n<p> Tools</p>\n<p> Chord Calculator</p>\n<ul>\n<li><a href=\"https://www.musictheory.net/tools\">Music Theory Tools</a></li>\n</ul>\n<p> 音乐排版</p>\n<ul>\n<li><a href=\"https://blog.twofei.com/1425/\">音乐排版工具</a></li>\n</ul>\n<p> 调性和声笔记<br>陈文戈老师《和声学捷径》</p>\n<ul>\n<li><a href=\"https://www.bilibili.com/video/BV1GY411W7GL\">Bilibili 视频</a></li>\n</ul>\n<p> 调性和声基础<br> 1.1 七级音分属三功能</p>\n<ul>\n<li>Tonic: $T &#x3D; {1}$</li>\n<li>Dominant: $D &#x3D; {5, 3, 7}$</li>\n<li>Subdominant: $S &#x3D; {4, 2, 6}$</li>\n</ul>\n<p> 1.2 自然音体系遍历</p>\n<ul>\n<li>${3, 6, 46, 7, 56, 34, 24, 9, 7-13, \\text{sub6}}$</li>\n</ul>\n<p> 1.3 离调，连锁，模进<br> Main &#x2F; Auxiliary 主&#x2F;副调</p>\n<ul>\n<li>主 key of C: $C - Em$ \\</li>\n<li>$C^7$ (副属七) &#x2F; $E^{\\circ 7}$ (副导) \\</li>\n<li>key of F: $Fm - D^{b} - Bm^{b}$ \\</li>\n<li>$D^7$ (副属) &#x2F; $F^{\\ \\circ 7}$ (副导)</li>\n</ul>\n<p> Strict &#x2F; Free Sequence<br>连锁进行：</p>\n<ul>\n<li>沿着五度圈进行，例如属七导七。</li>\n</ul>\n<p>和声模进：</p>\n<ul>\n<li><strong>严格模进</strong>：严格遵循音程变化。</li>\n<li><strong>自由模进</strong>：不严格遵循音程。</li>\n</ul>\n<p> 1.4 阻碍进行&#x2F;离调阻碍<br>阻碍进行 Deceptive progression<br>离调阻碍 Tonicization + Deceptive progression</p>\n<p> 1.5 音阶借用&#x2F;调式交替</p>\n<ul>\n<li><strong>音阶借用</strong>：如 $Fm, 6^{b}$</li>\n<li><strong>调式交替</strong>：平行大小调、同主音调等。</li>\n</ul>\n<p> 1.6 和弦外音</p>\n<ol>\n<li>延留音 Suspension $+$ </li>\n<li>经过音 Passing note $\\times$ &#x2F; 辅助音 Auxiliary $\\bigtriangleup$</li>\n<li>先现音 Anticipation $\\Box$ &#x2F; 持续音 Pedal Point $\\text{P}$</li>\n</ol>\n<p> 对位写作</p>\n<p> 四部和声写作</p>\n<p> Cadence</p>\n<p> Perfect Authentic Cadence (PAC)</p>\n<ul>\n<li>$5^{(7)}-1$: 需满足 5 和 1 都是根音位置，1 的最高音是主音。</li>\n</ul>\n<p> Imperfect Authentic Cadence (IAC)</p>\n<ul>\n<li>$5^{(7)}-1$: 根音或最高音位置不严格。</li>\n</ul>\n<p> Half Cadence (HC)</p>\n<ul>\n<li>1, 2, 4 - 5 的结束语。</li>\n</ul>\n<p> Plagal Cadence (Pl.C.)</p>\n<ul>\n<li>4 - 1，常用于教堂音乐。</li>\n</ul>\n","excerpt":"","more":"<p>不知道为啥就是不好渲染的一篇<br> ?<br> Counterpoint</p>\n<ul>\n<li><p><a href=\"https://github.com/ave-llan/counterpoint\">GitHub - Counterpoint</a></p>\n</li>\n<li><p><a href=\"https://github.com/ave-llan/counterpoint-guide\">Counterpoint Guide</a></p>\n</li>\n<li><p><a href=\"https://coconets.github.io/\">Counterpoint by Convolution</a></p>\n</li>\n</ul>\n<p> Chords</p>\n<ul>\n<li><a href=\"https://github.com/cjbayron/autochord\">Autochord</a></li>\n</ul>\n<p> crx 陈文戈</p>\n<ul>\n<li><a href=\"https://github.com/Chen-and-Sim/ChordNova\">ChordNova</a></li>\n</ul>\n<p> xy 鲜远</p>\n<ul>\n<li><a href=\"https://www.xygangqin.com/\">XY Gangqin</a></li>\n</ul>\n<p> wly 王乐游</p>\n<ul>\n<li><a href=\"https://www.wangleyou.net/zh/biography\">Biography of Wang Leyou</a></li>\n<li><a href=\"http://homepage.eircom.net/~gerfmcc/links.html\">Homepage Music Links</a></li>\n</ul>\n<p> Tools</p>\n<p> Chord Calculator</p>\n<ul>\n<li><a href=\"https://www.musictheory.net/tools\">Music Theory Tools</a></li>\n</ul>\n<p> 音乐排版</p>\n<ul>\n<li><a href=\"https://blog.twofei.com/1425/\">音乐排版工具</a></li>\n</ul>\n<p> 调性和声笔记<br>陈文戈老师《和声学捷径》</p>\n<ul>\n<li><a href=\"https://www.bilibili.com/video/BV1GY411W7GL\">Bilibili 视频</a></li>\n</ul>\n<p> 调性和声基础<br> 1.1 七级音分属三功能</p>\n<ul>\n<li>Tonic: $T &#x3D; {1}$</li>\n<li>Dominant: $D &#x3D; {5, 3, 7}$</li>\n<li>Subdominant: $S &#x3D; {4, 2, 6}$</li>\n</ul>\n<p> 1.2 自然音体系遍历</p>\n<ul>\n<li>${3, 6, 46, 7, 56, 34, 24, 9, 7-13, \\text{sub6}}$</li>\n</ul>\n<p> 1.3 离调，连锁，模进<br> Main &#x2F; Auxiliary 主&#x2F;副调</p>\n<ul>\n<li>主 key of C: $C - Em$ \\</li>\n<li>$C^7$ (副属七) &#x2F; $E^{\\circ 7}$ (副导) \\</li>\n<li>key of F: $Fm - D^{b} - Bm^{b}$ \\</li>\n<li>$D^7$ (副属) &#x2F; $F^{\\ \\circ 7}$ (副导)</li>\n</ul>\n<p> Strict &#x2F; Free Sequence<br>连锁进行：</p>\n<ul>\n<li>沿着五度圈进行，例如属七导七。</li>\n</ul>\n<p>和声模进：</p>\n<ul>\n<li><strong>严格模进</strong>：严格遵循音程变化。</li>\n<li><strong>自由模进</strong>：不严格遵循音程。</li>\n</ul>\n<p> 1.4 阻碍进行&#x2F;离调阻碍<br>阻碍进行 Deceptive progression<br>离调阻碍 Tonicization + Deceptive progression</p>\n<p> 1.5 音阶借用&#x2F;调式交替</p>\n<ul>\n<li><strong>音阶借用</strong>：如 $Fm, 6^{b}$</li>\n<li><strong>调式交替</strong>：平行大小调、同主音调等。</li>\n</ul>\n<p> 1.6 和弦外音</p>\n<ol>\n<li>延留音 Suspension $+$ </li>\n<li>经过音 Passing note $\\times$ &#x2F; 辅助音 Auxiliary $\\bigtriangleup$</li>\n<li>先现音 Anticipation $\\Box$ &#x2F; 持续音 Pedal Point $\\text{P}$</li>\n</ol>\n<p> 对位写作</p>\n<p> 四部和声写作</p>\n<p> Cadence</p>\n<p> Perfect Authentic Cadence (PAC)</p>\n<ul>\n<li>$5^{(7)}-1$: 需满足 5 和 1 都是根音位置，1 的最高音是主音。</li>\n</ul>\n<p> Imperfect Authentic Cadence (IAC)</p>\n<ul>\n<li>$5^{(7)}-1$: 根音或最高音位置不严格。</li>\n</ul>\n<p> Half Cadence (HC)</p>\n<ul>\n<li>1, 2, 4 - 5 的结束语。</li>\n</ul>\n<p> Plagal Cadence (Pl.C.)</p>\n<ul>\n<li>4 - 1，常用于教堂音乐。</li>\n</ul>\n"},{"title":"Transport layer","date":"2024-02-07T15:55:06.000Z","_content":"\n# 3c internectworking\n\n## Service model\nno guarantees\n\n## IP packet header\n\n## Fragmentation\nExamples with detail\n\n\n## Addressing\n### IP Address properties\n### 4 class\n### Subnets/CIDR\n\n## packet forwarding\n### IP forward algorithm\n### Routin tables\n\n## Address translation\n## ARP Adression Resolution Protocol\n\n## Node autoconfiguration\n### DHCP\ndynamic host configuration ptcl\n\n\n## Error Reporting\n### ICMP Internet Control messsage protocol\n### MTU Discovery\n\n# 3d Routing\n## Forwarding(One path) vs Routing(Mutiple path)\n## Distance Vector protocol: Bellman_ford\n## Link-state protocol\neach router teel all the otehr routers about its link\n## Reliable flooding (LSP)\nlink metrics\n## Interdomain routing - definition\n### BGP\n### ASs\nBGP between ASs: compute gglobal policy-compliant routers\nOSPF in an AS: compute shortest routes between routers\n\n\n# 4a Transport\n## Recap\nIntra-domain protocols\n- Lowest cost shortest protocol/ disseminate full information about the topology\n- Distance vector protocol(RIPv2)\n- link state pctl: OSPF\n\nInter-domainprotocol (BGP)\n- most preffeered policy-compliant route\n- information hiding for scalability and secrecy\n\n## UDP \nwell known ports\nchoosing ports\n\n## TCP\n### byte stram abstraction\nsegment format\n### three handshake\n### flow controlslly window synfrome\n### Nagels' algorithm\n\n\n\n\n# 4b RPC- RTP\n## RPC Remote procedure call\ngRPC: stubs, request and responses\nAcknowledge models\nSyn, Asyn ptcls\nMessage and encoding\n### Data transmission in real time\nRead- time data transmission (RTP)\nStram transmission ptcl\n\n\n\n# 4c src and congestion \n## Traffic flows\nTaxonomy of congestion flow\nRED\n## Congestion control\n## \n","source":"_posts/2024-02-07-Transport-layer.md","raw":"---\ntitle: Transport layer\ndate: 2024-02-07 10:55:06\ntags:\n---\n\n# 3c internectworking\n\n## Service model\nno guarantees\n\n## IP packet header\n\n## Fragmentation\nExamples with detail\n\n\n## Addressing\n### IP Address properties\n### 4 class\n### Subnets/CIDR\n\n## packet forwarding\n### IP forward algorithm\n### Routin tables\n\n## Address translation\n## ARP Adression Resolution Protocol\n\n## Node autoconfiguration\n### DHCP\ndynamic host configuration ptcl\n\n\n## Error Reporting\n### ICMP Internet Control messsage protocol\n### MTU Discovery\n\n# 3d Routing\n## Forwarding(One path) vs Routing(Mutiple path)\n## Distance Vector protocol: Bellman_ford\n## Link-state protocol\neach router teel all the otehr routers about its link\n## Reliable flooding (LSP)\nlink metrics\n## Interdomain routing - definition\n### BGP\n### ASs\nBGP between ASs: compute gglobal policy-compliant routers\nOSPF in an AS: compute shortest routes between routers\n\n\n# 4a Transport\n## Recap\nIntra-domain protocols\n- Lowest cost shortest protocol/ disseminate full information about the topology\n- Distance vector protocol(RIPv2)\n- link state pctl: OSPF\n\nInter-domainprotocol (BGP)\n- most preffeered policy-compliant route\n- information hiding for scalability and secrecy\n\n## UDP \nwell known ports\nchoosing ports\n\n## TCP\n### byte stram abstraction\nsegment format\n### three handshake\n### flow controlslly window synfrome\n### Nagels' algorithm\n\n\n\n\n# 4b RPC- RTP\n## RPC Remote procedure call\ngRPC: stubs, request and responses\nAcknowledge models\nSyn, Asyn ptcls\nMessage and encoding\n### Data transmission in real time\nRead- time data transmission (RTP)\nStram transmission ptcl\n\n\n\n# 4c src and congestion \n## Traffic flows\nTaxonomy of congestion flow\nRED\n## Congestion control\n## \n","slug":"2024-02-07-Transport-layer","published":1,"updated":"2024-11-13T14:46:26.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagst001izc3da1gq4ho9","content":"<h1 id=\"3c-internectworking\"><a href=\"#3c-internectworking\" class=\"headerlink\" title=\"3c internectworking\"></a>3c internectworking</h1><h2 id=\"Service-model\"><a href=\"#Service-model\" class=\"headerlink\" title=\"Service model\"></a>Service model</h2><p>no guarantees</p>\n<h2 id=\"IP-packet-header\"><a href=\"#IP-packet-header\" class=\"headerlink\" title=\"IP packet header\"></a>IP packet header</h2><h2 id=\"Fragmentation\"><a href=\"#Fragmentation\" class=\"headerlink\" title=\"Fragmentation\"></a>Fragmentation</h2><p>Examples with detail</p>\n<h2 id=\"Addressing\"><a href=\"#Addressing\" class=\"headerlink\" title=\"Addressing\"></a>Addressing</h2><h3 id=\"IP-Address-properties\"><a href=\"#IP-Address-properties\" class=\"headerlink\" title=\"IP Address properties\"></a>IP Address properties</h3><h3 id=\"4-class\"><a href=\"#4-class\" class=\"headerlink\" title=\"4 class\"></a>4 class</h3><h3 id=\"Subnets-CIDR\"><a href=\"#Subnets-CIDR\" class=\"headerlink\" title=\"Subnets&#x2F;CIDR\"></a>Subnets&#x2F;CIDR</h3><h2 id=\"packet-forwarding\"><a href=\"#packet-forwarding\" class=\"headerlink\" title=\"packet forwarding\"></a>packet forwarding</h2><h3 id=\"IP-forward-algorithm\"><a href=\"#IP-forward-algorithm\" class=\"headerlink\" title=\"IP forward algorithm\"></a>IP forward algorithm</h3><h3 id=\"Routin-tables\"><a href=\"#Routin-tables\" class=\"headerlink\" title=\"Routin tables\"></a>Routin tables</h3><h2 id=\"Address-translation\"><a href=\"#Address-translation\" class=\"headerlink\" title=\"Address translation\"></a>Address translation</h2><h2 id=\"ARP-Adression-Resolution-Protocol\"><a href=\"#ARP-Adression-Resolution-Protocol\" class=\"headerlink\" title=\"ARP Adression Resolution Protocol\"></a>ARP Adression Resolution Protocol</h2><h2 id=\"Node-autoconfiguration\"><a href=\"#Node-autoconfiguration\" class=\"headerlink\" title=\"Node autoconfiguration\"></a>Node autoconfiguration</h2><h3 id=\"DHCP\"><a href=\"#DHCP\" class=\"headerlink\" title=\"DHCP\"></a>DHCP</h3><p>dynamic host configuration ptcl</p>\n<h2 id=\"Error-Reporting\"><a href=\"#Error-Reporting\" class=\"headerlink\" title=\"Error Reporting\"></a>Error Reporting</h2><h3 id=\"ICMP-Internet-Control-messsage-protocol\"><a href=\"#ICMP-Internet-Control-messsage-protocol\" class=\"headerlink\" title=\"ICMP Internet Control messsage protocol\"></a>ICMP Internet Control messsage protocol</h3><h3 id=\"MTU-Discovery\"><a href=\"#MTU-Discovery\" class=\"headerlink\" title=\"MTU Discovery\"></a>MTU Discovery</h3><h1 id=\"3d-Routing\"><a href=\"#3d-Routing\" class=\"headerlink\" title=\"3d Routing\"></a>3d Routing</h1><h2 id=\"Forwarding-One-path-vs-Routing-Mutiple-path\"><a href=\"#Forwarding-One-path-vs-Routing-Mutiple-path\" class=\"headerlink\" title=\"Forwarding(One path) vs Routing(Mutiple path)\"></a>Forwarding(One path) vs Routing(Mutiple path)</h2><h2 id=\"Distance-Vector-protocol-Bellman-ford\"><a href=\"#Distance-Vector-protocol-Bellman-ford\" class=\"headerlink\" title=\"Distance Vector protocol: Bellman_ford\"></a>Distance Vector protocol: Bellman_ford</h2><h2 id=\"Link-state-protocol\"><a href=\"#Link-state-protocol\" class=\"headerlink\" title=\"Link-state protocol\"></a>Link-state protocol</h2><p>each router teel all the otehr routers about its link</p>\n<h2 id=\"Reliable-flooding-LSP\"><a href=\"#Reliable-flooding-LSP\" class=\"headerlink\" title=\"Reliable flooding (LSP)\"></a>Reliable flooding (LSP)</h2><p>link metrics</p>\n<h2 id=\"Interdomain-routing-definition\"><a href=\"#Interdomain-routing-definition\" class=\"headerlink\" title=\"Interdomain routing - definition\"></a>Interdomain routing - definition</h2><h3 id=\"BGP\"><a href=\"#BGP\" class=\"headerlink\" title=\"BGP\"></a>BGP</h3><h3 id=\"ASs\"><a href=\"#ASs\" class=\"headerlink\" title=\"ASs\"></a>ASs</h3><p>BGP between ASs: compute gglobal policy-compliant routers<br>OSPF in an AS: compute shortest routes between routers</p>\n<h1 id=\"4a-Transport\"><a href=\"#4a-Transport\" class=\"headerlink\" title=\"4a Transport\"></a>4a Transport</h1><h2 id=\"Recap\"><a href=\"#Recap\" class=\"headerlink\" title=\"Recap\"></a>Recap</h2><p>Intra-domain protocols</p>\n<ul>\n<li>Lowest cost shortest protocol&#x2F; disseminate full information about the topology</li>\n<li>Distance vector protocol(RIPv2)</li>\n<li>link state pctl: OSPF</li>\n</ul>\n<p>Inter-domainprotocol (BGP)</p>\n<ul>\n<li>most preffeered policy-compliant route</li>\n<li>information hiding for scalability and secrecy</li>\n</ul>\n<h2 id=\"UDP\"><a href=\"#UDP\" class=\"headerlink\" title=\"UDP\"></a>UDP</h2><p>well known ports<br>choosing ports</p>\n<h2 id=\"TCP\"><a href=\"#TCP\" class=\"headerlink\" title=\"TCP\"></a>TCP</h2><h3 id=\"byte-stram-abstraction\"><a href=\"#byte-stram-abstraction\" class=\"headerlink\" title=\"byte stram abstraction\"></a>byte stram abstraction</h3><p>segment format</p>\n<h3 id=\"three-handshake\"><a href=\"#three-handshake\" class=\"headerlink\" title=\"three handshake\"></a>three handshake</h3><h3 id=\"flow-controlslly-window-synfrome\"><a href=\"#flow-controlslly-window-synfrome\" class=\"headerlink\" title=\"flow controlslly window synfrome\"></a>flow controlslly window synfrome</h3><h3 id=\"Nagels’-algorithm\"><a href=\"#Nagels’-algorithm\" class=\"headerlink\" title=\"Nagels’ algorithm\"></a>Nagels’ algorithm</h3><h1 id=\"4b-RPC-RTP\"><a href=\"#4b-RPC-RTP\" class=\"headerlink\" title=\"4b RPC- RTP\"></a>4b RPC- RTP</h1><h2 id=\"RPC-Remote-procedure-call\"><a href=\"#RPC-Remote-procedure-call\" class=\"headerlink\" title=\"RPC Remote procedure call\"></a>RPC Remote procedure call</h2><p>gRPC: stubs, request and responses<br>Acknowledge models<br>Syn, Asyn ptcls<br>Message and encoding</p>\n<h3 id=\"Data-transmission-in-real-time\"><a href=\"#Data-transmission-in-real-time\" class=\"headerlink\" title=\"Data transmission in real time\"></a>Data transmission in real time</h3><p>Read- time data transmission (RTP)<br>Stram transmission ptcl</p>\n<h1 id=\"4c-src-and-congestion\"><a href=\"#4c-src-and-congestion\" class=\"headerlink\" title=\"4c src and congestion\"></a>4c src and congestion</h1><h2 id=\"Traffic-flows\"><a href=\"#Traffic-flows\" class=\"headerlink\" title=\"Traffic flows\"></a>Traffic flows</h2><p>Taxonomy of congestion flow<br>RED</p>\n<h2 id=\"Congestion-control\"><a href=\"#Congestion-control\" class=\"headerlink\" title=\"Congestion control\"></a>Congestion control</h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>","excerpt":"","more":"<h1 id=\"3c-internectworking\"><a href=\"#3c-internectworking\" class=\"headerlink\" title=\"3c internectworking\"></a>3c internectworking</h1><h2 id=\"Service-model\"><a href=\"#Service-model\" class=\"headerlink\" title=\"Service model\"></a>Service model</h2><p>no guarantees</p>\n<h2 id=\"IP-packet-header\"><a href=\"#IP-packet-header\" class=\"headerlink\" title=\"IP packet header\"></a>IP packet header</h2><h2 id=\"Fragmentation\"><a href=\"#Fragmentation\" class=\"headerlink\" title=\"Fragmentation\"></a>Fragmentation</h2><p>Examples with detail</p>\n<h2 id=\"Addressing\"><a href=\"#Addressing\" class=\"headerlink\" title=\"Addressing\"></a>Addressing</h2><h3 id=\"IP-Address-properties\"><a href=\"#IP-Address-properties\" class=\"headerlink\" title=\"IP Address properties\"></a>IP Address properties</h3><h3 id=\"4-class\"><a href=\"#4-class\" class=\"headerlink\" title=\"4 class\"></a>4 class</h3><h3 id=\"Subnets-CIDR\"><a href=\"#Subnets-CIDR\" class=\"headerlink\" title=\"Subnets&#x2F;CIDR\"></a>Subnets&#x2F;CIDR</h3><h2 id=\"packet-forwarding\"><a href=\"#packet-forwarding\" class=\"headerlink\" title=\"packet forwarding\"></a>packet forwarding</h2><h3 id=\"IP-forward-algorithm\"><a href=\"#IP-forward-algorithm\" class=\"headerlink\" title=\"IP forward algorithm\"></a>IP forward algorithm</h3><h3 id=\"Routin-tables\"><a href=\"#Routin-tables\" class=\"headerlink\" title=\"Routin tables\"></a>Routin tables</h3><h2 id=\"Address-translation\"><a href=\"#Address-translation\" class=\"headerlink\" title=\"Address translation\"></a>Address translation</h2><h2 id=\"ARP-Adression-Resolution-Protocol\"><a href=\"#ARP-Adression-Resolution-Protocol\" class=\"headerlink\" title=\"ARP Adression Resolution Protocol\"></a>ARP Adression Resolution Protocol</h2><h2 id=\"Node-autoconfiguration\"><a href=\"#Node-autoconfiguration\" class=\"headerlink\" title=\"Node autoconfiguration\"></a>Node autoconfiguration</h2><h3 id=\"DHCP\"><a href=\"#DHCP\" class=\"headerlink\" title=\"DHCP\"></a>DHCP</h3><p>dynamic host configuration ptcl</p>\n<h2 id=\"Error-Reporting\"><a href=\"#Error-Reporting\" class=\"headerlink\" title=\"Error Reporting\"></a>Error Reporting</h2><h3 id=\"ICMP-Internet-Control-messsage-protocol\"><a href=\"#ICMP-Internet-Control-messsage-protocol\" class=\"headerlink\" title=\"ICMP Internet Control messsage protocol\"></a>ICMP Internet Control messsage protocol</h3><h3 id=\"MTU-Discovery\"><a href=\"#MTU-Discovery\" class=\"headerlink\" title=\"MTU Discovery\"></a>MTU Discovery</h3><h1 id=\"3d-Routing\"><a href=\"#3d-Routing\" class=\"headerlink\" title=\"3d Routing\"></a>3d Routing</h1><h2 id=\"Forwarding-One-path-vs-Routing-Mutiple-path\"><a href=\"#Forwarding-One-path-vs-Routing-Mutiple-path\" class=\"headerlink\" title=\"Forwarding(One path) vs Routing(Mutiple path)\"></a>Forwarding(One path) vs Routing(Mutiple path)</h2><h2 id=\"Distance-Vector-protocol-Bellman-ford\"><a href=\"#Distance-Vector-protocol-Bellman-ford\" class=\"headerlink\" title=\"Distance Vector protocol: Bellman_ford\"></a>Distance Vector protocol: Bellman_ford</h2><h2 id=\"Link-state-protocol\"><a href=\"#Link-state-protocol\" class=\"headerlink\" title=\"Link-state protocol\"></a>Link-state protocol</h2><p>each router teel all the otehr routers about its link</p>\n<h2 id=\"Reliable-flooding-LSP\"><a href=\"#Reliable-flooding-LSP\" class=\"headerlink\" title=\"Reliable flooding (LSP)\"></a>Reliable flooding (LSP)</h2><p>link metrics</p>\n<h2 id=\"Interdomain-routing-definition\"><a href=\"#Interdomain-routing-definition\" class=\"headerlink\" title=\"Interdomain routing - definition\"></a>Interdomain routing - definition</h2><h3 id=\"BGP\"><a href=\"#BGP\" class=\"headerlink\" title=\"BGP\"></a>BGP</h3><h3 id=\"ASs\"><a href=\"#ASs\" class=\"headerlink\" title=\"ASs\"></a>ASs</h3><p>BGP between ASs: compute gglobal policy-compliant routers<br>OSPF in an AS: compute shortest routes between routers</p>\n<h1 id=\"4a-Transport\"><a href=\"#4a-Transport\" class=\"headerlink\" title=\"4a Transport\"></a>4a Transport</h1><h2 id=\"Recap\"><a href=\"#Recap\" class=\"headerlink\" title=\"Recap\"></a>Recap</h2><p>Intra-domain protocols</p>\n<ul>\n<li>Lowest cost shortest protocol&#x2F; disseminate full information about the topology</li>\n<li>Distance vector protocol(RIPv2)</li>\n<li>link state pctl: OSPF</li>\n</ul>\n<p>Inter-domainprotocol (BGP)</p>\n<ul>\n<li>most preffeered policy-compliant route</li>\n<li>information hiding for scalability and secrecy</li>\n</ul>\n<h2 id=\"UDP\"><a href=\"#UDP\" class=\"headerlink\" title=\"UDP\"></a>UDP</h2><p>well known ports<br>choosing ports</p>\n<h2 id=\"TCP\"><a href=\"#TCP\" class=\"headerlink\" title=\"TCP\"></a>TCP</h2><h3 id=\"byte-stram-abstraction\"><a href=\"#byte-stram-abstraction\" class=\"headerlink\" title=\"byte stram abstraction\"></a>byte stram abstraction</h3><p>segment format</p>\n<h3 id=\"three-handshake\"><a href=\"#three-handshake\" class=\"headerlink\" title=\"three handshake\"></a>three handshake</h3><h3 id=\"flow-controlslly-window-synfrome\"><a href=\"#flow-controlslly-window-synfrome\" class=\"headerlink\" title=\"flow controlslly window synfrome\"></a>flow controlslly window synfrome</h3><h3 id=\"Nagels’-algorithm\"><a href=\"#Nagels’-algorithm\" class=\"headerlink\" title=\"Nagels’ algorithm\"></a>Nagels’ algorithm</h3><h1 id=\"4b-RPC-RTP\"><a href=\"#4b-RPC-RTP\" class=\"headerlink\" title=\"4b RPC- RTP\"></a>4b RPC- RTP</h1><h2 id=\"RPC-Remote-procedure-call\"><a href=\"#RPC-Remote-procedure-call\" class=\"headerlink\" title=\"RPC Remote procedure call\"></a>RPC Remote procedure call</h2><p>gRPC: stubs, request and responses<br>Acknowledge models<br>Syn, Asyn ptcls<br>Message and encoding</p>\n<h3 id=\"Data-transmission-in-real-time\"><a href=\"#Data-transmission-in-real-time\" class=\"headerlink\" title=\"Data transmission in real time\"></a>Data transmission in real time</h3><p>Read- time data transmission (RTP)<br>Stram transmission ptcl</p>\n<h1 id=\"4c-src-and-congestion\"><a href=\"#4c-src-and-congestion\" class=\"headerlink\" title=\"4c src and congestion\"></a>4c src and congestion</h1><h2 id=\"Traffic-flows\"><a href=\"#Traffic-flows\" class=\"headerlink\" title=\"Traffic flows\"></a>Traffic flows</h2><p>Taxonomy of congestion flow<br>RED</p>\n<h2 id=\"Congestion-control\"><a href=\"#Congestion-control\" class=\"headerlink\" title=\"Congestion control\"></a>Congestion control</h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>"},{"title":"Sth to Look","date":"2024-02-05T01:42:13.000Z","cover":"img/bc1.jpg","_content":"\n# Appreciated good games:\n\n1.Evolution of trust\n\nmoegirl wiki: https://zh.moegirl.org.cn/zh-hans/%E4%BF%A1%E4%BB%BB%E7%9A%84%E8%BF%9B%E5%8C%96\n\nGame link: https://ncase.me/trust/\n\n2.Cube Escape (Rusty Lake Series) \n\nhttps://www.rustylake.com/room-escape-games/cube-escape-collection.html\n\n3. Evolution \nGame link: https://keiwan.itch.io/evolution\n![Alt text](asset/Sth_to_Look/1d559bbca4dc8ce283aec32a0bba4b1.png)\n\n\n\n![alt text](2024-02-04-Sth-to-look/image.png)\n\n\n4. 极乐迪斯科\n\n# Something really helps me out of \nOD\n\nhttps://www.overdose.wiki/\n\nhttps://m.psychonautwiki.org/wiki/Main_Page\n\nMusic: 精神鸦片","source":"_posts/2024-02-04-Sth-to-look.md","raw":"---\ntitle: Sth to Look \ndate: 2024-02-04 20:42:13\ntags:\ncover: img/bc1.jpg\n---\n\n# Appreciated good games:\n\n1.Evolution of trust\n\nmoegirl wiki: https://zh.moegirl.org.cn/zh-hans/%E4%BF%A1%E4%BB%BB%E7%9A%84%E8%BF%9B%E5%8C%96\n\nGame link: https://ncase.me/trust/\n\n2.Cube Escape (Rusty Lake Series) \n\nhttps://www.rustylake.com/room-escape-games/cube-escape-collection.html\n\n3. Evolution \nGame link: https://keiwan.itch.io/evolution\n![Alt text](asset/Sth_to_Look/1d559bbca4dc8ce283aec32a0bba4b1.png)\n\n\n\n![alt text](2024-02-04-Sth-to-look/image.png)\n\n\n4. 极乐迪斯科\n\n# Something really helps me out of \nOD\n\nhttps://www.overdose.wiki/\n\nhttps://m.psychonautwiki.org/wiki/Main_Page\n\nMusic: 精神鸦片","slug":"2024-02-04-Sth-to-look","published":1,"updated":"2024-11-13T14:46:26.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsu001jzc3ddvu228h8","content":"<h1 id=\"Appreciated-good-games\"><a href=\"#Appreciated-good-games\" class=\"headerlink\" title=\"Appreciated good games:\"></a>Appreciated good games:</h1><p>1.Evolution of trust</p>\n<p>moegirl wiki: <a href=\"https://zh.moegirl.org.cn/zh-hans/%E4%BF%A1%E4%BB%BB%E7%9A%84%E8%BF%9B%E5%8C%96\">https://zh.moegirl.org.cn/zh-hans/%E4%BF%A1%E4%BB%BB%E7%9A%84%E8%BF%9B%E5%8C%96</a></p>\n<p>Game link: <a href=\"https://ncase.me/trust/\">https://ncase.me/trust/</a></p>\n<p>2.Cube Escape (Rusty Lake Series) </p>\n<p><a href=\"https://www.rustylake.com/room-escape-games/cube-escape-collection.html\">https://www.rustylake.com/room-escape-games/cube-escape-collection.html</a></p>\n<ol start=\"3\">\n<li>Evolution<br>Game link: <a href=\"https://keiwan.itch.io/evolution\">https://keiwan.itch.io/evolution</a><br><img src=\"/asset/Sth_to_Look/1d559bbca4dc8ce283aec32a0bba4b1.png\" alt=\"Alt text\"></li>\n</ol>\n<p><img src=\"/2024-02-04-Sth-to-look/image.png\" alt=\"alt text\"></p>\n<ol start=\"4\">\n<li>极乐迪斯科</li>\n</ol>\n<h1 id=\"Something-really-helps-me-out-of\"><a href=\"#Something-really-helps-me-out-of\" class=\"headerlink\" title=\"Something really helps me out of\"></a>Something really helps me out of</h1><p>OD</p>\n<p><a href=\"https://www.overdose.wiki/\">https://www.overdose.wiki/</a></p>\n<p><a href=\"https://m.psychonautwiki.org/wiki/Main_Page\">https://m.psychonautwiki.org/wiki/Main_Page</a></p>\n<p>Music: 精神鸦片</p>\n","excerpt":"","more":"<h1 id=\"Appreciated-good-games\"><a href=\"#Appreciated-good-games\" class=\"headerlink\" title=\"Appreciated good games:\"></a>Appreciated good games:</h1><p>1.Evolution of trust</p>\n<p>moegirl wiki: <a href=\"https://zh.moegirl.org.cn/zh-hans/%E4%BF%A1%E4%BB%BB%E7%9A%84%E8%BF%9B%E5%8C%96\">https://zh.moegirl.org.cn/zh-hans/%E4%BF%A1%E4%BB%BB%E7%9A%84%E8%BF%9B%E5%8C%96</a></p>\n<p>Game link: <a href=\"https://ncase.me/trust/\">https://ncase.me/trust/</a></p>\n<p>2.Cube Escape (Rusty Lake Series) </p>\n<p><a href=\"https://www.rustylake.com/room-escape-games/cube-escape-collection.html\">https://www.rustylake.com/room-escape-games/cube-escape-collection.html</a></p>\n<ol start=\"3\">\n<li>Evolution<br>Game link: <a href=\"https://keiwan.itch.io/evolution\">https://keiwan.itch.io/evolution</a><br><img src=\"/asset/Sth_to_Look/1d559bbca4dc8ce283aec32a0bba4b1.png\" alt=\"Alt text\"></li>\n</ol>\n<p><img src=\"/2024-02-04-Sth-to-look/image.png\" alt=\"alt text\"></p>\n<ol start=\"4\">\n<li>极乐迪斯科</li>\n</ol>\n<h1 id=\"Something-really-helps-me-out-of\"><a href=\"#Something-really-helps-me-out-of\" class=\"headerlink\" title=\"Something really helps me out of\"></a>Something really helps me out of</h1><p>OD</p>\n<p><a href=\"https://www.overdose.wiki/\">https://www.overdose.wiki/</a></p>\n<p><a href=\"https://m.psychonautwiki.org/wiki/Main_Page\">https://m.psychonautwiki.org/wiki/Main_Page</a></p>\n<p>Music: 精神鸦片</p>\n"},{"title":"A Trial For HW3 CS 311","date":"2024-03-07T00:50:14.000Z","_content":"\n# HW 311\n\n## Flask and REST API\nSome helpful Web that helps understand flask \n1. Flask-RESTPlus is an extension for flask. It comes with built-in support for Swagger, which allows automatic generation of interactive API documentation that can be used by developers to test the API.\nhttps://github.com/flask-restful/flask-restful\nhttps://flask-restplus.readthedocs.io/en/stable/quickstart.html#\n\n2. Swager UI:\nhttps://github.com/swagger-api/swagger-ui\n\n3. Flask swagger:\nhttps://github.com/getsling/flask-swagger\n\n### key word: Flask + Web\nAn example for flask web: https://www.cnblogs.com/xianyi-yk/p/14695401.html\n\n### Virtual environment \n    ```Ctrl P >``` to call the pannel, \n    ```Python: select intepreter```\n    then you will have a local environment in the current work space!!!!\n\n## Swagger\n\n","source":"_posts/2024-03-06-A-Trial-For-HW3-CS-311.md","raw":"---\ntitle: A Trial For HW3 CS 311\ndate: 2024-03-06 19:50:14\ntags:\n---\n\n# HW 311\n\n## Flask and REST API\nSome helpful Web that helps understand flask \n1. Flask-RESTPlus is an extension for flask. It comes with built-in support for Swagger, which allows automatic generation of interactive API documentation that can be used by developers to test the API.\nhttps://github.com/flask-restful/flask-restful\nhttps://flask-restplus.readthedocs.io/en/stable/quickstart.html#\n\n2. Swager UI:\nhttps://github.com/swagger-api/swagger-ui\n\n3. Flask swagger:\nhttps://github.com/getsling/flask-swagger\n\n### key word: Flask + Web\nAn example for flask web: https://www.cnblogs.com/xianyi-yk/p/14695401.html\n\n### Virtual environment \n    ```Ctrl P >``` to call the pannel, \n    ```Python: select intepreter```\n    then you will have a local environment in the current work space!!!!\n\n## Swagger\n\n","slug":"2024-03-06-A-Trial-For-HW3-CS-311","published":1,"updated":"2024-11-13T14:46:26.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsu001kzc3db1be8dua","content":"<h1 id=\"HW-311\"><a href=\"#HW-311\" class=\"headerlink\" title=\"HW 311\"></a>HW 311</h1><h2 id=\"Flask-and-REST-API\"><a href=\"#Flask-and-REST-API\" class=\"headerlink\" title=\"Flask and REST API\"></a>Flask and REST API</h2><p>Some helpful Web that helps understand flask </p>\n<ol>\n<li><p>Flask-RESTPlus is an extension for flask. It comes with built-in support for Swagger, which allows automatic generation of interactive API documentation that can be used by developers to test the API.<br><a href=\"https://github.com/flask-restful/flask-restful\">https://github.com/flask-restful/flask-restful</a><br><a href=\"https://flask-restplus.readthedocs.io/en/stable/quickstart.html#\">https://flask-restplus.readthedocs.io/en/stable/quickstart.html#</a></p>\n</li>\n<li><p>Swager UI:<br><a href=\"https://github.com/swagger-api/swagger-ui\">https://github.com/swagger-api/swagger-ui</a></p>\n</li>\n<li><p>Flask swagger:<br><a href=\"https://github.com/getsling/flask-swagger\">https://github.com/getsling/flask-swagger</a></p>\n</li>\n</ol>\n<h3 id=\"key-word-Flask-Web\"><a href=\"#key-word-Flask-Web\" class=\"headerlink\" title=\"key word: Flask + Web\"></a>key word: Flask + Web</h3><p>An example for flask web: <a href=\"https://www.cnblogs.com/xianyi-yk/p/14695401.html\">https://www.cnblogs.com/xianyi-yk/p/14695401.html</a></p>\n<h3 id=\"Virtual-environment\"><a href=\"#Virtual-environment\" class=\"headerlink\" title=\"Virtual environment\"></a>Virtual environment</h3><pre><code>```Ctrl P &gt;``` to call the pannel, \n```Python: select intepreter```\nthen you will have a local environment in the current work space!!!!\n</code></pre>\n<h2 id=\"Swagger\"><a href=\"#Swagger\" class=\"headerlink\" title=\"Swagger\"></a>Swagger</h2>","excerpt":"","more":"<h1 id=\"HW-311\"><a href=\"#HW-311\" class=\"headerlink\" title=\"HW 311\"></a>HW 311</h1><h2 id=\"Flask-and-REST-API\"><a href=\"#Flask-and-REST-API\" class=\"headerlink\" title=\"Flask and REST API\"></a>Flask and REST API</h2><p>Some helpful Web that helps understand flask </p>\n<ol>\n<li><p>Flask-RESTPlus is an extension for flask. It comes with built-in support for Swagger, which allows automatic generation of interactive API documentation that can be used by developers to test the API.<br><a href=\"https://github.com/flask-restful/flask-restful\">https://github.com/flask-restful/flask-restful</a><br><a href=\"https://flask-restplus.readthedocs.io/en/stable/quickstart.html#\">https://flask-restplus.readthedocs.io/en/stable/quickstart.html#</a></p>\n</li>\n<li><p>Swager UI:<br><a href=\"https://github.com/swagger-api/swagger-ui\">https://github.com/swagger-api/swagger-ui</a></p>\n</li>\n<li><p>Flask swagger:<br><a href=\"https://github.com/getsling/flask-swagger\">https://github.com/getsling/flask-swagger</a></p>\n</li>\n</ol>\n<h3 id=\"key-word-Flask-Web\"><a href=\"#key-word-Flask-Web\" class=\"headerlink\" title=\"key word: Flask + Web\"></a>key word: Flask + Web</h3><p>An example for flask web: <a href=\"https://www.cnblogs.com/xianyi-yk/p/14695401.html\">https://www.cnblogs.com/xianyi-yk/p/14695401.html</a></p>\n<h3 id=\"Virtual-environment\"><a href=\"#Virtual-environment\" class=\"headerlink\" title=\"Virtual environment\"></a>Virtual environment</h3><pre><code>```Ctrl P &gt;``` to call the pannel, \n```Python: select intepreter```\nthen you will have a local environment in the current work space!!!!\n</code></pre>\n<h2 id=\"Swagger\"><a href=\"#Swagger\" class=\"headerlink\" title=\"Swagger\"></a>Swagger</h2>"},{"title":"First attempt on deploying blog","date":"2024-02-03T14:36:51.000Z","type":null,"_content":"\n脑袋坏掉了，不要在这里git commit 啊，这里只要hexo g之类的就好了！！！！！！！！！\n\n- Reference on building this blog: https://fe32.top/articles/hexo1600/\n\n- Document on butterfly: https://butterfly.js.org/posts/4aa8abbe/\n\n- Inserting the index page picture: https://android99.com/2021/08/10/butterfly-top-image-modify/\n\n\n一图流背景 https://blog.gzzz.pro/posts/22283ba3/index.html\n\n主题调色，但是貌似失败了https://www.cnblogs.com/thinkgone/p/16349002.html\n\n- Markdown picture copy/paste with vscode: https://www.cnblogs.com/xbotter/p/17528063.html\n1. `Ctrl + ,` or `Ctrl + Shift + P ` to summon setting panel\n2. Search `markdown.copyFiles.destination`\n3. Add new item with item of name and value of direction: e.g.`Item: **/*.md Value: ${documentBaseName}/${fileName}`\n\n4. https://leay.net/2019/12/25/hexo/\n-\n\nWordpress搭建个人网站:\nhttps://www.cnblogs.com/wongbingming/p/13819905.html\n\n\n\n\n\n\n有用的数学公式渲染\nhttps://nickxu.me/2022/04/17/Hexo-Butterfly-%E5%BB%BA%E7%AB%99%E6%8C%87%E5%8D%97%EF%BC%88%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8-KaTeX-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/\n\n\n\n\n\nhttps://butterfly.zhheo.com/home.html\n\n\n\n# 网络问题\n如果 `pnpm install` 卡住了，可以尝试以下几种解决方案：\n\n### 1. 检查网络连接\n\n确认你的网络连接是否稳定。可以尝试访问一些网站，确保没有网络问题。\n\n### 2. 更改 DNS 设置\n\n有时候 DNS 设置可能会导致网络请求超时。可以尝试更改 DNS 设置为公共 DNS（如 Google 的 8.8.8.8 或 Cloudflare 的 1.1.1.1）：\n\n- **在 Linux 系统上**，你可以编辑 `/etc/resolv.conf` 文件：\n\n  ```bash\n  sudo nano /etc/resolv.conf\n  ```\n\n  添加以下行：\n\n  ```\n  nameserver 8.8.8.8\n  nameserver 1.1.1.1\n  ```\n\n- 然后保存并退出。\n\n### 3. 增加超时设置\n\n你可以通过设置 `pnpm` 的超时来防止其卡住。可以使用以下命令增加超时时间：\n\n```bash\npnpm install --timeout 60000\n```\n\n这个命令会将超时时间设置为 60 秒。\n\n### 4. 清理缓存\n\n有时候清理缓存能够解决问题，可以使用以下命令：\n\n```bash\npnpm store prune\n```\n\n然后再次尝试安装：\n\n```bash\npnpm install\n```\n\n### 5. 使用 `--no-progress` 选项\n\n使用 `--no-progress` 选项可以禁用安装进度条，这可能会帮助安装更快完成：\n\n```bash\npnpm install --no-progress\n```\n\n### 6. 代理设置\n\n如果你在公司或校园网络中，可能需要设置代理。检查和设置你的 npm 代理：\n\n```bash\nnpm config get proxy\nnpm config get https-proxy\n```\n\n如果没有设置，可以使用以下命令设置：\n\n```bash\nnpm config set proxy http://your-proxy-url:port\nnpm config set https-proxy http://your-proxy-url:port\n```\n\n### 7. 使用其他安装方式\n\n如果 `pnpm` 继续卡住，可以尝试使用 `npm` 来安装依赖：\n\n```bash\nnpm install\n```\n\n### 8. 查看日志\n\n如果仍然卡住，检查 `pnpm` 的日志文件，可以查看输出的错误信息，以确定问题的根本原因。\n\n### 9. 重启终端\n\n有时简单地关闭终端并重新打开，然后再尝试安装可以解决问题。\n\n\n\n# Github mirror\nhttps://mirror.ghproxy.com/","source":"_posts/2024-02-03.md","raw":"---\ntitle: First attempt on deploying blog\ndate: 2024-02-03 09:36:51\ntype: \n---\n\n脑袋坏掉了，不要在这里git commit 啊，这里只要hexo g之类的就好了！！！！！！！！！\n\n- Reference on building this blog: https://fe32.top/articles/hexo1600/\n\n- Document on butterfly: https://butterfly.js.org/posts/4aa8abbe/\n\n- Inserting the index page picture: https://android99.com/2021/08/10/butterfly-top-image-modify/\n\n\n一图流背景 https://blog.gzzz.pro/posts/22283ba3/index.html\n\n主题调色，但是貌似失败了https://www.cnblogs.com/thinkgone/p/16349002.html\n\n- Markdown picture copy/paste with vscode: https://www.cnblogs.com/xbotter/p/17528063.html\n1. `Ctrl + ,` or `Ctrl + Shift + P ` to summon setting panel\n2. Search `markdown.copyFiles.destination`\n3. Add new item with item of name and value of direction: e.g.`Item: **/*.md Value: ${documentBaseName}/${fileName}`\n\n4. https://leay.net/2019/12/25/hexo/\n-\n\nWordpress搭建个人网站:\nhttps://www.cnblogs.com/wongbingming/p/13819905.html\n\n\n\n\n\n\n有用的数学公式渲染\nhttps://nickxu.me/2022/04/17/Hexo-Butterfly-%E5%BB%BA%E7%AB%99%E6%8C%87%E5%8D%97%EF%BC%88%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8-KaTeX-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/\n\n\n\n\n\nhttps://butterfly.zhheo.com/home.html\n\n\n\n# 网络问题\n如果 `pnpm install` 卡住了，可以尝试以下几种解决方案：\n\n### 1. 检查网络连接\n\n确认你的网络连接是否稳定。可以尝试访问一些网站，确保没有网络问题。\n\n### 2. 更改 DNS 设置\n\n有时候 DNS 设置可能会导致网络请求超时。可以尝试更改 DNS 设置为公共 DNS（如 Google 的 8.8.8.8 或 Cloudflare 的 1.1.1.1）：\n\n- **在 Linux 系统上**，你可以编辑 `/etc/resolv.conf` 文件：\n\n  ```bash\n  sudo nano /etc/resolv.conf\n  ```\n\n  添加以下行：\n\n  ```\n  nameserver 8.8.8.8\n  nameserver 1.1.1.1\n  ```\n\n- 然后保存并退出。\n\n### 3. 增加超时设置\n\n你可以通过设置 `pnpm` 的超时来防止其卡住。可以使用以下命令增加超时时间：\n\n```bash\npnpm install --timeout 60000\n```\n\n这个命令会将超时时间设置为 60 秒。\n\n### 4. 清理缓存\n\n有时候清理缓存能够解决问题，可以使用以下命令：\n\n```bash\npnpm store prune\n```\n\n然后再次尝试安装：\n\n```bash\npnpm install\n```\n\n### 5. 使用 `--no-progress` 选项\n\n使用 `--no-progress` 选项可以禁用安装进度条，这可能会帮助安装更快完成：\n\n```bash\npnpm install --no-progress\n```\n\n### 6. 代理设置\n\n如果你在公司或校园网络中，可能需要设置代理。检查和设置你的 npm 代理：\n\n```bash\nnpm config get proxy\nnpm config get https-proxy\n```\n\n如果没有设置，可以使用以下命令设置：\n\n```bash\nnpm config set proxy http://your-proxy-url:port\nnpm config set https-proxy http://your-proxy-url:port\n```\n\n### 7. 使用其他安装方式\n\n如果 `pnpm` 继续卡住，可以尝试使用 `npm` 来安装依赖：\n\n```bash\nnpm install\n```\n\n### 8. 查看日志\n\n如果仍然卡住，检查 `pnpm` 的日志文件，可以查看输出的错误信息，以确定问题的根本原因。\n\n### 9. 重启终端\n\n有时简单地关闭终端并重新打开，然后再尝试安装可以解决问题。\n\n\n\n# Github mirror\nhttps://mirror.ghproxy.com/","slug":"2024-02-03","published":1,"updated":"2024-11-30T20:40:23.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsv001lzc3ddcgw7hy5","content":"<p>脑袋坏掉了，不要在这里git commit 啊，这里只要hexo g之类的就好了！！！！！！！！！</p>\n<ul>\n<li><p>Reference on building this blog: <a href=\"https://fe32.top/articles/hexo1600/\">https://fe32.top/articles/hexo1600/</a></p>\n</li>\n<li><p>Document on butterfly: <a href=\"https://butterfly.js.org/posts/4aa8abbe/\">https://butterfly.js.org/posts/4aa8abbe/</a></p>\n</li>\n<li><p>Inserting the index page picture: <a href=\"https://android99.com/2021/08/10/butterfly-top-image-modify/\">https://android99.com/2021/08/10/butterfly-top-image-modify/</a></p>\n</li>\n</ul>\n<p>一图流背景 <a href=\"https://blog.gzzz.pro/posts/22283ba3/index.html\">https://blog.gzzz.pro/posts/22283ba3/index.html</a></p>\n<p>主题调色，但是貌似失败了<a href=\"https://www.cnblogs.com/thinkgone/p/16349002.html\">https://www.cnblogs.com/thinkgone/p/16349002.html</a></p>\n<ul>\n<li>Markdown picture copy&#x2F;paste with vscode: <a href=\"https://www.cnblogs.com/xbotter/p/17528063.html\">https://www.cnblogs.com/xbotter/p/17528063.html</a></li>\n</ul>\n<ol>\n<li><p><code>Ctrl + ,</code> or <code>Ctrl + Shift + P </code> to summon setting panel</p>\n</li>\n<li><p>Search <code>markdown.copyFiles.destination</code></p>\n</li>\n<li><p>Add new item with item of name and value of direction: e.g.<code>Item: **/*.md Value: $&#123;documentBaseName&#125;/$&#123;fileName&#125;</code></p>\n</li>\n<li><p><a href=\"https://leay.net/2019/12/25/hexo/\">https://leay.net/2019/12/25/hexo/</a></p>\n</li>\n</ol>\n<ul>\n<li></li>\n</ul>\n<p>Wordpress搭建个人网站:<br><a href=\"https://www.cnblogs.com/wongbingming/p/13819905.html\">https://www.cnblogs.com/wongbingming/p/13819905.html</a></p>\n<p>有用的数学公式渲染<br><a href=\"https://nickxu.me/2022/04/17/Hexo-Butterfly-%E5%BB%BA%E7%AB%99%E6%8C%87%E5%8D%97%EF%BC%88%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8-KaTeX-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/\">https://nickxu.me/2022/04/17/Hexo-Butterfly-%E5%BB%BA%E7%AB%99%E6%8C%87%E5%8D%97%EF%BC%88%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8-KaTeX-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</a></p>\n<p><a href=\"https://butterfly.zhheo.com/home.html\">https://butterfly.zhheo.com/home.html</a></p>\n<h1 id=\"网络问题\"><a href=\"#网络问题\" class=\"headerlink\" title=\"网络问题\"></a>网络问题</h1><p>如果 <code>pnpm install</code> 卡住了，可以尝试以下几种解决方案：</p>\n<h3 id=\"1-检查网络连接\"><a href=\"#1-检查网络连接\" class=\"headerlink\" title=\"1. 检查网络连接\"></a>1. 检查网络连接</h3><p>确认你的网络连接是否稳定。可以尝试访问一些网站，确保没有网络问题。</p>\n<h3 id=\"2-更改-DNS-设置\"><a href=\"#2-更改-DNS-设置\" class=\"headerlink\" title=\"2. 更改 DNS 设置\"></a>2. 更改 DNS 设置</h3><p>有时候 DNS 设置可能会导致网络请求超时。可以尝试更改 DNS 设置为公共 DNS（如 Google 的 8.8.8.8 或 Cloudflare 的 1.1.1.1）：</p>\n<ul>\n<li><p><strong>在 Linux 系统上</strong>，你可以编辑 <code>/etc/resolv.conf</code> 文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> nano /etc/resolv.conf</span><br></pre></td></tr></table></figure>\n\n<p>添加以下行：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nameserver 8.8.8.8</span><br><span class=\"line\">nameserver 1.1.1.1</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>然后保存并退出。</p>\n</li>\n</ul>\n<h3 id=\"3-增加超时设置\"><a href=\"#3-增加超时设置\" class=\"headerlink\" title=\"3. 增加超时设置\"></a>3. 增加超时设置</h3><p>你可以通过设置 <code>pnpm</code> 的超时来防止其卡住。可以使用以下命令增加超时时间：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pnpm install --<span class=\"built_in\">timeout</span> 60000</span><br></pre></td></tr></table></figure>\n\n<p>这个命令会将超时时间设置为 60 秒。</p>\n<h3 id=\"4-清理缓存\"><a href=\"#4-清理缓存\" class=\"headerlink\" title=\"4. 清理缓存\"></a>4. 清理缓存</h3><p>有时候清理缓存能够解决问题，可以使用以下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pnpm store prune</span><br></pre></td></tr></table></figure>\n\n<p>然后再次尝试安装：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pnpm install</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"5-使用-no-progress-选项\"><a href=\"#5-使用-no-progress-选项\" class=\"headerlink\" title=\"5. 使用 --no-progress 选项\"></a>5. 使用 <code>--no-progress</code> 选项</h3><p>使用 <code>--no-progress</code> 选项可以禁用安装进度条，这可能会帮助安装更快完成：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pnpm install --no-progress</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"6-代理设置\"><a href=\"#6-代理设置\" class=\"headerlink\" title=\"6. 代理设置\"></a>6. 代理设置</h3><p>如果你在公司或校园网络中，可能需要设置代理。检查和设置你的 npm 代理：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm config get proxy</span><br><span class=\"line\">npm config get https-proxy</span><br></pre></td></tr></table></figure>\n\n<p>如果没有设置，可以使用以下命令设置：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm config <span class=\"built_in\">set</span> proxy http://your-proxy-url:port</span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> https-proxy http://your-proxy-url:port</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-使用其他安装方式\"><a href=\"#7-使用其他安装方式\" class=\"headerlink\" title=\"7. 使用其他安装方式\"></a>7. 使用其他安装方式</h3><p>如果 <code>pnpm</code> 继续卡住，可以尝试使用 <code>npm</code> 来安装依赖：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"8-查看日志\"><a href=\"#8-查看日志\" class=\"headerlink\" title=\"8. 查看日志\"></a>8. 查看日志</h3><p>如果仍然卡住，检查 <code>pnpm</code> 的日志文件，可以查看输出的错误信息，以确定问题的根本原因。</p>\n<h3 id=\"9-重启终端\"><a href=\"#9-重启终端\" class=\"headerlink\" title=\"9. 重启终端\"></a>9. 重启终端</h3><p>有时简单地关闭终端并重新打开，然后再尝试安装可以解决问题。</p>\n<h1 id=\"Github-mirror\"><a href=\"#Github-mirror\" class=\"headerlink\" title=\"Github mirror\"></a>Github mirror</h1><p><a href=\"https://mirror.ghproxy.com/\">https://mirror.ghproxy.com/</a></p>\n","excerpt":"","more":"<p>脑袋坏掉了，不要在这里git commit 啊，这里只要hexo g之类的就好了！！！！！！！！！</p>\n<ul>\n<li><p>Reference on building this blog: <a href=\"https://fe32.top/articles/hexo1600/\">https://fe32.top/articles/hexo1600/</a></p>\n</li>\n<li><p>Document on butterfly: <a href=\"https://butterfly.js.org/posts/4aa8abbe/\">https://butterfly.js.org/posts/4aa8abbe/</a></p>\n</li>\n<li><p>Inserting the index page picture: <a href=\"https://android99.com/2021/08/10/butterfly-top-image-modify/\">https://android99.com/2021/08/10/butterfly-top-image-modify/</a></p>\n</li>\n</ul>\n<p>一图流背景 <a href=\"https://blog.gzzz.pro/posts/22283ba3/index.html\">https://blog.gzzz.pro/posts/22283ba3/index.html</a></p>\n<p>主题调色，但是貌似失败了<a href=\"https://www.cnblogs.com/thinkgone/p/16349002.html\">https://www.cnblogs.com/thinkgone/p/16349002.html</a></p>\n<ul>\n<li>Markdown picture copy&#x2F;paste with vscode: <a href=\"https://www.cnblogs.com/xbotter/p/17528063.html\">https://www.cnblogs.com/xbotter/p/17528063.html</a></li>\n</ul>\n<ol>\n<li><p><code>Ctrl + ,</code> or <code>Ctrl + Shift + P </code> to summon setting panel</p>\n</li>\n<li><p>Search <code>markdown.copyFiles.destination</code></p>\n</li>\n<li><p>Add new item with item of name and value of direction: e.g.<code>Item: **/*.md Value: $&#123;documentBaseName&#125;/$&#123;fileName&#125;</code></p>\n</li>\n<li><p><a href=\"https://leay.net/2019/12/25/hexo/\">https://leay.net/2019/12/25/hexo/</a></p>\n</li>\n</ol>\n<ul>\n<li></li>\n</ul>\n<p>Wordpress搭建个人网站:<br><a href=\"https://www.cnblogs.com/wongbingming/p/13819905.html\">https://www.cnblogs.com/wongbingming/p/13819905.html</a></p>\n<p>有用的数学公式渲染<br><a href=\"https://nickxu.me/2022/04/17/Hexo-Butterfly-%E5%BB%BA%E7%AB%99%E6%8C%87%E5%8D%97%EF%BC%88%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8-KaTeX-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/\">https://nickxu.me/2022/04/17/Hexo-Butterfly-%E5%BB%BA%E7%AB%99%E6%8C%87%E5%8D%97%EF%BC%88%E5%85%AB%EF%BC%89%E4%BD%BF%E7%94%A8-KaTeX-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</a></p>\n<p><a href=\"https://butterfly.zhheo.com/home.html\">https://butterfly.zhheo.com/home.html</a></p>\n<h1 id=\"网络问题\"><a href=\"#网络问题\" class=\"headerlink\" title=\"网络问题\"></a>网络问题</h1><p>如果 <code>pnpm install</code> 卡住了，可以尝试以下几种解决方案：</p>\n<h3 id=\"1-检查网络连接\"><a href=\"#1-检查网络连接\" class=\"headerlink\" title=\"1. 检查网络连接\"></a>1. 检查网络连接</h3><p>确认你的网络连接是否稳定。可以尝试访问一些网站，确保没有网络问题。</p>\n<h3 id=\"2-更改-DNS-设置\"><a href=\"#2-更改-DNS-设置\" class=\"headerlink\" title=\"2. 更改 DNS 设置\"></a>2. 更改 DNS 设置</h3><p>有时候 DNS 设置可能会导致网络请求超时。可以尝试更改 DNS 设置为公共 DNS（如 Google 的 8.8.8.8 或 Cloudflare 的 1.1.1.1）：</p>\n<ul>\n<li><p><strong>在 Linux 系统上</strong>，你可以编辑 <code>/etc/resolv.conf</code> 文件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">sudo</span> nano /etc/resolv.conf</span><br></pre></td></tr></table></figure>\n\n<p>添加以下行：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nameserver 8.8.8.8</span><br><span class=\"line\">nameserver 1.1.1.1</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>然后保存并退出。</p>\n</li>\n</ul>\n<h3 id=\"3-增加超时设置\"><a href=\"#3-增加超时设置\" class=\"headerlink\" title=\"3. 增加超时设置\"></a>3. 增加超时设置</h3><p>你可以通过设置 <code>pnpm</code> 的超时来防止其卡住。可以使用以下命令增加超时时间：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pnpm install --<span class=\"built_in\">timeout</span> 60000</span><br></pre></td></tr></table></figure>\n\n<p>这个命令会将超时时间设置为 60 秒。</p>\n<h3 id=\"4-清理缓存\"><a href=\"#4-清理缓存\" class=\"headerlink\" title=\"4. 清理缓存\"></a>4. 清理缓存</h3><p>有时候清理缓存能够解决问题，可以使用以下命令：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pnpm store prune</span><br></pre></td></tr></table></figure>\n\n<p>然后再次尝试安装：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pnpm install</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"5-使用-no-progress-选项\"><a href=\"#5-使用-no-progress-选项\" class=\"headerlink\" title=\"5. 使用 --no-progress 选项\"></a>5. 使用 <code>--no-progress</code> 选项</h3><p>使用 <code>--no-progress</code> 选项可以禁用安装进度条，这可能会帮助安装更快完成：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pnpm install --no-progress</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"6-代理设置\"><a href=\"#6-代理设置\" class=\"headerlink\" title=\"6. 代理设置\"></a>6. 代理设置</h3><p>如果你在公司或校园网络中，可能需要设置代理。检查和设置你的 npm 代理：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm config get proxy</span><br><span class=\"line\">npm config get https-proxy</span><br></pre></td></tr></table></figure>\n\n<p>如果没有设置，可以使用以下命令设置：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm config <span class=\"built_in\">set</span> proxy http://your-proxy-url:port</span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> https-proxy http://your-proxy-url:port</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"7-使用其他安装方式\"><a href=\"#7-使用其他安装方式\" class=\"headerlink\" title=\"7. 使用其他安装方式\"></a>7. 使用其他安装方式</h3><p>如果 <code>pnpm</code> 继续卡住，可以尝试使用 <code>npm</code> 来安装依赖：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"8-查看日志\"><a href=\"#8-查看日志\" class=\"headerlink\" title=\"8. 查看日志\"></a>8. 查看日志</h3><p>如果仍然卡住，检查 <code>pnpm</code> 的日志文件，可以查看输出的错误信息，以确定问题的根本原因。</p>\n<h3 id=\"9-重启终端\"><a href=\"#9-重启终端\" class=\"headerlink\" title=\"9. 重启终端\"></a>9. 重启终端</h3><p>有时简单地关闭终端并重新打开，然后再尝试安装可以解决问题。</p>\n<h1 id=\"Github-mirror\"><a href=\"#Github-mirror\" class=\"headerlink\" title=\"Github mirror\"></a>Github mirror</h1><p><a href=\"https://mirror.ghproxy.com/\">https://mirror.ghproxy.com/</a></p>\n"},{"title":"2024-09-08 Lofi","date":"2024-09-09T03:21:24.000Z","_content":"\n\n\n\n# lofi pixel\nhttps://github.com/nixonsu/lofi-lounge?tab=readme-ov-file\nhttps://lofi-lounge.com/\n\n## pixel art drwaing/gif\nhttps://www.pixilart.com/draw\n\n\n\n# Music \nhttps://github.com/jacbz/Lofi\n\n\n\n\n\n\n\n\n\n","source":"_posts/2024-09-08-Lofi.md","raw":"---\ntitle: 2024-09-08 Lofi\ndate: 2024-09-08 23:21:24\ntags:\n---\n\n\n\n\n# lofi pixel\nhttps://github.com/nixonsu/lofi-lounge?tab=readme-ov-file\nhttps://lofi-lounge.com/\n\n## pixel art drwaing/gif\nhttps://www.pixilart.com/draw\n\n\n\n# Music \nhttps://github.com/jacbz/Lofi\n\n\n\n\n\n\n\n\n\n","slug":"2024-09-08-Lofi","published":1,"updated":"2024-12-15T03:51:49.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsv001mzc3d6qiehpz7","content":"<h1 id=\"lofi-pixel\"><a href=\"#lofi-pixel\" class=\"headerlink\" title=\"lofi pixel\"></a>lofi pixel</h1><p><a href=\"https://github.com/nixonsu/lofi-lounge?tab=readme-ov-file\">https://github.com/nixonsu/lofi-lounge?tab=readme-ov-file</a><br><a href=\"https://lofi-lounge.com/\">https://lofi-lounge.com/</a></p>\n<h2 id=\"pixel-art-drwaing-gif\"><a href=\"#pixel-art-drwaing-gif\" class=\"headerlink\" title=\"pixel art drwaing&#x2F;gif\"></a>pixel art drwaing&#x2F;gif</h2><p><a href=\"https://www.pixilart.com/draw\">https://www.pixilart.com/draw</a></p>\n<h1 id=\"Music\"><a href=\"#Music\" class=\"headerlink\" title=\"Music\"></a>Music</h1><p><a href=\"https://github.com/jacbz/Lofi\">https://github.com/jacbz/Lofi</a></p>\n","excerpt":"","more":"<h1 id=\"lofi-pixel\"><a href=\"#lofi-pixel\" class=\"headerlink\" title=\"lofi pixel\"></a>lofi pixel</h1><p><a href=\"https://github.com/nixonsu/lofi-lounge?tab=readme-ov-file\">https://github.com/nixonsu/lofi-lounge?tab=readme-ov-file</a><br><a href=\"https://lofi-lounge.com/\">https://lofi-lounge.com/</a></p>\n<h2 id=\"pixel-art-drwaing-gif\"><a href=\"#pixel-art-drwaing-gif\" class=\"headerlink\" title=\"pixel art drwaing&#x2F;gif\"></a>pixel art drwaing&#x2F;gif</h2><p><a href=\"https://www.pixilart.com/draw\">https://www.pixilart.com/draw</a></p>\n<h1 id=\"Music\"><a href=\"#Music\" class=\"headerlink\" title=\"Music\"></a>Music</h1><p><a href=\"https://github.com/jacbz/Lofi\">https://github.com/jacbz/Lofi</a></p>\n"},{"title":"Casual Inference","date":"2024-05-29T17:53:31.000Z","mathjax":true,"_content":"\n\n## 与贝叶斯有关的\n频率派的观点\n为 $p(X|\\theta)\\mathop{=}\\limits_{iid}\\prod\\limits _{i=1}^{N}p(x_{i}|\\theta)$ \n\n为了求常量 $\\theta$ 的大小,最大对数似然MLE的方法：\n$\\theta_{MLE}=\\mathop{argmax}\\limits _{\\theta}\\log p(X|\\theta)\\mathop{=}\\limits _{iid}\\mathop{argmax}\\limits _{\\theta}\\sum\\limits _{i=1}^{N}\\log p(x_{i}|\\theta)$\n\n\n贝叶斯派的观点\n$p(x|\\theta)$ 中的 $\\theta$ 不是一个常量。这个 $\\theta$ 满足一个预设的先验的分布 $\\theta\\sim p(\\theta)$\n\n$p(\\theta|X)=\\frac{p(X|\\theta)\\cdot p(\\theta)}{p(X)}=\\frac{p(X|\\theta)\\cdot p(\\theta)}{\\int\\limits _{\\theta}p(X|\\theta)\\cdot p(\\theta)d\\theta}$\n\n为了求 $\\theta$ 的值，我们要最大化这个参数后验MAP：\n\n$\\theta_{MAP}=\\mathop{argmax}\\limits _{\\theta}p(\\theta|X)=\\mathop{argmax}\\limits _{\\theta}p(X|\\theta)\\cdot p(\\theta)$\n\n\n\n\n\n\n\n\n\n#\n![alt text](2024-05-29-Casual-Inference/image.png)\n![alt text](2024-05-29-Casual-Inference/image-1.png)\n\n\n基础知识和概念，包括d-分离\ndo算子\n后门调整\n前门调整\n逆概率加权\n反事实\n因果关系发现中最基本的两类方法：基于独立性测试的方法，以及通过加性噪声模型的形式分析残差与预测者独立性关系的方法\n\n## chap1\npartition, law of total probability\nsumming up its probabilities over all Bi is called marginalizing over $B$, and the resulting probability P(A) is called the marginal probability of $A$.\n$P(A)=P(A,B_1)+P(A,B_2)+···+P(A,B_n)$\n\nDef conditional probabilities\n$P(A|B)=P(A,B)∕P(B)$\n\n\nindependence, giving no additional information\n$P(A,B)=P(A)P(B)$\n\n$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}$\n\n\n$P(A)=P(A|B_1)P(B_1)+P(A|B_2)P(B-2)+···+P(A|B_k)P(B_k)$\n\nSructual Casual Models SCM\nU exogenous variables, external to the model;\n\n\n\n\n## HMM\nhttps://www.yuque.com/bystander-wg876/yc5f72/dvgo5b\n机器学习模型可以从频率派和贝叶斯派\n频率派的方法中的核心是优化问题，而在贝叶斯派的方法中，核心是积分问题，也发展出来了一系列的积分方法如变分推断，MCMC 等\n### Def\n$\\lambda=(\\pi,A,B)$\n  \n- $\\pi$ is the initial state distribution\n- $o_t$ 来表示观测变量，$O$ 为观测序列，$V=\\{v_1,v_2,\\cdots,v_M\\}$ 表示观测的值域\n- $i_t$ 表示状态变量，$I$ 为状态序列，$Q=\\{q_1,q_2,\\cdots,q_N\\}$ 表示状态变量的值域\n- $A=(a_{ij}=p(i_{t+1}=q_j|i_t=q_i))$状态转移矩阵\n- $B=(b_j(k)=p(o_t=v_k|i_t=q_j))$ 发射矩阵\n- \n\n#### 两个基本假设\n1. 齐次 Markov 假设（未来只依赖于当前）： \n$p(i_{t+1}|i_t,i_{t-1},\\cdots,i_1,o_t,o_{t-1},\\cdots,o_1)=p(i_{t+1}|i_t)$\n2. 观测独立假设： \n$p(o_t|i_t,i_{t-1},\\cdots,i_1,o_{t-1},\\cdots,o_1)=p(o_t|i_t)$\n\n#### 三个基本问题\n1. Evaluation：$p(O|\\lambda)$，Forward-Backward \n2. Learning：$\\lambda=\\mathop{argmax}\\limits_{\\lambda}p(O|\\lambda)$，EM （Baum-Welch）\n3. Decoding：$I=\\mathop{argmax}\\limits_{I}p(I|O,\\lambda)$，Vierbi 算法\n  a. 预测问题：$p(i_{t+1}|o_1,o_2,\\cdots,o_t)$\n  b. 滤波问题：$p(i_t|o_1,o_2,\\cdots,o_t)$\n\n\n\n\n##\n##\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 有关MCMC\n一个比较基础的介绍： https://zhuanlan.zhihu.com/p/420214359\n- Abstract:\n  - 贝叶斯推断估计参数的方法是：我们可以算出参数$\\Theta$的分布函数$P(\\Theta)$，我们用参数分布的数学期望作为对参数的估计值\n  - MCMC的作用是：可以帮我们从任意（无论有没有解析形式的）分布上抽样一批数据，然后用这堆抽样数据的均值作为对这个分布期望的估计\n  - 我们用MCMC这种求期望的方法求参数分布期望的估计值，以此求出参数的估计值\n  - \n### 1 Monte Carlo Sampling\n如果$X$服从$f(x)$这个概率分布，我怎么获得$E(X)$\\\n最常见的一种Monte Carlo方法的使用场景就是：对随机变量进行充分多的采样后，使用这些采样的均值来估计总体的期望\n\n对于随机变量$X$，它的概率密度函数为$p(x)$，因此它的数学期望为\n$E(x)=\\int_{-\\infty}^{+\\infty}xp(x)dx$\\\n我们对于这个随机变量随机采样得到$n$个采样值$x_i$，根据大数定理，有\n$\\lim_{n\\rightarrow+\\infty}{\\frac1n\\sum_i^n{x_i}}=E(X)$\n\n### 2 Bayes & MCMC\n#### 2.1 Bayes Model: 参数$\\Theta$ ，Observed data: $D$\n   \n贝叶斯公式：$P(\\Theta|D)=\\frac1{P(D)}P(D|\\Theta)P(\\Theta)$\n\n由于$P(D)$是一个无关紧要的常数，因此上式往往直接写成一个正比关系式：\n$P(\\Theta|D)\\propto P(D|\\Theta)P(\\Theta)$\n\n在贝叶斯推断里：\n1. 通过$P(\\Theta|D)$来得到$\\Theta$的估计值\n2. 模型给出$P(D|\\Theta)$， 即likelihood$P(D|\\Theta)$\n3. 还可以通过$P(\\Theta)$来对参数的分布情况做一些先验的猜测。（如果你什么都不知道，$P(\\Theta)$自然可以猜一个均匀分布）\n\n#### 2.2 通过后验概率$P(\\Theta|D)$获取参数$\\Theta$的估计值\n想法：众数或者期望作为\n估计值\n1. 众数：$\\hat\\Theta=\\arg\\max_\\Theta{P(\\Theta|D)}$\n2. 期望：$\\hat\\Theta=\\int_\\Theta\\Theta P(\\Theta|D)d\\Theta$\n\n\nMCMC就是教我们怎么在一个没有解析形式的数据上「抽样几个数据算平均值」的方法\n\n\n### 3 Sampling 采样\n1. Uniform\n2. Gaussian: \n   Given $U_1,U_2$    \n     $$\n      Z_0 = \\sqrt{-2 \\ln U_1} \\cos(2\\pi U_2)\n      $$\n      $$\n      Z_1 = \\sqrt{-2 \\ln U_1} \\sin(2\\pi U_2)\n      $$\n3. Reject-Accept: 用于对很不规则的$f(x)$采样。具体细节没看\n4. \n\n\n### Markov Chain\n一个对马尔可夫状态讲的比较详细的文章：\nhttps://zhuanlan.zhihu.com/p/250146007\n#### Def\n转移概率矩阵：\n\n$P=\\begin{bmatrix}p_{11} & p_{12} &p_{13} \\\\ p_{21} & p_{22} &p_{23} \\\\ p_{31} & p_{32} &p_{33}\\end{bmatrix}$ \n\n其中 $p_{ij}=P(X_{t}=i|X_{t-1}=j)$ 。\n\n定义：马尔科夫链在 $t$ 时刻的概率分布称为 $t$ 时刻的状态分布：\n\n$\\pi (t)=\\begin{bmatrix}\\pi_{1}(t) \\\\ \\pi_{2}(t) \\\\ \\pi_{3}(t)\\end{bmatrix}$ \n\n其中  $\\pi_{i} (t)=P(X_{t}=i),i=1,2,...$ 。\n#### 性质\n1. 定理：给定一个马尔科夫链 $X=\\left\\{ X_0,X_1,...,X_t,... \\right\\}$ ， $t$ 时刻的状态分布：\n $\\pi=(\\pi_1,\\pi_2,...)$ 是 $X$ 的平稳分布的条件是 $\\pi=(\\pi_1,\\pi_2,...)$ 是下列方程组的解：\n $x_{i}=\\sum_{j}{p_{ij}x_j},i=1,2,...$ \n $x_i\\geq0,i=1,2,...$ \n $\\sum_{i}{x_{i}=1}$\n\n2. \n\n\n\n\n\n\n### MCMC具体细节\nhttps://zhuanlan.zhihu.com/p/253784711\n\n\n\n## Conditional Random Field(CRF)\n- HMM 生成模型\n- MEMM Maximum Entropy Markov Model\n\n![alt text](2024-05-29-Casual-Inference/image-4.png)\n\n\n\n- HMM:\n  $$ P(\\mathbf{X}, \\mathbf{Y} | \\lambda) = P(\\mathbf{Y} | \\lambda) P(\\mathbf{X} | \\mathbf{Y}, \\lambda) $$\n- MEMM:\n  $$ P(y_t | y_{t-1}, x_t) $$\n- CRF:\n  $$ P(\\mathbf{Y} | \\mathbf{X}, \\lambda) = \\frac{1}{Z(\\mathbf{X})} \\exp \\left( \\sum_{t=1}^{T} \\lambda_t f(y_t, y_{t-1}, \\mathbf{X}, t) \\right) $$\n\n\n\n\n## 概率图模型\nhttps://www.bilibili.com/video/BV1BW41117xo/?spm_id_from=333.999.0.0&vd_source=441679270dda23308fe16f3c5602b058\n\n\n### 概率和图\n概率图\n- 表示 Representation\n  - 有向图 Beyesian Netowrk\n  - 无向图\n  - 高斯图（连续的随机变量）\n- 推断 Inference\n  - 精确推断\n  - 近似推断\n    - 确定性推断（变分）\n    - 随机近似 MCMC\n- 学习\n  - 参数学习\n    - 完备数据\n    - 隐变量\n  - 结构学习\n\n\n\n高维随机变量\n  - sum: $P(x_1) = \\int P(x_1, x_2)dx_2$\n  - product: $P(x_1|x_2) = P(x_1|x_2)P(x_2)=P(x_2|x_1)P(x_1)$\n\n链式法则\n- $$P(X_1,X_2,...,X_n)=P(X_1)P(X_2|X_1)P(X_3|X_2,X_1)···P(X_n|X_{n-1},X_{n-2},...,X_1)$$\n\n\n全概率公式\n  - $P(X_i)=\\sum_{j}{P(X_i,X_j)}=\\sum_{j}{P(X_i|X_j)P(X_j)}$\n\n贝叶斯公式\n  - $P(X_i|X_j)=\\frac{P(X_i,X_j)}{P(X_j)}=\\frac{P(X_i|X_j)P(X_j)}{P(X_j)}$\n\n\n\n困境： \n维度高$P(X_1,X_2,...,X_n)$计算复杂\n- 1.假设$X_i$相互独立:\n  - $P(X_1,X_2,...,X_n)=\\prod_{i}{P(X_i)}$\n- 2.Markov Property(HMM齐次马尔可夫):\n  - $x_j\\perp x_i+1|x_i, j<i$ \n  - $P(X_1, X_2,...,X_n)=P(X_1)P(X_2|X_1)P(X_3|X_2,X_1)···P(X_n|X_{n-1},X_{n-2},...,X_1)$\n- 3.假设$X_i$条件独立: \n  - $x_a\\perp x_b|x_c$\n  - $P(X_1,X_2,...,X_n)=\\prod_{i}{P(X_i|X_{i-1})}$\n#### 概率补充知识\n指数族分布\n- 充分统计量$\\phi(x)$\n- 共轭\n- 最大熵\n- 广义线性模型\n- 概率图模型\n- 变分推断\n  \n充分统计量\n- $P(x|\\eta)=h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))$\n  - $h(x)$: base measure\n  - $\\eta$: parameter 参数向量\n  - $\\phi(x)$: feature function\n  - $A(\\eta)$： log partition function 配分函数\n- $P(x|\\theta)=\\frac{1}{z}\\hat P(x|\\theta)$\n  - $z=\\int \\hat P(x|\\theta)dx$ 归一化因子\n- $P(x|\\eta)=h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))$\n  - $=\\frac{1}{exp(A(\\eta))}h(x)exp(\\eta^T\\phi(x))$\n  - $=\\frac{1}{z}\\hat P(x|\\eta)$\n    - $\\hat P(x|\\eta)=h(x)exp(\\eta^T\\phi(x))$\n    - $z=exp(A(\\eta))$\n\n共轭, 先后验分布同组方便计算\n- $P(\\theta|x)=\\frac{P(x|\\theta)P(\\theta)}{P(x)}$\n- $P(\\theta|x)$和$P(x|\\theta)$属于同一个指数族\n- $P(\\theta|x)$的参数是$P(\\theta|x)$的参数的函数\n\n先验\n- 共轭 - 计算方便\n- 最大熵 无信息先验\n- Jerrif\n\n广义线性模型\n- 线性组合 $w^Tx$\n- Link funciton ->aactivation function\n- 指数分布 $y|x\\sim$指数组分布（$Bernulli, Poisson, N(\\mu, \\Sigma)$）\n\n##### Gaussian\n- $P(x|\\mu,\\Sigma)=\\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)$\n- $\\eta=\n\\left(\\!\n    \\begin{array}{c}\n      \\eta_1 =\\frac{\\mu}{\\sigma^2}\\\\\n      \\eta_2=-\\frac{1}{\\sigma^2}\n    \\end{array}\n    \\!\\right)$\n- $\\phi(x)=\\left(\\!\n    \\begin{array}{c}\n      x\\\\\n      x^2\n    \\end{array}\n    \\!\\right)$\n- $A(\\eta)=-\\frac{\\eta_1^2}{4\\eta_2}+\\frac{1}{2}\\ln(-\\frac{\\pi}{\\eta_2})$\n\n####\n- $P(x | \\eta) = h(x) \\exp (\\eta^T \\phi(x) - A(\\eta))$\n  - $\\eta$: 参数 (parameter)\n  - $\\phi(x)$: 充分统计量 (sufficient statistics)\n  - $A(\\eta)$: 对数配分函数 (log partition function)\n\n1. $A'(\\eta) = \\mathbb{E}_{P(x|\\eta)}[\\phi(x)]$\n2. $A''(\\eta) = \\text{Var}[\\phi(x)]$\n3. $A(\\eta)$ 是凸函数 (convex function)\n\n对这个函数求导\n- $\\exp(A(\\eta)) = \\int h(x) \\exp(\\eta^T \\phi(x)) \\, dx$\n- $A'(\\eta) = \\frac{\\partial}{\\partial \\eta} \\log \\left( \\int h(x) \\exp(\\eta^T \\phi(x)) \\, dx \\right)$\n- $A'(\\eta) = \\int \\frac{h(x) \\exp(\\eta^T \\phi(x)) \\phi(x) \\, dx}{\\exp(A(\\eta))}$\n- $A'(\\eta) = \\int P(x | \\eta) \\phi(x) \\, dx = \\mathbb{E}_{P(x|\\eta)}[\\phi(x)]$\n\n##### MLE\n$D=\\{x_1, \\cdots, x_N\\}$\n\n$\\eta_{MLE}=\\text{argmax  } log(P(D|\\eta))$\n- $=\\sum_{i=1}^N\\text{argmax  }log\\cdot h(x_i)+(\\eta^T \\phi(x_i) - A(\\eta))$\n- - $=\\sum_{i=1}^N\\text{argmax  }\\eta^T \\phi(x_i) - A(\\eta)$\n\nset $\\frac{\\partial \\eta_{MLE}}{\\partial \\eta}=0$\n- $\\sum \\phi(x_i)-NA'(\\eta)=0$\n\n##### Entorpy 最大熵\n信息熵 $-log\\ p$\n熵，（对可能性的衡量）\n- $E_{p(x)}[-log\\ p]=\\int -p(x)log\\ p(x)dx= \\sum -p(x)log\\ p(x)$\n  \n\n\n- $\\hat p_i=\\text{argmax } H(p)$ \n- 拉格朗日$\\mathcal{L}(p, \\lambda)=\\sum p_ilog\\ p_i$\n  - $\\frac{\\partial \\mathcal{L}}{\\partial p_i}=log\\ p_i+1-\\lambda$\n  - $\\hat p_i=exp(\\lambda-1)=1/k$\n\n##### 经验分布\n$Data = \\{x_1, \\cdots, x_N\\}$\n\n- **频率分布**： $P(x_1, x_2, \\ldots, x_n) \\approx \\hat{P}(x) = \\frac{\\text{count}(x)}{N}$\n- **经验期望**： $\\mathbb{E}_p[f(x)] = \\Delta \\approx \\frac{1}{N} \\sum_{i=1}^N f(x_i)$\n\n最大熵问题的求解\n$$\n\\begin{aligned}\n\\min_{p(x)} & \\sum_x p(x) \\log p(x) \\\\\n\\text{subject to} & \\sum_x p(x) = 1 \\\\\n& \\mathbb{E}_p[f(x)] = \\mathbb{E}_{\\hat{p}}[f(x)] = \\Delta\n\\end{aligned}\n$$\n\n拉格朗日乘数法求解\n$$\n\\begin{aligned}\nL(p, \\lambda, \\eta) &= \\sum_x p(x) \\log p(x) + \\lambda (1 - \\sum_x p(x)) + \\eta (\\Delta - \\sum_x p(x) f(x)) \\\\\n\\frac{\\partial}{\\partial p(x)} &= \\log p(x) + 1 - \\lambda_0 - \\lambda f(x) = 0 \\\\\np(x) &= \\exp(\\lambda_1 f(x) + \\lambda_0 - 1) \\\\\n&= \\frac{\\exp(\\eta^T f(x))}{Z(\\eta)}\n\\end{aligned}\n$$\n\n### 贝叶斯网络\n有向无环图\n因子分解\n- $P(X_1,X_2,...,X_n)=\\prod_{i}{P(X_i|Pa(X_i))}$\n- $P(X_i|Pa(X_i))$是局部概率分布\n- $Pa(X_i)$是$X_i$的父节点集合\n#### 三种模型\n##### tail-to-tail\n  ```mermaid\n  graph LR;\n    a--> b\n    a--> c\n  ```\n因子分解：\n- $P(a, b, c)=P(a)P(b|a)P(c|a)$\n\n链式法则：\n- $P(a, b, c)=P(a)P(b|a)P(c|a, b)$\n  \n$\\implies P(c|a)=P(c|a, b)\\implies c\\perp b |a$\n若$b$ 被观测则路径被阻塞： \n\n##### head-to-tail\n  ```mermaid\n  graph LR;\n    a -->b \n    b -->c \n  ```\n$a\\perp c |b$\n若$b$ 被观测则路径被阻塞： \n\n##### head-to-head\n  ```mermaid\n  graph LR;\n    b--> c\n    a--> c\n  ```\n- $P(a, b, c)=P(a)P(b)P(c|a, b)$\n- $P(a, b, c)=P(a)P(b|a)P(c | a, b)$\n\n$\\implies P(b)=P(b|a)\\implies a\\perp b$\n若$b$ 被观测则路径被连通：\n\n#### D-seperation\n  ```mermaid\n  graph LR;\n    a  --> b1\n    a  --> b2\n    a  --> b*\n    b1 --> c\n    b2 --> c\n    c  --> b*\n  ```\n- 如果$b1, b2\\in B$被观测了\n，那么$a$和$c$被阻断，\n- 但是$b*$没有被观测到,且$b*$的后续节点都不在$b$中\n$a\\perp c|b$\n\n![alt text](2024-05-29-Casual-Inference/image-2.png)\n马尔可夫毯(Markov Blanket)\n- $x_{pa(i)}$：$x_i$的父节点\n- $x_{child(i)}$: childs of $x_i$\n- $x_{pa(child(i))}$: parent of $x_{child(i)}$\n- $x_{-i}=x/x_i$ 表示除了 $x_i$ 以外的所有变量。\n  - 和$x$有关:$\\Delta$\n    - $P(x_i|x_{Pa(i)})=f(\\bar \\Delta)$\n  - 和$x$无关:$\\bar \\Delta$\n\n马尔可夫毯的作用是在给定马尔可夫毯内所有节点的情况下，$x_i$ 与网络中其他节点条件独立。\n\n$$\nP(x_i | x_{-i}) = \\frac{P(x_i, x_{-i})}{P(x_{-i})} = \\frac{P(x)}{\\int_{x_i} P(x_{-i})} = \\frac{ \\int_{x_i} P(x) \\, dx_i }{ \\int_{x_i} P(x_j | x_{\\text{pa}(j)}) \\, dx_i }\n$$\n\n\n$$\nP(x_{\\text{child}(i)} | x_i, x_{\\text{Parent}(\\text{Child}(i))})\n$$\n\n#### 贝叶斯网络 Beyesian Network\nNB\n  ```mermaid\n  graph LR;\n    y--> x1 \n    y--> xp\n  ```\n\nGMM\n  ```mermaid\n  graph LR;\n    z--> x\n\n  ```\nBeyesian Network\n- 单一： Naive Bayes\n  - p维： $P(x|y)=\\prod^p_{i=1}P(x_i|y=1)$\n  - $x_1\\perp x_2|y$\n- 混合：GMM\n  - Z discrete, z=1,2,3,4\n- 时间\n  - Markov Chain\n  - Gaussian Process(无限维分布)\n- 连续： Gaussian Network\n\n动态模型\n- HMM 离散\n- LDS Kalman Filter 连续线性\n- Particle filter 非线性非高斯\n\n\n\n### Markov Network\n条件独立性\n- 全局 Global Markov Property\n  - $X_A \\perp X_C \\mid X_B$\n  - 如果集合 $X_A$ 和 $X_C$ 被集合 $X_B$ 分隔开，那么 $X_A$ 和 $X_C$ 是条件独立的\n- 局部 Local Markov Property\n  - $a \\perp \\{Non-Neighbour\\} \\mid \\{Neighbour\\}$\n  - { }：集合\n- 成对 Pairwise Markov Property\n  - $x_i \\perp x_j \\mid x_{-ij}$\n  - 如果节点 $x_i$ 和 $x_j$ 直接相连，那么在给定其他所有节点的情况下，$x_i$ 和 $x_j$ 是条件独立的\n\n\n\n#### Factorization\n团: Clique\n最大团: Maximal Clique\n$$\nP(X) = \\frac{1}{Z} \\prod_{i=1}^K \\psi(X_{C_i})\n$$\n- $c_i$ 最大团\n- $x_{c_i}$: 最大团随机变量集合\n- $\\psi(x_{c_i})$: 势函数\n- $Z$:\n  - $Z = \\sum_{X} \\prod_{i=1}^K \\psi(X_{C_i})$\n- $\\psi(X_{C_i})$ 是定义在最大团 $C_i$ 上的因子函数\n\n何弃疗\n![alt text](2024-05-29-Casual-Inference/image-3.png)\n\n### Inference\n\n- 联合概率 Joint Probability\n  - $P(X) = P(x_1, x_2, \\ldots, x_p)$\n\n- 边缘概率 Marginal Probability\n  - $P(x) = \\sum_{x_j} P(x_j)$\n\n- 条件概率 Conditional Probability\n  - $P(x_i | x_j)$, 其中$x_j = \\{x \\backslash x_i\\}$\n\n- 最大后验概率估计 MAP Inference\n  - $\\hat{z} = \\arg \\max_z P(z | x) \\propto \\arg \\max_z P(z, x)$\n\n---\n\n-  精确推断 Exact Inference\n   - Variable Elimination (VE)\n   - Belief Propagation (BP) → Sum-Product Algorithm (求和-乘积算法)\n   -  Junction Tree Algorithm (树形算法)\n\n- 近似推断 Approximate Inference\n  -  Loop Belief Propagation (循环信念传播)\n  -  Monte Carlo Inference: Importance Sampling, MCMC (蒙特卡罗推断：重要性采样，MCMC)\n  -  Variational Inference (变分推断)\n\n\n#### Variable Elimination\n\n$P(x) = \\prod_{i} \\phi_i(x_i)$\n\n#### 示例\n\n假设我们有四个二值随机变量 $a, b, c, d\\in {0,1}$。我们想计算边缘概率 $P(d)$。\n$a\\rightarrow b \\rightarrow c \\rightarrow d$\n1. 展开联合分布：\n   - $P(d) = \\sum_{a, b, c} P(a, b, c, d)$\n\n2. Chain rule\n   - $P(a, b, c, d) = P(a) P(b | a) P(c | b) P(d | c)$\n\n3. 1->2\n   - $P(d) = \\sum_{a, b, c} P(a) P(b | a) P(c | b) P(d | c)$\n     - $= \\sum_{b, c} P(d | c) \\left( \\sum_{a} P(a) P(b | a) \\right) P(c | b)$\n\n4. 定义新的因子函数：\n   - $\\phi_1(b, c) = \\sum_{a} P(a) P(b | a)$\n\n5. 最终得到：\n   - $P(d) = \\sum_{c} P(d | c) \\left( \\sum_{b} \\phi_1(b, c) P(c | b) \\right)$\n\n6. 得到另一个因子函数 $\\phi_2(c, d)$：\n   - $P(d) = \\sum_{c} \\phi_2(c, d)$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/2024-05-29-Casual-Inference.md","raw":"\n---\ntitle: Casual Inference\ndate: 2024-05-29 13:53:31\ntags:\nmathjax: true\n---\n\n\n## 与贝叶斯有关的\n频率派的观点\n为 $p(X|\\theta)\\mathop{=}\\limits_{iid}\\prod\\limits _{i=1}^{N}p(x_{i}|\\theta)$ \n\n为了求常量 $\\theta$ 的大小,最大对数似然MLE的方法：\n$\\theta_{MLE}=\\mathop{argmax}\\limits _{\\theta}\\log p(X|\\theta)\\mathop{=}\\limits _{iid}\\mathop{argmax}\\limits _{\\theta}\\sum\\limits _{i=1}^{N}\\log p(x_{i}|\\theta)$\n\n\n贝叶斯派的观点\n$p(x|\\theta)$ 中的 $\\theta$ 不是一个常量。这个 $\\theta$ 满足一个预设的先验的分布 $\\theta\\sim p(\\theta)$\n\n$p(\\theta|X)=\\frac{p(X|\\theta)\\cdot p(\\theta)}{p(X)}=\\frac{p(X|\\theta)\\cdot p(\\theta)}{\\int\\limits _{\\theta}p(X|\\theta)\\cdot p(\\theta)d\\theta}$\n\n为了求 $\\theta$ 的值，我们要最大化这个参数后验MAP：\n\n$\\theta_{MAP}=\\mathop{argmax}\\limits _{\\theta}p(\\theta|X)=\\mathop{argmax}\\limits _{\\theta}p(X|\\theta)\\cdot p(\\theta)$\n\n\n\n\n\n\n\n\n\n#\n![alt text](2024-05-29-Casual-Inference/image.png)\n![alt text](2024-05-29-Casual-Inference/image-1.png)\n\n\n基础知识和概念，包括d-分离\ndo算子\n后门调整\n前门调整\n逆概率加权\n反事实\n因果关系发现中最基本的两类方法：基于独立性测试的方法，以及通过加性噪声模型的形式分析残差与预测者独立性关系的方法\n\n## chap1\npartition, law of total probability\nsumming up its probabilities over all Bi is called marginalizing over $B$, and the resulting probability P(A) is called the marginal probability of $A$.\n$P(A)=P(A,B_1)+P(A,B_2)+···+P(A,B_n)$\n\nDef conditional probabilities\n$P(A|B)=P(A,B)∕P(B)$\n\n\nindependence, giving no additional information\n$P(A,B)=P(A)P(B)$\n\n$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}$\n\n\n$P(A)=P(A|B_1)P(B_1)+P(A|B_2)P(B-2)+···+P(A|B_k)P(B_k)$\n\nSructual Casual Models SCM\nU exogenous variables, external to the model;\n\n\n\n\n## HMM\nhttps://www.yuque.com/bystander-wg876/yc5f72/dvgo5b\n机器学习模型可以从频率派和贝叶斯派\n频率派的方法中的核心是优化问题，而在贝叶斯派的方法中，核心是积分问题，也发展出来了一系列的积分方法如变分推断，MCMC 等\n### Def\n$\\lambda=(\\pi,A,B)$\n  \n- $\\pi$ is the initial state distribution\n- $o_t$ 来表示观测变量，$O$ 为观测序列，$V=\\{v_1,v_2,\\cdots,v_M\\}$ 表示观测的值域\n- $i_t$ 表示状态变量，$I$ 为状态序列，$Q=\\{q_1,q_2,\\cdots,q_N\\}$ 表示状态变量的值域\n- $A=(a_{ij}=p(i_{t+1}=q_j|i_t=q_i))$状态转移矩阵\n- $B=(b_j(k)=p(o_t=v_k|i_t=q_j))$ 发射矩阵\n- \n\n#### 两个基本假设\n1. 齐次 Markov 假设（未来只依赖于当前）： \n$p(i_{t+1}|i_t,i_{t-1},\\cdots,i_1,o_t,o_{t-1},\\cdots,o_1)=p(i_{t+1}|i_t)$\n2. 观测独立假设： \n$p(o_t|i_t,i_{t-1},\\cdots,i_1,o_{t-1},\\cdots,o_1)=p(o_t|i_t)$\n\n#### 三个基本问题\n1. Evaluation：$p(O|\\lambda)$，Forward-Backward \n2. Learning：$\\lambda=\\mathop{argmax}\\limits_{\\lambda}p(O|\\lambda)$，EM （Baum-Welch）\n3. Decoding：$I=\\mathop{argmax}\\limits_{I}p(I|O,\\lambda)$，Vierbi 算法\n  a. 预测问题：$p(i_{t+1}|o_1,o_2,\\cdots,o_t)$\n  b. 滤波问题：$p(i_t|o_1,o_2,\\cdots,o_t)$\n\n\n\n\n##\n##\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 有关MCMC\n一个比较基础的介绍： https://zhuanlan.zhihu.com/p/420214359\n- Abstract:\n  - 贝叶斯推断估计参数的方法是：我们可以算出参数$\\Theta$的分布函数$P(\\Theta)$，我们用参数分布的数学期望作为对参数的估计值\n  - MCMC的作用是：可以帮我们从任意（无论有没有解析形式的）分布上抽样一批数据，然后用这堆抽样数据的均值作为对这个分布期望的估计\n  - 我们用MCMC这种求期望的方法求参数分布期望的估计值，以此求出参数的估计值\n  - \n### 1 Monte Carlo Sampling\n如果$X$服从$f(x)$这个概率分布，我怎么获得$E(X)$\\\n最常见的一种Monte Carlo方法的使用场景就是：对随机变量进行充分多的采样后，使用这些采样的均值来估计总体的期望\n\n对于随机变量$X$，它的概率密度函数为$p(x)$，因此它的数学期望为\n$E(x)=\\int_{-\\infty}^{+\\infty}xp(x)dx$\\\n我们对于这个随机变量随机采样得到$n$个采样值$x_i$，根据大数定理，有\n$\\lim_{n\\rightarrow+\\infty}{\\frac1n\\sum_i^n{x_i}}=E(X)$\n\n### 2 Bayes & MCMC\n#### 2.1 Bayes Model: 参数$\\Theta$ ，Observed data: $D$\n   \n贝叶斯公式：$P(\\Theta|D)=\\frac1{P(D)}P(D|\\Theta)P(\\Theta)$\n\n由于$P(D)$是一个无关紧要的常数，因此上式往往直接写成一个正比关系式：\n$P(\\Theta|D)\\propto P(D|\\Theta)P(\\Theta)$\n\n在贝叶斯推断里：\n1. 通过$P(\\Theta|D)$来得到$\\Theta$的估计值\n2. 模型给出$P(D|\\Theta)$， 即likelihood$P(D|\\Theta)$\n3. 还可以通过$P(\\Theta)$来对参数的分布情况做一些先验的猜测。（如果你什么都不知道，$P(\\Theta)$自然可以猜一个均匀分布）\n\n#### 2.2 通过后验概率$P(\\Theta|D)$获取参数$\\Theta$的估计值\n想法：众数或者期望作为\n估计值\n1. 众数：$\\hat\\Theta=\\arg\\max_\\Theta{P(\\Theta|D)}$\n2. 期望：$\\hat\\Theta=\\int_\\Theta\\Theta P(\\Theta|D)d\\Theta$\n\n\nMCMC就是教我们怎么在一个没有解析形式的数据上「抽样几个数据算平均值」的方法\n\n\n### 3 Sampling 采样\n1. Uniform\n2. Gaussian: \n   Given $U_1,U_2$    \n     $$\n      Z_0 = \\sqrt{-2 \\ln U_1} \\cos(2\\pi U_2)\n      $$\n      $$\n      Z_1 = \\sqrt{-2 \\ln U_1} \\sin(2\\pi U_2)\n      $$\n3. Reject-Accept: 用于对很不规则的$f(x)$采样。具体细节没看\n4. \n\n\n### Markov Chain\n一个对马尔可夫状态讲的比较详细的文章：\nhttps://zhuanlan.zhihu.com/p/250146007\n#### Def\n转移概率矩阵：\n\n$P=\\begin{bmatrix}p_{11} & p_{12} &p_{13} \\\\ p_{21} & p_{22} &p_{23} \\\\ p_{31} & p_{32} &p_{33}\\end{bmatrix}$ \n\n其中 $p_{ij}=P(X_{t}=i|X_{t-1}=j)$ 。\n\n定义：马尔科夫链在 $t$ 时刻的概率分布称为 $t$ 时刻的状态分布：\n\n$\\pi (t)=\\begin{bmatrix}\\pi_{1}(t) \\\\ \\pi_{2}(t) \\\\ \\pi_{3}(t)\\end{bmatrix}$ \n\n其中  $\\pi_{i} (t)=P(X_{t}=i),i=1,2,...$ 。\n#### 性质\n1. 定理：给定一个马尔科夫链 $X=\\left\\{ X_0,X_1,...,X_t,... \\right\\}$ ， $t$ 时刻的状态分布：\n $\\pi=(\\pi_1,\\pi_2,...)$ 是 $X$ 的平稳分布的条件是 $\\pi=(\\pi_1,\\pi_2,...)$ 是下列方程组的解：\n $x_{i}=\\sum_{j}{p_{ij}x_j},i=1,2,...$ \n $x_i\\geq0,i=1,2,...$ \n $\\sum_{i}{x_{i}=1}$\n\n2. \n\n\n\n\n\n\n### MCMC具体细节\nhttps://zhuanlan.zhihu.com/p/253784711\n\n\n\n## Conditional Random Field(CRF)\n- HMM 生成模型\n- MEMM Maximum Entropy Markov Model\n\n![alt text](2024-05-29-Casual-Inference/image-4.png)\n\n\n\n- HMM:\n  $$ P(\\mathbf{X}, \\mathbf{Y} | \\lambda) = P(\\mathbf{Y} | \\lambda) P(\\mathbf{X} | \\mathbf{Y}, \\lambda) $$\n- MEMM:\n  $$ P(y_t | y_{t-1}, x_t) $$\n- CRF:\n  $$ P(\\mathbf{Y} | \\mathbf{X}, \\lambda) = \\frac{1}{Z(\\mathbf{X})} \\exp \\left( \\sum_{t=1}^{T} \\lambda_t f(y_t, y_{t-1}, \\mathbf{X}, t) \\right) $$\n\n\n\n\n## 概率图模型\nhttps://www.bilibili.com/video/BV1BW41117xo/?spm_id_from=333.999.0.0&vd_source=441679270dda23308fe16f3c5602b058\n\n\n### 概率和图\n概率图\n- 表示 Representation\n  - 有向图 Beyesian Netowrk\n  - 无向图\n  - 高斯图（连续的随机变量）\n- 推断 Inference\n  - 精确推断\n  - 近似推断\n    - 确定性推断（变分）\n    - 随机近似 MCMC\n- 学习\n  - 参数学习\n    - 完备数据\n    - 隐变量\n  - 结构学习\n\n\n\n高维随机变量\n  - sum: $P(x_1) = \\int P(x_1, x_2)dx_2$\n  - product: $P(x_1|x_2) = P(x_1|x_2)P(x_2)=P(x_2|x_1)P(x_1)$\n\n链式法则\n- $$P(X_1,X_2,...,X_n)=P(X_1)P(X_2|X_1)P(X_3|X_2,X_1)···P(X_n|X_{n-1},X_{n-2},...,X_1)$$\n\n\n全概率公式\n  - $P(X_i)=\\sum_{j}{P(X_i,X_j)}=\\sum_{j}{P(X_i|X_j)P(X_j)}$\n\n贝叶斯公式\n  - $P(X_i|X_j)=\\frac{P(X_i,X_j)}{P(X_j)}=\\frac{P(X_i|X_j)P(X_j)}{P(X_j)}$\n\n\n\n困境： \n维度高$P(X_1,X_2,...,X_n)$计算复杂\n- 1.假设$X_i$相互独立:\n  - $P(X_1,X_2,...,X_n)=\\prod_{i}{P(X_i)}$\n- 2.Markov Property(HMM齐次马尔可夫):\n  - $x_j\\perp x_i+1|x_i, j<i$ \n  - $P(X_1, X_2,...,X_n)=P(X_1)P(X_2|X_1)P(X_3|X_2,X_1)···P(X_n|X_{n-1},X_{n-2},...,X_1)$\n- 3.假设$X_i$条件独立: \n  - $x_a\\perp x_b|x_c$\n  - $P(X_1,X_2,...,X_n)=\\prod_{i}{P(X_i|X_{i-1})}$\n#### 概率补充知识\n指数族分布\n- 充分统计量$\\phi(x)$\n- 共轭\n- 最大熵\n- 广义线性模型\n- 概率图模型\n- 变分推断\n  \n充分统计量\n- $P(x|\\eta)=h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))$\n  - $h(x)$: base measure\n  - $\\eta$: parameter 参数向量\n  - $\\phi(x)$: feature function\n  - $A(\\eta)$： log partition function 配分函数\n- $P(x|\\theta)=\\frac{1}{z}\\hat P(x|\\theta)$\n  - $z=\\int \\hat P(x|\\theta)dx$ 归一化因子\n- $P(x|\\eta)=h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))$\n  - $=\\frac{1}{exp(A(\\eta))}h(x)exp(\\eta^T\\phi(x))$\n  - $=\\frac{1}{z}\\hat P(x|\\eta)$\n    - $\\hat P(x|\\eta)=h(x)exp(\\eta^T\\phi(x))$\n    - $z=exp(A(\\eta))$\n\n共轭, 先后验分布同组方便计算\n- $P(\\theta|x)=\\frac{P(x|\\theta)P(\\theta)}{P(x)}$\n- $P(\\theta|x)$和$P(x|\\theta)$属于同一个指数族\n- $P(\\theta|x)$的参数是$P(\\theta|x)$的参数的函数\n\n先验\n- 共轭 - 计算方便\n- 最大熵 无信息先验\n- Jerrif\n\n广义线性模型\n- 线性组合 $w^Tx$\n- Link funciton ->aactivation function\n- 指数分布 $y|x\\sim$指数组分布（$Bernulli, Poisson, N(\\mu, \\Sigma)$）\n\n##### Gaussian\n- $P(x|\\mu,\\Sigma)=\\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)$\n- $\\eta=\n\\left(\\!\n    \\begin{array}{c}\n      \\eta_1 =\\frac{\\mu}{\\sigma^2}\\\\\n      \\eta_2=-\\frac{1}{\\sigma^2}\n    \\end{array}\n    \\!\\right)$\n- $\\phi(x)=\\left(\\!\n    \\begin{array}{c}\n      x\\\\\n      x^2\n    \\end{array}\n    \\!\\right)$\n- $A(\\eta)=-\\frac{\\eta_1^2}{4\\eta_2}+\\frac{1}{2}\\ln(-\\frac{\\pi}{\\eta_2})$\n\n####\n- $P(x | \\eta) = h(x) \\exp (\\eta^T \\phi(x) - A(\\eta))$\n  - $\\eta$: 参数 (parameter)\n  - $\\phi(x)$: 充分统计量 (sufficient statistics)\n  - $A(\\eta)$: 对数配分函数 (log partition function)\n\n1. $A'(\\eta) = \\mathbb{E}_{P(x|\\eta)}[\\phi(x)]$\n2. $A''(\\eta) = \\text{Var}[\\phi(x)]$\n3. $A(\\eta)$ 是凸函数 (convex function)\n\n对这个函数求导\n- $\\exp(A(\\eta)) = \\int h(x) \\exp(\\eta^T \\phi(x)) \\, dx$\n- $A'(\\eta) = \\frac{\\partial}{\\partial \\eta} \\log \\left( \\int h(x) \\exp(\\eta^T \\phi(x)) \\, dx \\right)$\n- $A'(\\eta) = \\int \\frac{h(x) \\exp(\\eta^T \\phi(x)) \\phi(x) \\, dx}{\\exp(A(\\eta))}$\n- $A'(\\eta) = \\int P(x | \\eta) \\phi(x) \\, dx = \\mathbb{E}_{P(x|\\eta)}[\\phi(x)]$\n\n##### MLE\n$D=\\{x_1, \\cdots, x_N\\}$\n\n$\\eta_{MLE}=\\text{argmax  } log(P(D|\\eta))$\n- $=\\sum_{i=1}^N\\text{argmax  }log\\cdot h(x_i)+(\\eta^T \\phi(x_i) - A(\\eta))$\n- - $=\\sum_{i=1}^N\\text{argmax  }\\eta^T \\phi(x_i) - A(\\eta)$\n\nset $\\frac{\\partial \\eta_{MLE}}{\\partial \\eta}=0$\n- $\\sum \\phi(x_i)-NA'(\\eta)=0$\n\n##### Entorpy 最大熵\n信息熵 $-log\\ p$\n熵，（对可能性的衡量）\n- $E_{p(x)}[-log\\ p]=\\int -p(x)log\\ p(x)dx= \\sum -p(x)log\\ p(x)$\n  \n\n\n- $\\hat p_i=\\text{argmax } H(p)$ \n- 拉格朗日$\\mathcal{L}(p, \\lambda)=\\sum p_ilog\\ p_i$\n  - $\\frac{\\partial \\mathcal{L}}{\\partial p_i}=log\\ p_i+1-\\lambda$\n  - $\\hat p_i=exp(\\lambda-1)=1/k$\n\n##### 经验分布\n$Data = \\{x_1, \\cdots, x_N\\}$\n\n- **频率分布**： $P(x_1, x_2, \\ldots, x_n) \\approx \\hat{P}(x) = \\frac{\\text{count}(x)}{N}$\n- **经验期望**： $\\mathbb{E}_p[f(x)] = \\Delta \\approx \\frac{1}{N} \\sum_{i=1}^N f(x_i)$\n\n最大熵问题的求解\n$$\n\\begin{aligned}\n\\min_{p(x)} & \\sum_x p(x) \\log p(x) \\\\\n\\text{subject to} & \\sum_x p(x) = 1 \\\\\n& \\mathbb{E}_p[f(x)] = \\mathbb{E}_{\\hat{p}}[f(x)] = \\Delta\n\\end{aligned}\n$$\n\n拉格朗日乘数法求解\n$$\n\\begin{aligned}\nL(p, \\lambda, \\eta) &= \\sum_x p(x) \\log p(x) + \\lambda (1 - \\sum_x p(x)) + \\eta (\\Delta - \\sum_x p(x) f(x)) \\\\\n\\frac{\\partial}{\\partial p(x)} &= \\log p(x) + 1 - \\lambda_0 - \\lambda f(x) = 0 \\\\\np(x) &= \\exp(\\lambda_1 f(x) + \\lambda_0 - 1) \\\\\n&= \\frac{\\exp(\\eta^T f(x))}{Z(\\eta)}\n\\end{aligned}\n$$\n\n### 贝叶斯网络\n有向无环图\n因子分解\n- $P(X_1,X_2,...,X_n)=\\prod_{i}{P(X_i|Pa(X_i))}$\n- $P(X_i|Pa(X_i))$是局部概率分布\n- $Pa(X_i)$是$X_i$的父节点集合\n#### 三种模型\n##### tail-to-tail\n  ```mermaid\n  graph LR;\n    a--> b\n    a--> c\n  ```\n因子分解：\n- $P(a, b, c)=P(a)P(b|a)P(c|a)$\n\n链式法则：\n- $P(a, b, c)=P(a)P(b|a)P(c|a, b)$\n  \n$\\implies P(c|a)=P(c|a, b)\\implies c\\perp b |a$\n若$b$ 被观测则路径被阻塞： \n\n##### head-to-tail\n  ```mermaid\n  graph LR;\n    a -->b \n    b -->c \n  ```\n$a\\perp c |b$\n若$b$ 被观测则路径被阻塞： \n\n##### head-to-head\n  ```mermaid\n  graph LR;\n    b--> c\n    a--> c\n  ```\n- $P(a, b, c)=P(a)P(b)P(c|a, b)$\n- $P(a, b, c)=P(a)P(b|a)P(c | a, b)$\n\n$\\implies P(b)=P(b|a)\\implies a\\perp b$\n若$b$ 被观测则路径被连通：\n\n#### D-seperation\n  ```mermaid\n  graph LR;\n    a  --> b1\n    a  --> b2\n    a  --> b*\n    b1 --> c\n    b2 --> c\n    c  --> b*\n  ```\n- 如果$b1, b2\\in B$被观测了\n，那么$a$和$c$被阻断，\n- 但是$b*$没有被观测到,且$b*$的后续节点都不在$b$中\n$a\\perp c|b$\n\n![alt text](2024-05-29-Casual-Inference/image-2.png)\n马尔可夫毯(Markov Blanket)\n- $x_{pa(i)}$：$x_i$的父节点\n- $x_{child(i)}$: childs of $x_i$\n- $x_{pa(child(i))}$: parent of $x_{child(i)}$\n- $x_{-i}=x/x_i$ 表示除了 $x_i$ 以外的所有变量。\n  - 和$x$有关:$\\Delta$\n    - $P(x_i|x_{Pa(i)})=f(\\bar \\Delta)$\n  - 和$x$无关:$\\bar \\Delta$\n\n马尔可夫毯的作用是在给定马尔可夫毯内所有节点的情况下，$x_i$ 与网络中其他节点条件独立。\n\n$$\nP(x_i | x_{-i}) = \\frac{P(x_i, x_{-i})}{P(x_{-i})} = \\frac{P(x)}{\\int_{x_i} P(x_{-i})} = \\frac{ \\int_{x_i} P(x) \\, dx_i }{ \\int_{x_i} P(x_j | x_{\\text{pa}(j)}) \\, dx_i }\n$$\n\n\n$$\nP(x_{\\text{child}(i)} | x_i, x_{\\text{Parent}(\\text{Child}(i))})\n$$\n\n#### 贝叶斯网络 Beyesian Network\nNB\n  ```mermaid\n  graph LR;\n    y--> x1 \n    y--> xp\n  ```\n\nGMM\n  ```mermaid\n  graph LR;\n    z--> x\n\n  ```\nBeyesian Network\n- 单一： Naive Bayes\n  - p维： $P(x|y)=\\prod^p_{i=1}P(x_i|y=1)$\n  - $x_1\\perp x_2|y$\n- 混合：GMM\n  - Z discrete, z=1,2,3,4\n- 时间\n  - Markov Chain\n  - Gaussian Process(无限维分布)\n- 连续： Gaussian Network\n\n动态模型\n- HMM 离散\n- LDS Kalman Filter 连续线性\n- Particle filter 非线性非高斯\n\n\n\n### Markov Network\n条件独立性\n- 全局 Global Markov Property\n  - $X_A \\perp X_C \\mid X_B$\n  - 如果集合 $X_A$ 和 $X_C$ 被集合 $X_B$ 分隔开，那么 $X_A$ 和 $X_C$ 是条件独立的\n- 局部 Local Markov Property\n  - $a \\perp \\{Non-Neighbour\\} \\mid \\{Neighbour\\}$\n  - { }：集合\n- 成对 Pairwise Markov Property\n  - $x_i \\perp x_j \\mid x_{-ij}$\n  - 如果节点 $x_i$ 和 $x_j$ 直接相连，那么在给定其他所有节点的情况下，$x_i$ 和 $x_j$ 是条件独立的\n\n\n\n#### Factorization\n团: Clique\n最大团: Maximal Clique\n$$\nP(X) = \\frac{1}{Z} \\prod_{i=1}^K \\psi(X_{C_i})\n$$\n- $c_i$ 最大团\n- $x_{c_i}$: 最大团随机变量集合\n- $\\psi(x_{c_i})$: 势函数\n- $Z$:\n  - $Z = \\sum_{X} \\prod_{i=1}^K \\psi(X_{C_i})$\n- $\\psi(X_{C_i})$ 是定义在最大团 $C_i$ 上的因子函数\n\n何弃疗\n![alt text](2024-05-29-Casual-Inference/image-3.png)\n\n### Inference\n\n- 联合概率 Joint Probability\n  - $P(X) = P(x_1, x_2, \\ldots, x_p)$\n\n- 边缘概率 Marginal Probability\n  - $P(x) = \\sum_{x_j} P(x_j)$\n\n- 条件概率 Conditional Probability\n  - $P(x_i | x_j)$, 其中$x_j = \\{x \\backslash x_i\\}$\n\n- 最大后验概率估计 MAP Inference\n  - $\\hat{z} = \\arg \\max_z P(z | x) \\propto \\arg \\max_z P(z, x)$\n\n---\n\n-  精确推断 Exact Inference\n   - Variable Elimination (VE)\n   - Belief Propagation (BP) → Sum-Product Algorithm (求和-乘积算法)\n   -  Junction Tree Algorithm (树形算法)\n\n- 近似推断 Approximate Inference\n  -  Loop Belief Propagation (循环信念传播)\n  -  Monte Carlo Inference: Importance Sampling, MCMC (蒙特卡罗推断：重要性采样，MCMC)\n  -  Variational Inference (变分推断)\n\n\n#### Variable Elimination\n\n$P(x) = \\prod_{i} \\phi_i(x_i)$\n\n#### 示例\n\n假设我们有四个二值随机变量 $a, b, c, d\\in {0,1}$。我们想计算边缘概率 $P(d)$。\n$a\\rightarrow b \\rightarrow c \\rightarrow d$\n1. 展开联合分布：\n   - $P(d) = \\sum_{a, b, c} P(a, b, c, d)$\n\n2. Chain rule\n   - $P(a, b, c, d) = P(a) P(b | a) P(c | b) P(d | c)$\n\n3. 1->2\n   - $P(d) = \\sum_{a, b, c} P(a) P(b | a) P(c | b) P(d | c)$\n     - $= \\sum_{b, c} P(d | c) \\left( \\sum_{a} P(a) P(b | a) \\right) P(c | b)$\n\n4. 定义新的因子函数：\n   - $\\phi_1(b, c) = \\sum_{a} P(a) P(b | a)$\n\n5. 最终得到：\n   - $P(d) = \\sum_{c} P(d | c) \\left( \\sum_{b} \\phi_1(b, c) P(c | b) \\right)$\n\n6. 得到另一个因子函数 $\\phi_2(c, d)$：\n   - $P(d) = \\sum_{c} \\phi_2(c, d)$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"2024-05-29-Casual-Inference","published":1,"updated":"2024-12-15T11:14:33.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsv001nzc3d2zxgc2mm","content":"<h2 id=\"与贝叶斯有关的\"><a href=\"#与贝叶斯有关的\" class=\"headerlink\" title=\"与贝叶斯有关的\"></a>与贝叶斯有关的</h2><p>频率派的观点<br>为 $p(X|\\theta)\\mathop{&#x3D;}\\limits_{iid}\\prod\\limits <em>{i&#x3D;1}^{N}p(x</em>{i}|\\theta)$ </p>\n<p>为了求常量 $\\theta$ 的大小,最大对数似然MLE的方法：<br>$\\theta_{MLE}&#x3D;\\mathop{argmax}\\limits _{\\theta}\\log p(X|\\theta)\\mathop{&#x3D;}\\limits _{iid}\\mathop{argmax}\\limits _{\\theta}\\sum\\limits <em>{i&#x3D;1}^{N}\\log p(x</em>{i}|\\theta)$</p>\n<p>贝叶斯派的观点<br>$p(x|\\theta)$ 中的 $\\theta$ 不是一个常量。这个 $\\theta$ 满足一个预设的先验的分布 $\\theta\\sim p(\\theta)$</p>\n<p>$p(\\theta|X)&#x3D;\\frac{p(X|\\theta)\\cdot p(\\theta)}{p(X)}&#x3D;\\frac{p(X|\\theta)\\cdot p(\\theta)}{\\int\\limits _{\\theta}p(X|\\theta)\\cdot p(\\theta)d\\theta}$</p>\n<p>为了求 $\\theta$ 的值，我们要最大化这个参数后验MAP：</p>\n<p>$\\theta_{MAP}&#x3D;\\mathop{argmax}\\limits _{\\theta}p(\\theta|X)&#x3D;\\mathop{argmax}\\limits _{\\theta}p(X|\\theta)\\cdot p(\\theta)$</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><img src=\"/2024-05-29-Casual-Inference/image.png\" alt=\"alt text\"><br><img src=\"/2024-05-29-Casual-Inference/image-1.png\" alt=\"alt text\"></p>\n<p>基础知识和概念，包括d-分离<br>do算子<br>后门调整<br>前门调整<br>逆概率加权<br>反事实<br>因果关系发现中最基本的两类方法：基于独立性测试的方法，以及通过加性噪声模型的形式分析残差与预测者独立性关系的方法</p>\n<h2 id=\"chap1\"><a href=\"#chap1\" class=\"headerlink\" title=\"chap1\"></a>chap1</h2><p>partition, law of total probability<br>summing up its probabilities over all Bi is called marginalizing over $B$, and the resulting probability P(A) is called the marginal probability of $A$.<br>$P(A)&#x3D;P(A,B_1)+P(A,B_2)+···+P(A,B_n)$</p>\n<p>Def conditional probabilities<br>$P(A|B)&#x3D;P(A,B)∕P(B)$</p>\n<p>independence, giving no additional information<br>$P(A,B)&#x3D;P(A)P(B)$</p>\n<p>$P(A|B)&#x3D;\\frac{P(B|A)P(A)}{P(B)}$</p>\n<p>$P(A)&#x3D;P(A|B_1)P(B_1)+P(A|B_2)P(B-2)+···+P(A|B_k)P(B_k)$</p>\n<p>Sructual Casual Models SCM<br>U exogenous variables, external to the model;</p>\n<h2 id=\"HMM\"><a href=\"#HMM\" class=\"headerlink\" title=\"HMM\"></a>HMM</h2><h2 id=\"https-www-yuque-com-bystander-wg876-yc5f72-dvgo5b机器学习模型可以从频率派和贝叶斯派频率派的方法中的核心是优化问题，而在贝叶斯派的方法中，核心是积分问题，也发展出来了一系列的积分方法如变分推断，MCMC-等-Def-lambda-pi-A-B-pi-is-the-initial-state-distribution-o-t-来表示观测变量，-O-为观测序列，-V-v-1-v-2-cdots-v-M-表示观测的值域-i-t-表示状态变量，-I-为状态序列，-Q-q-1-q-2-cdots-q-N-表示状态变量的值域-A-a-ij-p-i-t-1-q-j-i-t-q-i-状态转移矩阵-B-b-j-k-p-o-t-v-k-i-t-q-j-发射矩阵\"><a href=\"#https-www-yuque-com-bystander-wg876-yc5f72-dvgo5b机器学习模型可以从频率派和贝叶斯派频率派的方法中的核心是优化问题，而在贝叶斯派的方法中，核心是积分问题，也发展出来了一系列的积分方法如变分推断，MCMC-等-Def-lambda-pi-A-B-pi-is-the-initial-state-distribution-o-t-来表示观测变量，-O-为观测序列，-V-v-1-v-2-cdots-v-M-表示观测的值域-i-t-表示状态变量，-I-为状态序列，-Q-q-1-q-2-cdots-q-N-表示状态变量的值域-A-a-ij-p-i-t-1-q-j-i-t-q-i-状态转移矩阵-B-b-j-k-p-o-t-v-k-i-t-q-j-发射矩阵\" class=\"headerlink\" title=\"https://www.yuque.com/bystander-wg876/yc5f72/dvgo5b机器学习模型可以从频率派和贝叶斯派频率派的方法中的核心是优化问题，而在贝叶斯派的方法中，核心是积分问题，也发展出来了一系列的积分方法如变分推断，MCMC 等### Def$\\lambda&#x3D;(\\pi,A,B)$- $\\pi$ is the initial state distribution- $o_t$ 来表示观测变量，$O$ 为观测序列，$V&#x3D;{v_1,v_2,\\cdots,v_M}$ 表示观测的值域- $i_t$ 表示状态变量，$I$ 为状态序列，$Q&#x3D;{q_1,q_2,\\cdots,q_N}$ 表示状态变量的值域- $A&#x3D;(a_{ij}&#x3D;p(i_{t+1}&#x3D;q_j|i_t&#x3D;q_i))$状态转移矩阵- $B&#x3D;(b_j(k)&#x3D;p(o_t&#x3D;v_k|i_t&#x3D;q_j))$ 发射矩阵\"></a><a href=\"https://www.yuque.com/bystander-wg876/yc5f72/dvgo5b\">https://www.yuque.com/bystander-wg876/yc5f72/dvgo5b</a><br>机器学习模型可以从频率派和贝叶斯派<br>频率派的方法中的核心是优化问题，而在贝叶斯派的方法中，核心是积分问题，也发展出来了一系列的积分方法如变分推断，MCMC 等<br>### Def<br>$\\lambda&#x3D;(\\pi,A,B)$<br><br>- $\\pi$ is the initial state distribution<br>- $o_t$ 来表示观测变量，$O$ 为观测序列，$V&#x3D;{v_1,v_2,\\cdots,v_M}$ 表示观测的值域<br>- $i_t$ 表示状态变量，$I$ 为状态序列，$Q&#x3D;{q_1,q_2,\\cdots,q_N}$ 表示状态变量的值域<br>- $A&#x3D;(a_{ij}&#x3D;p(i_{t+1}&#x3D;q_j|i_t&#x3D;q_i))$状态转移矩阵<br>- $B&#x3D;(b_j(k)&#x3D;p(o_t&#x3D;v_k|i_t&#x3D;q_j))$ 发射矩阵</h2><h4 id=\"两个基本假设\"><a href=\"#两个基本假设\" class=\"headerlink\" title=\"两个基本假设\"></a>两个基本假设</h4><ol>\n<li>齐次 Markov 假设（未来只依赖于当前）：<br>$p(i_{t+1}|i_t,i_{t-1},\\cdots,i_1,o_t,o_{t-1},\\cdots,o_1)&#x3D;p(i_{t+1}|i_t)$</li>\n<li>观测独立假设：<br>$p(o_t|i_t,i_{t-1},\\cdots,i_1,o_{t-1},\\cdots,o_1)&#x3D;p(o_t|i_t)$</li>\n</ol>\n<h4 id=\"三个基本问题\"><a href=\"#三个基本问题\" class=\"headerlink\" title=\"三个基本问题\"></a>三个基本问题</h4><ol>\n<li>Evaluation：$p(O|\\lambda)$，Forward-Backward </li>\n<li>Learning：$\\lambda&#x3D;\\mathop{argmax}\\limits_{\\lambda}p(O|\\lambda)$，EM （Baum-Welch）</li>\n<li>Decoding：$I&#x3D;\\mathop{argmax}\\limits_{I}p(I|O,\\lambda)$，Vierbi 算法<br>  a. 预测问题：$p(i_{t+1}|o_1,o_2,\\cdots,o_t)$<br>  b. 滤波问题：$p(i_t|o_1,o_2,\\cdots,o_t)$</li>\n</ol>\n<h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"-2\"><a href=\"#-2\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"有关MCMC\"><a href=\"#有关MCMC\" class=\"headerlink\" title=\"有关MCMC\"></a>有关MCMC</h2><h2 id=\"一个比较基础的介绍：-https-zhuanlan-zhihu-com-p-420214359-Abstract-贝叶斯推断估计参数的方法是：我们可以算出参数-Theta-的分布函数-P-Theta-，我们用参数分布的数学期望作为对参数的估计值-MCMC的作用是：可以帮我们从任意（无论有没有解析形式的）分布上抽样一批数据，然后用这堆抽样数据的均值作为对这个分布期望的估计-我们用MCMC这种求期望的方法求参数分布期望的估计值，以此求出参数的估计值\"><a href=\"#一个比较基础的介绍：-https-zhuanlan-zhihu-com-p-420214359-Abstract-贝叶斯推断估计参数的方法是：我们可以算出参数-Theta-的分布函数-P-Theta-，我们用参数分布的数学期望作为对参数的估计值-MCMC的作用是：可以帮我们从任意（无论有没有解析形式的）分布上抽样一批数据，然后用这堆抽样数据的均值作为对这个分布期望的估计-我们用MCMC这种求期望的方法求参数分布期望的估计值，以此求出参数的估计值\" class=\"headerlink\" title=\"一个比较基础的介绍： https://zhuanlan.zhihu.com/p/420214359- Abstract:  - 贝叶斯推断估计参数的方法是：我们可以算出参数$\\Theta$的分布函数$P(\\Theta)$，我们用参数分布的数学期望作为对参数的估计值  - MCMC的作用是：可以帮我们从任意（无论有没有解析形式的）分布上抽样一批数据，然后用这堆抽样数据的均值作为对这个分布期望的估计  - 我们用MCMC这种求期望的方法求参数分布期望的估计值，以此求出参数的估计值\"></a>一个比较基础的介绍： <a href=\"https://zhuanlan.zhihu.com/p/420214359\">https://zhuanlan.zhihu.com/p/420214359</a><br>- Abstract:<br>  - 贝叶斯推断估计参数的方法是：我们可以算出参数$\\Theta$的分布函数$P(\\Theta)$，我们用参数分布的数学期望作为对参数的估计值<br>  - MCMC的作用是：可以帮我们从任意（无论有没有解析形式的）分布上抽样一批数据，然后用这堆抽样数据的均值作为对这个分布期望的估计<br>  - 我们用MCMC这种求期望的方法求参数分布期望的估计值，以此求出参数的估计值</h2><h3 id=\"1-Monte-Carlo-Sampling\"><a href=\"#1-Monte-Carlo-Sampling\" class=\"headerlink\" title=\"1 Monte Carlo Sampling\"></a>1 Monte Carlo Sampling</h3><p>如果$X$服从$f(x)$这个概率分布，我怎么获得$E(X)$<br>最常见的一种Monte Carlo方法的使用场景就是：对随机变量进行充分多的采样后，使用这些采样的均值来估计总体的期望</p>\n<p>对于随机变量$X$，它的概率密度函数为$p(x)$，因此它的数学期望为<br>$E(x)&#x3D;\\int_{-\\infty}^{+\\infty}xp(x)dx$<br>我们对于这个随机变量随机采样得到$n$个采样值$x_i$，根据大数定理，有<br>$\\lim_{n\\rightarrow+\\infty}{\\frac1n\\sum_i^n{x_i}}&#x3D;E(X)$</p>\n<h3 id=\"2-Bayes-MCMC\"><a href=\"#2-Bayes-MCMC\" class=\"headerlink\" title=\"2 Bayes &amp; MCMC\"></a>2 Bayes &amp; MCMC</h3><h4 id=\"2-1-Bayes-Model-参数-Theta-，Observed-data-D\"><a href=\"#2-1-Bayes-Model-参数-Theta-，Observed-data-D\" class=\"headerlink\" title=\"2.1 Bayes Model: 参数$\\Theta$ ，Observed data: $D$\"></a>2.1 Bayes Model: 参数$\\Theta$ ，Observed data: $D$</h4><p>贝叶斯公式：$P(\\Theta|D)&#x3D;\\frac1{P(D)}P(D|\\Theta)P(\\Theta)$</p>\n<p>由于$P(D)$是一个无关紧要的常数，因此上式往往直接写成一个正比关系式：<br>$P(\\Theta|D)\\propto P(D|\\Theta)P(\\Theta)$</p>\n<p>在贝叶斯推断里：</p>\n<ol>\n<li>通过$P(\\Theta|D)$来得到$\\Theta$的估计值</li>\n<li>模型给出$P(D|\\Theta)$， 即likelihood$P(D|\\Theta)$</li>\n<li>还可以通过$P(\\Theta)$来对参数的分布情况做一些先验的猜测。（如果你什么都不知道，$P(\\Theta)$自然可以猜一个均匀分布）</li>\n</ol>\n<h4 id=\"2-2-通过后验概率-P-Theta-D-获取参数-Theta-的估计值\"><a href=\"#2-2-通过后验概率-P-Theta-D-获取参数-Theta-的估计值\" class=\"headerlink\" title=\"2.2 通过后验概率$P(\\Theta|D)$获取参数$\\Theta$的估计值\"></a>2.2 通过后验概率$P(\\Theta|D)$获取参数$\\Theta$的估计值</h4><p>想法：众数或者期望作为<br>估计值</p>\n<ol>\n<li>众数：$\\hat\\Theta&#x3D;\\arg\\max_\\Theta{P(\\Theta|D)}$</li>\n<li>期望：$\\hat\\Theta&#x3D;\\int_\\Theta\\Theta P(\\Theta|D)d\\Theta$</li>\n</ol>\n<p>MCMC就是教我们怎么在一个没有解析形式的数据上「抽样几个数据算平均值」的方法</p>\n<h3 id=\"3-Sampling-采样\"><a href=\"#3-Sampling-采样\" class=\"headerlink\" title=\"3 Sampling 采样\"></a>3 Sampling 采样</h3><ol>\n<li>Uniform</li>\n<li>Gaussian:<br>Given $U_1,U_2$<br>  $$<br>   Z_0 &#x3D; \\sqrt{-2 \\ln U_1} \\cos(2\\pi U_2)<br>   $$<br>   $$<br>   Z_1 &#x3D; \\sqrt{-2 \\ln U_1} \\sin(2\\pi U_2)<br>   $$</li>\n<li>Reject-Accept: 用于对很不规则的$f(x)$采样。具体细节没看</li>\n<li></li>\n</ol>\n<h3 id=\"Markov-Chain\"><a href=\"#Markov-Chain\" class=\"headerlink\" title=\"Markov Chain\"></a>Markov Chain</h3><p>一个对马尔可夫状态讲的比较详细的文章：<br><a href=\"https://zhuanlan.zhihu.com/p/250146007\">https://zhuanlan.zhihu.com/p/250146007</a></p>\n<h4 id=\"Def\"><a href=\"#Def\" class=\"headerlink\" title=\"Def\"></a>Def</h4><p>转移概率矩阵：</p>\n<p>$P&#x3D;\\begin{bmatrix}p_{11} &amp; p_{12} &amp;p_{13} \\ p_{21} &amp; p_{22} &amp;p_{23} \\ p_{31} &amp; p_{32} &amp;p_{33}\\end{bmatrix}$ </p>\n<p>其中 $p_{ij}&#x3D;P(X_{t}&#x3D;i|X_{t-1}&#x3D;j)$ 。</p>\n<p>定义：马尔科夫链在 $t$ 时刻的概率分布称为 $t$ 时刻的状态分布：</p>\n<p>$\\pi (t)&#x3D;\\begin{bmatrix}\\pi_{1}(t) \\ \\pi_{2}(t) \\ \\pi_{3}(t)\\end{bmatrix}$ </p>\n<p>其中  $\\pi_{i} (t)&#x3D;P(X_{t}&#x3D;i),i&#x3D;1,2,…$ 。</p>\n<h4 id=\"性质\"><a href=\"#性质\" class=\"headerlink\" title=\"性质\"></a>性质</h4><ol>\n<li><p>定理：给定一个马尔科夫链 $X&#x3D;\\left{ X_0,X_1,…,X_t,… \\right}$ ， $t$ 时刻的状态分布：<br> $\\pi&#x3D;(\\pi_1,\\pi_2,…)$ 是 $X$ 的平稳分布的条件是 $\\pi&#x3D;(\\pi_1,\\pi_2,…)$ 是下列方程组的解：<br> $x_{i}&#x3D;\\sum_{j}{p_{ij}x_j},i&#x3D;1,2,…$<br> $x_i\\geq0,i&#x3D;1,2,…$<br> $\\sum_{i}{x_{i}&#x3D;1}$</p>\n</li>\n<li></li>\n</ol>\n<h3 id=\"MCMC具体细节\"><a href=\"#MCMC具体细节\" class=\"headerlink\" title=\"MCMC具体细节\"></a>MCMC具体细节</h3><p><a href=\"https://zhuanlan.zhihu.com/p/253784711\">https://zhuanlan.zhihu.com/p/253784711</a></p>\n<h2 id=\"Conditional-Random-Field-CRF\"><a href=\"#Conditional-Random-Field-CRF\" class=\"headerlink\" title=\"Conditional Random Field(CRF)\"></a>Conditional Random Field(CRF)</h2><ul>\n<li>HMM 生成模型</li>\n<li>MEMM Maximum Entropy Markov Model</li>\n</ul>\n<p><img src=\"/2024-05-29-Casual-Inference/image-4.png\" alt=\"alt text\"></p>\n<ul>\n<li>HMM:<br>$$ P(\\mathbf{X}, \\mathbf{Y} | \\lambda) &#x3D; P(\\mathbf{Y} | \\lambda) P(\\mathbf{X} | \\mathbf{Y}, \\lambda) $$</li>\n<li>MEMM:<br>$$ P(y_t | y_{t-1}, x_t) $$</li>\n<li>CRF:<br>$$ P(\\mathbf{Y} | \\mathbf{X}, \\lambda) &#x3D; \\frac{1}{Z(\\mathbf{X})} \\exp \\left( \\sum_{t&#x3D;1}^{T} \\lambda_t f(y_t, y_{t-1}, \\mathbf{X}, t) \\right) $$</li>\n</ul>\n<h2 id=\"概率图模型\"><a href=\"#概率图模型\" class=\"headerlink\" title=\"概率图模型\"></a>概率图模型</h2><p><a href=\"https://www.bilibili.com/video/BV1BW41117xo/?spm_id_from=333.999.0.0&vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1BW41117xo/?spm_id_from=333.999.0.0&amp;vd_source=441679270dda23308fe16f3c5602b058</a></p>\n<h3 id=\"概率和图\"><a href=\"#概率和图\" class=\"headerlink\" title=\"概率和图\"></a>概率和图</h3><p>概率图</p>\n<ul>\n<li>表示 Representation<ul>\n<li>有向图 Beyesian Netowrk</li>\n<li>无向图</li>\n<li>高斯图（连续的随机变量）</li>\n</ul>\n</li>\n<li>推断 Inference<ul>\n<li>精确推断</li>\n<li>近似推断<ul>\n<li>确定性推断（变分）</li>\n<li>随机近似 MCMC</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>学习<ul>\n<li>参数学习<ul>\n<li>完备数据</li>\n<li>隐变量</li>\n</ul>\n</li>\n<li>结构学习</li>\n</ul>\n</li>\n</ul>\n<p>高维随机变量</p>\n<ul>\n<li>sum: $P(x_1) &#x3D; \\int P(x_1, x_2)dx_2$</li>\n<li>product: $P(x_1|x_2) &#x3D; P(x_1|x_2)P(x_2)&#x3D;P(x_2|x_1)P(x_1)$</li>\n</ul>\n<p>链式法则</p>\n<ul>\n<li>$$P(X_1,X_2,…,X_n)&#x3D;P(X_1)P(X_2|X_1)P(X_3|X_2,X_1)···P(X_n|X_{n-1},X_{n-2},…,X_1)$$</li>\n</ul>\n<p>全概率公式</p>\n<ul>\n<li>$P(X_i)&#x3D;\\sum_{j}{P(X_i,X_j)}&#x3D;\\sum_{j}{P(X_i|X_j)P(X_j)}$</li>\n</ul>\n<p>贝叶斯公式</p>\n<ul>\n<li>$P(X_i|X_j)&#x3D;\\frac{P(X_i,X_j)}{P(X_j)}&#x3D;\\frac{P(X_i|X_j)P(X_j)}{P(X_j)}$</li>\n</ul>\n<p>困境：<br>维度高$P(X_1,X_2,…,X_n)$计算复杂</p>\n<ul>\n<li>1.假设$X_i$相互独立:<ul>\n<li>$P(X_1,X_2,…,X_n)&#x3D;\\prod_{i}{P(X_i)}$</li>\n</ul>\n</li>\n<li>2.Markov Property(HMM齐次马尔可夫):<ul>\n<li>$x_j\\perp x_i+1|x_i, j&lt;i$ </li>\n<li>$P(X_1, X_2,…,X_n)&#x3D;P(X_1)P(X_2|X_1)P(X_3|X_2,X_1)···P(X_n|X_{n-1},X_{n-2},…,X_1)$</li>\n</ul>\n</li>\n<li>3.假设$X_i$条件独立: <ul>\n<li>$x_a\\perp x_b|x_c$</li>\n<li>$P(X_1,X_2,…,X_n)&#x3D;\\prod_{i}{P(X_i|X_{i-1})}$</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"概率补充知识\"><a href=\"#概率补充知识\" class=\"headerlink\" title=\"概率补充知识\"></a>概率补充知识</h4><p>指数族分布</p>\n<ul>\n<li>充分统计量$\\phi(x)$</li>\n<li>共轭</li>\n<li>最大熵</li>\n<li>广义线性模型</li>\n<li>概率图模型</li>\n<li>变分推断</li>\n</ul>\n<p>充分统计量</p>\n<ul>\n<li>$P(x|\\eta)&#x3D;h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))$<ul>\n<li>$h(x)$: base measure</li>\n<li>$\\eta$: parameter 参数向量</li>\n<li>$\\phi(x)$: feature function</li>\n<li>$A(\\eta)$： log partition function 配分函数</li>\n</ul>\n</li>\n<li>$P(x|\\theta)&#x3D;\\frac{1}{z}\\hat P(x|\\theta)$<ul>\n<li>$z&#x3D;\\int \\hat P(x|\\theta)dx$ 归一化因子</li>\n</ul>\n</li>\n<li>$P(x|\\eta)&#x3D;h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))$<ul>\n<li>$&#x3D;\\frac{1}{exp(A(\\eta))}h(x)exp(\\eta^T\\phi(x))$</li>\n<li>$&#x3D;\\frac{1}{z}\\hat P(x|\\eta)$<ul>\n<li>$\\hat P(x|\\eta)&#x3D;h(x)exp(\\eta^T\\phi(x))$</li>\n<li>$z&#x3D;exp(A(\\eta))$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>共轭, 先后验分布同组方便计算</p>\n<ul>\n<li>$P(\\theta|x)&#x3D;\\frac{P(x|\\theta)P(\\theta)}{P(x)}$</li>\n<li>$P(\\theta|x)$和$P(x|\\theta)$属于同一个指数族</li>\n<li>$P(\\theta|x)$的参数是$P(\\theta|x)$的参数的函数</li>\n</ul>\n<p>先验</p>\n<ul>\n<li>共轭 - 计算方便</li>\n<li>最大熵 无信息先验</li>\n<li>Jerrif</li>\n</ul>\n<p>广义线性模型</p>\n<ul>\n<li>线性组合 $w^Tx$</li>\n<li>Link funciton -&gt;aactivation function</li>\n<li>指数分布 $y|x\\sim$指数组分布（$Bernulli, Poisson, N(\\mu, \\Sigma)$）</li>\n</ul>\n<h5 id=\"Gaussian\"><a href=\"#Gaussian\" class=\"headerlink\" title=\"Gaussian\"></a>Gaussian</h5><ul>\n<li>$P(x|\\mu,\\Sigma)&#x3D;\\frac{1}{(2\\pi)^{n&#x2F;2}|\\Sigma|^{1&#x2F;2}}\\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)$</li>\n<li>$\\eta&#x3D;<br>\\left(!<br>  \\begin{array}{c}<br>\\eta_1 &#x3D;\\frac{\\mu}{\\sigma^2}\\<br>\\eta_2&#x3D;-\\frac{1}{\\sigma^2}<br>  \\end{array}<br>  !\\right)$</li>\n<li>$\\phi(x)&#x3D;\\left(!<br>  \\begin{array}{c}<br>x\\<br>x^2<br>  \\end{array}<br>  !\\right)$</li>\n<li>$A(\\eta)&#x3D;-\\frac{\\eta_1^2}{4\\eta_2}+\\frac{1}{2}\\ln(-\\frac{\\pi}{\\eta_2})$</li>\n</ul>\n<h4 id=\"-3\"><a href=\"#-3\" class=\"headerlink\" title=\"\"></a></h4><ul>\n<li>$P(x | \\eta) &#x3D; h(x) \\exp (\\eta^T \\phi(x) - A(\\eta))$<ul>\n<li>$\\eta$: 参数 (parameter)</li>\n<li>$\\phi(x)$: 充分统计量 (sufficient statistics)</li>\n<li>$A(\\eta)$: 对数配分函数 (log partition function)</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li>$A’(\\eta) &#x3D; \\mathbb{E}_{P(x|\\eta)}[\\phi(x)]$</li>\n<li>$A’’(\\eta) &#x3D; \\text{Var}[\\phi(x)]$</li>\n<li>$A(\\eta)$ 是凸函数 (convex function)</li>\n</ol>\n<p>对这个函数求导</p>\n<ul>\n<li>$\\exp(A(\\eta)) &#x3D; \\int h(x) \\exp(\\eta^T \\phi(x)) , dx$</li>\n<li>$A’(\\eta) &#x3D; \\frac{\\partial}{\\partial \\eta} \\log \\left( \\int h(x) \\exp(\\eta^T \\phi(x)) , dx \\right)$</li>\n<li>$A’(\\eta) &#x3D; \\int \\frac{h(x) \\exp(\\eta^T \\phi(x)) \\phi(x) , dx}{\\exp(A(\\eta))}$</li>\n<li>$A’(\\eta) &#x3D; \\int P(x | \\eta) \\phi(x) , dx &#x3D; \\mathbb{E}_{P(x|\\eta)}[\\phi(x)]$</li>\n</ul>\n<h5 id=\"MLE\"><a href=\"#MLE\" class=\"headerlink\" title=\"MLE\"></a>MLE</h5><p>$D&#x3D;{x_1, \\cdots, x_N}$</p>\n<p>$\\eta_{MLE}&#x3D;\\text{argmax  } log(P(D|\\eta))$</p>\n<ul>\n<li>$&#x3D;\\sum_{i&#x3D;1}^N\\text{argmax  }log\\cdot h(x_i)+(\\eta^T \\phi(x_i) - A(\\eta))$</li>\n<li><ul>\n<li>$&#x3D;\\sum_{i&#x3D;1}^N\\text{argmax  }\\eta^T \\phi(x_i) - A(\\eta)$</li>\n</ul>\n</li>\n</ul>\n<p>set $\\frac{\\partial \\eta_{MLE}}{\\partial \\eta}&#x3D;0$</p>\n<ul>\n<li>$\\sum \\phi(x_i)-NA’(\\eta)&#x3D;0$</li>\n</ul>\n<h5 id=\"Entorpy-最大熵\"><a href=\"#Entorpy-最大熵\" class=\"headerlink\" title=\"Entorpy 最大熵\"></a>Entorpy 最大熵</h5><p>信息熵 $-log\\ p$<br>熵，（对可能性的衡量）</p>\n<ul>\n<li><p>$E_{p(x)}[-log\\ p]&#x3D;\\int -p(x)log\\ p(x)dx&#x3D; \\sum -p(x)log\\ p(x)$</p>\n</li>\n<li><p>$\\hat p_i&#x3D;\\text{argmax } H(p)$ </p>\n</li>\n<li><p>拉格朗日$\\mathcal{L}(p, \\lambda)&#x3D;\\sum p_ilog\\ p_i$</p>\n<ul>\n<li>$\\frac{\\partial \\mathcal{L}}{\\partial p_i}&#x3D;log\\ p_i+1-\\lambda$</li>\n<li>$\\hat p_i&#x3D;exp(\\lambda-1)&#x3D;1&#x2F;k$</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"经验分布\"><a href=\"#经验分布\" class=\"headerlink\" title=\"经验分布\"></a>经验分布</h5><p>$Data &#x3D; {x_1, \\cdots, x_N}$</p>\n<ul>\n<li><strong>频率分布</strong>： $P(x_1, x_2, \\ldots, x_n) \\approx \\hat{P}(x) &#x3D; \\frac{\\text{count}(x)}{N}$</li>\n<li><strong>经验期望</strong>： $\\mathbb{E}<em>p[f(x)] &#x3D; \\Delta \\approx \\frac{1}{N} \\sum</em>{i&#x3D;1}^N f(x_i)$</li>\n</ul>\n<p>最大熵问题的求解<br>$$<br>\\begin{aligned}<br>\\min_{p(x)} &amp; \\sum_x p(x) \\log p(x) \\<br>\\text{subject to} &amp; \\sum_x p(x) &#x3D; 1 \\<br>&amp; \\mathbb{E}<em>p[f(x)] &#x3D; \\mathbb{E}</em>{\\hat{p}}[f(x)] &#x3D; \\Delta<br>\\end{aligned}<br>$$</p>\n<p>拉格朗日乘数法求解<br>$$<br>\\begin{aligned}<br>L(p, \\lambda, \\eta) &amp;&#x3D; \\sum_x p(x) \\log p(x) + \\lambda (1 - \\sum_x p(x)) + \\eta (\\Delta - \\sum_x p(x) f(x)) \\<br>\\frac{\\partial}{\\partial p(x)} &amp;&#x3D; \\log p(x) + 1 - \\lambda_0 - \\lambda f(x) &#x3D; 0 \\<br>p(x) &amp;&#x3D; \\exp(\\lambda_1 f(x) + \\lambda_0 - 1) \\<br>&amp;&#x3D; \\frac{\\exp(\\eta^T f(x))}{Z(\\eta)}<br>\\end{aligned}<br>$$</p>\n<h3 id=\"贝叶斯网络\"><a href=\"#贝叶斯网络\" class=\"headerlink\" title=\"贝叶斯网络\"></a>贝叶斯网络</h3><p>有向无环图<br>因子分解</p>\n<ul>\n<li>$P(X_1,X_2,…,X_n)&#x3D;\\prod_{i}{P(X_i|Pa(X_i))}$</li>\n<li>$P(X_i|Pa(X_i))$是局部概率分布</li>\n<li>$Pa(X_i)$是$X_i$的父节点集合</li>\n</ul>\n<h4 id=\"三种模型\"><a href=\"#三种模型\" class=\"headerlink\" title=\"三种模型\"></a>三种模型</h4><h5 id=\"tail-to-tail\"><a href=\"#tail-to-tail\" class=\"headerlink\" title=\"tail-to-tail\"></a>tail-to-tail</h5>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  a--&gt; b</span><br><span class=\"line\">  a--&gt; c</span><br></pre></td></tr></table></figure>\n<p>因子分解：</p>\n<ul>\n<li>$P(a, b, c)&#x3D;P(a)P(b|a)P(c|a)$</li>\n</ul>\n<p>链式法则：</p>\n<ul>\n<li>$P(a, b, c)&#x3D;P(a)P(b|a)P(c|a, b)$</li>\n</ul>\n<p>$\\implies P(c|a)&#x3D;P(c|a, b)\\implies c\\perp b |a$<br>若$b$ 被观测则路径被阻塞： </p>\n<h5 id=\"head-to-tail\"><a href=\"#head-to-tail\" class=\"headerlink\" title=\"head-to-tail\"></a>head-to-tail</h5>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  a --&gt;b </span><br><span class=\"line\">  b --&gt;c </span><br></pre></td></tr></table></figure>\n<p>$a\\perp c |b$<br>若$b$ 被观测则路径被阻塞： </p>\n<h5 id=\"head-to-head\"><a href=\"#head-to-head\" class=\"headerlink\" title=\"head-to-head\"></a>head-to-head</h5>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  b--&gt; c</span><br><span class=\"line\">  a--&gt; c</span><br></pre></td></tr></table></figure>\n<ul>\n<li>$P(a, b, c)&#x3D;P(a)P(b)P(c|a, b)$</li>\n<li>$P(a, b, c)&#x3D;P(a)P(b|a)P(c | a, b)$</li>\n</ul>\n<p>$\\implies P(b)&#x3D;P(b|a)\\implies a\\perp b$<br>若$b$ 被观测则路径被连通：</p>\n<h4 id=\"D-seperation\"><a href=\"#D-seperation\" class=\"headerlink\" title=\"D-seperation\"></a>D-seperation</h4>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  a  --&gt; b1</span><br><span class=\"line\">  a  --&gt; b2</span><br><span class=\"line\">  a  --&gt; b*</span><br><span class=\"line\">  b1 --&gt; c</span><br><span class=\"line\">  b2 --&gt; c</span><br><span class=\"line\">  c  --&gt; b*</span><br></pre></td></tr></table></figure>\n<ul>\n<li>如果$b1, b2\\in B$被观测了<br>，那么$a$和$c$被阻断，</li>\n<li>但是$b*$没有被观测到,且$b*$的后续节点都不在$b$中<br>$a\\perp c|b$</li>\n</ul>\n<p><img src=\"/2024-05-29-Casual-Inference/image-2.png\" alt=\"alt text\"><br>马尔可夫毯(Markov Blanket)</p>\n<ul>\n<li>$x_{pa(i)}$：$x_i$的父节点</li>\n<li>$x_{child(i)}$: childs of $x_i$</li>\n<li>$x_{pa(child(i))}$: parent of $x_{child(i)}$</li>\n<li>$x_{-i}&#x3D;x&#x2F;x_i$ 表示除了 $x_i$ 以外的所有变量。<ul>\n<li>和$x$有关:$\\Delta$<ul>\n<li>$P(x_i|x_{Pa(i)})&#x3D;f(\\bar \\Delta)$</li>\n</ul>\n</li>\n<li>和$x$无关:$\\bar \\Delta$</li>\n</ul>\n</li>\n</ul>\n<p>马尔可夫毯的作用是在给定马尔可夫毯内所有节点的情况下，$x_i$ 与网络中其他节点条件独立。</p>\n<p>$$<br>P(x_i | x_{-i}) &#x3D; \\frac{P(x_i, x_{-i})}{P(x_{-i})} &#x3D; \\frac{P(x)}{\\int_{x_i} P(x_{-i})} &#x3D; \\frac{ \\int_{x_i} P(x) , dx_i }{ \\int_{x_i} P(x_j | x_{\\text{pa}(j)}) , dx_i }<br>$$</p>\n<p>$$<br>P(x_{\\text{child}(i)} | x_i, x_{\\text{Parent}(\\text{Child}(i))})<br>$$</p>\n<h4 id=\"贝叶斯网络-Beyesian-Network\"><a href=\"#贝叶斯网络-Beyesian-Network\" class=\"headerlink\" title=\"贝叶斯网络 Beyesian Network\"></a>贝叶斯网络 Beyesian Network</h4><p>NB<br>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  y--&gt; x1 </span><br><span class=\"line\">  y--&gt; xp</span><br></pre></td></tr></table></figure></p>\n<p>GMM<br>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  z--&gt; x</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure><br>Beyesian Network</p>\n<ul>\n<li>单一： Naive Bayes<ul>\n<li>p维： $P(x|y)&#x3D;\\prod^p_{i&#x3D;1}P(x_i|y&#x3D;1)$</li>\n<li>$x_1\\perp x_2|y$</li>\n</ul>\n</li>\n<li>混合：GMM<ul>\n<li>Z discrete, z&#x3D;1,2,3,4</li>\n</ul>\n</li>\n<li>时间<ul>\n<li>Markov Chain</li>\n<li>Gaussian Process(无限维分布)</li>\n</ul>\n</li>\n<li>连续： Gaussian Network</li>\n</ul>\n<p>动态模型</p>\n<ul>\n<li>HMM 离散</li>\n<li>LDS Kalman Filter 连续线性</li>\n<li>Particle filter 非线性非高斯</li>\n</ul>\n<h3 id=\"Markov-Network\"><a href=\"#Markov-Network\" class=\"headerlink\" title=\"Markov Network\"></a>Markov Network</h3><p>条件独立性</p>\n<ul>\n<li>全局 Global Markov Property<ul>\n<li>$X_A \\perp X_C \\mid X_B$</li>\n<li>如果集合 $X_A$ 和 $X_C$ 被集合 $X_B$ 分隔开，那么 $X_A$ 和 $X_C$ 是条件独立的</li>\n</ul>\n</li>\n<li>局部 Local Markov Property<ul>\n<li>$a \\perp {Non-Neighbour} \\mid {Neighbour}$</li>\n<li>{ }：集合</li>\n</ul>\n</li>\n<li>成对 Pairwise Markov Property<ul>\n<li>$x_i \\perp x_j \\mid x_{-ij}$</li>\n<li>如果节点 $x_i$ 和 $x_j$ 直接相连，那么在给定其他所有节点的情况下，$x_i$ 和 $x_j$ 是条件独立的</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Factorization\"><a href=\"#Factorization\" class=\"headerlink\" title=\"Factorization\"></a>Factorization</h4><p>团: Clique<br>最大团: Maximal Clique<br>$$<br>P(X) &#x3D; \\frac{1}{Z} \\prod_{i&#x3D;1}^K \\psi(X_{C_i})<br>$$</p>\n<ul>\n<li>$c_i$ 最大团</li>\n<li>$x_{c_i}$: 最大团随机变量集合</li>\n<li>$\\psi(x_{c_i})$: 势函数</li>\n<li>$Z$:<ul>\n<li>$Z &#x3D; \\sum_{X} \\prod_{i&#x3D;1}^K \\psi(X_{C_i})$</li>\n</ul>\n</li>\n<li>$\\psi(X_{C_i})$ 是定义在最大团 $C_i$ 上的因子函数</li>\n</ul>\n<p>何弃疗<br><img src=\"/2024-05-29-Casual-Inference/image-3.png\" alt=\"alt text\"></p>\n<h3 id=\"Inference\"><a href=\"#Inference\" class=\"headerlink\" title=\"Inference\"></a>Inference</h3><ul>\n<li><p>联合概率 Joint Probability</p>\n<ul>\n<li>$P(X) &#x3D; P(x_1, x_2, \\ldots, x_p)$</li>\n</ul>\n</li>\n<li><p>边缘概率 Marginal Probability</p>\n<ul>\n<li>$P(x) &#x3D; \\sum_{x_j} P(x_j)$</li>\n</ul>\n</li>\n<li><p>条件概率 Conditional Probability</p>\n<ul>\n<li>$P(x_i | x_j)$, 其中$x_j &#x3D; {x \\backslash x_i}$</li>\n</ul>\n</li>\n<li><p>最大后验概率估计 MAP Inference</p>\n<ul>\n<li>$\\hat{z} &#x3D; \\arg \\max_z P(z | x) \\propto \\arg \\max_z P(z, x)$</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li><p>精确推断 Exact Inference</p>\n<ul>\n<li>Variable Elimination (VE)</li>\n<li>Belief Propagation (BP) → Sum-Product Algorithm (求和-乘积算法)</li>\n<li>Junction Tree Algorithm (树形算法)</li>\n</ul>\n</li>\n<li><p>近似推断 Approximate Inference</p>\n<ul>\n<li>Loop Belief Propagation (循环信念传播)</li>\n<li>Monte Carlo Inference: Importance Sampling, MCMC (蒙特卡罗推断：重要性采样，MCMC)</li>\n<li>Variational Inference (变分推断)</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Variable-Elimination\"><a href=\"#Variable-Elimination\" class=\"headerlink\" title=\"Variable Elimination\"></a>Variable Elimination</h4><p>$P(x) &#x3D; \\prod_{i} \\phi_i(x_i)$</p>\n<h4 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h4><p>假设我们有四个二值随机变量 $a, b, c, d\\in {0,1}$。我们想计算边缘概率 $P(d)$。<br>$a\\rightarrow b \\rightarrow c \\rightarrow d$</p>\n<ol>\n<li><p>展开联合分布：</p>\n<ul>\n<li>$P(d) &#x3D; \\sum_{a, b, c} P(a, b, c, d)$</li>\n</ul>\n</li>\n<li><p>Chain rule</p>\n<ul>\n<li>$P(a, b, c, d) &#x3D; P(a) P(b | a) P(c | b) P(d | c)$</li>\n</ul>\n</li>\n<li><p>1-&gt;2</p>\n<ul>\n<li>$P(d) &#x3D; \\sum_{a, b, c} P(a) P(b | a) P(c | b) P(d | c)$<ul>\n<li>$&#x3D; \\sum_{b, c} P(d | c) \\left( \\sum_{a} P(a) P(b | a) \\right) P(c | b)$</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>定义新的因子函数：</p>\n<ul>\n<li>$\\phi_1(b, c) &#x3D; \\sum_{a} P(a) P(b | a)$</li>\n</ul>\n</li>\n<li><p>最终得到：</p>\n<ul>\n<li>$P(d) &#x3D; \\sum_{c} P(d | c) \\left( \\sum_{b} \\phi_1(b, c) P(c | b) \\right)$</li>\n</ul>\n</li>\n<li><p>得到另一个因子函数 $\\phi_2(c, d)$：</p>\n<ul>\n<li>$P(d) &#x3D; \\sum_{c} \\phi_2(c, d)$</li>\n</ul>\n</li>\n</ol>\n","excerpt":"","more":"<h2 id=\"与贝叶斯有关的\"><a href=\"#与贝叶斯有关的\" class=\"headerlink\" title=\"与贝叶斯有关的\"></a>与贝叶斯有关的</h2><p>频率派的观点<br>为 $p(X|\\theta)\\mathop{&#x3D;}\\limits_{iid}\\prod\\limits <em>{i&#x3D;1}^{N}p(x</em>{i}|\\theta)$ </p>\n<p>为了求常量 $\\theta$ 的大小,最大对数似然MLE的方法：<br>$\\theta_{MLE}&#x3D;\\mathop{argmax}\\limits _{\\theta}\\log p(X|\\theta)\\mathop{&#x3D;}\\limits _{iid}\\mathop{argmax}\\limits _{\\theta}\\sum\\limits <em>{i&#x3D;1}^{N}\\log p(x</em>{i}|\\theta)$</p>\n<p>贝叶斯派的观点<br>$p(x|\\theta)$ 中的 $\\theta$ 不是一个常量。这个 $\\theta$ 满足一个预设的先验的分布 $\\theta\\sim p(\\theta)$</p>\n<p>$p(\\theta|X)&#x3D;\\frac{p(X|\\theta)\\cdot p(\\theta)}{p(X)}&#x3D;\\frac{p(X|\\theta)\\cdot p(\\theta)}{\\int\\limits _{\\theta}p(X|\\theta)\\cdot p(\\theta)d\\theta}$</p>\n<p>为了求 $\\theta$ 的值，我们要最大化这个参数后验MAP：</p>\n<p>$\\theta_{MAP}&#x3D;\\mathop{argmax}\\limits _{\\theta}p(\\theta|X)&#x3D;\\mathop{argmax}\\limits _{\\theta}p(X|\\theta)\\cdot p(\\theta)$</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><img src=\"/2024-05-29-Casual-Inference/image.png\" alt=\"alt text\"><br><img src=\"/2024-05-29-Casual-Inference/image-1.png\" alt=\"alt text\"></p>\n<p>基础知识和概念，包括d-分离<br>do算子<br>后门调整<br>前门调整<br>逆概率加权<br>反事实<br>因果关系发现中最基本的两类方法：基于独立性测试的方法，以及通过加性噪声模型的形式分析残差与预测者独立性关系的方法</p>\n<h2 id=\"chap1\"><a href=\"#chap1\" class=\"headerlink\" title=\"chap1\"></a>chap1</h2><p>partition, law of total probability<br>summing up its probabilities over all Bi is called marginalizing over $B$, and the resulting probability P(A) is called the marginal probability of $A$.<br>$P(A)&#x3D;P(A,B_1)+P(A,B_2)+···+P(A,B_n)$</p>\n<p>Def conditional probabilities<br>$P(A|B)&#x3D;P(A,B)∕P(B)$</p>\n<p>independence, giving no additional information<br>$P(A,B)&#x3D;P(A)P(B)$</p>\n<p>$P(A|B)&#x3D;\\frac{P(B|A)P(A)}{P(B)}$</p>\n<p>$P(A)&#x3D;P(A|B_1)P(B_1)+P(A|B_2)P(B-2)+···+P(A|B_k)P(B_k)$</p>\n<p>Sructual Casual Models SCM<br>U exogenous variables, external to the model;</p>\n<h2 id=\"HMM\"><a href=\"#HMM\" class=\"headerlink\" title=\"HMM\"></a>HMM</h2><h2 id=\"https-www-yuque-com-bystander-wg876-yc5f72-dvgo5b机器学习模型可以从频率派和贝叶斯派频率派的方法中的核心是优化问题，而在贝叶斯派的方法中，核心是积分问题，也发展出来了一系列的积分方法如变分推断，MCMC-等-Def-lambda-pi-A-B-pi-is-the-initial-state-distribution-o-t-来表示观测变量，-O-为观测序列，-V-v-1-v-2-cdots-v-M-表示观测的值域-i-t-表示状态变量，-I-为状态序列，-Q-q-1-q-2-cdots-q-N-表示状态变量的值域-A-a-ij-p-i-t-1-q-j-i-t-q-i-状态转移矩阵-B-b-j-k-p-o-t-v-k-i-t-q-j-发射矩阵\"><a href=\"#https-www-yuque-com-bystander-wg876-yc5f72-dvgo5b机器学习模型可以从频率派和贝叶斯派频率派的方法中的核心是优化问题，而在贝叶斯派的方法中，核心是积分问题，也发展出来了一系列的积分方法如变分推断，MCMC-等-Def-lambda-pi-A-B-pi-is-the-initial-state-distribution-o-t-来表示观测变量，-O-为观测序列，-V-v-1-v-2-cdots-v-M-表示观测的值域-i-t-表示状态变量，-I-为状态序列，-Q-q-1-q-2-cdots-q-N-表示状态变量的值域-A-a-ij-p-i-t-1-q-j-i-t-q-i-状态转移矩阵-B-b-j-k-p-o-t-v-k-i-t-q-j-发射矩阵\" class=\"headerlink\" title=\"https://www.yuque.com/bystander-wg876/yc5f72/dvgo5b机器学习模型可以从频率派和贝叶斯派频率派的方法中的核心是优化问题，而在贝叶斯派的方法中，核心是积分问题，也发展出来了一系列的积分方法如变分推断，MCMC 等### Def$\\lambda&#x3D;(\\pi,A,B)$- $\\pi$ is the initial state distribution- $o_t$ 来表示观测变量，$O$ 为观测序列，$V&#x3D;{v_1,v_2,\\cdots,v_M}$ 表示观测的值域- $i_t$ 表示状态变量，$I$ 为状态序列，$Q&#x3D;{q_1,q_2,\\cdots,q_N}$ 表示状态变量的值域- $A&#x3D;(a_{ij}&#x3D;p(i_{t+1}&#x3D;q_j|i_t&#x3D;q_i))$状态转移矩阵- $B&#x3D;(b_j(k)&#x3D;p(o_t&#x3D;v_k|i_t&#x3D;q_j))$ 发射矩阵\"></a><a href=\"https://www.yuque.com/bystander-wg876/yc5f72/dvgo5b\">https://www.yuque.com/bystander-wg876/yc5f72/dvgo5b</a><br>机器学习模型可以从频率派和贝叶斯派<br>频率派的方法中的核心是优化问题，而在贝叶斯派的方法中，核心是积分问题，也发展出来了一系列的积分方法如变分推断，MCMC 等<br>### Def<br>$\\lambda&#x3D;(\\pi,A,B)$<br><br>- $\\pi$ is the initial state distribution<br>- $o_t$ 来表示观测变量，$O$ 为观测序列，$V&#x3D;{v_1,v_2,\\cdots,v_M}$ 表示观测的值域<br>- $i_t$ 表示状态变量，$I$ 为状态序列，$Q&#x3D;{q_1,q_2,\\cdots,q_N}$ 表示状态变量的值域<br>- $A&#x3D;(a_{ij}&#x3D;p(i_{t+1}&#x3D;q_j|i_t&#x3D;q_i))$状态转移矩阵<br>- $B&#x3D;(b_j(k)&#x3D;p(o_t&#x3D;v_k|i_t&#x3D;q_j))$ 发射矩阵</h2><h4 id=\"两个基本假设\"><a href=\"#两个基本假设\" class=\"headerlink\" title=\"两个基本假设\"></a>两个基本假设</h4><ol>\n<li>齐次 Markov 假设（未来只依赖于当前）：<br>$p(i_{t+1}|i_t,i_{t-1},\\cdots,i_1,o_t,o_{t-1},\\cdots,o_1)&#x3D;p(i_{t+1}|i_t)$</li>\n<li>观测独立假设：<br>$p(o_t|i_t,i_{t-1},\\cdots,i_1,o_{t-1},\\cdots,o_1)&#x3D;p(o_t|i_t)$</li>\n</ol>\n<h4 id=\"三个基本问题\"><a href=\"#三个基本问题\" class=\"headerlink\" title=\"三个基本问题\"></a>三个基本问题</h4><ol>\n<li>Evaluation：$p(O|\\lambda)$，Forward-Backward </li>\n<li>Learning：$\\lambda&#x3D;\\mathop{argmax}\\limits_{\\lambda}p(O|\\lambda)$，EM （Baum-Welch）</li>\n<li>Decoding：$I&#x3D;\\mathop{argmax}\\limits_{I}p(I|O,\\lambda)$，Vierbi 算法<br>  a. 预测问题：$p(i_{t+1}|o_1,o_2,\\cdots,o_t)$<br>  b. 滤波问题：$p(i_t|o_1,o_2,\\cdots,o_t)$</li>\n</ol>\n<h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"-2\"><a href=\"#-2\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"有关MCMC\"><a href=\"#有关MCMC\" class=\"headerlink\" title=\"有关MCMC\"></a>有关MCMC</h2><h2 id=\"一个比较基础的介绍：-https-zhuanlan-zhihu-com-p-420214359-Abstract-贝叶斯推断估计参数的方法是：我们可以算出参数-Theta-的分布函数-P-Theta-，我们用参数分布的数学期望作为对参数的估计值-MCMC的作用是：可以帮我们从任意（无论有没有解析形式的）分布上抽样一批数据，然后用这堆抽样数据的均值作为对这个分布期望的估计-我们用MCMC这种求期望的方法求参数分布期望的估计值，以此求出参数的估计值\"><a href=\"#一个比较基础的介绍：-https-zhuanlan-zhihu-com-p-420214359-Abstract-贝叶斯推断估计参数的方法是：我们可以算出参数-Theta-的分布函数-P-Theta-，我们用参数分布的数学期望作为对参数的估计值-MCMC的作用是：可以帮我们从任意（无论有没有解析形式的）分布上抽样一批数据，然后用这堆抽样数据的均值作为对这个分布期望的估计-我们用MCMC这种求期望的方法求参数分布期望的估计值，以此求出参数的估计值\" class=\"headerlink\" title=\"一个比较基础的介绍： https://zhuanlan.zhihu.com/p/420214359- Abstract:  - 贝叶斯推断估计参数的方法是：我们可以算出参数$\\Theta$的分布函数$P(\\Theta)$，我们用参数分布的数学期望作为对参数的估计值  - MCMC的作用是：可以帮我们从任意（无论有没有解析形式的）分布上抽样一批数据，然后用这堆抽样数据的均值作为对这个分布期望的估计  - 我们用MCMC这种求期望的方法求参数分布期望的估计值，以此求出参数的估计值\"></a>一个比较基础的介绍： <a href=\"https://zhuanlan.zhihu.com/p/420214359\">https://zhuanlan.zhihu.com/p/420214359</a><br>- Abstract:<br>  - 贝叶斯推断估计参数的方法是：我们可以算出参数$\\Theta$的分布函数$P(\\Theta)$，我们用参数分布的数学期望作为对参数的估计值<br>  - MCMC的作用是：可以帮我们从任意（无论有没有解析形式的）分布上抽样一批数据，然后用这堆抽样数据的均值作为对这个分布期望的估计<br>  - 我们用MCMC这种求期望的方法求参数分布期望的估计值，以此求出参数的估计值</h2><h3 id=\"1-Monte-Carlo-Sampling\"><a href=\"#1-Monte-Carlo-Sampling\" class=\"headerlink\" title=\"1 Monte Carlo Sampling\"></a>1 Monte Carlo Sampling</h3><p>如果$X$服从$f(x)$这个概率分布，我怎么获得$E(X)$<br>最常见的一种Monte Carlo方法的使用场景就是：对随机变量进行充分多的采样后，使用这些采样的均值来估计总体的期望</p>\n<p>对于随机变量$X$，它的概率密度函数为$p(x)$，因此它的数学期望为<br>$E(x)&#x3D;\\int_{-\\infty}^{+\\infty}xp(x)dx$<br>我们对于这个随机变量随机采样得到$n$个采样值$x_i$，根据大数定理，有<br>$\\lim_{n\\rightarrow+\\infty}{\\frac1n\\sum_i^n{x_i}}&#x3D;E(X)$</p>\n<h3 id=\"2-Bayes-MCMC\"><a href=\"#2-Bayes-MCMC\" class=\"headerlink\" title=\"2 Bayes &amp; MCMC\"></a>2 Bayes &amp; MCMC</h3><h4 id=\"2-1-Bayes-Model-参数-Theta-，Observed-data-D\"><a href=\"#2-1-Bayes-Model-参数-Theta-，Observed-data-D\" class=\"headerlink\" title=\"2.1 Bayes Model: 参数$\\Theta$ ，Observed data: $D$\"></a>2.1 Bayes Model: 参数$\\Theta$ ，Observed data: $D$</h4><p>贝叶斯公式：$P(\\Theta|D)&#x3D;\\frac1{P(D)}P(D|\\Theta)P(\\Theta)$</p>\n<p>由于$P(D)$是一个无关紧要的常数，因此上式往往直接写成一个正比关系式：<br>$P(\\Theta|D)\\propto P(D|\\Theta)P(\\Theta)$</p>\n<p>在贝叶斯推断里：</p>\n<ol>\n<li>通过$P(\\Theta|D)$来得到$\\Theta$的估计值</li>\n<li>模型给出$P(D|\\Theta)$， 即likelihood$P(D|\\Theta)$</li>\n<li>还可以通过$P(\\Theta)$来对参数的分布情况做一些先验的猜测。（如果你什么都不知道，$P(\\Theta)$自然可以猜一个均匀分布）</li>\n</ol>\n<h4 id=\"2-2-通过后验概率-P-Theta-D-获取参数-Theta-的估计值\"><a href=\"#2-2-通过后验概率-P-Theta-D-获取参数-Theta-的估计值\" class=\"headerlink\" title=\"2.2 通过后验概率$P(\\Theta|D)$获取参数$\\Theta$的估计值\"></a>2.2 通过后验概率$P(\\Theta|D)$获取参数$\\Theta$的估计值</h4><p>想法：众数或者期望作为<br>估计值</p>\n<ol>\n<li>众数：$\\hat\\Theta&#x3D;\\arg\\max_\\Theta{P(\\Theta|D)}$</li>\n<li>期望：$\\hat\\Theta&#x3D;\\int_\\Theta\\Theta P(\\Theta|D)d\\Theta$</li>\n</ol>\n<p>MCMC就是教我们怎么在一个没有解析形式的数据上「抽样几个数据算平均值」的方法</p>\n<h3 id=\"3-Sampling-采样\"><a href=\"#3-Sampling-采样\" class=\"headerlink\" title=\"3 Sampling 采样\"></a>3 Sampling 采样</h3><ol>\n<li>Uniform</li>\n<li>Gaussian:<br>Given $U_1,U_2$<br>  $$<br>   Z_0 &#x3D; \\sqrt{-2 \\ln U_1} \\cos(2\\pi U_2)<br>   $$<br>   $$<br>   Z_1 &#x3D; \\sqrt{-2 \\ln U_1} \\sin(2\\pi U_2)<br>   $$</li>\n<li>Reject-Accept: 用于对很不规则的$f(x)$采样。具体细节没看</li>\n<li></li>\n</ol>\n<h3 id=\"Markov-Chain\"><a href=\"#Markov-Chain\" class=\"headerlink\" title=\"Markov Chain\"></a>Markov Chain</h3><p>一个对马尔可夫状态讲的比较详细的文章：<br><a href=\"https://zhuanlan.zhihu.com/p/250146007\">https://zhuanlan.zhihu.com/p/250146007</a></p>\n<h4 id=\"Def\"><a href=\"#Def\" class=\"headerlink\" title=\"Def\"></a>Def</h4><p>转移概率矩阵：</p>\n<p>$P&#x3D;\\begin{bmatrix}p_{11} &amp; p_{12} &amp;p_{13} \\ p_{21} &amp; p_{22} &amp;p_{23} \\ p_{31} &amp; p_{32} &amp;p_{33}\\end{bmatrix}$ </p>\n<p>其中 $p_{ij}&#x3D;P(X_{t}&#x3D;i|X_{t-1}&#x3D;j)$ 。</p>\n<p>定义：马尔科夫链在 $t$ 时刻的概率分布称为 $t$ 时刻的状态分布：</p>\n<p>$\\pi (t)&#x3D;\\begin{bmatrix}\\pi_{1}(t) \\ \\pi_{2}(t) \\ \\pi_{3}(t)\\end{bmatrix}$ </p>\n<p>其中  $\\pi_{i} (t)&#x3D;P(X_{t}&#x3D;i),i&#x3D;1,2,…$ 。</p>\n<h4 id=\"性质\"><a href=\"#性质\" class=\"headerlink\" title=\"性质\"></a>性质</h4><ol>\n<li><p>定理：给定一个马尔科夫链 $X&#x3D;\\left{ X_0,X_1,…,X_t,… \\right}$ ， $t$ 时刻的状态分布：<br> $\\pi&#x3D;(\\pi_1,\\pi_2,…)$ 是 $X$ 的平稳分布的条件是 $\\pi&#x3D;(\\pi_1,\\pi_2,…)$ 是下列方程组的解：<br> $x_{i}&#x3D;\\sum_{j}{p_{ij}x_j},i&#x3D;1,2,…$<br> $x_i\\geq0,i&#x3D;1,2,…$<br> $\\sum_{i}{x_{i}&#x3D;1}$</p>\n</li>\n<li></li>\n</ol>\n<h3 id=\"MCMC具体细节\"><a href=\"#MCMC具体细节\" class=\"headerlink\" title=\"MCMC具体细节\"></a>MCMC具体细节</h3><p><a href=\"https://zhuanlan.zhihu.com/p/253784711\">https://zhuanlan.zhihu.com/p/253784711</a></p>\n<h2 id=\"Conditional-Random-Field-CRF\"><a href=\"#Conditional-Random-Field-CRF\" class=\"headerlink\" title=\"Conditional Random Field(CRF)\"></a>Conditional Random Field(CRF)</h2><ul>\n<li>HMM 生成模型</li>\n<li>MEMM Maximum Entropy Markov Model</li>\n</ul>\n<p><img src=\"/2024-05-29-Casual-Inference/image-4.png\" alt=\"alt text\"></p>\n<ul>\n<li>HMM:<br>$$ P(\\mathbf{X}, \\mathbf{Y} | \\lambda) &#x3D; P(\\mathbf{Y} | \\lambda) P(\\mathbf{X} | \\mathbf{Y}, \\lambda) $$</li>\n<li>MEMM:<br>$$ P(y_t | y_{t-1}, x_t) $$</li>\n<li>CRF:<br>$$ P(\\mathbf{Y} | \\mathbf{X}, \\lambda) &#x3D; \\frac{1}{Z(\\mathbf{X})} \\exp \\left( \\sum_{t&#x3D;1}^{T} \\lambda_t f(y_t, y_{t-1}, \\mathbf{X}, t) \\right) $$</li>\n</ul>\n<h2 id=\"概率图模型\"><a href=\"#概率图模型\" class=\"headerlink\" title=\"概率图模型\"></a>概率图模型</h2><p><a href=\"https://www.bilibili.com/video/BV1BW41117xo/?spm_id_from=333.999.0.0&vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1BW41117xo/?spm_id_from=333.999.0.0&amp;vd_source=441679270dda23308fe16f3c5602b058</a></p>\n<h3 id=\"概率和图\"><a href=\"#概率和图\" class=\"headerlink\" title=\"概率和图\"></a>概率和图</h3><p>概率图</p>\n<ul>\n<li>表示 Representation<ul>\n<li>有向图 Beyesian Netowrk</li>\n<li>无向图</li>\n<li>高斯图（连续的随机变量）</li>\n</ul>\n</li>\n<li>推断 Inference<ul>\n<li>精确推断</li>\n<li>近似推断<ul>\n<li>确定性推断（变分）</li>\n<li>随机近似 MCMC</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>学习<ul>\n<li>参数学习<ul>\n<li>完备数据</li>\n<li>隐变量</li>\n</ul>\n</li>\n<li>结构学习</li>\n</ul>\n</li>\n</ul>\n<p>高维随机变量</p>\n<ul>\n<li>sum: $P(x_1) &#x3D; \\int P(x_1, x_2)dx_2$</li>\n<li>product: $P(x_1|x_2) &#x3D; P(x_1|x_2)P(x_2)&#x3D;P(x_2|x_1)P(x_1)$</li>\n</ul>\n<p>链式法则</p>\n<ul>\n<li>$$P(X_1,X_2,…,X_n)&#x3D;P(X_1)P(X_2|X_1)P(X_3|X_2,X_1)···P(X_n|X_{n-1},X_{n-2},…,X_1)$$</li>\n</ul>\n<p>全概率公式</p>\n<ul>\n<li>$P(X_i)&#x3D;\\sum_{j}{P(X_i,X_j)}&#x3D;\\sum_{j}{P(X_i|X_j)P(X_j)}$</li>\n</ul>\n<p>贝叶斯公式</p>\n<ul>\n<li>$P(X_i|X_j)&#x3D;\\frac{P(X_i,X_j)}{P(X_j)}&#x3D;\\frac{P(X_i|X_j)P(X_j)}{P(X_j)}$</li>\n</ul>\n<p>困境：<br>维度高$P(X_1,X_2,…,X_n)$计算复杂</p>\n<ul>\n<li>1.假设$X_i$相互独立:<ul>\n<li>$P(X_1,X_2,…,X_n)&#x3D;\\prod_{i}{P(X_i)}$</li>\n</ul>\n</li>\n<li>2.Markov Property(HMM齐次马尔可夫):<ul>\n<li>$x_j\\perp x_i+1|x_i, j&lt;i$ </li>\n<li>$P(X_1, X_2,…,X_n)&#x3D;P(X_1)P(X_2|X_1)P(X_3|X_2,X_1)···P(X_n|X_{n-1},X_{n-2},…,X_1)$</li>\n</ul>\n</li>\n<li>3.假设$X_i$条件独立: <ul>\n<li>$x_a\\perp x_b|x_c$</li>\n<li>$P(X_1,X_2,…,X_n)&#x3D;\\prod_{i}{P(X_i|X_{i-1})}$</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"概率补充知识\"><a href=\"#概率补充知识\" class=\"headerlink\" title=\"概率补充知识\"></a>概率补充知识</h4><p>指数族分布</p>\n<ul>\n<li>充分统计量$\\phi(x)$</li>\n<li>共轭</li>\n<li>最大熵</li>\n<li>广义线性模型</li>\n<li>概率图模型</li>\n<li>变分推断</li>\n</ul>\n<p>充分统计量</p>\n<ul>\n<li>$P(x|\\eta)&#x3D;h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))$<ul>\n<li>$h(x)$: base measure</li>\n<li>$\\eta$: parameter 参数向量</li>\n<li>$\\phi(x)$: feature function</li>\n<li>$A(\\eta)$： log partition function 配分函数</li>\n</ul>\n</li>\n<li>$P(x|\\theta)&#x3D;\\frac{1}{z}\\hat P(x|\\theta)$<ul>\n<li>$z&#x3D;\\int \\hat P(x|\\theta)dx$ 归一化因子</li>\n</ul>\n</li>\n<li>$P(x|\\eta)&#x3D;h(x)\\exp(\\eta^T\\phi(x)-A(\\eta))$<ul>\n<li>$&#x3D;\\frac{1}{exp(A(\\eta))}h(x)exp(\\eta^T\\phi(x))$</li>\n<li>$&#x3D;\\frac{1}{z}\\hat P(x|\\eta)$<ul>\n<li>$\\hat P(x|\\eta)&#x3D;h(x)exp(\\eta^T\\phi(x))$</li>\n<li>$z&#x3D;exp(A(\\eta))$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>共轭, 先后验分布同组方便计算</p>\n<ul>\n<li>$P(\\theta|x)&#x3D;\\frac{P(x|\\theta)P(\\theta)}{P(x)}$</li>\n<li>$P(\\theta|x)$和$P(x|\\theta)$属于同一个指数族</li>\n<li>$P(\\theta|x)$的参数是$P(\\theta|x)$的参数的函数</li>\n</ul>\n<p>先验</p>\n<ul>\n<li>共轭 - 计算方便</li>\n<li>最大熵 无信息先验</li>\n<li>Jerrif</li>\n</ul>\n<p>广义线性模型</p>\n<ul>\n<li>线性组合 $w^Tx$</li>\n<li>Link funciton -&gt;aactivation function</li>\n<li>指数分布 $y|x\\sim$指数组分布（$Bernulli, Poisson, N(\\mu, \\Sigma)$）</li>\n</ul>\n<h5 id=\"Gaussian\"><a href=\"#Gaussian\" class=\"headerlink\" title=\"Gaussian\"></a>Gaussian</h5><ul>\n<li>$P(x|\\mu,\\Sigma)&#x3D;\\frac{1}{(2\\pi)^{n&#x2F;2}|\\Sigma|^{1&#x2F;2}}\\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)$</li>\n<li>$\\eta&#x3D;<br>\\left(!<br>  \\begin{array}{c}<br>\\eta_1 &#x3D;\\frac{\\mu}{\\sigma^2}\\<br>\\eta_2&#x3D;-\\frac{1}{\\sigma^2}<br>  \\end{array}<br>  !\\right)$</li>\n<li>$\\phi(x)&#x3D;\\left(!<br>  \\begin{array}{c}<br>x\\<br>x^2<br>  \\end{array}<br>  !\\right)$</li>\n<li>$A(\\eta)&#x3D;-\\frac{\\eta_1^2}{4\\eta_2}+\\frac{1}{2}\\ln(-\\frac{\\pi}{\\eta_2})$</li>\n</ul>\n<h4 id=\"-3\"><a href=\"#-3\" class=\"headerlink\" title=\"\"></a></h4><ul>\n<li>$P(x | \\eta) &#x3D; h(x) \\exp (\\eta^T \\phi(x) - A(\\eta))$<ul>\n<li>$\\eta$: 参数 (parameter)</li>\n<li>$\\phi(x)$: 充分统计量 (sufficient statistics)</li>\n<li>$A(\\eta)$: 对数配分函数 (log partition function)</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li>$A’(\\eta) &#x3D; \\mathbb{E}_{P(x|\\eta)}[\\phi(x)]$</li>\n<li>$A’’(\\eta) &#x3D; \\text{Var}[\\phi(x)]$</li>\n<li>$A(\\eta)$ 是凸函数 (convex function)</li>\n</ol>\n<p>对这个函数求导</p>\n<ul>\n<li>$\\exp(A(\\eta)) &#x3D; \\int h(x) \\exp(\\eta^T \\phi(x)) , dx$</li>\n<li>$A’(\\eta) &#x3D; \\frac{\\partial}{\\partial \\eta} \\log \\left( \\int h(x) \\exp(\\eta^T \\phi(x)) , dx \\right)$</li>\n<li>$A’(\\eta) &#x3D; \\int \\frac{h(x) \\exp(\\eta^T \\phi(x)) \\phi(x) , dx}{\\exp(A(\\eta))}$</li>\n<li>$A’(\\eta) &#x3D; \\int P(x | \\eta) \\phi(x) , dx &#x3D; \\mathbb{E}_{P(x|\\eta)}[\\phi(x)]$</li>\n</ul>\n<h5 id=\"MLE\"><a href=\"#MLE\" class=\"headerlink\" title=\"MLE\"></a>MLE</h5><p>$D&#x3D;{x_1, \\cdots, x_N}$</p>\n<p>$\\eta_{MLE}&#x3D;\\text{argmax  } log(P(D|\\eta))$</p>\n<ul>\n<li>$&#x3D;\\sum_{i&#x3D;1}^N\\text{argmax  }log\\cdot h(x_i)+(\\eta^T \\phi(x_i) - A(\\eta))$</li>\n<li><ul>\n<li>$&#x3D;\\sum_{i&#x3D;1}^N\\text{argmax  }\\eta^T \\phi(x_i) - A(\\eta)$</li>\n</ul>\n</li>\n</ul>\n<p>set $\\frac{\\partial \\eta_{MLE}}{\\partial \\eta}&#x3D;0$</p>\n<ul>\n<li>$\\sum \\phi(x_i)-NA’(\\eta)&#x3D;0$</li>\n</ul>\n<h5 id=\"Entorpy-最大熵\"><a href=\"#Entorpy-最大熵\" class=\"headerlink\" title=\"Entorpy 最大熵\"></a>Entorpy 最大熵</h5><p>信息熵 $-log\\ p$<br>熵，（对可能性的衡量）</p>\n<ul>\n<li><p>$E_{p(x)}[-log\\ p]&#x3D;\\int -p(x)log\\ p(x)dx&#x3D; \\sum -p(x)log\\ p(x)$</p>\n</li>\n<li><p>$\\hat p_i&#x3D;\\text{argmax } H(p)$ </p>\n</li>\n<li><p>拉格朗日$\\mathcal{L}(p, \\lambda)&#x3D;\\sum p_ilog\\ p_i$</p>\n<ul>\n<li>$\\frac{\\partial \\mathcal{L}}{\\partial p_i}&#x3D;log\\ p_i+1-\\lambda$</li>\n<li>$\\hat p_i&#x3D;exp(\\lambda-1)&#x3D;1&#x2F;k$</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"经验分布\"><a href=\"#经验分布\" class=\"headerlink\" title=\"经验分布\"></a>经验分布</h5><p>$Data &#x3D; {x_1, \\cdots, x_N}$</p>\n<ul>\n<li><strong>频率分布</strong>： $P(x_1, x_2, \\ldots, x_n) \\approx \\hat{P}(x) &#x3D; \\frac{\\text{count}(x)}{N}$</li>\n<li><strong>经验期望</strong>： $\\mathbb{E}<em>p[f(x)] &#x3D; \\Delta \\approx \\frac{1}{N} \\sum</em>{i&#x3D;1}^N f(x_i)$</li>\n</ul>\n<p>最大熵问题的求解<br>$$<br>\\begin{aligned}<br>\\min_{p(x)} &amp; \\sum_x p(x) \\log p(x) \\<br>\\text{subject to} &amp; \\sum_x p(x) &#x3D; 1 \\<br>&amp; \\mathbb{E}<em>p[f(x)] &#x3D; \\mathbb{E}</em>{\\hat{p}}[f(x)] &#x3D; \\Delta<br>\\end{aligned}<br>$$</p>\n<p>拉格朗日乘数法求解<br>$$<br>\\begin{aligned}<br>L(p, \\lambda, \\eta) &amp;&#x3D; \\sum_x p(x) \\log p(x) + \\lambda (1 - \\sum_x p(x)) + \\eta (\\Delta - \\sum_x p(x) f(x)) \\<br>\\frac{\\partial}{\\partial p(x)} &amp;&#x3D; \\log p(x) + 1 - \\lambda_0 - \\lambda f(x) &#x3D; 0 \\<br>p(x) &amp;&#x3D; \\exp(\\lambda_1 f(x) + \\lambda_0 - 1) \\<br>&amp;&#x3D; \\frac{\\exp(\\eta^T f(x))}{Z(\\eta)}<br>\\end{aligned}<br>$$</p>\n<h3 id=\"贝叶斯网络\"><a href=\"#贝叶斯网络\" class=\"headerlink\" title=\"贝叶斯网络\"></a>贝叶斯网络</h3><p>有向无环图<br>因子分解</p>\n<ul>\n<li>$P(X_1,X_2,…,X_n)&#x3D;\\prod_{i}{P(X_i|Pa(X_i))}$</li>\n<li>$P(X_i|Pa(X_i))$是局部概率分布</li>\n<li>$Pa(X_i)$是$X_i$的父节点集合</li>\n</ul>\n<h4 id=\"三种模型\"><a href=\"#三种模型\" class=\"headerlink\" title=\"三种模型\"></a>三种模型</h4><h5 id=\"tail-to-tail\"><a href=\"#tail-to-tail\" class=\"headerlink\" title=\"tail-to-tail\"></a>tail-to-tail</h5>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  a--&gt; b</span><br><span class=\"line\">  a--&gt; c</span><br></pre></td></tr></table></figure>\n<p>因子分解：</p>\n<ul>\n<li>$P(a, b, c)&#x3D;P(a)P(b|a)P(c|a)$</li>\n</ul>\n<p>链式法则：</p>\n<ul>\n<li>$P(a, b, c)&#x3D;P(a)P(b|a)P(c|a, b)$</li>\n</ul>\n<p>$\\implies P(c|a)&#x3D;P(c|a, b)\\implies c\\perp b |a$<br>若$b$ 被观测则路径被阻塞： </p>\n<h5 id=\"head-to-tail\"><a href=\"#head-to-tail\" class=\"headerlink\" title=\"head-to-tail\"></a>head-to-tail</h5>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  a --&gt;b </span><br><span class=\"line\">  b --&gt;c </span><br></pre></td></tr></table></figure>\n<p>$a\\perp c |b$<br>若$b$ 被观测则路径被阻塞： </p>\n<h5 id=\"head-to-head\"><a href=\"#head-to-head\" class=\"headerlink\" title=\"head-to-head\"></a>head-to-head</h5>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  b--&gt; c</span><br><span class=\"line\">  a--&gt; c</span><br></pre></td></tr></table></figure>\n<ul>\n<li>$P(a, b, c)&#x3D;P(a)P(b)P(c|a, b)$</li>\n<li>$P(a, b, c)&#x3D;P(a)P(b|a)P(c | a, b)$</li>\n</ul>\n<p>$\\implies P(b)&#x3D;P(b|a)\\implies a\\perp b$<br>若$b$ 被观测则路径被连通：</p>\n<h4 id=\"D-seperation\"><a href=\"#D-seperation\" class=\"headerlink\" title=\"D-seperation\"></a>D-seperation</h4>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  a  --&gt; b1</span><br><span class=\"line\">  a  --&gt; b2</span><br><span class=\"line\">  a  --&gt; b*</span><br><span class=\"line\">  b1 --&gt; c</span><br><span class=\"line\">  b2 --&gt; c</span><br><span class=\"line\">  c  --&gt; b*</span><br></pre></td></tr></table></figure>\n<ul>\n<li>如果$b1, b2\\in B$被观测了<br>，那么$a$和$c$被阻断，</li>\n<li>但是$b*$没有被观测到,且$b*$的后续节点都不在$b$中<br>$a\\perp c|b$</li>\n</ul>\n<p><img src=\"/2024-05-29-Casual-Inference/image-2.png\" alt=\"alt text\"><br>马尔可夫毯(Markov Blanket)</p>\n<ul>\n<li>$x_{pa(i)}$：$x_i$的父节点</li>\n<li>$x_{child(i)}$: childs of $x_i$</li>\n<li>$x_{pa(child(i))}$: parent of $x_{child(i)}$</li>\n<li>$x_{-i}&#x3D;x&#x2F;x_i$ 表示除了 $x_i$ 以外的所有变量。<ul>\n<li>和$x$有关:$\\Delta$<ul>\n<li>$P(x_i|x_{Pa(i)})&#x3D;f(\\bar \\Delta)$</li>\n</ul>\n</li>\n<li>和$x$无关:$\\bar \\Delta$</li>\n</ul>\n</li>\n</ul>\n<p>马尔可夫毯的作用是在给定马尔可夫毯内所有节点的情况下，$x_i$ 与网络中其他节点条件独立。</p>\n<p>$$<br>P(x_i | x_{-i}) &#x3D; \\frac{P(x_i, x_{-i})}{P(x_{-i})} &#x3D; \\frac{P(x)}{\\int_{x_i} P(x_{-i})} &#x3D; \\frac{ \\int_{x_i} P(x) , dx_i }{ \\int_{x_i} P(x_j | x_{\\text{pa}(j)}) , dx_i }<br>$$</p>\n<p>$$<br>P(x_{\\text{child}(i)} | x_i, x_{\\text{Parent}(\\text{Child}(i))})<br>$$</p>\n<h4 id=\"贝叶斯网络-Beyesian-Network\"><a href=\"#贝叶斯网络-Beyesian-Network\" class=\"headerlink\" title=\"贝叶斯网络 Beyesian Network\"></a>贝叶斯网络 Beyesian Network</h4><p>NB<br>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  y--&gt; x1 </span><br><span class=\"line\">  y--&gt; xp</span><br></pre></td></tr></table></figure></p>\n<p>GMM<br>  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">graph LR;</span><br><span class=\"line\">  z--&gt; x</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure><br>Beyesian Network</p>\n<ul>\n<li>单一： Naive Bayes<ul>\n<li>p维： $P(x|y)&#x3D;\\prod^p_{i&#x3D;1}P(x_i|y&#x3D;1)$</li>\n<li>$x_1\\perp x_2|y$</li>\n</ul>\n</li>\n<li>混合：GMM<ul>\n<li>Z discrete, z&#x3D;1,2,3,4</li>\n</ul>\n</li>\n<li>时间<ul>\n<li>Markov Chain</li>\n<li>Gaussian Process(无限维分布)</li>\n</ul>\n</li>\n<li>连续： Gaussian Network</li>\n</ul>\n<p>动态模型</p>\n<ul>\n<li>HMM 离散</li>\n<li>LDS Kalman Filter 连续线性</li>\n<li>Particle filter 非线性非高斯</li>\n</ul>\n<h3 id=\"Markov-Network\"><a href=\"#Markov-Network\" class=\"headerlink\" title=\"Markov Network\"></a>Markov Network</h3><p>条件独立性</p>\n<ul>\n<li>全局 Global Markov Property<ul>\n<li>$X_A \\perp X_C \\mid X_B$</li>\n<li>如果集合 $X_A$ 和 $X_C$ 被集合 $X_B$ 分隔开，那么 $X_A$ 和 $X_C$ 是条件独立的</li>\n</ul>\n</li>\n<li>局部 Local Markov Property<ul>\n<li>$a \\perp {Non-Neighbour} \\mid {Neighbour}$</li>\n<li>{ }：集合</li>\n</ul>\n</li>\n<li>成对 Pairwise Markov Property<ul>\n<li>$x_i \\perp x_j \\mid x_{-ij}$</li>\n<li>如果节点 $x_i$ 和 $x_j$ 直接相连，那么在给定其他所有节点的情况下，$x_i$ 和 $x_j$ 是条件独立的</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Factorization\"><a href=\"#Factorization\" class=\"headerlink\" title=\"Factorization\"></a>Factorization</h4><p>团: Clique<br>最大团: Maximal Clique<br>$$<br>P(X) &#x3D; \\frac{1}{Z} \\prod_{i&#x3D;1}^K \\psi(X_{C_i})<br>$$</p>\n<ul>\n<li>$c_i$ 最大团</li>\n<li>$x_{c_i}$: 最大团随机变量集合</li>\n<li>$\\psi(x_{c_i})$: 势函数</li>\n<li>$Z$:<ul>\n<li>$Z &#x3D; \\sum_{X} \\prod_{i&#x3D;1}^K \\psi(X_{C_i})$</li>\n</ul>\n</li>\n<li>$\\psi(X_{C_i})$ 是定义在最大团 $C_i$ 上的因子函数</li>\n</ul>\n<p>何弃疗<br><img src=\"/2024-05-29-Casual-Inference/image-3.png\" alt=\"alt text\"></p>\n<h3 id=\"Inference\"><a href=\"#Inference\" class=\"headerlink\" title=\"Inference\"></a>Inference</h3><ul>\n<li><p>联合概率 Joint Probability</p>\n<ul>\n<li>$P(X) &#x3D; P(x_1, x_2, \\ldots, x_p)$</li>\n</ul>\n</li>\n<li><p>边缘概率 Marginal Probability</p>\n<ul>\n<li>$P(x) &#x3D; \\sum_{x_j} P(x_j)$</li>\n</ul>\n</li>\n<li><p>条件概率 Conditional Probability</p>\n<ul>\n<li>$P(x_i | x_j)$, 其中$x_j &#x3D; {x \\backslash x_i}$</li>\n</ul>\n</li>\n<li><p>最大后验概率估计 MAP Inference</p>\n<ul>\n<li>$\\hat{z} &#x3D; \\arg \\max_z P(z | x) \\propto \\arg \\max_z P(z, x)$</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li><p>精确推断 Exact Inference</p>\n<ul>\n<li>Variable Elimination (VE)</li>\n<li>Belief Propagation (BP) → Sum-Product Algorithm (求和-乘积算法)</li>\n<li>Junction Tree Algorithm (树形算法)</li>\n</ul>\n</li>\n<li><p>近似推断 Approximate Inference</p>\n<ul>\n<li>Loop Belief Propagation (循环信念传播)</li>\n<li>Monte Carlo Inference: Importance Sampling, MCMC (蒙特卡罗推断：重要性采样，MCMC)</li>\n<li>Variational Inference (变分推断)</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Variable-Elimination\"><a href=\"#Variable-Elimination\" class=\"headerlink\" title=\"Variable Elimination\"></a>Variable Elimination</h4><p>$P(x) &#x3D; \\prod_{i} \\phi_i(x_i)$</p>\n<h4 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a>示例</h4><p>假设我们有四个二值随机变量 $a, b, c, d\\in {0,1}$。我们想计算边缘概率 $P(d)$。<br>$a\\rightarrow b \\rightarrow c \\rightarrow d$</p>\n<ol>\n<li><p>展开联合分布：</p>\n<ul>\n<li>$P(d) &#x3D; \\sum_{a, b, c} P(a, b, c, d)$</li>\n</ul>\n</li>\n<li><p>Chain rule</p>\n<ul>\n<li>$P(a, b, c, d) &#x3D; P(a) P(b | a) P(c | b) P(d | c)$</li>\n</ul>\n</li>\n<li><p>1-&gt;2</p>\n<ul>\n<li>$P(d) &#x3D; \\sum_{a, b, c} P(a) P(b | a) P(c | b) P(d | c)$<ul>\n<li>$&#x3D; \\sum_{b, c} P(d | c) \\left( \\sum_{a} P(a) P(b | a) \\right) P(c | b)$</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>定义新的因子函数：</p>\n<ul>\n<li>$\\phi_1(b, c) &#x3D; \\sum_{a} P(a) P(b | a)$</li>\n</ul>\n</li>\n<li><p>最终得到：</p>\n<ul>\n<li>$P(d) &#x3D; \\sum_{c} P(d | c) \\left( \\sum_{b} \\phi_1(b, c) P(c | b) \\right)$</li>\n</ul>\n</li>\n<li><p>得到另一个因子函数 $\\phi_2(c, d)$：</p>\n<ul>\n<li>$P(d) &#x3D; \\sum_{c} \\phi_2(c, d)$</li>\n</ul>\n</li>\n</ol>\n"},{"title":"Papers Collection","date":"2024-07-15T01:24:36.000Z","mathjax":true,"_content":"<!-- \n\n# Counterfactual fairness\nCounterfactual fairness\nlink: https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf\n\n###\nDefinitions:\n#### defs\n$A$: Protected attributes, sensitive features\\\n$X$: features of individuals, excluding A\\\n$U$: latent features not observed, represented\\\n$Y$: predictor    \n#### Fairness through unawareness (FTU):\n_An algorithm is fair so long as any protected attributes $A$ are not explicitly used in the decision-making process._\nShortcoming: $X$ might intersects $A$\n\n#### Individual Fairness (IF).\nFor distance metric(should be carefully choosen), $d(\\cdot , \\cdot)$, if $d(i, j)$ is small, then $\\hat Y(X^{(i)}, A^{(i)}) \\approx \\hat Y(X^{(j)}, A^{(j)})$\n\n#### Demographic Parity (DP)(人口统计学意义上的平等)\nPredictor $\\hat Y$ satisfies demographic partiy if $P(\\hat Y|A=0)=P(\\hat Y|A=1)$ \n#### Equality of Opportunity\n$P(\\hat Y|A=0, Y=1)=P(\\hat Y|A=1, Y=1)$ \n\n### Causal Models(因果推断), Counterfacutal、\nCasual Model $(U, V, F)$,\\\n$U$: latent background variables,\\\n$V$: observed variables, \\\n$F=\\{f_1. f_2, \\cdots, f_n\\}$, for each $V_i=f_i(pa_i, U_{pa_i})\\in V, pa_i \\subseteq V \\backslash {V_i}$ \n\n**Three Steps of Inference**\\\n- Abduction：for a given prior on $U$, compute the posterior distribution of $U$ given the evidence $W = w$\n- Action：substitute the equations for $Z$ with the interventional values $z$, resulting in the modified set of equations $F_z$\n- Prediction: \n\n\n\n# FairGAD\nhttps://openreview.net/forum?id=3cE6NKYy8x\n\nhttps://arxiv.org/abs/2307.04937\n## Fair GAD problem\n**GAD**\\\n$G=(V, E, X)$, \\\nnode feature matrix $X\\in \\R^{n\\times d}$, \\\nAdjacency matrix $A\\in \\{0,1\\}^{n\\times n}$, \\\nAnomaly labels $Y\\in \\{0, 1\\}^n$, predicted $\\hat Y$, \\\n**Fair GAD**\\\nsensitive attributes $S\\in \\{0, 1\\}^n$, a binary feature $X$.\\\nPerformance matrix: accuracy and _AUCROC_: Area under the ROC Curve \\\nUnfairness Mextrics, Statistic Parity(SP):$SP = |P(\\hat Y=1|S=0)−P(\\hat Y =1|S=1)|$, \\\nEquality of Odds _(EOO)_: $SP = |P(\\hat Y=1|S=0, Y=1)−P(\\hat Y =1|S=1, Y=1)|$\n## Data\n- Reddit: \ngraph structure： linking two user posted the name subreddit within 24h.\nNode feature: Embedding from post histories.\n- Twitter: \ngraph structure:: A follows B.\nNode feature: demographic infromation using M3 system, multimodal, multilingual, multi attirbute demographix inderence framework.\n\n## GAD Methods\n### DOMINANT (Ding et al., 2019a)\n### CONAD (Xu et al., 2022)\n### COLA (Liu et al., 2021)\n### VGOD (Huang et al., 2023)\n\n## Non-Graph AD methods\n- DONE (Bandyopadhyay et al., 2020)\n- AdONE (Bandyopadhyay et al., 2020)\n- ECOD (Li et al., 2022)\n- VAE (Kingma & Welling, 2014)\n- ONE (Bandyopadhyay et al., 2019)\n- LOF (Breunig et al., 2000)\n- F (Liu et al., 2008)\n\n## Fainess Method:\n### FAIROD (Shekhar et al., 2021)\n### CORRELATION (Shekhar et al., 2021)\n### HIN (Zeng et al., 2021)\n### EDITS (Dong et al., 2022)\n### FAIRWALK (Rahman et al., 2019)\n\n## Distance \n### Wasserstein Distance\n### Minkowski distance \n\n\n# 2024 Counterfactual Learning on Graphs: A Survey \n3.5.1 How to create synthetic dataset \n\n# 2022 Learning Fair Node Representations with Graph Counter factual Fairness\nTwo limitation on existing CF on graph:\n1. $S_i$ affect the predetection. Red\n2. $S_i$ affect $A, X_i$ Green \n\nGEAR: Graph Counterfactually Fair Node Representation\n1. subgraph generation\nNode **Importance Score** by prune range of casualmodel to **ego-centric subgraph**( node and its neighbour)\n2. Counterfactual Data Argmentation: \nGraph Auto encodder and fair contrains: **self-pertubation**(flip its $S_i$), **neighbour pertubatiob**\n3. Node Representation Learning  :\nSiamese network to minimize discrepancy \n\n**Def, Graph conterfactual fairness:**\nAn encoder $\\Phi(\\cdot)$ satisfies graph counterfactual fairness if for any node $i$:\n$$\nP((Z_i)_{S \\leftarrow s'} | X = \\mathbf{X}, A = \\mathbf{A}) = P((Z_i)_{S \\leftarrow s''} | X = \\mathbf{X}, A = \\mathbf{A}),\n$$\nfor all $s' \\neq s''$, where $s', s'' \\in \\{0, 1\\}^n$ are arbitrary sensitive attribute values of all nodes, $Z_i = (\\Phi(\\mathbf{X}, \\mathbf{A}))_i$ denotes the node representations.\n\n$\\Phi$, minimize the discrepancy between representation $\\Phi(X_{S\\leftarrow s'}, A_{S\\leftarrow s'})$ and $\\Phi(X_{S\\leftarrow s''}, A_{S\\leftarrow s''})$\n\n\n### GEAR\n### 1) subgraph generation\nPersonalized Pagerank algorithm:\nImportance score $\\mathbf R=\\alpha (\\mathbf I-(1-\\alpha \\mathbf {\\bar A}))$, $\\mathbf I$, identity\\\n$R_{i,j}$ How node $j$ is important for node $i$, $\\alpha \\in [0,1]$\n\n$\\mathbf {\\bar A}=\\mathbf A \\mathbf D^{-1} $ column-normalized adjacency matric, $\\mathbf D: \\mathbf D_{i, i}=\\sum_j A{i, j}$\n\n$\\mathcal{G}^{(i)}=Sub(i, \\mathcal{G}, k)$ :, subgraph generation\n\n- $\\mathcal{G}^{(i)} = \\{ \\mathcal{V}^{(i)}, \\mathcal{E}^{(i)}, \\mathbf{X}^{(i)} \\} = \\{ \\mathbf{A}^{(i)}, \\mathbf{X}^{(i)} \\},\n$ Vertive, Edge, Features with $S=\\{s_i\\}_{i=1}^n $ includes in $X$, and $X^{\\neg s} = \\{ x_1^{\\neg s}, ..., x_n^{\\neg s} \\} $, where $ x_i^{\\neg s} = x_i \\setminus s_i$\n\n- $\\mathcal{V}^{(i)} = \\text{TOP}(\\mathbf{R}_{i,:}, k),$\n\n- $\\mathbf{A}^{(i)} = \\mathbf{A}_{\\mathcal{V}^{(i)}, \\mathcal{V}^{(i)}}, \\quad \\mathbf{X}^{(i)} = \\mathbf{X}_{\\mathcal{V}^{(i)}, :},\n$, \n\n### 2）Counterfactual Data Augmentation\n**GraphVAG**: graph variational auto-encoder\\\nlatent embedding $H=\\{h_1, h_2, \\cdots, h_k\\}$  $H$ is sampled from $q(H|X, A)$,  $p(𝐻)$ is a standard Normal prior distribution\\\n$\\mathcal{L}=$\n\n$\\tilde{s}_i$: summary of neighbor info, aggregationof all nodes in subgarph $\\mathcal{G}^{(i)}$\\\n$\\tilde{s}_i = \\frac{1}{|\\mathcal{V}^{(i)}|} \\sum_{j \\in \\mathcal{V}^{(i)}} s_j$\n\nDiscriminator,$D(\\cdot)$\\\n$D(\\mathbf{H}, b)$  predicts the probability of whether the summary of sensitive attribute values is in range $b$\n\nFairness Constraint\\\n$L_d = \\sum_{b \\in B} \\mathbb{E} [\\log(D(\\mathbf{H}, b))]$\\\n$L_d$ is a regularizer to minimize the mutual information between the summary of sensitive attribute values and the\nembeddings\n\n**Final Loss** for Counterfactual Data Augmentation\\\n$L_a = L_r + \\beta L_d$\\\n$\\beta$ is a hyperparameter for the weight of fairness constraint\\\nUse alternating SGD for optimization: \n1) minimize $L_{a}$ by fixing the discriminator and updating parameters in other parts; \n2) minimize $−L_{a}$ with respect to the discriminator while other parts fixed.\n\n\n#### Self-Perturbation\n$\\overline{\\mathcal{G}}^{(i)} = \\{ \\mathcal{G}^{(i)}_{S_i \\leftarrow 1-s_i} \\}$ (flipping sensitive feature)\n\n#### Neighbor-Perturbation\n$\\underline{\\mathcal{G}}^{(i)} = \\left\\{ \\mathcal{G}^{(i)}_{S^{(i)}_{\\setminus i} \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})} \\right\\}$\n\nsubgraph $\\mathcal{G}^{(i)}$ ego($i$)-center subgraph with noes $\\mathcal{V}^{(i)}$, exclude node $i$: $\\mathcal{V}^{(i)}_{\\setminus i}$, randomly preterbe the sentsitice value of other nodes: $SMP(\\mathcal{V}^{(i)}_{\\setminus i})$\n\n\n\nReconstruction Loss (GraphVAE Module)\\\n$L_r = \\mathbb{E}_{q(\\mathbf{H}|X, A)} \\left[ -\\log(p(X, A | \\mathbf{H}, S)) \\right] + \\text{KL}[q(\\mathbf{H} | X, A) \\| p(\\mathbf{H})]$\n\n\n### 3) Fair Representation learning\n**Fairness Loss**\n$\nL_f = \\frac{1}{|\\mathcal{V}|} \\sum_{i \\in \\mathcal{V}} \\left( (1 - \\lambda_s) d(z_i, \\bar{z}_i) + \\lambda_s d(z_i, \\underline{z}_i) \\right),\n$\\\n$\\lambda_s$ hyperparam control neig-preturbation weight\n\n**Node Representations**\n- $\nz_i = (\\phi(\\mathbf{X}^{(i)}, \\mathbf{A}^{(i)}))_i,\n$\n- $\n\\bar{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow 1-s_i}, \\mathbf{A}^{(i)}_{S_i \\leftarrow 1-s_i}))_i \\right\\} \\right),\n$\n- $\n\\underline{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})}, \\mathbf{A}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})})_i \\right\\} \\right),\n$\n\nPrediction Loss\n$L_p = \\frac{1}{n} \\sum_{i \\in [n]} l(f(z_i), y_i),$ $l$: could be CE(Cross entropy), $f(\\cdot)$ makes predictions for downstream tasks with the representations, i.e.$ \\hat y_i=f(z_i)$\n\nOverall Loss\n$\nL = L_p + \\lambda L_f + \\mu \\| \\theta \\|^2,\n$\n\n### Dataset creation\n\nSensitive Attributes\n$S_i \\sim \\text{Bernoulli}(p),$ $p=0.4$ percent $S_i=1$\n\nLatent Embeddings\n$Z_i \\sim \\mathcal{N}(0, \\mathbf{I}),$ \\\n$\\mathbf{I}$ identity, dimension of $Z_i$: $d_s=50$\n\nNode Features\n$X_i = \\mathcal{S}(Z_i) + S_i \\mathbf{v},$\\\nsampling operation $S(\\cdot)$ select 25 dims from $Z_i$, $\\mathbf{v} \\sim \\mathcal{N}(0, \\mathbf{I})$\n\nGraph Structure\n$P(A_{i,j} = 1) = \\sigma(\\text{cos}(Z_i, Z_j) + a \\mathbf{1}(S_i = S_j)),$\\\n$\\sigma$ sigmoid function, $\\mathbf{1}(S_i = S_j)==S_i = S_j. \\alpha=0.01$\n\nNode Labels\n$Y_i = \\mathcal{B}(w Z_i + w_s \\frac{\\sum_{j \\in \\mathcal{N}_i} S_j}{|\\mathcal{N}_i|}),$\\\n$\\mathcal{B}$ Bernulli distribution,$\\mathcal{N}_i$ set of neighbors of node i $w, w_i$ weight vector\n\n### Result\nUsing Synthetic dataset, Bail, Credit\n\n\n\n\n\n\n\n\n\n\n# 24 Three Revisits to Node-Level Graph Anomaly Detection\nOutliers, Message Passing and Hyperbolic Neural Networks\n\n### Previous Outlier injection method\n$\\mathcal{G}=(\\mathcal{V}, \\mathcal{E}, X, y)$: vertice set, edge set, attibute matrix, label of class\n\n- **Contextual(cntxt.) outlier injection**\nNormalize features $x_i'=\\frac{x_i}{||x_i||_1}$\nSample $o$ nodes from $\\mathcal{V}$ as $\\mathcal{V}_c$. without replacement\nFor node $i$ in $\\mathcal{V}_c$, sample $q$ nodes from $\\mathcal{V}_r=\\mathcal{V}- \\mathcal{V}_c$, among them choose the farthest one $j = \\text{argmax}_k(||x_i'-x_k'||_2)$ to replace $x_i$ with $x_j$.\n\n- **Strctural(stct.) outlier injection**\ncreate $t$ groups sized $s$ with anomalous nodes.\nsample $o=t\\times s$ from $\\mathcal{V}$ without replacement\nThen randoms partition into $t$ groups.\nAdd edges to make them a clique(fully connected), then drop edges with $p$ probability\n\n#### Score function\nThe farthest node will have large $||\\tilde{\\mathbf x}_i||_2$ \\\nA structural outlier node $i$ will have many neighbors leads to large $||\\tilde{\\mathbf a}_i||_1$ \n\n\nScore function: $score_{norm}(i)=\\alpha||\\tilde{\\mathbf x}_i||_2+(1-\\alpha)||\\tilde {\\mathbf a}_i||_1$,  $\\tilde{\\mathbf x}_i$: $x_i$ after outlier injection, $\\tilde{\\mathbf a}_i$: $a_i$ after outlier injection, $A_{ii}=1$\\\nwhere cntxt OD, $\\alpha=1$, stct OD, $\\alpha=0$ :  $\\alpha$ ratio of two methods \n\n\ntest 1: ROC-AUC\nFor each dataset, use original dataset v.s. l2-nrom for each $x_i$\\\ndo anomaly injection. apply GAD Method to get  $score_{norm}$\n\n### Novel Anomaly injection method\n\n## Sum in terms of Dataset\n从数据集的角度来说：\n### FairGAD:\nReddit:\n- 数据来源：Post on politic related subReddit\n- Labelling Y: based on FACTOID(Sakketou et al., 2022), use the num of posted link(left or right)\n- Graph construciton: \n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n# CaD-VAE\n Causal Disentangled Variational Auto-Encoder \nCausal Disentangled Variational Auto-Encoder for Preference Understanding in Recommendation\nLink: https://arxiv.org/pdf/2304.07922\n\nChallenges: inability to disentangle the latent factor\nDLR: Disentangled Representation learning \n     - DEAR: (Disentangled gEnerative cAusal Representation (DEAR)) https://arxiv.org/abs/2010.02637\n     - CasualVAE: https://doi.org/10.1109/CVPR46437.2021.00947\n\n![alt text](2024-07-14-Papers-Collection/image.png)\n\n## In Casual Layer: The SCM is \n### 2.1\n- $u \\in \\{1, \\ldots, U\\}$: user index\n- $i \\in \\{1, \\ldots, I\\}$: item index \n - $\\mathcal{D}=(U, I, X)$: dataset  \n   - For a user $u$, the historical interactions $D_u = \\{x_{u,i} : x_{u,i} \\in \\{0,1\\}\\}$ form a multi-hot vector.\n   - $x_{u,i} = 0$ means no recorded interaction between user $u$ and item $i$.\n   - $x_{u,i} = 1$ means an interaction between user $u$ and item $i$, such as a click.\n\n- $x_u$ denotes all interactions of the user $u$:\n$$\nx_u = \\{x_{u,i} : x_{u,i} = 1\\}\n$$\n   - Users may have diverse interests and interact with items that belong to many high-level concepts, such as preferred film directors, actors, genres, and year of production.\n\n### 2.2\n\n$$\nz = g \\left( (I - A^T)^{-1} \\epsilon \\right) := F_\\alpha (\\epsilon)\n$$\n \n- $z$: causal variable\n- $\\epsilon$: exogenous variables from a normal distribution - $\\mathcal{N}(0, I)$\n- $g$: nonlinear element-wise transformations\n- $\\alpha$: parameters $(A, g)$.\n- $A$: weighted adjacency matrix: $A_{ij}$ is non-zero only if $[z]_i$ is a parent of $[z]_j$. The binary adjacency matrix $I_A$ indicates where $A \\neq 0$\n- To ensure disentanglement, labels of concepts $c$ are used as additional information\n\n\n  - If $g$ is invertible, the equation can be rephrased as:\n   $$\n   g_i^{-1}(z_i) = A_i^T g_i^{-1}(z) + \\epsilon_i\n   $$\n   This implies that after a nonlinear transformation $g$, the factors $z$ satisfy a linear SCM.\n\n1. **Generative Model Assumption**:\n   - For a user $u$, the generative model parameterized by $\\theta$ assumes that the observed data are generated from the following distribution:\n     $$\n     p_\\theta(x_u) = \\mathbb{E}_{p_\\theta(c)} \\left[ \\iint p_\\theta (x_u | \\epsilon, z_u, c) p_\\theta (\\epsilon, z_u | c) d\\epsilon dz_u \\right]\n     $$\n     Here, $x_u$ is the observed data for user $u$, $\\epsilon$ are the exogenous variables, $z_u$ are the latent variables, and $c$ are the labels of the concepts.\n\n\n\n\n\n\n\n\n\n\n# GUIDE\n- Paper:\n   https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9671990\n\n- Github:\n   https://github.com/yushuowiki/GUIDE_pytorch\n\n\n\n![alt text](2024-07-14-Papers-Collection/image-1.png)\n\n\nStructure: 主要用（三阶和四阶）Motif来encode\nEncoderResidual Attention Layer\n\n\nAttribute: 就是普通的X \nEncoder用三层GCN。\n\n\n\n\n\n\n\n\n\n24.02的 FairGAD\nhttps://arxiv.org/pdf/2402.15988\nhttps://openreview.net/pdf?id=3cE6NKYy8x\nhttps://github.com/nigelnnk/FairGAD\n造数据集的\nDOMINANT 19\nCONAD 22\nCola 21\n VGOD 23\n\n\n23的GFCN\nGraph Fairing Convolutional Networks for Anomaly Detection\nhttps://github.com/MahsaMesgaran/GFCN\nhttps://arxiv.org/pdf/2010.10274\n\nVGOD 23.01\nhttps://arxiv.org/pdf/2210.12941\n\nEdits\n\n\n\n\n很多数据集和model\nhttps://proceedings.neurips.cc/paper_files/paper/2023/file/5eaafd67434a4cfb1cf829722c65f184-Paper-Datasets_and_Benchmarks.pdf\n![alt text](2024-07-14-Papers-Collection/image-3.png)\n\n\n\n# 一讲Deep Casual Learning 21的\nhttps://arxiv.org/ftp/arxiv/papers/2211/2211.03374.pdf\n![alt text](2024-07-14-Papers-Collection/image-4.png)\n\n# Disentanglement learn\n## Fair Rep learn by disentanglement 19\nhttps://proceedings.mlr.press/v97/creager19a/creager19a.pdf\n![alt text](2024-07-14-Papers-Collection/image-6.png)\n## CAF 也是disen,,\n## DEFEND 24\npaper： https://arxiv.org/pdf/2406.00987\n![alt text](2024-07-14-Papers-Collection/image-7.png)\n\n\n\n\n\n\n\n\n\n\n# Counterfactual Augmentation\n## CFGAD 24\nhttps://ojs.aaai.org/index.php/AAAI/article/view/30524\nCounterfactual Graph Learning for Anomaly Detection with Feature\nDisentanglement and Generation (Student Abstract)\n## NIFTY 21\n- paper: https://arxiv.org/pdf/2102.13186\n- Code: https://github.com/chirag126/nifty?tab=readme-ov-file\n\n![alt text](2024-07-14-Papers-Collection/image-2.png)\n\nAugmented:\n-  Node level \n     - attribute masking $r \\sim \\mathcal{B}(P_n)$\n     - $\\tilde{\\mathbf{x}}_u = \\mathbf{x}_u + \\mathbf{r} \\circ \\delta$, where $\\delta \\in \\mathbb{R}^M$ is sampled from a normal distribution.\n- sens attribute level\n  - \n- edge level\n\n## DEFEND\n![alt text](2024-07-14-Papers-Collection/image-5.png)\n\n\n## GEAR 22\nc\n## MCCNIFTY 21\n## Fairness-Aware 21\n## CAF 23\npaper: https://arxiv.org/pdf/2307.04937\ncode: https://github.com/TimeLovercc/CAF-GNN?tab=readme-ov-file\n\n![alt text](2024-07-14-Papers-Collection/image-10.png)\n## FairGNN\nuses adversarial training to achieve fairness on graphs. It trains the learned representation via an adversary which is optimized to predict the sensitive attribute\n## EDITS 23\nis a pre-processing method for fair graph learning. It aims to debias the input network to remove the sensitive\ninformation in the graph data\n## Fatra 24\n\n## CAGAD 24\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10564850\nheterophily dominant neighbors: most of its neighbors have different class labels from the target node\n1. GPNN graph pointer nn:  detect heter nodes\n   composed of encoder and decoder\n2. DDMP (deniosing difussion probabilistic model): translate, create anomaly neigbors for heter nodes\n3. GAT Graph attention network: detect anomaly nodes\n有点想加一个PRAUC的测试指标： 所以当我们希望模型在正负样本上都能表现较好时使用 ROC-AUC 衡量，如果我们只关注模型对正样本的分辨能力使用 PR-AUC 更好\n\n\n## GFCN 24\nhttps://arxiv.org/abs/2010.10274\n\n\n## GAD-NR 24 (in Pygod)\n![alt text](2024-07-14-Papers-Collection/image-11.png)\n\n# GAD with node rep learn\n## a survey on GAD -21\nmethod and datasets\nhttps://github.com/XiaoxiaoMa-MQ/Awesome-Deep-Graph-Anomaly-Detection\n\n## a survey 23: Graph Learning for Anomaly Analytics: Algorithms, Applications, and Challenges\nhttps://dl.acm.org/doi/full/10.1145/3570906\n\n## ADA-GAD 24 AAAI（Anomaly-Denoised Autoencoders for Graph Anomaly Detection）\nhttps://ojs.aaai.org/index.php/AAAI/article/view/28691\n\n\n\n\n\n\n\n\n感觉最后写出来的应该类似是 Improving fairness for node-level GAE based GAD models via disentanglement learning\n\n\n\n\n# Domain Adaptation\n属于transfer learning\n2.2 GDA的两个用途：node/graph classification\n\n\n- $\\mathcal{U}\\in\\{S,T\\}$ Domain\n- $P_{\\mathcal{U}}(X,Y)$: joint feature and label distribution \n- $\\{(x_i,y_i)\\}_{i=1}^N$: labeled source data \n- $\\{(x_i)\\}_{i=1}^M$: unlabeled target data IID sampled from the source and target domain respectively.\n- $\\phi:\\mathcal{X}\\rightarrow\\mathcal{H}$: a feature encoder\n- $g:\\mathcal{H}\\rightarrow\\mathcal{Y}$: a classifier \n- $\\epsilon_{\\mathcal{U}}(g\\circ\\phi)=P_{\\mathcal{U}}(g(\\phi(X))\\neq Y)$:classification error in domain $\\mathcal{U}$ \n- The objective is to train the model with available data to minimize target error $\\epsilon_T(g\\circ\\phi)$ when predicting target labels.\n\nA popular DA strategy is to learn domain-invariant representation, ensuring similar $P_S(H)$ and $P_T(H)$ and minimizing the source error $\\epsilon_S(g\\circ\\phi)$ to retain classification capability simultaneously ([Zhao et al., 2019](https://arxiv.org/abs/1904.05801)). This is achieved through \n\n- Feature Shift: $P_S(X|Y) \\neq P_T(X|Y)$\n  - Assume ndoe feature $x_u$，$u \\in \\mathcal{V}$ are IID sampled from $P(X|Y)$. Therefore, $P(X = x|Y = y) = \\prod_{u \\in \\mathcal{V}} P(X = x_u|Y = y_u)$\n\nPreassumption on model:\n\n $X\\leftarrow Y \\rightarrow A$. Lables are generated first, then A and X are generated.\n- Strcture Shift: $P_S(A, Y) \\neq P_T(A, Y)$\n  - Given joint distribution of $A$, and node labels $P(A, Y)$\n\n\nPreassumption:\n1. Model: $X\\leftarrow Y \\rightarrow A$. Lables are generated first, then A and X are generated.\n2. No Feature Shift: $P_S(X|Y) = P_T(X|Y)$\n\nStructure Shift: $P_{U}(A, Y) = P_{U}(A|Y)P_{U}(Y)$ \n  - Conditional Structure Shift: $P_S(A|Y) \\neq P_T(A|Y)$\n  - Label Shift: $P_S(Y) \\neq P_T(Y)$\n\n\nBecause of the interconnected nature of graph data, the IID is not satisfied for strcture shift, and new alogrithm is needed for solving CSS.\n\n structure shift is unique to graphs. In contrast to feature shift, which is analogous to non-IID feature shift in non-graph data, structure shift cannot be solved by adapting traditional conditional shift methods. Therefore, we assume feature shift is resolved, i.e., $P_S(X|Y) = P_T\n\n\nEven if $P_S(H^{(k)}|Y) = P_T(H^{(k)}|Y)$\\\nCSS may lead to $P_S(H^{(k+1)}|Y) \\neq P_T(H^{(k+1)}|Y)$\n\n\n\n### GNN\n  $$h_u^{(k+1)} = \\text{UPT}\\left(h_u^{(k)}, \\text{AGG}\\left(\\{\\{h_v^{(k)} : v \\in \\mathcal{N}_u\\}\\}\\right)\\right)$$\n- $\\{\\{\\cdot\\}\\}$: Multiset\n- $h_u^{(k+1)}$: The updated representation of node $u$ at layer $k+1$.\n- $\\text{AGG}(\\cdot)$: Aggregates message from neighbors.\n- $\\text{UPT}(\\cdot)$: Update function\n\n\n**Theorem 3.3 (Sufficient conditions for addressing CSS).**\n\n*Given the following assumptions*\n\n- *Conditional Alignment in the previous layer k* \n  - $P_S(H^{(k)}|Y) = P_T(H^{(k)}|Y)$ and $\\forall u \\in \\mathcal{V}_u$, *given* $Y = y_u$, $h_u^{(k)}$ *is independently sampled from* $P_{\\mathcal{U}}(H^{(k)}|Y)$.\n- *Edge Conditional Independence* \n  - *Given node labels* $y$, *edges mutually independently exist in the graph*.\n\n*If there exists a transformation that modifies the neighborhood of node* $u$: $\\mathcal{N}_u \\rightarrow \\tilde{\\mathcal{N}}_u, \\forall u \\in \\mathcal{V}_S$, *such that*\n- $P_S(|\\tilde{\\mathcal{N}}_u||Y_u = i) = P_T(|\\tilde{\\mathcal{N}}_u||Y_u = i)$ \n-  $P_S(Y_v|Y_u = i, v \\in \\tilde{\\mathcal{N}}_u) = P_T(Y_v|Y_u = i, v \\in \\mathcal{N}_u), \\forall i, v \\in \\mathcal{Y}$\n  \n*then*\n$P_S(H^{(k+1)}|Y) = P_T(H^{(k+1)}|Y) \\text{ is satisfied}$\n\n\n\n$\\phi_\\gamma$: GNN encoding with edge weight adjusting\\\n$\\phi$: GNN encoding without adjusting\\\nlast-layer alignment $P_S(H^{(L)} \\mid Y) = P_T(H^{(L)} \\mid Y)$can be achieved with $h_S^{(L)} = \\phi_\\gamma(x_S, A_S)$ and $h_T^{(L)} = \\phi(x_T, A_T)$. Note that based on conditional alignment in the distribution of randomly sampled node representations $P_S(H^{(L)} \\mid Y) = P_T(H^{(L)} \\mid Y)$ and under the conditions in Thm 3.3, $P_S(\\mathbf{H}^{(L)} \\mid Y) = P_T(\\mathbf{H}^{(L)} \\mid Y)$ can also be achieved in the matrix form.\n\n$G_s=(A_s,X_s)$\\\n$G_t=(A_t,X_t)$\\\n$g \\circ \\phi_\\gamma$\\\n$g \\circ \\phi$\\\n$\\hat Y_s$\n$\\hat Y_t$\n\nDrawback of StrucRW\n1. using $w$ instead of $\\gamma$ to reweigt $G_s$\n2. Rough estimation for $w$\n3. Not considering LS\n\n\n# LLM GAD\n## problem\nGNN缺点：\nGNN的message passing会导致N和A趋同，降低识别率\n尽管在Heterophilic graph上有改进，但是没有改变single node rep的本质\n\n\n## method\n(1) Sequence Construction\n(2) Coherence-Aware Rep Computation\n(3) Anomaly Detection via LLMs\n\n**text coherence**\nelvalueated by \n- llama 2: LLM model\n- LCD-G: cross-domain coherence eval od sentence\n![alt text](2024-07-14-Papers-Collection/image-12.png)\n48,509 normal sequences and 7,108 anomalous sequences\n\n### Sequence Construction\nMulti sequences for each node by random walk (local)\n- starting from the target node (以target node为中点)\n- iteratively sampling neighboring nodes and their connecting edges. (h:点, e:边, hzhzhzh)\n  \n### Coherence-Aware Rep Computation\nmicro\n- AGG info from edges within same sequence\n\nmacro\n- holistic edge information within the\nentire graph\n\n### AD via LLMs\n\n\n\n\ncomment:\n可以解释一下为什么Multi-AD-MR表现差于ER吗\n40% labeled？-->\n","source":"_posts/2024-07-14-Papers-Collection.md","raw":"\n---\ntitle: Papers Collection\ndate: 2024-07-14 21:24:36\ntags:\nmathjax: true\n---\n<!-- \n\n# Counterfactual fairness\nCounterfactual fairness\nlink: https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf\n\n###\nDefinitions:\n#### defs\n$A$: Protected attributes, sensitive features\\\n$X$: features of individuals, excluding A\\\n$U$: latent features not observed, represented\\\n$Y$: predictor    \n#### Fairness through unawareness (FTU):\n_An algorithm is fair so long as any protected attributes $A$ are not explicitly used in the decision-making process._\nShortcoming: $X$ might intersects $A$\n\n#### Individual Fairness (IF).\nFor distance metric(should be carefully choosen), $d(\\cdot , \\cdot)$, if $d(i, j)$ is small, then $\\hat Y(X^{(i)}, A^{(i)}) \\approx \\hat Y(X^{(j)}, A^{(j)})$\n\n#### Demographic Parity (DP)(人口统计学意义上的平等)\nPredictor $\\hat Y$ satisfies demographic partiy if $P(\\hat Y|A=0)=P(\\hat Y|A=1)$ \n#### Equality of Opportunity\n$P(\\hat Y|A=0, Y=1)=P(\\hat Y|A=1, Y=1)$ \n\n### Causal Models(因果推断), Counterfacutal、\nCasual Model $(U, V, F)$,\\\n$U$: latent background variables,\\\n$V$: observed variables, \\\n$F=\\{f_1. f_2, \\cdots, f_n\\}$, for each $V_i=f_i(pa_i, U_{pa_i})\\in V, pa_i \\subseteq V \\backslash {V_i}$ \n\n**Three Steps of Inference**\\\n- Abduction：for a given prior on $U$, compute the posterior distribution of $U$ given the evidence $W = w$\n- Action：substitute the equations for $Z$ with the interventional values $z$, resulting in the modified set of equations $F_z$\n- Prediction: \n\n\n\n# FairGAD\nhttps://openreview.net/forum?id=3cE6NKYy8x\n\nhttps://arxiv.org/abs/2307.04937\n## Fair GAD problem\n**GAD**\\\n$G=(V, E, X)$, \\\nnode feature matrix $X\\in \\R^{n\\times d}$, \\\nAdjacency matrix $A\\in \\{0,1\\}^{n\\times n}$, \\\nAnomaly labels $Y\\in \\{0, 1\\}^n$, predicted $\\hat Y$, \\\n**Fair GAD**\\\nsensitive attributes $S\\in \\{0, 1\\}^n$, a binary feature $X$.\\\nPerformance matrix: accuracy and _AUCROC_: Area under the ROC Curve \\\nUnfairness Mextrics, Statistic Parity(SP):$SP = |P(\\hat Y=1|S=0)−P(\\hat Y =1|S=1)|$, \\\nEquality of Odds _(EOO)_: $SP = |P(\\hat Y=1|S=0, Y=1)−P(\\hat Y =1|S=1, Y=1)|$\n## Data\n- Reddit: \ngraph structure： linking two user posted the name subreddit within 24h.\nNode feature: Embedding from post histories.\n- Twitter: \ngraph structure:: A follows B.\nNode feature: demographic infromation using M3 system, multimodal, multilingual, multi attirbute demographix inderence framework.\n\n## GAD Methods\n### DOMINANT (Ding et al., 2019a)\n### CONAD (Xu et al., 2022)\n### COLA (Liu et al., 2021)\n### VGOD (Huang et al., 2023)\n\n## Non-Graph AD methods\n- DONE (Bandyopadhyay et al., 2020)\n- AdONE (Bandyopadhyay et al., 2020)\n- ECOD (Li et al., 2022)\n- VAE (Kingma & Welling, 2014)\n- ONE (Bandyopadhyay et al., 2019)\n- LOF (Breunig et al., 2000)\n- F (Liu et al., 2008)\n\n## Fainess Method:\n### FAIROD (Shekhar et al., 2021)\n### CORRELATION (Shekhar et al., 2021)\n### HIN (Zeng et al., 2021)\n### EDITS (Dong et al., 2022)\n### FAIRWALK (Rahman et al., 2019)\n\n## Distance \n### Wasserstein Distance\n### Minkowski distance \n\n\n# 2024 Counterfactual Learning on Graphs: A Survey \n3.5.1 How to create synthetic dataset \n\n# 2022 Learning Fair Node Representations with Graph Counter factual Fairness\nTwo limitation on existing CF on graph:\n1. $S_i$ affect the predetection. Red\n2. $S_i$ affect $A, X_i$ Green \n\nGEAR: Graph Counterfactually Fair Node Representation\n1. subgraph generation\nNode **Importance Score** by prune range of casualmodel to **ego-centric subgraph**( node and its neighbour)\n2. Counterfactual Data Argmentation: \nGraph Auto encodder and fair contrains: **self-pertubation**(flip its $S_i$), **neighbour pertubatiob**\n3. Node Representation Learning  :\nSiamese network to minimize discrepancy \n\n**Def, Graph conterfactual fairness:**\nAn encoder $\\Phi(\\cdot)$ satisfies graph counterfactual fairness if for any node $i$:\n$$\nP((Z_i)_{S \\leftarrow s'} | X = \\mathbf{X}, A = \\mathbf{A}) = P((Z_i)_{S \\leftarrow s''} | X = \\mathbf{X}, A = \\mathbf{A}),\n$$\nfor all $s' \\neq s''$, where $s', s'' \\in \\{0, 1\\}^n$ are arbitrary sensitive attribute values of all nodes, $Z_i = (\\Phi(\\mathbf{X}, \\mathbf{A}))_i$ denotes the node representations.\n\n$\\Phi$, minimize the discrepancy between representation $\\Phi(X_{S\\leftarrow s'}, A_{S\\leftarrow s'})$ and $\\Phi(X_{S\\leftarrow s''}, A_{S\\leftarrow s''})$\n\n\n### GEAR\n### 1) subgraph generation\nPersonalized Pagerank algorithm:\nImportance score $\\mathbf R=\\alpha (\\mathbf I-(1-\\alpha \\mathbf {\\bar A}))$, $\\mathbf I$, identity\\\n$R_{i,j}$ How node $j$ is important for node $i$, $\\alpha \\in [0,1]$\n\n$\\mathbf {\\bar A}=\\mathbf A \\mathbf D^{-1} $ column-normalized adjacency matric, $\\mathbf D: \\mathbf D_{i, i}=\\sum_j A{i, j}$\n\n$\\mathcal{G}^{(i)}=Sub(i, \\mathcal{G}, k)$ :, subgraph generation\n\n- $\\mathcal{G}^{(i)} = \\{ \\mathcal{V}^{(i)}, \\mathcal{E}^{(i)}, \\mathbf{X}^{(i)} \\} = \\{ \\mathbf{A}^{(i)}, \\mathbf{X}^{(i)} \\},\n$ Vertive, Edge, Features with $S=\\{s_i\\}_{i=1}^n $ includes in $X$, and $X^{\\neg s} = \\{ x_1^{\\neg s}, ..., x_n^{\\neg s} \\} $, where $ x_i^{\\neg s} = x_i \\setminus s_i$\n\n- $\\mathcal{V}^{(i)} = \\text{TOP}(\\mathbf{R}_{i,:}, k),$\n\n- $\\mathbf{A}^{(i)} = \\mathbf{A}_{\\mathcal{V}^{(i)}, \\mathcal{V}^{(i)}}, \\quad \\mathbf{X}^{(i)} = \\mathbf{X}_{\\mathcal{V}^{(i)}, :},\n$, \n\n### 2）Counterfactual Data Augmentation\n**GraphVAG**: graph variational auto-encoder\\\nlatent embedding $H=\\{h_1, h_2, \\cdots, h_k\\}$  $H$ is sampled from $q(H|X, A)$,  $p(𝐻)$ is a standard Normal prior distribution\\\n$\\mathcal{L}=$\n\n$\\tilde{s}_i$: summary of neighbor info, aggregationof all nodes in subgarph $\\mathcal{G}^{(i)}$\\\n$\\tilde{s}_i = \\frac{1}{|\\mathcal{V}^{(i)}|} \\sum_{j \\in \\mathcal{V}^{(i)}} s_j$\n\nDiscriminator,$D(\\cdot)$\\\n$D(\\mathbf{H}, b)$  predicts the probability of whether the summary of sensitive attribute values is in range $b$\n\nFairness Constraint\\\n$L_d = \\sum_{b \\in B} \\mathbb{E} [\\log(D(\\mathbf{H}, b))]$\\\n$L_d$ is a regularizer to minimize the mutual information between the summary of sensitive attribute values and the\nembeddings\n\n**Final Loss** for Counterfactual Data Augmentation\\\n$L_a = L_r + \\beta L_d$\\\n$\\beta$ is a hyperparameter for the weight of fairness constraint\\\nUse alternating SGD for optimization: \n1) minimize $L_{a}$ by fixing the discriminator and updating parameters in other parts; \n2) minimize $−L_{a}$ with respect to the discriminator while other parts fixed.\n\n\n#### Self-Perturbation\n$\\overline{\\mathcal{G}}^{(i)} = \\{ \\mathcal{G}^{(i)}_{S_i \\leftarrow 1-s_i} \\}$ (flipping sensitive feature)\n\n#### Neighbor-Perturbation\n$\\underline{\\mathcal{G}}^{(i)} = \\left\\{ \\mathcal{G}^{(i)}_{S^{(i)}_{\\setminus i} \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})} \\right\\}$\n\nsubgraph $\\mathcal{G}^{(i)}$ ego($i$)-center subgraph with noes $\\mathcal{V}^{(i)}$, exclude node $i$: $\\mathcal{V}^{(i)}_{\\setminus i}$, randomly preterbe the sentsitice value of other nodes: $SMP(\\mathcal{V}^{(i)}_{\\setminus i})$\n\n\n\nReconstruction Loss (GraphVAE Module)\\\n$L_r = \\mathbb{E}_{q(\\mathbf{H}|X, A)} \\left[ -\\log(p(X, A | \\mathbf{H}, S)) \\right] + \\text{KL}[q(\\mathbf{H} | X, A) \\| p(\\mathbf{H})]$\n\n\n### 3) Fair Representation learning\n**Fairness Loss**\n$\nL_f = \\frac{1}{|\\mathcal{V}|} \\sum_{i \\in \\mathcal{V}} \\left( (1 - \\lambda_s) d(z_i, \\bar{z}_i) + \\lambda_s d(z_i, \\underline{z}_i) \\right),\n$\\\n$\\lambda_s$ hyperparam control neig-preturbation weight\n\n**Node Representations**\n- $\nz_i = (\\phi(\\mathbf{X}^{(i)}, \\mathbf{A}^{(i)}))_i,\n$\n- $\n\\bar{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow 1-s_i}, \\mathbf{A}^{(i)}_{S_i \\leftarrow 1-s_i}))_i \\right\\} \\right),\n$\n- $\n\\underline{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})}, \\mathbf{A}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})})_i \\right\\} \\right),\n$\n\nPrediction Loss\n$L_p = \\frac{1}{n} \\sum_{i \\in [n]} l(f(z_i), y_i),$ $l$: could be CE(Cross entropy), $f(\\cdot)$ makes predictions for downstream tasks with the representations, i.e.$ \\hat y_i=f(z_i)$\n\nOverall Loss\n$\nL = L_p + \\lambda L_f + \\mu \\| \\theta \\|^2,\n$\n\n### Dataset creation\n\nSensitive Attributes\n$S_i \\sim \\text{Bernoulli}(p),$ $p=0.4$ percent $S_i=1$\n\nLatent Embeddings\n$Z_i \\sim \\mathcal{N}(0, \\mathbf{I}),$ \\\n$\\mathbf{I}$ identity, dimension of $Z_i$: $d_s=50$\n\nNode Features\n$X_i = \\mathcal{S}(Z_i) + S_i \\mathbf{v},$\\\nsampling operation $S(\\cdot)$ select 25 dims from $Z_i$, $\\mathbf{v} \\sim \\mathcal{N}(0, \\mathbf{I})$\n\nGraph Structure\n$P(A_{i,j} = 1) = \\sigma(\\text{cos}(Z_i, Z_j) + a \\mathbf{1}(S_i = S_j)),$\\\n$\\sigma$ sigmoid function, $\\mathbf{1}(S_i = S_j)==S_i = S_j. \\alpha=0.01$\n\nNode Labels\n$Y_i = \\mathcal{B}(w Z_i + w_s \\frac{\\sum_{j \\in \\mathcal{N}_i} S_j}{|\\mathcal{N}_i|}),$\\\n$\\mathcal{B}$ Bernulli distribution,$\\mathcal{N}_i$ set of neighbors of node i $w, w_i$ weight vector\n\n### Result\nUsing Synthetic dataset, Bail, Credit\n\n\n\n\n\n\n\n\n\n\n# 24 Three Revisits to Node-Level Graph Anomaly Detection\nOutliers, Message Passing and Hyperbolic Neural Networks\n\n### Previous Outlier injection method\n$\\mathcal{G}=(\\mathcal{V}, \\mathcal{E}, X, y)$: vertice set, edge set, attibute matrix, label of class\n\n- **Contextual(cntxt.) outlier injection**\nNormalize features $x_i'=\\frac{x_i}{||x_i||_1}$\nSample $o$ nodes from $\\mathcal{V}$ as $\\mathcal{V}_c$. without replacement\nFor node $i$ in $\\mathcal{V}_c$, sample $q$ nodes from $\\mathcal{V}_r=\\mathcal{V}- \\mathcal{V}_c$, among them choose the farthest one $j = \\text{argmax}_k(||x_i'-x_k'||_2)$ to replace $x_i$ with $x_j$.\n\n- **Strctural(stct.) outlier injection**\ncreate $t$ groups sized $s$ with anomalous nodes.\nsample $o=t\\times s$ from $\\mathcal{V}$ without replacement\nThen randoms partition into $t$ groups.\nAdd edges to make them a clique(fully connected), then drop edges with $p$ probability\n\n#### Score function\nThe farthest node will have large $||\\tilde{\\mathbf x}_i||_2$ \\\nA structural outlier node $i$ will have many neighbors leads to large $||\\tilde{\\mathbf a}_i||_1$ \n\n\nScore function: $score_{norm}(i)=\\alpha||\\tilde{\\mathbf x}_i||_2+(1-\\alpha)||\\tilde {\\mathbf a}_i||_1$,  $\\tilde{\\mathbf x}_i$: $x_i$ after outlier injection, $\\tilde{\\mathbf a}_i$: $a_i$ after outlier injection, $A_{ii}=1$\\\nwhere cntxt OD, $\\alpha=1$, stct OD, $\\alpha=0$ :  $\\alpha$ ratio of two methods \n\n\ntest 1: ROC-AUC\nFor each dataset, use original dataset v.s. l2-nrom for each $x_i$\\\ndo anomaly injection. apply GAD Method to get  $score_{norm}$\n\n### Novel Anomaly injection method\n\n## Sum in terms of Dataset\n从数据集的角度来说：\n### FairGAD:\nReddit:\n- 数据来源：Post on politic related subReddit\n- Labelling Y: based on FACTOID(Sakketou et al., 2022), use the num of posted link(left or right)\n- Graph construciton: \n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n# CaD-VAE\n Causal Disentangled Variational Auto-Encoder \nCausal Disentangled Variational Auto-Encoder for Preference Understanding in Recommendation\nLink: https://arxiv.org/pdf/2304.07922\n\nChallenges: inability to disentangle the latent factor\nDLR: Disentangled Representation learning \n     - DEAR: (Disentangled gEnerative cAusal Representation (DEAR)) https://arxiv.org/abs/2010.02637\n     - CasualVAE: https://doi.org/10.1109/CVPR46437.2021.00947\n\n![alt text](2024-07-14-Papers-Collection/image.png)\n\n## In Casual Layer: The SCM is \n### 2.1\n- $u \\in \\{1, \\ldots, U\\}$: user index\n- $i \\in \\{1, \\ldots, I\\}$: item index \n - $\\mathcal{D}=(U, I, X)$: dataset  \n   - For a user $u$, the historical interactions $D_u = \\{x_{u,i} : x_{u,i} \\in \\{0,1\\}\\}$ form a multi-hot vector.\n   - $x_{u,i} = 0$ means no recorded interaction between user $u$ and item $i$.\n   - $x_{u,i} = 1$ means an interaction between user $u$ and item $i$, such as a click.\n\n- $x_u$ denotes all interactions of the user $u$:\n$$\nx_u = \\{x_{u,i} : x_{u,i} = 1\\}\n$$\n   - Users may have diverse interests and interact with items that belong to many high-level concepts, such as preferred film directors, actors, genres, and year of production.\n\n### 2.2\n\n$$\nz = g \\left( (I - A^T)^{-1} \\epsilon \\right) := F_\\alpha (\\epsilon)\n$$\n \n- $z$: causal variable\n- $\\epsilon$: exogenous variables from a normal distribution - $\\mathcal{N}(0, I)$\n- $g$: nonlinear element-wise transformations\n- $\\alpha$: parameters $(A, g)$.\n- $A$: weighted adjacency matrix: $A_{ij}$ is non-zero only if $[z]_i$ is a parent of $[z]_j$. The binary adjacency matrix $I_A$ indicates where $A \\neq 0$\n- To ensure disentanglement, labels of concepts $c$ are used as additional information\n\n\n  - If $g$ is invertible, the equation can be rephrased as:\n   $$\n   g_i^{-1}(z_i) = A_i^T g_i^{-1}(z) + \\epsilon_i\n   $$\n   This implies that after a nonlinear transformation $g$, the factors $z$ satisfy a linear SCM.\n\n1. **Generative Model Assumption**:\n   - For a user $u$, the generative model parameterized by $\\theta$ assumes that the observed data are generated from the following distribution:\n     $$\n     p_\\theta(x_u) = \\mathbb{E}_{p_\\theta(c)} \\left[ \\iint p_\\theta (x_u | \\epsilon, z_u, c) p_\\theta (\\epsilon, z_u | c) d\\epsilon dz_u \\right]\n     $$\n     Here, $x_u$ is the observed data for user $u$, $\\epsilon$ are the exogenous variables, $z_u$ are the latent variables, and $c$ are the labels of the concepts.\n\n\n\n\n\n\n\n\n\n\n# GUIDE\n- Paper:\n   https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9671990\n\n- Github:\n   https://github.com/yushuowiki/GUIDE_pytorch\n\n\n\n![alt text](2024-07-14-Papers-Collection/image-1.png)\n\n\nStructure: 主要用（三阶和四阶）Motif来encode\nEncoderResidual Attention Layer\n\n\nAttribute: 就是普通的X \nEncoder用三层GCN。\n\n\n\n\n\n\n\n\n\n24.02的 FairGAD\nhttps://arxiv.org/pdf/2402.15988\nhttps://openreview.net/pdf?id=3cE6NKYy8x\nhttps://github.com/nigelnnk/FairGAD\n造数据集的\nDOMINANT 19\nCONAD 22\nCola 21\n VGOD 23\n\n\n23的GFCN\nGraph Fairing Convolutional Networks for Anomaly Detection\nhttps://github.com/MahsaMesgaran/GFCN\nhttps://arxiv.org/pdf/2010.10274\n\nVGOD 23.01\nhttps://arxiv.org/pdf/2210.12941\n\nEdits\n\n\n\n\n很多数据集和model\nhttps://proceedings.neurips.cc/paper_files/paper/2023/file/5eaafd67434a4cfb1cf829722c65f184-Paper-Datasets_and_Benchmarks.pdf\n![alt text](2024-07-14-Papers-Collection/image-3.png)\n\n\n\n# 一讲Deep Casual Learning 21的\nhttps://arxiv.org/ftp/arxiv/papers/2211/2211.03374.pdf\n![alt text](2024-07-14-Papers-Collection/image-4.png)\n\n# Disentanglement learn\n## Fair Rep learn by disentanglement 19\nhttps://proceedings.mlr.press/v97/creager19a/creager19a.pdf\n![alt text](2024-07-14-Papers-Collection/image-6.png)\n## CAF 也是disen,,\n## DEFEND 24\npaper： https://arxiv.org/pdf/2406.00987\n![alt text](2024-07-14-Papers-Collection/image-7.png)\n\n\n\n\n\n\n\n\n\n\n# Counterfactual Augmentation\n## CFGAD 24\nhttps://ojs.aaai.org/index.php/AAAI/article/view/30524\nCounterfactual Graph Learning for Anomaly Detection with Feature\nDisentanglement and Generation (Student Abstract)\n## NIFTY 21\n- paper: https://arxiv.org/pdf/2102.13186\n- Code: https://github.com/chirag126/nifty?tab=readme-ov-file\n\n![alt text](2024-07-14-Papers-Collection/image-2.png)\n\nAugmented:\n-  Node level \n     - attribute masking $r \\sim \\mathcal{B}(P_n)$\n     - $\\tilde{\\mathbf{x}}_u = \\mathbf{x}_u + \\mathbf{r} \\circ \\delta$, where $\\delta \\in \\mathbb{R}^M$ is sampled from a normal distribution.\n- sens attribute level\n  - \n- edge level\n\n## DEFEND\n![alt text](2024-07-14-Papers-Collection/image-5.png)\n\n\n## GEAR 22\nc\n## MCCNIFTY 21\n## Fairness-Aware 21\n## CAF 23\npaper: https://arxiv.org/pdf/2307.04937\ncode: https://github.com/TimeLovercc/CAF-GNN?tab=readme-ov-file\n\n![alt text](2024-07-14-Papers-Collection/image-10.png)\n## FairGNN\nuses adversarial training to achieve fairness on graphs. It trains the learned representation via an adversary which is optimized to predict the sensitive attribute\n## EDITS 23\nis a pre-processing method for fair graph learning. It aims to debias the input network to remove the sensitive\ninformation in the graph data\n## Fatra 24\n\n## CAGAD 24\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10564850\nheterophily dominant neighbors: most of its neighbors have different class labels from the target node\n1. GPNN graph pointer nn:  detect heter nodes\n   composed of encoder and decoder\n2. DDMP (deniosing difussion probabilistic model): translate, create anomaly neigbors for heter nodes\n3. GAT Graph attention network: detect anomaly nodes\n有点想加一个PRAUC的测试指标： 所以当我们希望模型在正负样本上都能表现较好时使用 ROC-AUC 衡量，如果我们只关注模型对正样本的分辨能力使用 PR-AUC 更好\n\n\n## GFCN 24\nhttps://arxiv.org/abs/2010.10274\n\n\n## GAD-NR 24 (in Pygod)\n![alt text](2024-07-14-Papers-Collection/image-11.png)\n\n# GAD with node rep learn\n## a survey on GAD -21\nmethod and datasets\nhttps://github.com/XiaoxiaoMa-MQ/Awesome-Deep-Graph-Anomaly-Detection\n\n## a survey 23: Graph Learning for Anomaly Analytics: Algorithms, Applications, and Challenges\nhttps://dl.acm.org/doi/full/10.1145/3570906\n\n## ADA-GAD 24 AAAI（Anomaly-Denoised Autoencoders for Graph Anomaly Detection）\nhttps://ojs.aaai.org/index.php/AAAI/article/view/28691\n\n\n\n\n\n\n\n\n感觉最后写出来的应该类似是 Improving fairness for node-level GAE based GAD models via disentanglement learning\n\n\n\n\n# Domain Adaptation\n属于transfer learning\n2.2 GDA的两个用途：node/graph classification\n\n\n- $\\mathcal{U}\\in\\{S,T\\}$ Domain\n- $P_{\\mathcal{U}}(X,Y)$: joint feature and label distribution \n- $\\{(x_i,y_i)\\}_{i=1}^N$: labeled source data \n- $\\{(x_i)\\}_{i=1}^M$: unlabeled target data IID sampled from the source and target domain respectively.\n- $\\phi:\\mathcal{X}\\rightarrow\\mathcal{H}$: a feature encoder\n- $g:\\mathcal{H}\\rightarrow\\mathcal{Y}$: a classifier \n- $\\epsilon_{\\mathcal{U}}(g\\circ\\phi)=P_{\\mathcal{U}}(g(\\phi(X))\\neq Y)$:classification error in domain $\\mathcal{U}$ \n- The objective is to train the model with available data to minimize target error $\\epsilon_T(g\\circ\\phi)$ when predicting target labels.\n\nA popular DA strategy is to learn domain-invariant representation, ensuring similar $P_S(H)$ and $P_T(H)$ and minimizing the source error $\\epsilon_S(g\\circ\\phi)$ to retain classification capability simultaneously ([Zhao et al., 2019](https://arxiv.org/abs/1904.05801)). This is achieved through \n\n- Feature Shift: $P_S(X|Y) \\neq P_T(X|Y)$\n  - Assume ndoe feature $x_u$，$u \\in \\mathcal{V}$ are IID sampled from $P(X|Y)$. Therefore, $P(X = x|Y = y) = \\prod_{u \\in \\mathcal{V}} P(X = x_u|Y = y_u)$\n\nPreassumption on model:\n\n $X\\leftarrow Y \\rightarrow A$. Lables are generated first, then A and X are generated.\n- Strcture Shift: $P_S(A, Y) \\neq P_T(A, Y)$\n  - Given joint distribution of $A$, and node labels $P(A, Y)$\n\n\nPreassumption:\n1. Model: $X\\leftarrow Y \\rightarrow A$. Lables are generated first, then A and X are generated.\n2. No Feature Shift: $P_S(X|Y) = P_T(X|Y)$\n\nStructure Shift: $P_{U}(A, Y) = P_{U}(A|Y)P_{U}(Y)$ \n  - Conditional Structure Shift: $P_S(A|Y) \\neq P_T(A|Y)$\n  - Label Shift: $P_S(Y) \\neq P_T(Y)$\n\n\nBecause of the interconnected nature of graph data, the IID is not satisfied for strcture shift, and new alogrithm is needed for solving CSS.\n\n structure shift is unique to graphs. In contrast to feature shift, which is analogous to non-IID feature shift in non-graph data, structure shift cannot be solved by adapting traditional conditional shift methods. Therefore, we assume feature shift is resolved, i.e., $P_S(X|Y) = P_T\n\n\nEven if $P_S(H^{(k)}|Y) = P_T(H^{(k)}|Y)$\\\nCSS may lead to $P_S(H^{(k+1)}|Y) \\neq P_T(H^{(k+1)}|Y)$\n\n\n\n### GNN\n  $$h_u^{(k+1)} = \\text{UPT}\\left(h_u^{(k)}, \\text{AGG}\\left(\\{\\{h_v^{(k)} : v \\in \\mathcal{N}_u\\}\\}\\right)\\right)$$\n- $\\{\\{\\cdot\\}\\}$: Multiset\n- $h_u^{(k+1)}$: The updated representation of node $u$ at layer $k+1$.\n- $\\text{AGG}(\\cdot)$: Aggregates message from neighbors.\n- $\\text{UPT}(\\cdot)$: Update function\n\n\n**Theorem 3.3 (Sufficient conditions for addressing CSS).**\n\n*Given the following assumptions*\n\n- *Conditional Alignment in the previous layer k* \n  - $P_S(H^{(k)}|Y) = P_T(H^{(k)}|Y)$ and $\\forall u \\in \\mathcal{V}_u$, *given* $Y = y_u$, $h_u^{(k)}$ *is independently sampled from* $P_{\\mathcal{U}}(H^{(k)}|Y)$.\n- *Edge Conditional Independence* \n  - *Given node labels* $y$, *edges mutually independently exist in the graph*.\n\n*If there exists a transformation that modifies the neighborhood of node* $u$: $\\mathcal{N}_u \\rightarrow \\tilde{\\mathcal{N}}_u, \\forall u \\in \\mathcal{V}_S$, *such that*\n- $P_S(|\\tilde{\\mathcal{N}}_u||Y_u = i) = P_T(|\\tilde{\\mathcal{N}}_u||Y_u = i)$ \n-  $P_S(Y_v|Y_u = i, v \\in \\tilde{\\mathcal{N}}_u) = P_T(Y_v|Y_u = i, v \\in \\mathcal{N}_u), \\forall i, v \\in \\mathcal{Y}$\n  \n*then*\n$P_S(H^{(k+1)}|Y) = P_T(H^{(k+1)}|Y) \\text{ is satisfied}$\n\n\n\n$\\phi_\\gamma$: GNN encoding with edge weight adjusting\\\n$\\phi$: GNN encoding without adjusting\\\nlast-layer alignment $P_S(H^{(L)} \\mid Y) = P_T(H^{(L)} \\mid Y)$can be achieved with $h_S^{(L)} = \\phi_\\gamma(x_S, A_S)$ and $h_T^{(L)} = \\phi(x_T, A_T)$. Note that based on conditional alignment in the distribution of randomly sampled node representations $P_S(H^{(L)} \\mid Y) = P_T(H^{(L)} \\mid Y)$ and under the conditions in Thm 3.3, $P_S(\\mathbf{H}^{(L)} \\mid Y) = P_T(\\mathbf{H}^{(L)} \\mid Y)$ can also be achieved in the matrix form.\n\n$G_s=(A_s,X_s)$\\\n$G_t=(A_t,X_t)$\\\n$g \\circ \\phi_\\gamma$\\\n$g \\circ \\phi$\\\n$\\hat Y_s$\n$\\hat Y_t$\n\nDrawback of StrucRW\n1. using $w$ instead of $\\gamma$ to reweigt $G_s$\n2. Rough estimation for $w$\n3. Not considering LS\n\n\n# LLM GAD\n## problem\nGNN缺点：\nGNN的message passing会导致N和A趋同，降低识别率\n尽管在Heterophilic graph上有改进，但是没有改变single node rep的本质\n\n\n## method\n(1) Sequence Construction\n(2) Coherence-Aware Rep Computation\n(3) Anomaly Detection via LLMs\n\n**text coherence**\nelvalueated by \n- llama 2: LLM model\n- LCD-G: cross-domain coherence eval od sentence\n![alt text](2024-07-14-Papers-Collection/image-12.png)\n48,509 normal sequences and 7,108 anomalous sequences\n\n### Sequence Construction\nMulti sequences for each node by random walk (local)\n- starting from the target node (以target node为中点)\n- iteratively sampling neighboring nodes and their connecting edges. (h:点, e:边, hzhzhzh)\n  \n### Coherence-Aware Rep Computation\nmicro\n- AGG info from edges within same sequence\n\nmacro\n- holistic edge information within the\nentire graph\n\n### AD via LLMs\n\n\n\n\ncomment:\n可以解释一下为什么Multi-AD-MR表现差于ER吗\n40% labeled？-->\n","slug":"2024-07-14-Papers-Collection","published":1,"updated":"2024-12-20T04:09:07.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsw001ozc3d54l7fknk","content":"<!-- \n\n# Counterfactual fairness\nCounterfactual fairness\nlink: https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf\n\n###\nDefinitions:\n#### defs\n$A$: Protected attributes, sensitive features\\\n$X$: features of individuals, excluding A\\\n$U$: latent features not observed, represented\\\n$Y$: predictor    \n#### Fairness through unawareness (FTU):\n_An algorithm is fair so long as any protected attributes $A$ are not explicitly used in the decision-making process._\nShortcoming: $X$ might intersects $A$\n\n#### Individual Fairness (IF).\nFor distance metric(should be carefully choosen), $d(\\cdot , \\cdot)$, if $d(i, j)$ is small, then $\\hat Y(X^{(i)}, A^{(i)}) \\approx \\hat Y(X^{(j)}, A^{(j)})$\n\n#### Demographic Parity (DP)(人口统计学意义上的平等)\nPredictor $\\hat Y$ satisfies demographic partiy if $P(\\hat Y|A=0)=P(\\hat Y|A=1)$ \n#### Equality of Opportunity\n$P(\\hat Y|A=0, Y=1)=P(\\hat Y|A=1, Y=1)$ \n\n### Causal Models(因果推断), Counterfacutal、\nCasual Model $(U, V, F)$,\\\n$U$: latent background variables,\\\n$V$: observed variables, \\\n$F=\\{f_1. f_2, \\cdots, f_n\\}$, for each $V_i=f_i(pa_i, U_{pa_i})\\in V, pa_i \\subseteq V \\backslash {V_i}$ \n\n**Three Steps of Inference**\\\n- Abduction：for a given prior on $U$, compute the posterior distribution of $U$ given the evidence $W = w$\n- Action：substitute the equations for $Z$ with the interventional values $z$, resulting in the modified set of equations $F_z$\n- Prediction: \n\n\n\n# FairGAD\nhttps://openreview.net/forum?id=3cE6NKYy8x\n\nhttps://arxiv.org/abs/2307.04937\n## Fair GAD problem\n**GAD**\\\n$G=(V, E, X)$, \\\nnode feature matrix $X\\in \\R^{n\\times d}$, \\\nAdjacency matrix $A\\in \\{0,1\\}^{n\\times n}$, \\\nAnomaly labels $Y\\in \\{0, 1\\}^n$, predicted $\\hat Y$, \\\n**Fair GAD**\\\nsensitive attributes $S\\in \\{0, 1\\}^n$, a binary feature $X$.\\\nPerformance matrix: accuracy and _AUCROC_: Area under the ROC Curve \\\nUnfairness Mextrics, Statistic Parity(SP):$SP = |P(\\hat Y=1|S=0)−P(\\hat Y =1|S=1)|$, \\\nEquality of Odds _(EOO)_: $SP = |P(\\hat Y=1|S=0, Y=1)−P(\\hat Y =1|S=1, Y=1)|$\n## Data\n- Reddit: \ngraph structure： linking two user posted the name subreddit within 24h.\nNode feature: Embedding from post histories.\n- Twitter: \ngraph structure:: A follows B.\nNode feature: demographic infromation using M3 system, multimodal, multilingual, multi attirbute demographix inderence framework.\n\n## GAD Methods\n### DOMINANT (Ding et al., 2019a)\n### CONAD (Xu et al., 2022)\n### COLA (Liu et al., 2021)\n### VGOD (Huang et al., 2023)\n\n## Non-Graph AD methods\n- DONE (Bandyopadhyay et al., 2020)\n- AdONE (Bandyopadhyay et al., 2020)\n- ECOD (Li et al., 2022)\n- VAE (Kingma & Welling, 2014)\n- ONE (Bandyopadhyay et al., 2019)\n- LOF (Breunig et al., 2000)\n- F (Liu et al., 2008)\n\n## Fainess Method:\n### FAIROD (Shekhar et al., 2021)\n### CORRELATION (Shekhar et al., 2021)\n### HIN (Zeng et al., 2021)\n### EDITS (Dong et al., 2022)\n### FAIRWALK (Rahman et al., 2019)\n\n## Distance \n### Wasserstein Distance\n### Minkowski distance \n\n\n# 2024 Counterfactual Learning on Graphs: A Survey \n3.5.1 How to create synthetic dataset \n\n# 2022 Learning Fair Node Representations with Graph Counter factual Fairness\nTwo limitation on existing CF on graph:\n1. $S_i$ affect the predetection. Red\n2. $S_i$ affect $A, X_i$ Green \n\nGEAR: Graph Counterfactually Fair Node Representation\n1. subgraph generation\nNode **Importance Score** by prune range of casualmodel to **ego-centric subgraph**( node and its neighbour)\n2. Counterfactual Data Argmentation: \nGraph Auto encodder and fair contrains: **self-pertubation**(flip its $S_i$), **neighbour pertubatiob**\n3. Node Representation Learning  :\nSiamese network to minimize discrepancy \n\n**Def, Graph conterfactual fairness:**\nAn encoder $\\Phi(\\cdot)$ satisfies graph counterfactual fairness if for any node $i$:\n$$\nP((Z_i)_{S \\leftarrow s'} | X = \\mathbf{X}, A = \\mathbf{A}) = P((Z_i)_{S \\leftarrow s''} | X = \\mathbf{X}, A = \\mathbf{A}),\n$$\nfor all $s' \\neq s''$, where $s', s'' \\in \\{0, 1\\}^n$ are arbitrary sensitive attribute values of all nodes, $Z_i = (\\Phi(\\mathbf{X}, \\mathbf{A}))_i$ denotes the node representations.\n\n$\\Phi$, minimize the discrepancy between representation $\\Phi(X_{S\\leftarrow s'}, A_{S\\leftarrow s'})$ and $\\Phi(X_{S\\leftarrow s''}, A_{S\\leftarrow s''})$\n\n\n### GEAR\n### 1) subgraph generation\nPersonalized Pagerank algorithm:\nImportance score $\\mathbf R=\\alpha (\\mathbf I-(1-\\alpha \\mathbf {\\bar A}))$, $\\mathbf I$, identity\\\n$R_{i,j}$ How node $j$ is important for node $i$, $\\alpha \\in [0,1]$\n\n$\\mathbf {\\bar A}=\\mathbf A \\mathbf D^{-1} $ column-normalized adjacency matric, $\\mathbf D: \\mathbf D_{i, i}=\\sum_j A{i, j}$\n\n$\\mathcal{G}^{(i)}=Sub(i, \\mathcal{G}, k)$ :, subgraph generation\n\n- $\\mathcal{G}^{(i)} = \\{ \\mathcal{V}^{(i)}, \\mathcal{E}^{(i)}, \\mathbf{X}^{(i)} \\} = \\{ \\mathbf{A}^{(i)}, \\mathbf{X}^{(i)} \\},\n$ Vertive, Edge, Features with $S=\\{s_i\\}_{i=1}^n $ includes in $X$, and $X^{\\neg s} = \\{ x_1^{\\neg s}, ..., x_n^{\\neg s} \\} $, where $ x_i^{\\neg s} = x_i \\setminus s_i$\n\n- $\\mathcal{V}^{(i)} = \\text{TOP}(\\mathbf{R}_{i,:}, k),$\n\n- $\\mathbf{A}^{(i)} = \\mathbf{A}_{\\mathcal{V}^{(i)}, \\mathcal{V}^{(i)}}, \\quad \\mathbf{X}^{(i)} = \\mathbf{X}_{\\mathcal{V}^{(i)}, :},\n$, \n\n### 2）Counterfactual Data Augmentation\n**GraphVAG**: graph variational auto-encoder\\\nlatent embedding $H=\\{h_1, h_2, \\cdots, h_k\\}$  $H$ is sampled from $q(H|X, A)$,  $p(𝐻)$ is a standard Normal prior distribution\\\n$\\mathcal{L}=$\n\n$\\tilde{s}_i$: summary of neighbor info, aggregationof all nodes in subgarph $\\mathcal{G}^{(i)}$\\\n$\\tilde{s}_i = \\frac{1}{|\\mathcal{V}^{(i)}|} \\sum_{j \\in \\mathcal{V}^{(i)}} s_j$\n\nDiscriminator,$D(\\cdot)$\\\n$D(\\mathbf{H}, b)$  predicts the probability of whether the summary of sensitive attribute values is in range $b$\n\nFairness Constraint\\\n$L_d = \\sum_{b \\in B} \\mathbb{E} [\\log(D(\\mathbf{H}, b))]$\\\n$L_d$ is a regularizer to minimize the mutual information between the summary of sensitive attribute values and the\nembeddings\n\n**Final Loss** for Counterfactual Data Augmentation\\\n$L_a = L_r + \\beta L_d$\\\n$\\beta$ is a hyperparameter for the weight of fairness constraint\\\nUse alternating SGD for optimization: \n1) minimize $L_{a}$ by fixing the discriminator and updating parameters in other parts; \n2) minimize $−L_{a}$ with respect to the discriminator while other parts fixed.\n\n\n#### Self-Perturbation\n$\\overline{\\mathcal{G}}^{(i)} = \\{ \\mathcal{G}^{(i)}_{S_i \\leftarrow 1-s_i} \\}$ (flipping sensitive feature)\n\n#### Neighbor-Perturbation\n$\\underline{\\mathcal{G}}^{(i)} = \\left\\{ \\mathcal{G}^{(i)}_{S^{(i)}_{\\setminus i} \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})} \\right\\}$\n\nsubgraph $\\mathcal{G}^{(i)}$ ego($i$)-center subgraph with noes $\\mathcal{V}^{(i)}$, exclude node $i$: $\\mathcal{V}^{(i)}_{\\setminus i}$, randomly preterbe the sentsitice value of other nodes: $SMP(\\mathcal{V}^{(i)}_{\\setminus i})$\n\n\n\nReconstruction Loss (GraphVAE Module)\\\n$L_r = \\mathbb{E}_{q(\\mathbf{H}|X, A)} \\left[ -\\log(p(X, A | \\mathbf{H}, S)) \\right] + \\text{KL}[q(\\mathbf{H} | X, A) \\| p(\\mathbf{H})]$\n\n\n### 3) Fair Representation learning\n**Fairness Loss**\n$\nL_f = \\frac{1}{|\\mathcal{V}|} \\sum_{i \\in \\mathcal{V}} \\left( (1 - \\lambda_s) d(z_i, \\bar{z}_i) + \\lambda_s d(z_i, \\underline{z}_i) \\right),\n$\\\n$\\lambda_s$ hyperparam control neig-preturbation weight\n\n**Node Representations**\n- $\nz_i = (\\phi(\\mathbf{X}^{(i)}, \\mathbf{A}^{(i)}))_i,\n$\n- $\n\\bar{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow 1-s_i}, \\mathbf{A}^{(i)}_{S_i \\leftarrow 1-s_i}))_i \\right\\} \\right),\n$\n- $\n\\underline{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})}, \\mathbf{A}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})})_i \\right\\} \\right),\n$\n\nPrediction Loss\n$L_p = \\frac{1}{n} \\sum_{i \\in [n]} l(f(z_i), y_i),$ $l$: could be CE(Cross entropy), $f(\\cdot)$ makes predictions for downstream tasks with the representations, i.e.$ \\hat y_i=f(z_i)$\n\nOverall Loss\n$\nL = L_p + \\lambda L_f + \\mu \\| \\theta \\|^2,\n$\n\n### Dataset creation\n\nSensitive Attributes\n$S_i \\sim \\text{Bernoulli}(p),$ $p=0.4$ percent $S_i=1$\n\nLatent Embeddings\n$Z_i \\sim \\mathcal{N}(0, \\mathbf{I}),$ \\\n$\\mathbf{I}$ identity, dimension of $Z_i$: $d_s=50$\n\nNode Features\n$X_i = \\mathcal{S}(Z_i) + S_i \\mathbf{v},$\\\nsampling operation $S(\\cdot)$ select 25 dims from $Z_i$, $\\mathbf{v} \\sim \\mathcal{N}(0, \\mathbf{I})$\n\nGraph Structure\n$P(A_{i,j} = 1) = \\sigma(\\text{cos}(Z_i, Z_j) + a \\mathbf{1}(S_i = S_j)),$\\\n$\\sigma$ sigmoid function, $\\mathbf{1}(S_i = S_j)==S_i = S_j. \\alpha=0.01$\n\nNode Labels\n$Y_i = \\mathcal{B}(w Z_i + w_s \\frac{\\sum_{j \\in \\mathcal{N}_i} S_j}{|\\mathcal{N}_i|}),$\\\n$\\mathcal{B}$ Bernulli distribution,$\\mathcal{N}_i$ set of neighbors of node i $w, w_i$ weight vector\n\n### Result\nUsing Synthetic dataset, Bail, Credit\n\n\n\n\n\n\n\n\n\n\n# 24 Three Revisits to Node-Level Graph Anomaly Detection\nOutliers, Message Passing and Hyperbolic Neural Networks\n\n### Previous Outlier injection method\n$\\mathcal{G}=(\\mathcal{V}, \\mathcal{E}, X, y)$: vertice set, edge set, attibute matrix, label of class\n\n- **Contextual(cntxt.) outlier injection**\nNormalize features $x_i'=\\frac{x_i}{||x_i||_1}$\nSample $o$ nodes from $\\mathcal{V}$ as $\\mathcal{V}_c$. without replacement\nFor node $i$ in $\\mathcal{V}_c$, sample $q$ nodes from $\\mathcal{V}_r=\\mathcal{V}- \\mathcal{V}_c$, among them choose the farthest one $j = \\text{argmax}_k(||x_i'-x_k'||_2)$ to replace $x_i$ with $x_j$.\n\n- **Strctural(stct.) outlier injection**\ncreate $t$ groups sized $s$ with anomalous nodes.\nsample $o=t\\times s$ from $\\mathcal{V}$ without replacement\nThen randoms partition into $t$ groups.\nAdd edges to make them a clique(fully connected), then drop edges with $p$ probability\n\n#### Score function\nThe farthest node will have large $||\\tilde{\\mathbf x}_i||_2$ \\\nA structural outlier node $i$ will have many neighbors leads to large $||\\tilde{\\mathbf a}_i||_1$ \n\n\nScore function: $score_{norm}(i)=\\alpha||\\tilde{\\mathbf x}_i||_2+(1-\\alpha)||\\tilde {\\mathbf a}_i||_1$,  $\\tilde{\\mathbf x}_i$: $x_i$ after outlier injection, $\\tilde{\\mathbf a}_i$: $a_i$ after outlier injection, $A_{ii}=1$\\\nwhere cntxt OD, $\\alpha=1$, stct OD, $\\alpha=0$ :  $\\alpha$ ratio of two methods \n\n\ntest 1: ROC-AUC\nFor each dataset, use original dataset v.s. l2-nrom for each $x_i$\\\ndo anomaly injection. apply GAD Method to get  $score_{norm}$\n\n### Novel Anomaly injection method\n\n## Sum in terms of Dataset\n从数据集的角度来说：\n### FairGAD:\nReddit:\n- 数据来源：Post on politic related subReddit\n- Labelling Y: based on FACTOID(Sakketou et al., 2022), use the num of posted link(left or right)\n- Graph construciton: \n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n# CaD-VAE\n Causal Disentangled Variational Auto-Encoder \nCausal Disentangled Variational Auto-Encoder for Preference Understanding in Recommendation\nLink: https://arxiv.org/pdf/2304.07922\n\nChallenges: inability to disentangle the latent factor\nDLR: Disentangled Representation learning \n     - DEAR: (Disentangled gEnerative cAusal Representation (DEAR)) https://arxiv.org/abs/2010.02637\n     - CasualVAE: https://doi.org/10.1109/CVPR46437.2021.00947\n\n![alt text](2024-07-14-Papers-Collection/image.png)\n\n## In Casual Layer: The SCM is \n### 2.1\n- $u \\in \\{1, \\ldots, U\\}$: user index\n- $i \\in \\{1, \\ldots, I\\}$: item index \n - $\\mathcal{D}=(U, I, X)$: dataset  \n   - For a user $u$, the historical interactions $D_u = \\{x_{u,i} : x_{u,i} \\in \\{0,1\\}\\}$ form a multi-hot vector.\n   - $x_{u,i} = 0$ means no recorded interaction between user $u$ and item $i$.\n   - $x_{u,i} = 1$ means an interaction between user $u$ and item $i$, such as a click.\n\n- $x_u$ denotes all interactions of the user $u$:\n$$\nx_u = \\{x_{u,i} : x_{u,i} = 1\\}\n$$\n   - Users may have diverse interests and interact with items that belong to many high-level concepts, such as preferred film directors, actors, genres, and year of production.\n\n### 2.2\n\n$$\nz = g \\left( (I - A^T)^{-1} \\epsilon \\right) := F_\\alpha (\\epsilon)\n$$\n \n- $z$: causal variable\n- $\\epsilon$: exogenous variables from a normal distribution - $\\mathcal{N}(0, I)$\n- $g$: nonlinear element-wise transformations\n- $\\alpha$: parameters $(A, g)$.\n- $A$: weighted adjacency matrix: $A_{ij}$ is non-zero only if $[z]_i$ is a parent of $[z]_j$. The binary adjacency matrix $I_A$ indicates where $A \\neq 0$\n- To ensure disentanglement, labels of concepts $c$ are used as additional information\n\n\n  - If $g$ is invertible, the equation can be rephrased as:\n   $$\n   g_i^{-1}(z_i) = A_i^T g_i^{-1}(z) + \\epsilon_i\n   $$\n   This implies that after a nonlinear transformation $g$, the factors $z$ satisfy a linear SCM.\n\n1. **Generative Model Assumption**:\n   - For a user $u$, the generative model parameterized by $\\theta$ assumes that the observed data are generated from the following distribution:\n     $$\n     p_\\theta(x_u) = \\mathbb{E}_{p_\\theta(c)} \\left[ \\iint p_\\theta (x_u | \\epsilon, z_u, c) p_\\theta (\\epsilon, z_u | c) d\\epsilon dz_u \\right]\n     $$\n     Here, $x_u$ is the observed data for user $u$, $\\epsilon$ are the exogenous variables, $z_u$ are the latent variables, and $c$ are the labels of the concepts.\n\n\n\n\n\n\n\n\n\n\n# GUIDE\n- Paper:\n   https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9671990\n\n- Github:\n   https://github.com/yushuowiki/GUIDE_pytorch\n\n\n\n![alt text](2024-07-14-Papers-Collection/image-1.png)\n\n\nStructure: 主要用（三阶和四阶）Motif来encode\nEncoderResidual Attention Layer\n\n\nAttribute: 就是普通的X \nEncoder用三层GCN。\n\n\n\n\n\n\n\n\n\n24.02的 FairGAD\nhttps://arxiv.org/pdf/2402.15988\nhttps://openreview.net/pdf?id=3cE6NKYy8x\nhttps://github.com/nigelnnk/FairGAD\n造数据集的\nDOMINANT 19\nCONAD 22\nCola 21\n VGOD 23\n\n\n23的GFCN\nGraph Fairing Convolutional Networks for Anomaly Detection\nhttps://github.com/MahsaMesgaran/GFCN\nhttps://arxiv.org/pdf/2010.10274\n\nVGOD 23.01\nhttps://arxiv.org/pdf/2210.12941\n\nEdits\n\n\n\n\n很多数据集和model\nhttps://proceedings.neurips.cc/paper_files/paper/2023/file/5eaafd67434a4cfb1cf829722c65f184-Paper-Datasets_and_Benchmarks.pdf\n![alt text](2024-07-14-Papers-Collection/image-3.png)\n\n\n\n# 一讲Deep Casual Learning 21的\nhttps://arxiv.org/ftp/arxiv/papers/2211/2211.03374.pdf\n![alt text](2024-07-14-Papers-Collection/image-4.png)\n\n# Disentanglement learn\n## Fair Rep learn by disentanglement 19\nhttps://proceedings.mlr.press/v97/creager19a/creager19a.pdf\n![alt text](2024-07-14-Papers-Collection/image-6.png)\n## CAF 也是disen,,\n## DEFEND 24\npaper： https://arxiv.org/pdf/2406.00987\n![alt text](2024-07-14-Papers-Collection/image-7.png)\n\n\n\n\n\n\n\n\n\n\n# Counterfactual Augmentation\n## CFGAD 24\nhttps://ojs.aaai.org/index.php/AAAI/article/view/30524\nCounterfactual Graph Learning for Anomaly Detection with Feature\nDisentanglement and Generation (Student Abstract)\n## NIFTY 21\n- paper: https://arxiv.org/pdf/2102.13186\n- Code: https://github.com/chirag126/nifty?tab=readme-ov-file\n\n![alt text](2024-07-14-Papers-Collection/image-2.png)\n\nAugmented:\n-  Node level \n     - attribute masking $r \\sim \\mathcal{B}(P_n)$\n     - $\\tilde{\\mathbf{x}}_u = \\mathbf{x}_u + \\mathbf{r} \\circ \\delta$, where $\\delta \\in \\mathbb{R}^M$ is sampled from a normal distribution.\n- sens attribute level\n  - \n- edge level\n\n## DEFEND\n![alt text](2024-07-14-Papers-Collection/image-5.png)\n\n\n## GEAR 22\nc\n## MCCNIFTY 21\n## Fairness-Aware 21\n## CAF 23\npaper: https://arxiv.org/pdf/2307.04937\ncode: https://github.com/TimeLovercc/CAF-GNN?tab=readme-ov-file\n\n![alt text](2024-07-14-Papers-Collection/image-10.png)\n## FairGNN\nuses adversarial training to achieve fairness on graphs. It trains the learned representation via an adversary which is optimized to predict the sensitive attribute\n## EDITS 23\nis a pre-processing method for fair graph learning. It aims to debias the input network to remove the sensitive\ninformation in the graph data\n## Fatra 24\n\n## CAGAD 24\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10564850\nheterophily dominant neighbors: most of its neighbors have different class labels from the target node\n1. GPNN graph pointer nn:  detect heter nodes\n   composed of encoder and decoder\n2. DDMP (deniosing difussion probabilistic model): translate, create anomaly neigbors for heter nodes\n3. GAT Graph attention network: detect anomaly nodes\n有点想加一个PRAUC的测试指标： 所以当我们希望模型在正负样本上都能表现较好时使用 ROC-AUC 衡量，如果我们只关注模型对正样本的分辨能力使用 PR-AUC 更好\n\n\n## GFCN 24\nhttps://arxiv.org/abs/2010.10274\n\n\n## GAD-NR 24 (in Pygod)\n![alt text](2024-07-14-Papers-Collection/image-11.png)\n\n# GAD with node rep learn\n## a survey on GAD -21\nmethod and datasets\nhttps://github.com/XiaoxiaoMa-MQ/Awesome-Deep-Graph-Anomaly-Detection\n\n## a survey 23: Graph Learning for Anomaly Analytics: Algorithms, Applications, and Challenges\nhttps://dl.acm.org/doi/full/10.1145/3570906\n\n## ADA-GAD 24 AAAI（Anomaly-Denoised Autoencoders for Graph Anomaly Detection）\nhttps://ojs.aaai.org/index.php/AAAI/article/view/28691\n\n\n\n\n\n\n\n\n感觉最后写出来的应该类似是 Improving fairness for node-level GAE based GAD models via disentanglement learning\n\n\n\n\n# Domain Adaptation\n属于transfer learning\n2.2 GDA的两个用途：node/graph classification\n\n\n- $\\mathcal{U}\\in\\{S,T\\}$ Domain\n- $P_{\\mathcal{U}}(X,Y)$: joint feature and label distribution \n- $\\{(x_i,y_i)\\}_{i=1}^N$: labeled source data \n- $\\{(x_i)\\}_{i=1}^M$: unlabeled target data IID sampled from the source and target domain respectively.\n- $\\phi:\\mathcal{X}\\rightarrow\\mathcal{H}$: a feature encoder\n- $g:\\mathcal{H}\\rightarrow\\mathcal{Y}$: a classifier \n- $\\epsilon_{\\mathcal{U}}(g\\circ\\phi)=P_{\\mathcal{U}}(g(\\phi(X))\\neq Y)$:classification error in domain $\\mathcal{U}$ \n- The objective is to train the model with available data to minimize target error $\\epsilon_T(g\\circ\\phi)$ when predicting target labels.\n\nA popular DA strategy is to learn domain-invariant representation, ensuring similar $P_S(H)$ and $P_T(H)$ and minimizing the source error $\\epsilon_S(g\\circ\\phi)$ to retain classification capability simultaneously ([Zhao et al., 2019](https://arxiv.org/abs/1904.05801)). This is achieved through \n\n- Feature Shift: $P_S(X|Y) \\neq P_T(X|Y)$\n  - Assume ndoe feature $x_u$，$u \\in \\mathcal{V}$ are IID sampled from $P(X|Y)$. Therefore, $P(X = x|Y = y) = \\prod_{u \\in \\mathcal{V}} P(X = x_u|Y = y_u)$\n\nPreassumption on model:\n\n $X\\leftarrow Y \\rightarrow A$. Lables are generated first, then A and X are generated.\n- Strcture Shift: $P_S(A, Y) \\neq P_T(A, Y)$\n  - Given joint distribution of $A$, and node labels $P(A, Y)$\n\n\nPreassumption:\n1. Model: $X\\leftarrow Y \\rightarrow A$. Lables are generated first, then A and X are generated.\n2. No Feature Shift: $P_S(X|Y) = P_T(X|Y)$\n\nStructure Shift: $P_{U}(A, Y) = P_{U}(A|Y)P_{U}(Y)$ \n  - Conditional Structure Shift: $P_S(A|Y) \\neq P_T(A|Y)$\n  - Label Shift: $P_S(Y) \\neq P_T(Y)$\n\n\nBecause of the interconnected nature of graph data, the IID is not satisfied for strcture shift, and new alogrithm is needed for solving CSS.\n\n structure shift is unique to graphs. In contrast to feature shift, which is analogous to non-IID feature shift in non-graph data, structure shift cannot be solved by adapting traditional conditional shift methods. Therefore, we assume feature shift is resolved, i.e., $P_S(X|Y) = P_T\n\n\nEven if $P_S(H^{(k)}|Y) = P_T(H^{(k)}|Y)$\\\nCSS may lead to $P_S(H^{(k+1)}|Y) \\neq P_T(H^{(k+1)}|Y)$\n\n\n\n### GNN\n  $$h_u^{(k+1)} = \\text{UPT}\\left(h_u^{(k)}, \\text{AGG}\\left(\\{\\{h_v^{(k)} : v \\in \\mathcal{N}_u\\}\\}\\right)\\right)$$\n- $\\{\\{\\cdot\\}\\}$: Multiset\n- $h_u^{(k+1)}$: The updated representation of node $u$ at layer $k+1$.\n- $\\text{AGG}(\\cdot)$: Aggregates message from neighbors.\n- $\\text{UPT}(\\cdot)$: Update function\n\n\n**Theorem 3.3 (Sufficient conditions for addressing CSS).**\n\n*Given the following assumptions*\n\n- *Conditional Alignment in the previous layer k* \n  - $P_S(H^{(k)}|Y) = P_T(H^{(k)}|Y)$ and $\\forall u \\in \\mathcal{V}_u$, *given* $Y = y_u$, $h_u^{(k)}$ *is independently sampled from* $P_{\\mathcal{U}}(H^{(k)}|Y)$.\n- *Edge Conditional Independence* \n  - *Given node labels* $y$, *edges mutually independently exist in the graph*.\n\n*If there exists a transformation that modifies the neighborhood of node* $u$: $\\mathcal{N}_u \\rightarrow \\tilde{\\mathcal{N}}_u, \\forall u \\in \\mathcal{V}_S$, *such that*\n- $P_S(|\\tilde{\\mathcal{N}}_u||Y_u = i) = P_T(|\\tilde{\\mathcal{N}}_u||Y_u = i)$ \n-  $P_S(Y_v|Y_u = i, v \\in \\tilde{\\mathcal{N}}_u) = P_T(Y_v|Y_u = i, v \\in \\mathcal{N}_u), \\forall i, v \\in \\mathcal{Y}$\n  \n*then*\n$P_S(H^{(k+1)}|Y) = P_T(H^{(k+1)}|Y) \\text{ is satisfied}$\n\n\n\n$\\phi_\\gamma$: GNN encoding with edge weight adjusting\\\n$\\phi$: GNN encoding without adjusting\\\nlast-layer alignment $P_S(H^{(L)} \\mid Y) = P_T(H^{(L)} \\mid Y)$can be achieved with $h_S^{(L)} = \\phi_\\gamma(x_S, A_S)$ and $h_T^{(L)} = \\phi(x_T, A_T)$. Note that based on conditional alignment in the distribution of randomly sampled node representations $P_S(H^{(L)} \\mid Y) = P_T(H^{(L)} \\mid Y)$ and under the conditions in Thm 3.3, $P_S(\\mathbf{H}^{(L)} \\mid Y) = P_T(\\mathbf{H}^{(L)} \\mid Y)$ can also be achieved in the matrix form.\n\n$G_s=(A_s,X_s)$\\\n$G_t=(A_t,X_t)$\\\n$g \\circ \\phi_\\gamma$\\\n$g \\circ \\phi$\\\n$\\hat Y_s$\n$\\hat Y_t$\n\nDrawback of StrucRW\n1. using $w$ instead of $\\gamma$ to reweigt $G_s$\n2. Rough estimation for $w$\n3. Not considering LS\n\n\n# LLM GAD\n## problem\nGNN缺点：\nGNN的message passing会导致N和A趋同，降低识别率\n尽管在Heterophilic graph上有改进，但是没有改变single node rep的本质\n\n\n## method\n(1) Sequence Construction\n(2) Coherence-Aware Rep Computation\n(3) Anomaly Detection via LLMs\n\n**text coherence**\nelvalueated by \n- llama 2: LLM model\n- LCD-G: cross-domain coherence eval od sentence\n![alt text](2024-07-14-Papers-Collection/image-12.png)\n48,509 normal sequences and 7,108 anomalous sequences\n\n### Sequence Construction\nMulti sequences for each node by random walk (local)\n- starting from the target node (以target node为中点)\n- iteratively sampling neighboring nodes and their connecting edges. (h:点, e:边, hzhzhzh)\n  \n### Coherence-Aware Rep Computation\nmicro\n- AGG info from edges within same sequence\n\nmacro\n- holistic edge information within the\nentire graph\n\n### AD via LLMs\n\n\n\n\ncomment:\n可以解释一下为什么Multi-AD-MR表现差于ER吗\n40% labeled？-->\n","excerpt":"","more":"<!-- \n\n# Counterfactual fairness\nCounterfactual fairness\nlink: https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf\n\n###\nDefinitions:\n#### defs\n$A$: Protected attributes, sensitive features\\\n$X$: features of individuals, excluding A\\\n$U$: latent features not observed, represented\\\n$Y$: predictor    \n#### Fairness through unawareness (FTU):\n_An algorithm is fair so long as any protected attributes $A$ are not explicitly used in the decision-making process._\nShortcoming: $X$ might intersects $A$\n\n#### Individual Fairness (IF).\nFor distance metric(should be carefully choosen), $d(\\cdot , \\cdot)$, if $d(i, j)$ is small, then $\\hat Y(X^{(i)}, A^{(i)}) \\approx \\hat Y(X^{(j)}, A^{(j)})$\n\n#### Demographic Parity (DP)(人口统计学意义上的平等)\nPredictor $\\hat Y$ satisfies demographic partiy if $P(\\hat Y|A=0)=P(\\hat Y|A=1)$ \n#### Equality of Opportunity\n$P(\\hat Y|A=0, Y=1)=P(\\hat Y|A=1, Y=1)$ \n\n### Causal Models(因果推断), Counterfacutal、\nCasual Model $(U, V, F)$,\\\n$U$: latent background variables,\\\n$V$: observed variables, \\\n$F=\\{f_1. f_2, \\cdots, f_n\\}$, for each $V_i=f_i(pa_i, U_{pa_i})\\in V, pa_i \\subseteq V \\backslash {V_i}$ \n\n**Three Steps of Inference**\\\n- Abduction：for a given prior on $U$, compute the posterior distribution of $U$ given the evidence $W = w$\n- Action：substitute the equations for $Z$ with the interventional values $z$, resulting in the modified set of equations $F_z$\n- Prediction: \n\n\n\n# FairGAD\nhttps://openreview.net/forum?id=3cE6NKYy8x\n\nhttps://arxiv.org/abs/2307.04937\n## Fair GAD problem\n**GAD**\\\n$G=(V, E, X)$, \\\nnode feature matrix $X\\in \\R^{n\\times d}$, \\\nAdjacency matrix $A\\in \\{0,1\\}^{n\\times n}$, \\\nAnomaly labels $Y\\in \\{0, 1\\}^n$, predicted $\\hat Y$, \\\n**Fair GAD**\\\nsensitive attributes $S\\in \\{0, 1\\}^n$, a binary feature $X$.\\\nPerformance matrix: accuracy and _AUCROC_: Area under the ROC Curve \\\nUnfairness Mextrics, Statistic Parity(SP):$SP = |P(\\hat Y=1|S=0)−P(\\hat Y =1|S=1)|$, \\\nEquality of Odds _(EOO)_: $SP = |P(\\hat Y=1|S=0, Y=1)−P(\\hat Y =1|S=1, Y=1)|$\n## Data\n- Reddit: \ngraph structure： linking two user posted the name subreddit within 24h.\nNode feature: Embedding from post histories.\n- Twitter: \ngraph structure:: A follows B.\nNode feature: demographic infromation using M3 system, multimodal, multilingual, multi attirbute demographix inderence framework.\n\n## GAD Methods\n### DOMINANT (Ding et al., 2019a)\n### CONAD (Xu et al., 2022)\n### COLA (Liu et al., 2021)\n### VGOD (Huang et al., 2023)\n\n## Non-Graph AD methods\n- DONE (Bandyopadhyay et al., 2020)\n- AdONE (Bandyopadhyay et al., 2020)\n- ECOD (Li et al., 2022)\n- VAE (Kingma & Welling, 2014)\n- ONE (Bandyopadhyay et al., 2019)\n- LOF (Breunig et al., 2000)\n- F (Liu et al., 2008)\n\n## Fainess Method:\n### FAIROD (Shekhar et al., 2021)\n### CORRELATION (Shekhar et al., 2021)\n### HIN (Zeng et al., 2021)\n### EDITS (Dong et al., 2022)\n### FAIRWALK (Rahman et al., 2019)\n\n## Distance \n### Wasserstein Distance\n### Minkowski distance \n\n\n# 2024 Counterfactual Learning on Graphs: A Survey \n3.5.1 How to create synthetic dataset \n\n# 2022 Learning Fair Node Representations with Graph Counter factual Fairness\nTwo limitation on existing CF on graph:\n1. $S_i$ affect the predetection. Red\n2. $S_i$ affect $A, X_i$ Green \n\nGEAR: Graph Counterfactually Fair Node Representation\n1. subgraph generation\nNode **Importance Score** by prune range of casualmodel to **ego-centric subgraph**( node and its neighbour)\n2. Counterfactual Data Argmentation: \nGraph Auto encodder and fair contrains: **self-pertubation**(flip its $S_i$), **neighbour pertubatiob**\n3. Node Representation Learning  :\nSiamese network to minimize discrepancy \n\n**Def, Graph conterfactual fairness:**\nAn encoder $\\Phi(\\cdot)$ satisfies graph counterfactual fairness if for any node $i$:\n$$\nP((Z_i)_{S \\leftarrow s'} | X = \\mathbf{X}, A = \\mathbf{A}) = P((Z_i)_{S \\leftarrow s''} | X = \\mathbf{X}, A = \\mathbf{A}),\n$$\nfor all $s' \\neq s''$, where $s', s'' \\in \\{0, 1\\}^n$ are arbitrary sensitive attribute values of all nodes, $Z_i = (\\Phi(\\mathbf{X}, \\mathbf{A}))_i$ denotes the node representations.\n\n$\\Phi$, minimize the discrepancy between representation $\\Phi(X_{S\\leftarrow s'}, A_{S\\leftarrow s'})$ and $\\Phi(X_{S\\leftarrow s''}, A_{S\\leftarrow s''})$\n\n\n### GEAR\n### 1) subgraph generation\nPersonalized Pagerank algorithm:\nImportance score $\\mathbf R=\\alpha (\\mathbf I-(1-\\alpha \\mathbf {\\bar A}))$, $\\mathbf I$, identity\\\n$R_{i,j}$ How node $j$ is important for node $i$, $\\alpha \\in [0,1]$\n\n$\\mathbf {\\bar A}=\\mathbf A \\mathbf D^{-1} $ column-normalized adjacency matric, $\\mathbf D: \\mathbf D_{i, i}=\\sum_j A{i, j}$\n\n$\\mathcal{G}^{(i)}=Sub(i, \\mathcal{G}, k)$ :, subgraph generation\n\n- $\\mathcal{G}^{(i)} = \\{ \\mathcal{V}^{(i)}, \\mathcal{E}^{(i)}, \\mathbf{X}^{(i)} \\} = \\{ \\mathbf{A}^{(i)}, \\mathbf{X}^{(i)} \\},\n$ Vertive, Edge, Features with $S=\\{s_i\\}_{i=1}^n $ includes in $X$, and $X^{\\neg s} = \\{ x_1^{\\neg s}, ..., x_n^{\\neg s} \\} $, where $ x_i^{\\neg s} = x_i \\setminus s_i$\n\n- $\\mathcal{V}^{(i)} = \\text{TOP}(\\mathbf{R}_{i,:}, k),$\n\n- $\\mathbf{A}^{(i)} = \\mathbf{A}_{\\mathcal{V}^{(i)}, \\mathcal{V}^{(i)}}, \\quad \\mathbf{X}^{(i)} = \\mathbf{X}_{\\mathcal{V}^{(i)}, :},\n$, \n\n### 2）Counterfactual Data Augmentation\n**GraphVAG**: graph variational auto-encoder\\\nlatent embedding $H=\\{h_1, h_2, \\cdots, h_k\\}$  $H$ is sampled from $q(H|X, A)$,  $p(𝐻)$ is a standard Normal prior distribution\\\n$\\mathcal{L}=$\n\n$\\tilde{s}_i$: summary of neighbor info, aggregationof all nodes in subgarph $\\mathcal{G}^{(i)}$\\\n$\\tilde{s}_i = \\frac{1}{|\\mathcal{V}^{(i)}|} \\sum_{j \\in \\mathcal{V}^{(i)}} s_j$\n\nDiscriminator,$D(\\cdot)$\\\n$D(\\mathbf{H}, b)$  predicts the probability of whether the summary of sensitive attribute values is in range $b$\n\nFairness Constraint\\\n$L_d = \\sum_{b \\in B} \\mathbb{E} [\\log(D(\\mathbf{H}, b))]$\\\n$L_d$ is a regularizer to minimize the mutual information between the summary of sensitive attribute values and the\nembeddings\n\n**Final Loss** for Counterfactual Data Augmentation\\\n$L_a = L_r + \\beta L_d$\\\n$\\beta$ is a hyperparameter for the weight of fairness constraint\\\nUse alternating SGD for optimization: \n1) minimize $L_{a}$ by fixing the discriminator and updating parameters in other parts; \n2) minimize $−L_{a}$ with respect to the discriminator while other parts fixed.\n\n\n#### Self-Perturbation\n$\\overline{\\mathcal{G}}^{(i)} = \\{ \\mathcal{G}^{(i)}_{S_i \\leftarrow 1-s_i} \\}$ (flipping sensitive feature)\n\n#### Neighbor-Perturbation\n$\\underline{\\mathcal{G}}^{(i)} = \\left\\{ \\mathcal{G}^{(i)}_{S^{(i)}_{\\setminus i} \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})} \\right\\}$\n\nsubgraph $\\mathcal{G}^{(i)}$ ego($i$)-center subgraph with noes $\\mathcal{V}^{(i)}$, exclude node $i$: $\\mathcal{V}^{(i)}_{\\setminus i}$, randomly preterbe the sentsitice value of other nodes: $SMP(\\mathcal{V}^{(i)}_{\\setminus i})$\n\n\n\nReconstruction Loss (GraphVAE Module)\\\n$L_r = \\mathbb{E}_{q(\\mathbf{H}|X, A)} \\left[ -\\log(p(X, A | \\mathbf{H}, S)) \\right] + \\text{KL}[q(\\mathbf{H} | X, A) \\| p(\\mathbf{H})]$\n\n\n### 3) Fair Representation learning\n**Fairness Loss**\n$\nL_f = \\frac{1}{|\\mathcal{V}|} \\sum_{i \\in \\mathcal{V}} \\left( (1 - \\lambda_s) d(z_i, \\bar{z}_i) + \\lambda_s d(z_i, \\underline{z}_i) \\right),\n$\\\n$\\lambda_s$ hyperparam control neig-preturbation weight\n\n**Node Representations**\n- $\nz_i = (\\phi(\\mathbf{X}^{(i)}, \\mathbf{A}^{(i)}))_i,\n$\n- $\n\\bar{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow 1-s_i}, \\mathbf{A}^{(i)}_{S_i \\leftarrow 1-s_i}))_i \\right\\} \\right),\n$\n- $\n\\underline{z}_i = \\text{AGG} \\left( \\left\\{ (\\phi(\\mathbf{X}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})}, \\mathbf{A}^{(i)}_{S_i \\leftarrow \\text{SMP}(S^{(i)}_{\\mathcal{V}^{(i)}_{\\setminus i}})})_i \\right\\} \\right),\n$\n\nPrediction Loss\n$L_p = \\frac{1}{n} \\sum_{i \\in [n]} l(f(z_i), y_i),$ $l$: could be CE(Cross entropy), $f(\\cdot)$ makes predictions for downstream tasks with the representations, i.e.$ \\hat y_i=f(z_i)$\n\nOverall Loss\n$\nL = L_p + \\lambda L_f + \\mu \\| \\theta \\|^2,\n$\n\n### Dataset creation\n\nSensitive Attributes\n$S_i \\sim \\text{Bernoulli}(p),$ $p=0.4$ percent $S_i=1$\n\nLatent Embeddings\n$Z_i \\sim \\mathcal{N}(0, \\mathbf{I}),$ \\\n$\\mathbf{I}$ identity, dimension of $Z_i$: $d_s=50$\n\nNode Features\n$X_i = \\mathcal{S}(Z_i) + S_i \\mathbf{v},$\\\nsampling operation $S(\\cdot)$ select 25 dims from $Z_i$, $\\mathbf{v} \\sim \\mathcal{N}(0, \\mathbf{I})$\n\nGraph Structure\n$P(A_{i,j} = 1) = \\sigma(\\text{cos}(Z_i, Z_j) + a \\mathbf{1}(S_i = S_j)),$\\\n$\\sigma$ sigmoid function, $\\mathbf{1}(S_i = S_j)==S_i = S_j. \\alpha=0.01$\n\nNode Labels\n$Y_i = \\mathcal{B}(w Z_i + w_s \\frac{\\sum_{j \\in \\mathcal{N}_i} S_j}{|\\mathcal{N}_i|}),$\\\n$\\mathcal{B}$ Bernulli distribution,$\\mathcal{N}_i$ set of neighbors of node i $w, w_i$ weight vector\n\n### Result\nUsing Synthetic dataset, Bail, Credit\n\n\n\n\n\n\n\n\n\n\n# 24 Three Revisits to Node-Level Graph Anomaly Detection\nOutliers, Message Passing and Hyperbolic Neural Networks\n\n### Previous Outlier injection method\n$\\mathcal{G}=(\\mathcal{V}, \\mathcal{E}, X, y)$: vertice set, edge set, attibute matrix, label of class\n\n- **Contextual(cntxt.) outlier injection**\nNormalize features $x_i'=\\frac{x_i}{||x_i||_1}$\nSample $o$ nodes from $\\mathcal{V}$ as $\\mathcal{V}_c$. without replacement\nFor node $i$ in $\\mathcal{V}_c$, sample $q$ nodes from $\\mathcal{V}_r=\\mathcal{V}- \\mathcal{V}_c$, among them choose the farthest one $j = \\text{argmax}_k(||x_i'-x_k'||_2)$ to replace $x_i$ with $x_j$.\n\n- **Strctural(stct.) outlier injection**\ncreate $t$ groups sized $s$ with anomalous nodes.\nsample $o=t\\times s$ from $\\mathcal{V}$ without replacement\nThen randoms partition into $t$ groups.\nAdd edges to make them a clique(fully connected), then drop edges with $p$ probability\n\n#### Score function\nThe farthest node will have large $||\\tilde{\\mathbf x}_i||_2$ \\\nA structural outlier node $i$ will have many neighbors leads to large $||\\tilde{\\mathbf a}_i||_1$ \n\n\nScore function: $score_{norm}(i)=\\alpha||\\tilde{\\mathbf x}_i||_2+(1-\\alpha)||\\tilde {\\mathbf a}_i||_1$,  $\\tilde{\\mathbf x}_i$: $x_i$ after outlier injection, $\\tilde{\\mathbf a}_i$: $a_i$ after outlier injection, $A_{ii}=1$\\\nwhere cntxt OD, $\\alpha=1$, stct OD, $\\alpha=0$ :  $\\alpha$ ratio of two methods \n\n\ntest 1: ROC-AUC\nFor each dataset, use original dataset v.s. l2-nrom for each $x_i$\\\ndo anomaly injection. apply GAD Method to get  $score_{norm}$\n\n### Novel Anomaly injection method\n\n## Sum in terms of Dataset\n从数据集的角度来说：\n### FairGAD:\nReddit:\n- 数据来源：Post on politic related subReddit\n- Labelling Y: based on FACTOID(Sakketou et al., 2022), use the num of posted link(left or right)\n- Graph construciton: \n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n# CaD-VAE\n Causal Disentangled Variational Auto-Encoder \nCausal Disentangled Variational Auto-Encoder for Preference Understanding in Recommendation\nLink: https://arxiv.org/pdf/2304.07922\n\nChallenges: inability to disentangle the latent factor\nDLR: Disentangled Representation learning \n     - DEAR: (Disentangled gEnerative cAusal Representation (DEAR)) https://arxiv.org/abs/2010.02637\n     - CasualVAE: https://doi.org/10.1109/CVPR46437.2021.00947\n\n![alt text](2024-07-14-Papers-Collection/image.png)\n\n## In Casual Layer: The SCM is \n### 2.1\n- $u \\in \\{1, \\ldots, U\\}$: user index\n- $i \\in \\{1, \\ldots, I\\}$: item index \n - $\\mathcal{D}=(U, I, X)$: dataset  \n   - For a user $u$, the historical interactions $D_u = \\{x_{u,i} : x_{u,i} \\in \\{0,1\\}\\}$ form a multi-hot vector.\n   - $x_{u,i} = 0$ means no recorded interaction between user $u$ and item $i$.\n   - $x_{u,i} = 1$ means an interaction between user $u$ and item $i$, such as a click.\n\n- $x_u$ denotes all interactions of the user $u$:\n$$\nx_u = \\{x_{u,i} : x_{u,i} = 1\\}\n$$\n   - Users may have diverse interests and interact with items that belong to many high-level concepts, such as preferred film directors, actors, genres, and year of production.\n\n### 2.2\n\n$$\nz = g \\left( (I - A^T)^{-1} \\epsilon \\right) := F_\\alpha (\\epsilon)\n$$\n \n- $z$: causal variable\n- $\\epsilon$: exogenous variables from a normal distribution - $\\mathcal{N}(0, I)$\n- $g$: nonlinear element-wise transformations\n- $\\alpha$: parameters $(A, g)$.\n- $A$: weighted adjacency matrix: $A_{ij}$ is non-zero only if $[z]_i$ is a parent of $[z]_j$. The binary adjacency matrix $I_A$ indicates where $A \\neq 0$\n- To ensure disentanglement, labels of concepts $c$ are used as additional information\n\n\n  - If $g$ is invertible, the equation can be rephrased as:\n   $$\n   g_i^{-1}(z_i) = A_i^T g_i^{-1}(z) + \\epsilon_i\n   $$\n   This implies that after a nonlinear transformation $g$, the factors $z$ satisfy a linear SCM.\n\n1. **Generative Model Assumption**:\n   - For a user $u$, the generative model parameterized by $\\theta$ assumes that the observed data are generated from the following distribution:\n     $$\n     p_\\theta(x_u) = \\mathbb{E}_{p_\\theta(c)} \\left[ \\iint p_\\theta (x_u | \\epsilon, z_u, c) p_\\theta (\\epsilon, z_u | c) d\\epsilon dz_u \\right]\n     $$\n     Here, $x_u$ is the observed data for user $u$, $\\epsilon$ are the exogenous variables, $z_u$ are the latent variables, and $c$ are the labels of the concepts.\n\n\n\n\n\n\n\n\n\n\n# GUIDE\n- Paper:\n   https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9671990\n\n- Github:\n   https://github.com/yushuowiki/GUIDE_pytorch\n\n\n\n![alt text](2024-07-14-Papers-Collection/image-1.png)\n\n\nStructure: 主要用（三阶和四阶）Motif来encode\nEncoderResidual Attention Layer\n\n\nAttribute: 就是普通的X \nEncoder用三层GCN。\n\n\n\n\n\n\n\n\n\n24.02的 FairGAD\nhttps://arxiv.org/pdf/2402.15988\nhttps://openreview.net/pdf?id=3cE6NKYy8x\nhttps://github.com/nigelnnk/FairGAD\n造数据集的\nDOMINANT 19\nCONAD 22\nCola 21\n VGOD 23\n\n\n23的GFCN\nGraph Fairing Convolutional Networks for Anomaly Detection\nhttps://github.com/MahsaMesgaran/GFCN\nhttps://arxiv.org/pdf/2010.10274\n\nVGOD 23.01\nhttps://arxiv.org/pdf/2210.12941\n\nEdits\n\n\n\n\n很多数据集和model\nhttps://proceedings.neurips.cc/paper_files/paper/2023/file/5eaafd67434a4cfb1cf829722c65f184-Paper-Datasets_and_Benchmarks.pdf\n![alt text](2024-07-14-Papers-Collection/image-3.png)\n\n\n\n# 一讲Deep Casual Learning 21的\nhttps://arxiv.org/ftp/arxiv/papers/2211/2211.03374.pdf\n![alt text](2024-07-14-Papers-Collection/image-4.png)\n\n# Disentanglement learn\n## Fair Rep learn by disentanglement 19\nhttps://proceedings.mlr.press/v97/creager19a/creager19a.pdf\n![alt text](2024-07-14-Papers-Collection/image-6.png)\n## CAF 也是disen,,\n## DEFEND 24\npaper： https://arxiv.org/pdf/2406.00987\n![alt text](2024-07-14-Papers-Collection/image-7.png)\n\n\n\n\n\n\n\n\n\n\n# Counterfactual Augmentation\n## CFGAD 24\nhttps://ojs.aaai.org/index.php/AAAI/article/view/30524\nCounterfactual Graph Learning for Anomaly Detection with Feature\nDisentanglement and Generation (Student Abstract)\n## NIFTY 21\n- paper: https://arxiv.org/pdf/2102.13186\n- Code: https://github.com/chirag126/nifty?tab=readme-ov-file\n\n![alt text](2024-07-14-Papers-Collection/image-2.png)\n\nAugmented:\n-  Node level \n     - attribute masking $r \\sim \\mathcal{B}(P_n)$\n     - $\\tilde{\\mathbf{x}}_u = \\mathbf{x}_u + \\mathbf{r} \\circ \\delta$, where $\\delta \\in \\mathbb{R}^M$ is sampled from a normal distribution.\n- sens attribute level\n  - \n- edge level\n\n## DEFEND\n![alt text](2024-07-14-Papers-Collection/image-5.png)\n\n\n## GEAR 22\nc\n## MCCNIFTY 21\n## Fairness-Aware 21\n## CAF 23\npaper: https://arxiv.org/pdf/2307.04937\ncode: https://github.com/TimeLovercc/CAF-GNN?tab=readme-ov-file\n\n![alt text](2024-07-14-Papers-Collection/image-10.png)\n## FairGNN\nuses adversarial training to achieve fairness on graphs. It trains the learned representation via an adversary which is optimized to predict the sensitive attribute\n## EDITS 23\nis a pre-processing method for fair graph learning. It aims to debias the input network to remove the sensitive\ninformation in the graph data\n## Fatra 24\n\n## CAGAD 24\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10564850\nheterophily dominant neighbors: most of its neighbors have different class labels from the target node\n1. GPNN graph pointer nn:  detect heter nodes\n   composed of encoder and decoder\n2. DDMP (deniosing difussion probabilistic model): translate, create anomaly neigbors for heter nodes\n3. GAT Graph attention network: detect anomaly nodes\n有点想加一个PRAUC的测试指标： 所以当我们希望模型在正负样本上都能表现较好时使用 ROC-AUC 衡量，如果我们只关注模型对正样本的分辨能力使用 PR-AUC 更好\n\n\n## GFCN 24\nhttps://arxiv.org/abs/2010.10274\n\n\n## GAD-NR 24 (in Pygod)\n![alt text](2024-07-14-Papers-Collection/image-11.png)\n\n# GAD with node rep learn\n## a survey on GAD -21\nmethod and datasets\nhttps://github.com/XiaoxiaoMa-MQ/Awesome-Deep-Graph-Anomaly-Detection\n\n## a survey 23: Graph Learning for Anomaly Analytics: Algorithms, Applications, and Challenges\nhttps://dl.acm.org/doi/full/10.1145/3570906\n\n## ADA-GAD 24 AAAI（Anomaly-Denoised Autoencoders for Graph Anomaly Detection）\nhttps://ojs.aaai.org/index.php/AAAI/article/view/28691\n\n\n\n\n\n\n\n\n感觉最后写出来的应该类似是 Improving fairness for node-level GAE based GAD models via disentanglement learning\n\n\n\n\n# Domain Adaptation\n属于transfer learning\n2.2 GDA的两个用途：node/graph classification\n\n\n- $\\mathcal{U}\\in\\{S,T\\}$ Domain\n- $P_{\\mathcal{U}}(X,Y)$: joint feature and label distribution \n- $\\{(x_i,y_i)\\}_{i=1}^N$: labeled source data \n- $\\{(x_i)\\}_{i=1}^M$: unlabeled target data IID sampled from the source and target domain respectively.\n- $\\phi:\\mathcal{X}\\rightarrow\\mathcal{H}$: a feature encoder\n- $g:\\mathcal{H}\\rightarrow\\mathcal{Y}$: a classifier \n- $\\epsilon_{\\mathcal{U}}(g\\circ\\phi)=P_{\\mathcal{U}}(g(\\phi(X))\\neq Y)$:classification error in domain $\\mathcal{U}$ \n- The objective is to train the model with available data to minimize target error $\\epsilon_T(g\\circ\\phi)$ when predicting target labels.\n\nA popular DA strategy is to learn domain-invariant representation, ensuring similar $P_S(H)$ and $P_T(H)$ and minimizing the source error $\\epsilon_S(g\\circ\\phi)$ to retain classification capability simultaneously ([Zhao et al., 2019](https://arxiv.org/abs/1904.05801)). This is achieved through \n\n- Feature Shift: $P_S(X|Y) \\neq P_T(X|Y)$\n  - Assume ndoe feature $x_u$，$u \\in \\mathcal{V}$ are IID sampled from $P(X|Y)$. Therefore, $P(X = x|Y = y) = \\prod_{u \\in \\mathcal{V}} P(X = x_u|Y = y_u)$\n\nPreassumption on model:\n\n $X\\leftarrow Y \\rightarrow A$. Lables are generated first, then A and X are generated.\n- Strcture Shift: $P_S(A, Y) \\neq P_T(A, Y)$\n  - Given joint distribution of $A$, and node labels $P(A, Y)$\n\n\nPreassumption:\n1. Model: $X\\leftarrow Y \\rightarrow A$. Lables are generated first, then A and X are generated.\n2. No Feature Shift: $P_S(X|Y) = P_T(X|Y)$\n\nStructure Shift: $P_{U}(A, Y) = P_{U}(A|Y)P_{U}(Y)$ \n  - Conditional Structure Shift: $P_S(A|Y) \\neq P_T(A|Y)$\n  - Label Shift: $P_S(Y) \\neq P_T(Y)$\n\n\nBecause of the interconnected nature of graph data, the IID is not satisfied for strcture shift, and new alogrithm is needed for solving CSS.\n\n structure shift is unique to graphs. In contrast to feature shift, which is analogous to non-IID feature shift in non-graph data, structure shift cannot be solved by adapting traditional conditional shift methods. Therefore, we assume feature shift is resolved, i.e., $P_S(X|Y) = P_T\n\n\nEven if $P_S(H^{(k)}|Y) = P_T(H^{(k)}|Y)$\\\nCSS may lead to $P_S(H^{(k+1)}|Y) \\neq P_T(H^{(k+1)}|Y)$\n\n\n\n### GNN\n  $$h_u^{(k+1)} = \\text{UPT}\\left(h_u^{(k)}, \\text{AGG}\\left(\\{\\{h_v^{(k)} : v \\in \\mathcal{N}_u\\}\\}\\right)\\right)$$\n- $\\{\\{\\cdot\\}\\}$: Multiset\n- $h_u^{(k+1)}$: The updated representation of node $u$ at layer $k+1$.\n- $\\text{AGG}(\\cdot)$: Aggregates message from neighbors.\n- $\\text{UPT}(\\cdot)$: Update function\n\n\n**Theorem 3.3 (Sufficient conditions for addressing CSS).**\n\n*Given the following assumptions*\n\n- *Conditional Alignment in the previous layer k* \n  - $P_S(H^{(k)}|Y) = P_T(H^{(k)}|Y)$ and $\\forall u \\in \\mathcal{V}_u$, *given* $Y = y_u$, $h_u^{(k)}$ *is independently sampled from* $P_{\\mathcal{U}}(H^{(k)}|Y)$.\n- *Edge Conditional Independence* \n  - *Given node labels* $y$, *edges mutually independently exist in the graph*.\n\n*If there exists a transformation that modifies the neighborhood of node* $u$: $\\mathcal{N}_u \\rightarrow \\tilde{\\mathcal{N}}_u, \\forall u \\in \\mathcal{V}_S$, *such that*\n- $P_S(|\\tilde{\\mathcal{N}}_u||Y_u = i) = P_T(|\\tilde{\\mathcal{N}}_u||Y_u = i)$ \n-  $P_S(Y_v|Y_u = i, v \\in \\tilde{\\mathcal{N}}_u) = P_T(Y_v|Y_u = i, v \\in \\mathcal{N}_u), \\forall i, v \\in \\mathcal{Y}$\n  \n*then*\n$P_S(H^{(k+1)}|Y) = P_T(H^{(k+1)}|Y) \\text{ is satisfied}$\n\n\n\n$\\phi_\\gamma$: GNN encoding with edge weight adjusting\\\n$\\phi$: GNN encoding without adjusting\\\nlast-layer alignment $P_S(H^{(L)} \\mid Y) = P_T(H^{(L)} \\mid Y)$can be achieved with $h_S^{(L)} = \\phi_\\gamma(x_S, A_S)$ and $h_T^{(L)} = \\phi(x_T, A_T)$. Note that based on conditional alignment in the distribution of randomly sampled node representations $P_S(H^{(L)} \\mid Y) = P_T(H^{(L)} \\mid Y)$ and under the conditions in Thm 3.3, $P_S(\\mathbf{H}^{(L)} \\mid Y) = P_T(\\mathbf{H}^{(L)} \\mid Y)$ can also be achieved in the matrix form.\n\n$G_s=(A_s,X_s)$\\\n$G_t=(A_t,X_t)$\\\n$g \\circ \\phi_\\gamma$\\\n$g \\circ \\phi$\\\n$\\hat Y_s$\n$\\hat Y_t$\n\nDrawback of StrucRW\n1. using $w$ instead of $\\gamma$ to reweigt $G_s$\n2. Rough estimation for $w$\n3. Not considering LS\n\n\n# LLM GAD\n## problem\nGNN缺点：\nGNN的message passing会导致N和A趋同，降低识别率\n尽管在Heterophilic graph上有改进，但是没有改变single node rep的本质\n\n\n## method\n(1) Sequence Construction\n(2) Coherence-Aware Rep Computation\n(3) Anomaly Detection via LLMs\n\n**text coherence**\nelvalueated by \n- llama 2: LLM model\n- LCD-G: cross-domain coherence eval od sentence\n![alt text](2024-07-14-Papers-Collection/image-12.png)\n48,509 normal sequences and 7,108 anomalous sequences\n\n### Sequence Construction\nMulti sequences for each node by random walk (local)\n- starting from the target node (以target node为中点)\n- iteratively sampling neighboring nodes and their connecting edges. (h:点, e:边, hzhzhzh)\n  \n### Coherence-Aware Rep Computation\nmicro\n- AGG info from edges within same sequence\n\nmacro\n- holistic edge information within the\nentire graph\n\n### AD via LLMs\n\n\n\n\ncomment:\n可以解释一下为什么Multi-AD-MR表现差于ER吗\n40% labeled？-->\n"},{"title":"2024-10-25 Duke courses selection","date":"2024-10-25T22:06:08.000Z","_content":"\nCOMPSCI 527 CV\nprof: https://www.ratemyprofessors.com/professor/782570\n\nCOMPSCI 572 NLP\nhttps://scholars.duke.edu/person/monica.agrawal/credentials\nhttps://www.ratemyprofessors.com/professor/2877561\n\nMATH 317S\n有点难？？？计算考的比较多\nhttps://www.ratemyprofessors.com/professor/2843167\n\nECE 590 Generative AI\nhttps://scholars.duke.edu/person/Zhenqiang.Gong\n\n\nECE 590 FOURIER TRANSFORM &APPLICATION\nhttps://scholars.duke.edu/person/cummer/publications\nhttps://www.ratemyprofessors.com/professor/610337\n\nECON 101\nCR\n\n\n\n\nHope i will be fine.\n\n\n\n\n\n\n","source":"_posts/2024-10-25-Duke-courses-selection.md","raw":"---\ntitle: 2024-10-25 Duke courses selection\ndate: 2024-10-25 18:06:08\ntags:\n---\n\nCOMPSCI 527 CV\nprof: https://www.ratemyprofessors.com/professor/782570\n\nCOMPSCI 572 NLP\nhttps://scholars.duke.edu/person/monica.agrawal/credentials\nhttps://www.ratemyprofessors.com/professor/2877561\n\nMATH 317S\n有点难？？？计算考的比较多\nhttps://www.ratemyprofessors.com/professor/2843167\n\nECE 590 Generative AI\nhttps://scholars.duke.edu/person/Zhenqiang.Gong\n\n\nECE 590 FOURIER TRANSFORM &APPLICATION\nhttps://scholars.duke.edu/person/cummer/publications\nhttps://www.ratemyprofessors.com/professor/610337\n\nECON 101\nCR\n\n\n\n\nHope i will be fine.\n\n\n\n\n\n\n","slug":"2024-10-25-Duke-courses-selection","published":1,"updated":"2024-12-15T11:48:04.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsw001pzc3d5est9d5z","content":"<p>COMPSCI 527 CV<br>prof: <a href=\"https://www.ratemyprofessors.com/professor/782570\">https://www.ratemyprofessors.com/professor/782570</a></p>\n<p>COMPSCI 572 NLP<br><a href=\"https://scholars.duke.edu/person/monica.agrawal/credentials\">https://scholars.duke.edu/person/monica.agrawal/credentials</a><br><a href=\"https://www.ratemyprofessors.com/professor/2877561\">https://www.ratemyprofessors.com/professor/2877561</a></p>\n<p>MATH 317S<br>有点难？？？计算考的比较多<br><a href=\"https://www.ratemyprofessors.com/professor/2843167\">https://www.ratemyprofessors.com/professor/2843167</a></p>\n<p>ECE 590 Generative AI<br><a href=\"https://scholars.duke.edu/person/Zhenqiang.Gong\">https://scholars.duke.edu/person/Zhenqiang.Gong</a></p>\n<p>ECE 590 FOURIER TRANSFORM &amp;APPLICATION<br><a href=\"https://scholars.duke.edu/person/cummer/publications\">https://scholars.duke.edu/person/cummer/publications</a><br><a href=\"https://www.ratemyprofessors.com/professor/610337\">https://www.ratemyprofessors.com/professor/610337</a></p>\n<p>ECON 101<br>CR</p>\n<p>Hope i will be fine.</p>\n","excerpt":"","more":"<p>COMPSCI 527 CV<br>prof: <a href=\"https://www.ratemyprofessors.com/professor/782570\">https://www.ratemyprofessors.com/professor/782570</a></p>\n<p>COMPSCI 572 NLP<br><a href=\"https://scholars.duke.edu/person/monica.agrawal/credentials\">https://scholars.duke.edu/person/monica.agrawal/credentials</a><br><a href=\"https://www.ratemyprofessors.com/professor/2877561\">https://www.ratemyprofessors.com/professor/2877561</a></p>\n<p>MATH 317S<br>有点难？？？计算考的比较多<br><a href=\"https://www.ratemyprofessors.com/professor/2843167\">https://www.ratemyprofessors.com/professor/2843167</a></p>\n<p>ECE 590 Generative AI<br><a href=\"https://scholars.duke.edu/person/Zhenqiang.Gong\">https://scholars.duke.edu/person/Zhenqiang.Gong</a></p>\n<p>ECE 590 FOURIER TRANSFORM &amp;APPLICATION<br><a href=\"https://scholars.duke.edu/person/cummer/publications\">https://scholars.duke.edu/person/cummer/publications</a><br><a href=\"https://www.ratemyprofessors.com/professor/610337\">https://www.ratemyprofessors.com/professor/610337</a></p>\n<p>ECON 101<br>CR</p>\n<p>Hope i will be fine.</p>\n"},{"title":"2024-12-20-Lain","date":"2024-12-20T18:13:52.000Z","_content":"一个比较后悔的事情是2018自我确证为玉玉症，由此错过了无数好玩的东西，也短暂的丢失了六年的创造力。\nhttps://www.bilibili.com/video/BV1Bf421m7Kk/?spm_id_from=333.999.0.0&vd_source=441679270dda23308fe16f3c5602b058\n好玩，lain的恐怖解析，一个神秘学，互联网，后人类文化研究的大乱炖。道格拉斯罗希科夫。 克苏鲁。极乐迪斯科。\n\n\n同时代的动画： 攻壳95， 未麻的部屋，eva\n个性本生只是社会元素排列组合的结果。\n\n","source":"_posts/2024-12-20-Lain.md","raw":"---\ntitle: 2024-12-20-Lain\ndate: 2024-12-20 13:13:52\ntags:\n---\n一个比较后悔的事情是2018自我确证为玉玉症，由此错过了无数好玩的东西，也短暂的丢失了六年的创造力。\nhttps://www.bilibili.com/video/BV1Bf421m7Kk/?spm_id_from=333.999.0.0&vd_source=441679270dda23308fe16f3c5602b058\n好玩，lain的恐怖解析，一个神秘学，互联网，后人类文化研究的大乱炖。道格拉斯罗希科夫。 克苏鲁。极乐迪斯科。\n\n\n同时代的动画： 攻壳95， 未麻的部屋，eva\n个性本生只是社会元素排列组合的结果。\n\n","slug":"2024-12-20-Lain","published":1,"updated":"2024-12-20T05:20:42.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsw001qzc3d4q6p8mva","content":"<p>一个比较后悔的事情是2018自我确证为玉玉症，由此错过了无数好玩的东西，也短暂的丢失了六年的创造力。<br><a href=\"https://www.bilibili.com/video/BV1Bf421m7Kk/?spm_id_from=333.999.0.0&vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1Bf421m7Kk/?spm_id_from=333.999.0.0&amp;vd_source=441679270dda23308fe16f3c5602b058</a><br>好玩，lain的恐怖解析，一个神秘学，互联网，后人类文化研究的大乱炖。道格拉斯罗希科夫。 克苏鲁。极乐迪斯科。</p>\n<p>同时代的动画： 攻壳95， 未麻的部屋，eva<br>个性本生只是社会元素排列组合的结果。</p>\n","excerpt":"","more":"<p>一个比较后悔的事情是2018自我确证为玉玉症，由此错过了无数好玩的东西，也短暂的丢失了六年的创造力。<br><a href=\"https://www.bilibili.com/video/BV1Bf421m7Kk/?spm_id_from=333.999.0.0&vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1Bf421m7Kk/?spm_id_from=333.999.0.0&amp;vd_source=441679270dda23308fe16f3c5602b058</a><br>好玩，lain的恐怖解析，一个神秘学，互联网，后人类文化研究的大乱炖。道格拉斯罗希科夫。 克苏鲁。极乐迪斯科。</p>\n<p>同时代的动画： 攻壳95， 未麻的部屋，eva<br>个性本生只是社会元素排列组合的结果。</p>\n"},{"title":"2025-01-06-Update-on-RTIIP","date":"2025-01-06T09:53:24.000Z","_content":"123\n# Real-Time Instrumental Improvisation Project (RTIIP) \nlive musical system capable of real time music accompaniment\n\n## Exsit works:\nMulti-Track MusicLDM\nDiff-A-Riff\n\nPython ( Slow for diffusion models )\nMAX/MSP ( Lack ML generation API)\nOSC ( trans between python and max/msp) # open sound control\n\n\n\n\n\n\n\n\n# MusicLDM\nhttps://arxiv.org/pdf/2308.01546\n\n\n\n\n\n\n# CLAP\narxiv1: https://arxiv.org/pdf/2206.04769 （👏 22.06 microsoft）\nrepo: https://github.com/microsoft/CLAP\n\narxiv2: https://arxiv.org/pdf/2211.06687 (github上链接的那篇 24.05 LAION)\nrepo: https://github.com/LAION-AI/CLAP?tab=readme-ov-file\n\n","source":"_posts/2025-01-06-Update-on-RTIIP.md","raw":"---\ntitle: 2025-01-06-Update-on-RTIIP\ndate: 2025-01-06 04:53:24\ntags:\n---\n123\n# Real-Time Instrumental Improvisation Project (RTIIP) \nlive musical system capable of real time music accompaniment\n\n## Exsit works:\nMulti-Track MusicLDM\nDiff-A-Riff\n\nPython ( Slow for diffusion models )\nMAX/MSP ( Lack ML generation API)\nOSC ( trans between python and max/msp) # open sound control\n\n\n\n\n\n\n\n\n# MusicLDM\nhttps://arxiv.org/pdf/2308.01546\n\n\n\n\n\n\n# CLAP\narxiv1: https://arxiv.org/pdf/2206.04769 （👏 22.06 microsoft）\nrepo: https://github.com/microsoft/CLAP\n\narxiv2: https://arxiv.org/pdf/2211.06687 (github上链接的那篇 24.05 LAION)\nrepo: https://github.com/LAION-AI/CLAP?tab=readme-ov-file\n\n","slug":"2025-01-06-Update-on-RTIIP","published":1,"updated":"2025-04-03T20:37:03.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsw001rzc3d8jfkayjw","content":"<p>123</p>\n<h1 id=\"Real-Time-Instrumental-Improvisation-Project-RTIIP\"><a href=\"#Real-Time-Instrumental-Improvisation-Project-RTIIP\" class=\"headerlink\" title=\"Real-Time Instrumental Improvisation Project (RTIIP)\"></a>Real-Time Instrumental Improvisation Project (RTIIP)</h1><p>live musical system capable of real time music accompaniment</p>\n<h2 id=\"Exsit-works\"><a href=\"#Exsit-works\" class=\"headerlink\" title=\"Exsit works:\"></a>Exsit works:</h2><p>Multi-Track MusicLDM<br>Diff-A-Riff</p>\n<p>Python ( Slow for diffusion models )<br>MAX&#x2F;MSP ( Lack ML generation API)<br>OSC ( trans between python and max&#x2F;msp) # open sound control</p>\n<h1 id=\"MusicLDM\"><a href=\"#MusicLDM\" class=\"headerlink\" title=\"MusicLDM\"></a>MusicLDM</h1><p><a href=\"https://arxiv.org/pdf/2308.01546\">https://arxiv.org/pdf/2308.01546</a></p>\n<h1 id=\"CLAP\"><a href=\"#CLAP\" class=\"headerlink\" title=\"CLAP\"></a>CLAP</h1><p>arxiv1: <a href=\"https://arxiv.org/pdf/2206.04769\">https://arxiv.org/pdf/2206.04769</a> （👏 22.06 microsoft）<br>repo: <a href=\"https://github.com/microsoft/CLAP\">https://github.com/microsoft/CLAP</a></p>\n<p>arxiv2: <a href=\"https://arxiv.org/pdf/2211.06687\">https://arxiv.org/pdf/2211.06687</a> (github上链接的那篇 24.05 LAION)<br>repo: <a href=\"https://github.com/LAION-AI/CLAP?tab=readme-ov-file\">https://github.com/LAION-AI/CLAP?tab=readme-ov-file</a></p>\n","excerpt":"","more":"<p>123</p>\n<h1 id=\"Real-Time-Instrumental-Improvisation-Project-RTIIP\"><a href=\"#Real-Time-Instrumental-Improvisation-Project-RTIIP\" class=\"headerlink\" title=\"Real-Time Instrumental Improvisation Project (RTIIP)\"></a>Real-Time Instrumental Improvisation Project (RTIIP)</h1><p>live musical system capable of real time music accompaniment</p>\n<h2 id=\"Exsit-works\"><a href=\"#Exsit-works\" class=\"headerlink\" title=\"Exsit works:\"></a>Exsit works:</h2><p>Multi-Track MusicLDM<br>Diff-A-Riff</p>\n<p>Python ( Slow for diffusion models )<br>MAX&#x2F;MSP ( Lack ML generation API)<br>OSC ( trans between python and max&#x2F;msp) # open sound control</p>\n<h1 id=\"MusicLDM\"><a href=\"#MusicLDM\" class=\"headerlink\" title=\"MusicLDM\"></a>MusicLDM</h1><p><a href=\"https://arxiv.org/pdf/2308.01546\">https://arxiv.org/pdf/2308.01546</a></p>\n<h1 id=\"CLAP\"><a href=\"#CLAP\" class=\"headerlink\" title=\"CLAP\"></a>CLAP</h1><p>arxiv1: <a href=\"https://arxiv.org/pdf/2206.04769\">https://arxiv.org/pdf/2206.04769</a> （👏 22.06 microsoft）<br>repo: <a href=\"https://github.com/microsoft/CLAP\">https://github.com/microsoft/CLAP</a></p>\n<p>arxiv2: <a href=\"https://arxiv.org/pdf/2211.06687\">https://arxiv.org/pdf/2211.06687</a> (github上链接的那篇 24.05 LAION)<br>repo: <a href=\"https://github.com/LAION-AI/CLAP?tab=readme-ov-file\">https://github.com/LAION-AI/CLAP?tab=readme-ov-file</a></p>\n"},{"title":"2025-01-10-Finance","date":"2025-01-09T13:39:55.000Z","_content":"Prof C. J. \nProf电话\n9193321894\n\nICPQ: in class pop quiz\nTF: \n\n\n\nluca pachioli: father o accounting\n\nBig Four Accounting Firms \n- Deloitte\n- EY (Ernst & Young)\n- KPMG\n- PwC (PricewaterhouseCoopers)\n\nGAAP: Generally Accepted Accounting Principles\nIFRS: International Financial Reporting Standards\n\nAccounting Cycle\n- Journal Entries\n- Ledger Accounts\n- Trial Balance\n- Adjusted Trial Balance\n- Financial Statements\n- Closing Entries\n\nAccounting Equation\nAssets = Liabilities + Owner's Equity\n\nAccounting Equation\nAssets = Liabilities + Stockholders' Equity\n\nAccounting Equation\n\nFASB: Financial Accounting Standards Board\nAPB: Accounting Principles Board\n\n\n2: proprietorship (独资企业)\n3: partnership\n4: ‘c' corporation\n\nIncome statement: NI (net income) = Revenue - Expenses\nBalance Sheet: A () = L + OE (owner's equity)\nStatement of Cash Flows: CF = OCF (operating cash flow) + IC (investing cash flow) + FC (financing cash flow)\nStatement of owner equity: OE = OE (beginning) + NI (net income) - D (dividends)\n\nDebit \nCredit \n \n\n## 01-21\n\n### Cahpter 1\n1. Father of Accounting: Luca Pacioli\n2. FIN VS MAG\n3. Big Four Accounting Firms: Deloitte, EY, KPMG, PwC\n4. GAAP (Generally Accepted Accounting Principles) vs IFRS (International Financial Reporting Standards) vs SEC \n\n\n#### exercise\nbrought 6.1: $130$\nsell 12.31: $134$\npaid in the 3rd month of each quarter $3$\nannual return: $\\frac{12}{7} \\frac{(134-130)+ 3(3)}{130}=17.12\\%$\n\n### Chapter 2\n4 important concepts: revenue/expense liability asset \n- revenue/expense: nomial/temporary   $I/S： NetIncome = Revenue - Expense$\n- assets: economic resource \n- liability: creditors claim\n- owner's equity: owner's claim\n$B/S : A = L + OE$\n\n\nstatement of cash flow: $CashFlow = OCF + ICF + FCF$\nCashFlow \n- Operating Cash Flow (OCF): Cash from the core operations of the business (e.g., selling cakes).\n- Investing Cash Flow (ICF): Cash spent on buying or selling long-term assets (e.g., buying a new oven for baking).\n- Financing Cash Flow (FCF): Cash related to borrowing or repaying debts and investments in long-term liabilities or owner’s equity (e.g., taking a loan or paying dividends).\n\n\n\n#### Exercise\n$NetIncome = Revenue - Expense$\n$A = L + OE$\nA company incorrectly report an asset as expense $25\\$$:\nreported $NI=300\\$$\nreported Assets: $1000\\$$\nCorrect NI: ? $325\\$$\nCorrect A: ? $1025\\$$\n\n ni_wrong = r - e_wrong\n e_wrong = e_right + 25\n ni_right = r - e_right = r - (e_wrong - 25) = ni_wrong + 25\n\n## 01-30\n### Exer\nStarted business on 1/1/A. with A=50, L = 28\nDuring this year, addl inv by owner size 12, devidents decleared 20. devidents paid 15, at 12/31, A=27000, L= 60\n\nBegin RE + NI = Availability \nAval - Div Decleared = End RE\n1/1: A=50, OE(L = 28, CC = 22, RE = 0)\nbeg RE (0) + NI(196) - Div Decleared(20) = End RE (176)\nA (270) = L(60) + OE( CC(34) + RE(176) )\n\n1. 1/1 RE 0\n2. 1/1 CC 22\n3. 12/31 cc 34\n4. NI for YRA 196\n5. 12/31 RE 176\n6. If expense are 540 what are rev 736\n\n#### def\n- **A（Assets）= 资产**，公司拥有的东西，比如现金、设备、库存等。\n- **L（Liabilities）= 负债**，公司欠别人的钱，比如贷款、应付账款。\n- **OE（Owner’s Equity）= 所有者权益**，公司的净资产，等于**资产 - 负债**。\n- **CC（Contributed Capital）= 业主投入的资本**，即股东或创始人投的钱。\n- **RE（Retained Earnings）= 留存收益**，公司赚到的钱，减去派发的股息后剩下的利润。\n- **Dividends Declared（已宣告股息）**= 公司承诺支付给股东的股息。\n- **Dividends Paid（已支付股息）**= 公司实际支付出去的股息。\n- **NI（Net Income）= 净利润**，收入减去费用的结果。\n\n#### **第一步：公司一开始的情况**\n- **1/1 资产（A）= 50**  \n- **1/1 负债（L）= 28**  \n- **1/1 所有者权益（OE）= A - L = 50 - 28 = 22**\n- 这个**22** 就是**业主投入的资本（CC）**，因为公司刚刚开始，没有留存收益（RE = 0）。\n\n所以：  \n**1/1 的财务状况**  \n\\[\nA = L + OE\n\\]\n\\[\n50 = 28 + 22\n\\]\n\n#### **第二步：计算 12/31 财务状况**\n已知 **12/31** 的情况：\n- **资产（A）= 270**\n- **负债（L）= 60**\n- **OE 计算方式：**\n  \\[\n  OE = A - L = 270 - 60 = 210\n  \\]\n\nOE（所有者权益）由**CC（业主投入）和 RE（留存收益）**组成：\n- 12/31 业主投入资本 **CC = 34**\n- 计算 12/31 **留存收益 RE**：\n  \\[\n  OE = CC + RE\n  \\]\n  \\[\n  210 = 34 + RE\n  \\]\n  \\[\n  RE = 176\n  \\]\n\n---\n\n#### **第三步：如何计算 RE（留存收益）？**\n留存收益的计算公式：\n\\[\n\\text{期初 RE} + \\text{净利润（NI）} - \\text{已宣告股息（Div. Declared）} = \\text{期末 RE}\n\\]\n\n已知：\n- 期初 RE = **0**\n- 已宣告股息 = **20**\n- 期末 RE = **176**\n  \n代入公式：\n\\[\n0 + \\text{NI} - 20 = 176\n\\]\n\n所以：\n\\[\n\\text{NI} = 196\n\\]\n\n📌 **这一年公司赚了 196（净利润）！**\n\n---\n\n#### **第四步：如何计算收入（Rev）？**\n已知：\n\\[\n\\text{净利润（NI）} = \\text{收入（Rev）} - \\text{费用（Expenses）}\n\\]\n\n已知：\n- **NI = 196**\n- **Expenses = 540**\n\n代入公式：\n\\[\n\\text{Rev} - 540 = 196\n\\]\n\n所以：\n\\[\n\\text{Rev} = 736\n\\]\n\n **这一年公司的总收入是 736！**\n\n### concept\nsome concepts will be learn\n- Cash basis（现金制）:只有当现金真正流入或流出时，才记录收入和费用。 recognize revenues when cash comes in and expenses when cash goes out.\n- Accrual Basis（权责发生制）: 收入和费用在发生时就记录，而不是等到现金真正流动时。Recogmized revemues wen earn and determinable and then matches expenses with revenues.\n- 递延收入（Deferred Revenue）：公司先收钱，但服务还没提供，所以不能马上当收入，要先记为负债，等提供服务后再确认收入。\n- 递延费用（Deferred Expense）：公司先花钱，但服务还没享受，所以不能马上当费用，要先记为资产，等服务使用后再变成费用。\n- 折旧（Depreciation）：设备（equipment）会随着时间使用而变旧，价值会降低。不能一次性把设备的成本算成费用，而是要 每年分摊，这样才符合会计规则（权责发生制）。\n $\\text{Annual Depreciation Expense} = \\frac{\\text{Cost} - \\text{Salvage Value}}{\\text{Useful Life}}$\n \n \n### q1\n11/30  co. pays (Receive) 4 mos rent in advance (dec, ,jan, feb, mar) 2000/mo 8000 in total\nPay:  （租客） 11/30 prepaid rent A 8000, cahs A 8000, 12/31 rent exp E 2000, prepaid rent 2000.\nReceive: Landlord (房东) 11/30 cash 8000 unearned rent 8000 122/31 unearned rent L 2000 rent revenue R 2000\n我来帮你用简单的方式理解这个财务处理 😊💖，我们慢慢来，不急哦！\n\n---\n\n#### **1. 先理解「现金制」和「权责发生制」（Accrual Basis）**\n在财务会计里，有两种主要的记账方式：\n- **现金制（Cash Basis）**：只有当现金真正流入或流出时，才记录收入和费用。\n- **权责发生制（Accrual Basis）**：收入和费用在**发生时**就记录，而不是等到现金真正流动时。\n\n---\n\n#### **2. 什么是「递延」（Deferrals）？**\n- **递延收入（Deferred Revenue）**：公司**先收钱，但服务还没提供**，所以不能马上当收入，要先记为负债，等提供服务后再确认收入。\n- **递延费用（Deferred Expense）**：公司**先花钱，但服务还没享受**，所以不能马上当费用，要先记为资产，等服务使用后再变成费用。\n\n---\n\n#### **3. 你的问题：租金的会计处理**\n你的例子：\n📌 **11/30 公司支付 4 个月的房租，每月 2000，共 8000**。  \n- **公司是租客（Tenant）**，先付了钱，但这个房租是未来的 4 个月使用的。\n- **房东（Landlord）**，收到钱但服务还没完全提供，所以不能马上当收入。\n\n---\n\n##### **（1）租客（Tenant）的会计处理**\n租客在 11/30 付了 8000，但是这笔钱是未来 4 个月的房租，所以：\n- 不能马上当费用（因为钱是未来使用的）。\n- 先当作资产「**预付租金（Prepaid Rent）**」，之后再慢慢转成费用。\n\n📌 **11/30 公司支付租金时**\n| **账户**        | **借（Dr.）增加** | **贷（Cr.）减少** |\n|---------------|----------------|----------------|\n| 预付租金（资产） | 8000          |                |\n| 现金（资产）    |                | 8000          |\n\n📌 **12/31 调整分录（12 月使用了 1 个月租金）**\n| **账户**      | **借（Dr.）增加** | **贷（Cr.）减少** |\n|-------------|----------------|----------------|\n| 租金费用（Rent Expense） | 2000          |                |\n| 预付租金（Prepaid Rent） |                | 2000          |\n\n📌 **之后每个月（1 月、2 月、3 月）也要记类似的调整分录**。\n\n---\n\n##### **（2）房东（Landlord）的会计处理**\n房东 11/30 **收到 8000 现金**，但因为房租还没使用完，所以：\n- 不能马上算作收入（因为还没完全提供租赁服务）。\n- 先把它放到「**预收租金（Unearned Rent）**」，当作**负债**，因为房东还「欠」租客房屋使用权。\n\n📌 **11/30 房东收到租金**\n| **账户**         | **借（Dr.）增加** | **贷（Cr.）增加** |\n|--------------|----------------|----------------|\n| 现金（资产）     | 8000          |                |\n| 预收租金（负债） |                | 8000          |\n\n📌 **12/31 调整分录（房东 12 月已经提供 1 个月的租赁服务）**\n| **账户**         | **借（Dr.）减少** | **贷（Cr.）增加** |\n|--------------|----------------|----------------|\n| 预收租金（负债） | 2000          |                |\n| 租金收入（Revenue） |                | 2000          |\n\n📌 **之后每个月（1 月、2 月、3 月）也要记类似的调整分录**。\n\n---\n\n#### **4. 直观理解**\n##### **租客（Tenant）视角**\n租客 11/30 付了 8000，相当于提前预定了 4 个月的房子。\n- 11/30：钱出了，但房租的使用时间是未来的，所以要先当作**资产**（预付租金）。\n- 12/31：住了 1 个月，所以要把 2000 从**资产变成费用**。\n\n##### **房东（Landlord）视角**\n房东 11/30 收到了 8000，但租赁服务要分 4 个月提供。\n- 11/30：钱收到了，但服务还没完全提供，所以不能全部记收入，要当作**负债**（预收租金）。\n- 12/31：提供了 1 个月的租赁服务，所以要从**负债转成收入** 2000。\n\n-\n### 折旧（Depreciation）\n\n1/1/A equipment (A) 14900 cash(A) 14900\n12/31/A depreciation expense(E) 2400 auumulateddepreciation(XA) 2400 \nCl defr = $\\frac{cost - val}{est csefvl life} $ = (14900 - 2900)  / 5 = 2400/yr\neq(a)14900\nacc depr (XA) 2400 2400 = 4800\n\n#### **1. 什么是折旧（Depreciation）？**\n- 设备（equipment）会随着时间使用而变旧，价值会降低。\n- 不能一次性把设备的成本算成费用，而是要 **每年分摊**，这样才符合会计规则（权责发生制）。\n- 这就是 **折旧（Depreciation）** 的作用！\n\n\n#### **2. 计算折旧**\n公式：\n\\[\n\\text{Annual Depreciation Expense} = \\frac{\\text{Cost} - \\text{Salvage Value}}{\\text{Useful Life}}\n\\]\n\n已知：\n- **设备成本（Cost）= 14900**\n- **残值（Salvage Value）= 2900**\n- **使用年限（Useful Life）= 5 年**\n\n代入公式：\n\\[\n\\frac{14900 - 2900}{5} = \\frac{12000}{5} = 2400\n\\]\n\n📌 **所以每年折旧 2400！**\n\n---\n\n#### **3. 会计分录（Journal Entries）**\n##### **（1）1/1 购买设备**\n- 设备（资产）增加\n- 现金（资产）减少\n\n| **账户**       | **借方 Dr.（增加）** | **贷方 Cr.（减少）** |\n|--------------|----------------|----------------|\n| 设备（Equipment） | 14900         |                |\n| 现金（Cash）     |                | 14900         |\n\n##### **（2）12/31 记录折旧**\n- 设备的价值变旧，所以要记「**折旧费用（Depreciation Expense）**」。\n- 但我们不会直接减少设备，而是用「**累计折旧（Accumulated Depreciation, XA）**」，这是一种 **「资产的减少账户」**。\n\n| **账户**                  | **借方 Dr.（增加）** | **贷方 Cr.（增加）** |\n|-------------------------|----------------|----------------|\n| 折旧费用（Depreciation Expense, 费用） | 2400           |                |\n| 累计折旧（Accumulated Depreciation, 资产减少） |                | 2400           |\n\n#### **4. 设备的账面价值**\n设备的 **账面价值（Book Value）** 是：\n\\[\n\\text{账面价值} = \\text{设备成本} - \\text{累计折旧}\n\\]\n\n- **1/1** 设备的账面价值 = **14900**\n- **12/31** 设备的账面价值 = **14900 - 2400 = 12500**\n\n如果 **第二年再折旧 2400**：\n\\[\n\\text{累计折旧} = 2400 + 2400 = 4800\n\\]\n\\[\n\\text{账面价值} = 14900 - 4800 = 10100\n\\]\n\n#### **5. 总结**\n| **日期** | **资产（设备）** | **累计折旧（XA）** | **折旧费用（E）** | **账面价值** |\n|---------|---------------|----------------|----------------|-------------|\n| **1/1** | 14900         | 0              | 0              | 14900       |\n| **12/31** | 14900         | 2400           | 2400           | 12500       |\n| **第二年 12/31** | 14900         | 4800           | 2400           | 10100       |\n\n### \n\n## 02-25\nPresent Value : PV\nInterest Rate : $r$\n$FV = PV(1+r)^n$\n$C_0 + \\sum_{t=1}^n C_t(1+r)^{-t}$\n\n\nInventory\n3 types of firms\n - service:  provide services (like consulting or hairdressing)\n - merchandiseres: buy finished products and then sell them\n - manufacturers\n\n 2 formulas/schedules:\n dropout coasts = inventorials exp\n pexiod costs nominventoriable expensed as incurred \n \n $\\text{CGS cost of goods sold} = \\text{Beginning Inventory} + \\text{Purchases} - \\text{Ending Inventory}$\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/2025-01-10-Finance.md","raw":"---\ntitle: 2025-01-10-Finance\ndate: 2025-01-09 08:39:55\ntags:\n---\nProf C. J. \nProf电话\n9193321894\n\nICPQ: in class pop quiz\nTF: \n\n\n\nluca pachioli: father o accounting\n\nBig Four Accounting Firms \n- Deloitte\n- EY (Ernst & Young)\n- KPMG\n- PwC (PricewaterhouseCoopers)\n\nGAAP: Generally Accepted Accounting Principles\nIFRS: International Financial Reporting Standards\n\nAccounting Cycle\n- Journal Entries\n- Ledger Accounts\n- Trial Balance\n- Adjusted Trial Balance\n- Financial Statements\n- Closing Entries\n\nAccounting Equation\nAssets = Liabilities + Owner's Equity\n\nAccounting Equation\nAssets = Liabilities + Stockholders' Equity\n\nAccounting Equation\n\nFASB: Financial Accounting Standards Board\nAPB: Accounting Principles Board\n\n\n2: proprietorship (独资企业)\n3: partnership\n4: ‘c' corporation\n\nIncome statement: NI (net income) = Revenue - Expenses\nBalance Sheet: A () = L + OE (owner's equity)\nStatement of Cash Flows: CF = OCF (operating cash flow) + IC (investing cash flow) + FC (financing cash flow)\nStatement of owner equity: OE = OE (beginning) + NI (net income) - D (dividends)\n\nDebit \nCredit \n \n\n## 01-21\n\n### Cahpter 1\n1. Father of Accounting: Luca Pacioli\n2. FIN VS MAG\n3. Big Four Accounting Firms: Deloitte, EY, KPMG, PwC\n4. GAAP (Generally Accepted Accounting Principles) vs IFRS (International Financial Reporting Standards) vs SEC \n\n\n#### exercise\nbrought 6.1: $130$\nsell 12.31: $134$\npaid in the 3rd month of each quarter $3$\nannual return: $\\frac{12}{7} \\frac{(134-130)+ 3(3)}{130}=17.12\\%$\n\n### Chapter 2\n4 important concepts: revenue/expense liability asset \n- revenue/expense: nomial/temporary   $I/S： NetIncome = Revenue - Expense$\n- assets: economic resource \n- liability: creditors claim\n- owner's equity: owner's claim\n$B/S : A = L + OE$\n\n\nstatement of cash flow: $CashFlow = OCF + ICF + FCF$\nCashFlow \n- Operating Cash Flow (OCF): Cash from the core operations of the business (e.g., selling cakes).\n- Investing Cash Flow (ICF): Cash spent on buying or selling long-term assets (e.g., buying a new oven for baking).\n- Financing Cash Flow (FCF): Cash related to borrowing or repaying debts and investments in long-term liabilities or owner’s equity (e.g., taking a loan or paying dividends).\n\n\n\n#### Exercise\n$NetIncome = Revenue - Expense$\n$A = L + OE$\nA company incorrectly report an asset as expense $25\\$$:\nreported $NI=300\\$$\nreported Assets: $1000\\$$\nCorrect NI: ? $325\\$$\nCorrect A: ? $1025\\$$\n\n ni_wrong = r - e_wrong\n e_wrong = e_right + 25\n ni_right = r - e_right = r - (e_wrong - 25) = ni_wrong + 25\n\n## 01-30\n### Exer\nStarted business on 1/1/A. with A=50, L = 28\nDuring this year, addl inv by owner size 12, devidents decleared 20. devidents paid 15, at 12/31, A=27000, L= 60\n\nBegin RE + NI = Availability \nAval - Div Decleared = End RE\n1/1: A=50, OE(L = 28, CC = 22, RE = 0)\nbeg RE (0) + NI(196) - Div Decleared(20) = End RE (176)\nA (270) = L(60) + OE( CC(34) + RE(176) )\n\n1. 1/1 RE 0\n2. 1/1 CC 22\n3. 12/31 cc 34\n4. NI for YRA 196\n5. 12/31 RE 176\n6. If expense are 540 what are rev 736\n\n#### def\n- **A（Assets）= 资产**，公司拥有的东西，比如现金、设备、库存等。\n- **L（Liabilities）= 负债**，公司欠别人的钱，比如贷款、应付账款。\n- **OE（Owner’s Equity）= 所有者权益**，公司的净资产，等于**资产 - 负债**。\n- **CC（Contributed Capital）= 业主投入的资本**，即股东或创始人投的钱。\n- **RE（Retained Earnings）= 留存收益**，公司赚到的钱，减去派发的股息后剩下的利润。\n- **Dividends Declared（已宣告股息）**= 公司承诺支付给股东的股息。\n- **Dividends Paid（已支付股息）**= 公司实际支付出去的股息。\n- **NI（Net Income）= 净利润**，收入减去费用的结果。\n\n#### **第一步：公司一开始的情况**\n- **1/1 资产（A）= 50**  \n- **1/1 负债（L）= 28**  \n- **1/1 所有者权益（OE）= A - L = 50 - 28 = 22**\n- 这个**22** 就是**业主投入的资本（CC）**，因为公司刚刚开始，没有留存收益（RE = 0）。\n\n所以：  \n**1/1 的财务状况**  \n\\[\nA = L + OE\n\\]\n\\[\n50 = 28 + 22\n\\]\n\n#### **第二步：计算 12/31 财务状况**\n已知 **12/31** 的情况：\n- **资产（A）= 270**\n- **负债（L）= 60**\n- **OE 计算方式：**\n  \\[\n  OE = A - L = 270 - 60 = 210\n  \\]\n\nOE（所有者权益）由**CC（业主投入）和 RE（留存收益）**组成：\n- 12/31 业主投入资本 **CC = 34**\n- 计算 12/31 **留存收益 RE**：\n  \\[\n  OE = CC + RE\n  \\]\n  \\[\n  210 = 34 + RE\n  \\]\n  \\[\n  RE = 176\n  \\]\n\n---\n\n#### **第三步：如何计算 RE（留存收益）？**\n留存收益的计算公式：\n\\[\n\\text{期初 RE} + \\text{净利润（NI）} - \\text{已宣告股息（Div. Declared）} = \\text{期末 RE}\n\\]\n\n已知：\n- 期初 RE = **0**\n- 已宣告股息 = **20**\n- 期末 RE = **176**\n  \n代入公式：\n\\[\n0 + \\text{NI} - 20 = 176\n\\]\n\n所以：\n\\[\n\\text{NI} = 196\n\\]\n\n📌 **这一年公司赚了 196（净利润）！**\n\n---\n\n#### **第四步：如何计算收入（Rev）？**\n已知：\n\\[\n\\text{净利润（NI）} = \\text{收入（Rev）} - \\text{费用（Expenses）}\n\\]\n\n已知：\n- **NI = 196**\n- **Expenses = 540**\n\n代入公式：\n\\[\n\\text{Rev} - 540 = 196\n\\]\n\n所以：\n\\[\n\\text{Rev} = 736\n\\]\n\n **这一年公司的总收入是 736！**\n\n### concept\nsome concepts will be learn\n- Cash basis（现金制）:只有当现金真正流入或流出时，才记录收入和费用。 recognize revenues when cash comes in and expenses when cash goes out.\n- Accrual Basis（权责发生制）: 收入和费用在发生时就记录，而不是等到现金真正流动时。Recogmized revemues wen earn and determinable and then matches expenses with revenues.\n- 递延收入（Deferred Revenue）：公司先收钱，但服务还没提供，所以不能马上当收入，要先记为负债，等提供服务后再确认收入。\n- 递延费用（Deferred Expense）：公司先花钱，但服务还没享受，所以不能马上当费用，要先记为资产，等服务使用后再变成费用。\n- 折旧（Depreciation）：设备（equipment）会随着时间使用而变旧，价值会降低。不能一次性把设备的成本算成费用，而是要 每年分摊，这样才符合会计规则（权责发生制）。\n $\\text{Annual Depreciation Expense} = \\frac{\\text{Cost} - \\text{Salvage Value}}{\\text{Useful Life}}$\n \n \n### q1\n11/30  co. pays (Receive) 4 mos rent in advance (dec, ,jan, feb, mar) 2000/mo 8000 in total\nPay:  （租客） 11/30 prepaid rent A 8000, cahs A 8000, 12/31 rent exp E 2000, prepaid rent 2000.\nReceive: Landlord (房东) 11/30 cash 8000 unearned rent 8000 122/31 unearned rent L 2000 rent revenue R 2000\n我来帮你用简单的方式理解这个财务处理 😊💖，我们慢慢来，不急哦！\n\n---\n\n#### **1. 先理解「现金制」和「权责发生制」（Accrual Basis）**\n在财务会计里，有两种主要的记账方式：\n- **现金制（Cash Basis）**：只有当现金真正流入或流出时，才记录收入和费用。\n- **权责发生制（Accrual Basis）**：收入和费用在**发生时**就记录，而不是等到现金真正流动时。\n\n---\n\n#### **2. 什么是「递延」（Deferrals）？**\n- **递延收入（Deferred Revenue）**：公司**先收钱，但服务还没提供**，所以不能马上当收入，要先记为负债，等提供服务后再确认收入。\n- **递延费用（Deferred Expense）**：公司**先花钱，但服务还没享受**，所以不能马上当费用，要先记为资产，等服务使用后再变成费用。\n\n---\n\n#### **3. 你的问题：租金的会计处理**\n你的例子：\n📌 **11/30 公司支付 4 个月的房租，每月 2000，共 8000**。  \n- **公司是租客（Tenant）**，先付了钱，但这个房租是未来的 4 个月使用的。\n- **房东（Landlord）**，收到钱但服务还没完全提供，所以不能马上当收入。\n\n---\n\n##### **（1）租客（Tenant）的会计处理**\n租客在 11/30 付了 8000，但是这笔钱是未来 4 个月的房租，所以：\n- 不能马上当费用（因为钱是未来使用的）。\n- 先当作资产「**预付租金（Prepaid Rent）**」，之后再慢慢转成费用。\n\n📌 **11/30 公司支付租金时**\n| **账户**        | **借（Dr.）增加** | **贷（Cr.）减少** |\n|---------------|----------------|----------------|\n| 预付租金（资产） | 8000          |                |\n| 现金（资产）    |                | 8000          |\n\n📌 **12/31 调整分录（12 月使用了 1 个月租金）**\n| **账户**      | **借（Dr.）增加** | **贷（Cr.）减少** |\n|-------------|----------------|----------------|\n| 租金费用（Rent Expense） | 2000          |                |\n| 预付租金（Prepaid Rent） |                | 2000          |\n\n📌 **之后每个月（1 月、2 月、3 月）也要记类似的调整分录**。\n\n---\n\n##### **（2）房东（Landlord）的会计处理**\n房东 11/30 **收到 8000 现金**，但因为房租还没使用完，所以：\n- 不能马上算作收入（因为还没完全提供租赁服务）。\n- 先把它放到「**预收租金（Unearned Rent）**」，当作**负债**，因为房东还「欠」租客房屋使用权。\n\n📌 **11/30 房东收到租金**\n| **账户**         | **借（Dr.）增加** | **贷（Cr.）增加** |\n|--------------|----------------|----------------|\n| 现金（资产）     | 8000          |                |\n| 预收租金（负债） |                | 8000          |\n\n📌 **12/31 调整分录（房东 12 月已经提供 1 个月的租赁服务）**\n| **账户**         | **借（Dr.）减少** | **贷（Cr.）增加** |\n|--------------|----------------|----------------|\n| 预收租金（负债） | 2000          |                |\n| 租金收入（Revenue） |                | 2000          |\n\n📌 **之后每个月（1 月、2 月、3 月）也要记类似的调整分录**。\n\n---\n\n#### **4. 直观理解**\n##### **租客（Tenant）视角**\n租客 11/30 付了 8000，相当于提前预定了 4 个月的房子。\n- 11/30：钱出了，但房租的使用时间是未来的，所以要先当作**资产**（预付租金）。\n- 12/31：住了 1 个月，所以要把 2000 从**资产变成费用**。\n\n##### **房东（Landlord）视角**\n房东 11/30 收到了 8000，但租赁服务要分 4 个月提供。\n- 11/30：钱收到了，但服务还没完全提供，所以不能全部记收入，要当作**负债**（预收租金）。\n- 12/31：提供了 1 个月的租赁服务，所以要从**负债转成收入** 2000。\n\n-\n### 折旧（Depreciation）\n\n1/1/A equipment (A) 14900 cash(A) 14900\n12/31/A depreciation expense(E) 2400 auumulateddepreciation(XA) 2400 \nCl defr = $\\frac{cost - val}{est csefvl life} $ = (14900 - 2900)  / 5 = 2400/yr\neq(a)14900\nacc depr (XA) 2400 2400 = 4800\n\n#### **1. 什么是折旧（Depreciation）？**\n- 设备（equipment）会随着时间使用而变旧，价值会降低。\n- 不能一次性把设备的成本算成费用，而是要 **每年分摊**，这样才符合会计规则（权责发生制）。\n- 这就是 **折旧（Depreciation）** 的作用！\n\n\n#### **2. 计算折旧**\n公式：\n\\[\n\\text{Annual Depreciation Expense} = \\frac{\\text{Cost} - \\text{Salvage Value}}{\\text{Useful Life}}\n\\]\n\n已知：\n- **设备成本（Cost）= 14900**\n- **残值（Salvage Value）= 2900**\n- **使用年限（Useful Life）= 5 年**\n\n代入公式：\n\\[\n\\frac{14900 - 2900}{5} = \\frac{12000}{5} = 2400\n\\]\n\n📌 **所以每年折旧 2400！**\n\n---\n\n#### **3. 会计分录（Journal Entries）**\n##### **（1）1/1 购买设备**\n- 设备（资产）增加\n- 现金（资产）减少\n\n| **账户**       | **借方 Dr.（增加）** | **贷方 Cr.（减少）** |\n|--------------|----------------|----------------|\n| 设备（Equipment） | 14900         |                |\n| 现金（Cash）     |                | 14900         |\n\n##### **（2）12/31 记录折旧**\n- 设备的价值变旧，所以要记「**折旧费用（Depreciation Expense）**」。\n- 但我们不会直接减少设备，而是用「**累计折旧（Accumulated Depreciation, XA）**」，这是一种 **「资产的减少账户」**。\n\n| **账户**                  | **借方 Dr.（增加）** | **贷方 Cr.（增加）** |\n|-------------------------|----------------|----------------|\n| 折旧费用（Depreciation Expense, 费用） | 2400           |                |\n| 累计折旧（Accumulated Depreciation, 资产减少） |                | 2400           |\n\n#### **4. 设备的账面价值**\n设备的 **账面价值（Book Value）** 是：\n\\[\n\\text{账面价值} = \\text{设备成本} - \\text{累计折旧}\n\\]\n\n- **1/1** 设备的账面价值 = **14900**\n- **12/31** 设备的账面价值 = **14900 - 2400 = 12500**\n\n如果 **第二年再折旧 2400**：\n\\[\n\\text{累计折旧} = 2400 + 2400 = 4800\n\\]\n\\[\n\\text{账面价值} = 14900 - 4800 = 10100\n\\]\n\n#### **5. 总结**\n| **日期** | **资产（设备）** | **累计折旧（XA）** | **折旧费用（E）** | **账面价值** |\n|---------|---------------|----------------|----------------|-------------|\n| **1/1** | 14900         | 0              | 0              | 14900       |\n| **12/31** | 14900         | 2400           | 2400           | 12500       |\n| **第二年 12/31** | 14900         | 4800           | 2400           | 10100       |\n\n### \n\n## 02-25\nPresent Value : PV\nInterest Rate : $r$\n$FV = PV(1+r)^n$\n$C_0 + \\sum_{t=1}^n C_t(1+r)^{-t}$\n\n\nInventory\n3 types of firms\n - service:  provide services (like consulting or hairdressing)\n - merchandiseres: buy finished products and then sell them\n - manufacturers\n\n 2 formulas/schedules:\n dropout coasts = inventorials exp\n pexiod costs nominventoriable expensed as incurred \n \n $\\text{CGS cost of goods sold} = \\text{Beginning Inventory} + \\text{Purchases} - \\text{Ending Inventory}$\n\n\n\n\n\n\n\n\n\n\n\n","slug":"2025-01-10-Finance","published":1,"updated":"2025-02-25T14:24:42.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsx001szc3dg5ou2p8i","content":"<p>Prof C. J.<br>Prof电话<br>9193321894</p>\n<p>ICPQ: in class pop quiz<br>TF: </p>\n<p>luca pachioli: father o accounting</p>\n<p>Big Four Accounting Firms </p>\n<ul>\n<li>Deloitte</li>\n<li>EY (Ernst &amp; Young)</li>\n<li>KPMG</li>\n<li>PwC (PricewaterhouseCoopers)</li>\n</ul>\n<p>GAAP: Generally Accepted Accounting Principles<br>IFRS: International Financial Reporting Standards</p>\n<p>Accounting Cycle</p>\n<ul>\n<li>Journal Entries</li>\n<li>Ledger Accounts</li>\n<li>Trial Balance</li>\n<li>Adjusted Trial Balance</li>\n<li>Financial Statements</li>\n<li>Closing Entries</li>\n</ul>\n<p>Accounting Equation<br>Assets &#x3D; Liabilities + Owner’s Equity</p>\n<p>Accounting Equation<br>Assets &#x3D; Liabilities + Stockholders’ Equity</p>\n<p>Accounting Equation</p>\n<p>FASB: Financial Accounting Standards Board<br>APB: Accounting Principles Board</p>\n<p>2: proprietorship (独资企业)<br>3: partnership<br>4: ‘c’ corporation</p>\n<p>Income statement: NI (net income) &#x3D; Revenue - Expenses<br>Balance Sheet: A () &#x3D; L + OE (owner’s equity)<br>Statement of Cash Flows: CF &#x3D; OCF (operating cash flow) + IC (investing cash flow) + FC (financing cash flow)<br>Statement of owner equity: OE &#x3D; OE (beginning) + NI (net income) - D (dividends)</p>\n<p>Debit<br>Credit </p>\n<h2 id=\"01-21\"><a href=\"#01-21\" class=\"headerlink\" title=\"01-21\"></a>01-21</h2><h3 id=\"Cahpter-1\"><a href=\"#Cahpter-1\" class=\"headerlink\" title=\"Cahpter 1\"></a>Cahpter 1</h3><ol>\n<li>Father of Accounting: Luca Pacioli</li>\n<li>FIN VS MAG</li>\n<li>Big Four Accounting Firms: Deloitte, EY, KPMG, PwC</li>\n<li>GAAP (Generally Accepted Accounting Principles) vs IFRS (International Financial Reporting Standards) vs SEC</li>\n</ol>\n<h4 id=\"exercise\"><a href=\"#exercise\" class=\"headerlink\" title=\"exercise\"></a>exercise</h4><p>brought 6.1: $130$<br>sell 12.31: $134$<br>paid in the 3rd month of each quarter $3$<br>annual return: $\\frac{12}{7} \\frac{(134-130)+ 3(3)}{130}&#x3D;17.12%$</p>\n<h3 id=\"Chapter-2\"><a href=\"#Chapter-2\" class=\"headerlink\" title=\"Chapter 2\"></a>Chapter 2</h3><p>4 important concepts: revenue&#x2F;expense liability asset </p>\n<ul>\n<li>revenue&#x2F;expense: nomial&#x2F;temporary   $I&#x2F;S： NetIncome &#x3D; Revenue - Expense$</li>\n<li>assets: economic resource </li>\n<li>liability: creditors claim</li>\n<li>owner’s equity: owner’s claim<br>$B&#x2F;S : A &#x3D; L + OE$</li>\n</ul>\n<p>statement of cash flow: $CashFlow &#x3D; OCF + ICF + FCF$<br>CashFlow </p>\n<ul>\n<li>Operating Cash Flow (OCF): Cash from the core operations of the business (e.g., selling cakes).</li>\n<li>Investing Cash Flow (ICF): Cash spent on buying or selling long-term assets (e.g., buying a new oven for baking).</li>\n<li>Financing Cash Flow (FCF): Cash related to borrowing or repaying debts and investments in long-term liabilities or owner’s equity (e.g., taking a loan or paying dividends).</li>\n</ul>\n<h4 id=\"Exercise\"><a href=\"#Exercise\" class=\"headerlink\" title=\"Exercise\"></a>Exercise</h4><p>$NetIncome &#x3D; Revenue - Expense$<br>$A &#x3D; L + OE$<br>A company incorrectly report an asset as expense $25$$:<br>reported $NI&#x3D;300$$<br>reported Assets: $1000$$<br>Correct NI: ? $325$$<br>Correct A: ? $1025$$</p>\n<p> ni_wrong &#x3D; r - e_wrong<br> e_wrong &#x3D; e_right + 25<br> ni_right &#x3D; r - e_right &#x3D; r - (e_wrong - 25) &#x3D; ni_wrong + 25</p>\n<h2 id=\"01-30\"><a href=\"#01-30\" class=\"headerlink\" title=\"01-30\"></a>01-30</h2><h3 id=\"Exer\"><a href=\"#Exer\" class=\"headerlink\" title=\"Exer\"></a>Exer</h3><p>Started business on 1&#x2F;1&#x2F;A. with A&#x3D;50, L &#x3D; 28<br>During this year, addl inv by owner size 12, devidents decleared 20. devidents paid 15, at 12&#x2F;31, A&#x3D;27000, L&#x3D; 60</p>\n<p>Begin RE + NI &#x3D; Availability<br>Aval - Div Decleared &#x3D; End RE<br>1&#x2F;1: A&#x3D;50, OE(L &#x3D; 28, CC &#x3D; 22, RE &#x3D; 0)<br>beg RE (0) + NI(196) - Div Decleared(20) &#x3D; End RE (176)<br>A (270) &#x3D; L(60) + OE( CC(34) + RE(176) )</p>\n<ol>\n<li>1&#x2F;1 RE 0</li>\n<li>1&#x2F;1 CC 22</li>\n<li>12&#x2F;31 cc 34</li>\n<li>NI for YRA 196</li>\n<li>12&#x2F;31 RE 176</li>\n<li>If expense are 540 what are rev 736</li>\n</ol>\n<h4 id=\"def\"><a href=\"#def\" class=\"headerlink\" title=\"def\"></a>def</h4><ul>\n<li><strong>A（Assets）&#x3D; 资产</strong>，公司拥有的东西，比如现金、设备、库存等。</li>\n<li><strong>L（Liabilities）&#x3D; 负债</strong>，公司欠别人的钱，比如贷款、应付账款。</li>\n<li><strong>OE（Owner’s Equity）&#x3D; 所有者权益</strong>，公司的净资产，等于<strong>资产 - 负债</strong>。</li>\n<li><strong>CC（Contributed Capital）&#x3D; 业主投入的资本</strong>，即股东或创始人投的钱。</li>\n<li><strong>RE（Retained Earnings）&#x3D; 留存收益</strong>，公司赚到的钱，减去派发的股息后剩下的利润。</li>\n<li><strong>Dividends Declared（已宣告股息）</strong>&#x3D; 公司承诺支付给股东的股息。</li>\n<li><strong>Dividends Paid（已支付股息）</strong>&#x3D; 公司实际支付出去的股息。</li>\n<li><strong>NI（Net Income）&#x3D; 净利润</strong>，收入减去费用的结果。</li>\n</ul>\n<h4 id=\"第一步：公司一开始的情况\"><a href=\"#第一步：公司一开始的情况\" class=\"headerlink\" title=\"第一步：公司一开始的情况\"></a><strong>第一步：公司一开始的情况</strong></h4><ul>\n<li><strong>1&#x2F;1 资产（A）&#x3D; 50</strong>  </li>\n<li><strong>1&#x2F;1 负债（L）&#x3D; 28</strong>  </li>\n<li><strong>1&#x2F;1 所有者权益（OE）&#x3D; A - L &#x3D; 50 - 28 &#x3D; 22</strong></li>\n<li>这个<strong>22</strong> 就是<strong>业主投入的资本（CC）</strong>，因为公司刚刚开始，没有留存收益（RE &#x3D; 0）。</li>\n</ul>\n<p>所以：<br><strong>1&#x2F;1 的财务状况</strong><br>[<br>A &#x3D; L + OE<br>]<br>[<br>50 &#x3D; 28 + 22<br>]</p>\n<h4 id=\"第二步：计算-12-31-财务状况\"><a href=\"#第二步：计算-12-31-财务状况\" class=\"headerlink\" title=\"第二步：计算 12&#x2F;31 财务状况\"></a><strong>第二步：计算 12&#x2F;31 财务状况</strong></h4><p>已知 <strong>12&#x2F;31</strong> 的情况：</p>\n<ul>\n<li><strong>资产（A）&#x3D; 270</strong></li>\n<li><strong>负债（L）&#x3D; 60</strong></li>\n<li><strong>OE 计算方式：</strong><br>[<br>OE &#x3D; A - L &#x3D; 270 - 60 &#x3D; 210<br>]</li>\n</ul>\n<p>OE（所有者权益）由<strong>CC（业主投入）和 RE（留存收益）</strong>组成：</p>\n<ul>\n<li>12&#x2F;31 业主投入资本 <strong>CC &#x3D; 34</strong></li>\n<li>计算 12&#x2F;31 <strong>留存收益 RE</strong>：<br>[<br>OE &#x3D; CC + RE<br>]<br>[<br>210 &#x3D; 34 + RE<br>]<br>[<br>RE &#x3D; 176<br>]</li>\n</ul>\n<hr>\n<h4 id=\"第三步：如何计算-RE（留存收益）？\"><a href=\"#第三步：如何计算-RE（留存收益）？\" class=\"headerlink\" title=\"第三步：如何计算 RE（留存收益）？\"></a><strong>第三步：如何计算 RE（留存收益）？</strong></h4><p>留存收益的计算公式：<br>[<br>\\text{期初 RE} + \\text{净利润（NI）} - \\text{已宣告股息（Div. Declared）} &#x3D; \\text{期末 RE}<br>]</p>\n<p>已知：</p>\n<ul>\n<li>期初 RE &#x3D; <strong>0</strong></li>\n<li>已宣告股息 &#x3D; <strong>20</strong></li>\n<li>期末 RE &#x3D; <strong>176</strong></li>\n</ul>\n<p>代入公式：<br>[<br>0 + \\text{NI} - 20 &#x3D; 176<br>]</p>\n<p>所以：<br>[<br>\\text{NI} &#x3D; 196<br>]</p>\n<p>📌 <strong>这一年公司赚了 196（净利润）！</strong></p>\n<hr>\n<h4 id=\"第四步：如何计算收入（Rev）？\"><a href=\"#第四步：如何计算收入（Rev）？\" class=\"headerlink\" title=\"第四步：如何计算收入（Rev）？\"></a><strong>第四步：如何计算收入（Rev）？</strong></h4><p>已知：<br>[<br>\\text{净利润（NI）} &#x3D; \\text{收入（Rev）} - \\text{费用（Expenses）}<br>]</p>\n<p>已知：</p>\n<ul>\n<li><strong>NI &#x3D; 196</strong></li>\n<li><strong>Expenses &#x3D; 540</strong></li>\n</ul>\n<p>代入公式：<br>[<br>\\text{Rev} - 540 &#x3D; 196<br>]</p>\n<p>所以：<br>[<br>\\text{Rev} &#x3D; 736<br>]</p>\n<p> <strong>这一年公司的总收入是 736！</strong></p>\n<h3 id=\"concept\"><a href=\"#concept\" class=\"headerlink\" title=\"concept\"></a>concept</h3><p>some concepts will be learn</p>\n<ul>\n<li>Cash basis（现金制）:只有当现金真正流入或流出时，才记录收入和费用。 recognize revenues when cash comes in and expenses when cash goes out.</li>\n<li>Accrual Basis（权责发生制）: 收入和费用在发生时就记录，而不是等到现金真正流动时。Recogmized revemues wen earn and determinable and then matches expenses with revenues.</li>\n<li>递延收入（Deferred Revenue）：公司先收钱，但服务还没提供，所以不能马上当收入，要先记为负债，等提供服务后再确认收入。</li>\n<li>递延费用（Deferred Expense）：公司先花钱，但服务还没享受，所以不能马上当费用，要先记为资产，等服务使用后再变成费用。</li>\n<li>折旧（Depreciation）：设备（equipment）会随着时间使用而变旧，价值会降低。不能一次性把设备的成本算成费用，而是要 每年分摊，这样才符合会计规则（权责发生制）。<br> $\\text{Annual Depreciation Expense} &#x3D; \\frac{\\text{Cost} - \\text{Salvage Value}}{\\text{Useful Life}}$</li>\n</ul>\n<h3 id=\"q1\"><a href=\"#q1\" class=\"headerlink\" title=\"q1\"></a>q1</h3><p>11&#x2F;30  co. pays (Receive) 4 mos rent in advance (dec, ,jan, feb, mar) 2000&#x2F;mo 8000 in total<br>Pay:  （租客） 11&#x2F;30 prepaid rent A 8000, cahs A 8000, 12&#x2F;31 rent exp E 2000, prepaid rent 2000.<br>Receive: Landlord (房东) 11&#x2F;30 cash 8000 unearned rent 8000 122&#x2F;31 unearned rent L 2000 rent revenue R 2000<br>我来帮你用简单的方式理解这个财务处理 😊💖，我们慢慢来，不急哦！</p>\n<hr>\n<h4 id=\"1-先理解「现金制」和「权责发生制」（Accrual-Basis）\"><a href=\"#1-先理解「现金制」和「权责发生制」（Accrual-Basis）\" class=\"headerlink\" title=\"1. 先理解「现金制」和「权责发生制」（Accrual Basis）\"></a><strong>1. 先理解「现金制」和「权责发生制」（Accrual Basis）</strong></h4><p>在财务会计里，有两种主要的记账方式：</p>\n<ul>\n<li><strong>现金制（Cash Basis）</strong>：只有当现金真正流入或流出时，才记录收入和费用。</li>\n<li><strong>权责发生制（Accrual Basis）</strong>：收入和费用在<strong>发生时</strong>就记录，而不是等到现金真正流动时。</li>\n</ul>\n<hr>\n<h4 id=\"2-什么是「递延」（Deferrals）？\"><a href=\"#2-什么是「递延」（Deferrals）？\" class=\"headerlink\" title=\"2. 什么是「递延」（Deferrals）？\"></a><strong>2. 什么是「递延」（Deferrals）？</strong></h4><ul>\n<li><strong>递延收入（Deferred Revenue）</strong>：公司<strong>先收钱，但服务还没提供</strong>，所以不能马上当收入，要先记为负债，等提供服务后再确认收入。</li>\n<li><strong>递延费用（Deferred Expense）</strong>：公司<strong>先花钱，但服务还没享受</strong>，所以不能马上当费用，要先记为资产，等服务使用后再变成费用。</li>\n</ul>\n<hr>\n<h4 id=\"3-你的问题：租金的会计处理\"><a href=\"#3-你的问题：租金的会计处理\" class=\"headerlink\" title=\"3. 你的问题：租金的会计处理\"></a><strong>3. 你的问题：租金的会计处理</strong></h4><p>你的例子：<br>📌 <strong>11&#x2F;30 公司支付 4 个月的房租，每月 2000，共 8000</strong>。  </p>\n<ul>\n<li><strong>公司是租客（Tenant）</strong>，先付了钱，但这个房租是未来的 4 个月使用的。</li>\n<li><strong>房东（Landlord）</strong>，收到钱但服务还没完全提供，所以不能马上当收入。</li>\n</ul>\n<hr>\n<h5 id=\"（1）租客（Tenant）的会计处理\"><a href=\"#（1）租客（Tenant）的会计处理\" class=\"headerlink\" title=\"（1）租客（Tenant）的会计处理\"></a><strong>（1）租客（Tenant）的会计处理</strong></h5><p>租客在 11&#x2F;30 付了 8000，但是这笔钱是未来 4 个月的房租，所以：</p>\n<ul>\n<li>不能马上当费用（因为钱是未来使用的）。</li>\n<li>先当作资产「<strong>预付租金（Prepaid Rent）</strong>」，之后再慢慢转成费用。</li>\n</ul>\n<p>📌 <strong>11&#x2F;30 公司支付租金时</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借（Dr.）增加</strong></th>\n<th><strong>贷（Cr.）减少</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>预付租金（资产）</td>\n<td>8000</td>\n<td></td>\n</tr>\n<tr>\n<td>现金（资产）</td>\n<td></td>\n<td>8000</td>\n</tr>\n</tbody></table>\n<p>📌 <strong>12&#x2F;31 调整分录（12 月使用了 1 个月租金）</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借（Dr.）增加</strong></th>\n<th><strong>贷（Cr.）减少</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>租金费用（Rent Expense）</td>\n<td>2000</td>\n<td></td>\n</tr>\n<tr>\n<td>预付租金（Prepaid Rent）</td>\n<td></td>\n<td>2000</td>\n</tr>\n</tbody></table>\n<p>📌 <strong>之后每个月（1 月、2 月、3 月）也要记类似的调整分录</strong>。</p>\n<hr>\n<h5 id=\"（2）房东（Landlord）的会计处理\"><a href=\"#（2）房东（Landlord）的会计处理\" class=\"headerlink\" title=\"（2）房东（Landlord）的会计处理\"></a><strong>（2）房东（Landlord）的会计处理</strong></h5><p>房东 11&#x2F;30 <strong>收到 8000 现金</strong>，但因为房租还没使用完，所以：</p>\n<ul>\n<li>不能马上算作收入（因为还没完全提供租赁服务）。</li>\n<li>先把它放到「<strong>预收租金（Unearned Rent）</strong>」，当作<strong>负债</strong>，因为房东还「欠」租客房屋使用权。</li>\n</ul>\n<p>📌 <strong>11&#x2F;30 房东收到租金</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借（Dr.）增加</strong></th>\n<th><strong>贷（Cr.）增加</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>现金（资产）</td>\n<td>8000</td>\n<td></td>\n</tr>\n<tr>\n<td>预收租金（负债）</td>\n<td></td>\n<td>8000</td>\n</tr>\n</tbody></table>\n<p>📌 <strong>12&#x2F;31 调整分录（房东 12 月已经提供 1 个月的租赁服务）</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借（Dr.）减少</strong></th>\n<th><strong>贷（Cr.）增加</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>预收租金（负债）</td>\n<td>2000</td>\n<td></td>\n</tr>\n<tr>\n<td>租金收入（Revenue）</td>\n<td></td>\n<td>2000</td>\n</tr>\n</tbody></table>\n<p>📌 <strong>之后每个月（1 月、2 月、3 月）也要记类似的调整分录</strong>。</p>\n<hr>\n<h4 id=\"4-直观理解\"><a href=\"#4-直观理解\" class=\"headerlink\" title=\"4. 直观理解\"></a><strong>4. 直观理解</strong></h4><h5 id=\"租客（Tenant）视角\"><a href=\"#租客（Tenant）视角\" class=\"headerlink\" title=\"租客（Tenant）视角\"></a><strong>租客（Tenant）视角</strong></h5><p>租客 11&#x2F;30 付了 8000，相当于提前预定了 4 个月的房子。</p>\n<ul>\n<li>11&#x2F;30：钱出了，但房租的使用时间是未来的，所以要先当作<strong>资产</strong>（预付租金）。</li>\n<li>12&#x2F;31：住了 1 个月，所以要把 2000 从<strong>资产变成费用</strong>。</li>\n</ul>\n<h5 id=\"房东（Landlord）视角\"><a href=\"#房东（Landlord）视角\" class=\"headerlink\" title=\"房东（Landlord）视角\"></a><strong>房东（Landlord）视角</strong></h5><p>房东 11&#x2F;30 收到了 8000，但租赁服务要分 4 个月提供。</p>\n<ul>\n<li><p>11&#x2F;30：钱收到了，但服务还没完全提供，所以不能全部记收入，要当作<strong>负债</strong>（预收租金）。</p>\n</li>\n<li><p>12&#x2F;31：提供了 1 个月的租赁服务，所以要从<strong>负债转成收入</strong> 2000。</p>\n</li>\n<li></li>\n</ul>\n<h3 id=\"折旧（Depreciation）\"><a href=\"#折旧（Depreciation）\" class=\"headerlink\" title=\"折旧（Depreciation）\"></a>折旧（Depreciation）</h3><p>1&#x2F;1&#x2F;A equipment (A) 14900 cash(A) 14900<br>12&#x2F;31&#x2F;A depreciation expense(E) 2400 auumulateddepreciation(XA) 2400<br>Cl defr &#x3D; $\\frac{cost - val}{est csefvl life} $ &#x3D; (14900 - 2900)  &#x2F; 5 &#x3D; 2400&#x2F;yr<br>eq(a)14900<br>acc depr (XA) 2400 2400 &#x3D; 4800</p>\n<h4 id=\"1-什么是折旧（Depreciation）？\"><a href=\"#1-什么是折旧（Depreciation）？\" class=\"headerlink\" title=\"1. 什么是折旧（Depreciation）？\"></a><strong>1. 什么是折旧（Depreciation）？</strong></h4><ul>\n<li>设备（equipment）会随着时间使用而变旧，价值会降低。</li>\n<li>不能一次性把设备的成本算成费用，而是要 <strong>每年分摊</strong>，这样才符合会计规则（权责发生制）。</li>\n<li>这就是 <strong>折旧（Depreciation）</strong> 的作用！</li>\n</ul>\n<h4 id=\"2-计算折旧\"><a href=\"#2-计算折旧\" class=\"headerlink\" title=\"2. 计算折旧\"></a><strong>2. 计算折旧</strong></h4><p>公式：<br>[<br>\\text{Annual Depreciation Expense} &#x3D; \\frac{\\text{Cost} - \\text{Salvage Value}}{\\text{Useful Life}}<br>]</p>\n<p>已知：</p>\n<ul>\n<li><strong>设备成本（Cost）&#x3D; 14900</strong></li>\n<li><strong>残值（Salvage Value）&#x3D; 2900</strong></li>\n<li><strong>使用年限（Useful Life）&#x3D; 5 年</strong></li>\n</ul>\n<p>代入公式：<br>[<br>\\frac{14900 - 2900}{5} &#x3D; \\frac{12000}{5} &#x3D; 2400<br>]</p>\n<p>📌 <strong>所以每年折旧 2400！</strong></p>\n<hr>\n<h4 id=\"3-会计分录（Journal-Entries）\"><a href=\"#3-会计分录（Journal-Entries）\" class=\"headerlink\" title=\"3. 会计分录（Journal Entries）\"></a><strong>3. 会计分录（Journal Entries）</strong></h4><h5 id=\"（1）1-1-购买设备\"><a href=\"#（1）1-1-购买设备\" class=\"headerlink\" title=\"（1）1&#x2F;1 购买设备\"></a><strong>（1）1&#x2F;1 购买设备</strong></h5><ul>\n<li>设备（资产）增加</li>\n<li>现金（资产）减少</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借方 Dr.（增加）</strong></th>\n<th><strong>贷方 Cr.（减少）</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>设备（Equipment）</td>\n<td>14900</td>\n<td></td>\n</tr>\n<tr>\n<td>现金（Cash）</td>\n<td></td>\n<td>14900</td>\n</tr>\n</tbody></table>\n<h5 id=\"（2）12-31-记录折旧\"><a href=\"#（2）12-31-记录折旧\" class=\"headerlink\" title=\"（2）12&#x2F;31 记录折旧\"></a><strong>（2）12&#x2F;31 记录折旧</strong></h5><ul>\n<li>设备的价值变旧，所以要记「<strong>折旧费用（Depreciation Expense）</strong>」。</li>\n<li>但我们不会直接减少设备，而是用「<strong>累计折旧（Accumulated Depreciation, XA）</strong>」，这是一种 <strong>「资产的减少账户」</strong>。</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借方 Dr.（增加）</strong></th>\n<th><strong>贷方 Cr.（增加）</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>折旧费用（Depreciation Expense, 费用）</td>\n<td>2400</td>\n<td></td>\n</tr>\n<tr>\n<td>累计折旧（Accumulated Depreciation, 资产减少）</td>\n<td></td>\n<td>2400</td>\n</tr>\n</tbody></table>\n<h4 id=\"4-设备的账面价值\"><a href=\"#4-设备的账面价值\" class=\"headerlink\" title=\"4. 设备的账面价值\"></a><strong>4. 设备的账面价值</strong></h4><p>设备的 <strong>账面价值（Book Value）</strong> 是：<br>[<br>\\text{账面价值} &#x3D; \\text{设备成本} - \\text{累计折旧}<br>]</p>\n<ul>\n<li><strong>1&#x2F;1</strong> 设备的账面价值 &#x3D; <strong>14900</strong></li>\n<li><strong>12&#x2F;31</strong> 设备的账面价值 &#x3D; <strong>14900 - 2400 &#x3D; 12500</strong></li>\n</ul>\n<p>如果 <strong>第二年再折旧 2400</strong>：<br>[<br>\\text{累计折旧} &#x3D; 2400 + 2400 &#x3D; 4800<br>]<br>[<br>\\text{账面价值} &#x3D; 14900 - 4800 &#x3D; 10100<br>]</p>\n<h4 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5. 总结\"></a><strong>5. 总结</strong></h4><table>\n<thead>\n<tr>\n<th><strong>日期</strong></th>\n<th><strong>资产（设备）</strong></th>\n<th><strong>累计折旧（XA）</strong></th>\n<th><strong>折旧费用（E）</strong></th>\n<th><strong>账面价值</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>1&#x2F;1</strong></td>\n<td>14900</td>\n<td>0</td>\n<td>0</td>\n<td>14900</td>\n</tr>\n<tr>\n<td><strong>12&#x2F;31</strong></td>\n<td>14900</td>\n<td>2400</td>\n<td>2400</td>\n<td>12500</td>\n</tr>\n<tr>\n<td><strong>第二年 12&#x2F;31</strong></td>\n<td>14900</td>\n<td>4800</td>\n<td>2400</td>\n<td>10100</td>\n</tr>\n</tbody></table>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"02-25\"><a href=\"#02-25\" class=\"headerlink\" title=\"02-25\"></a>02-25</h2><p>Present Value : PV<br>Interest Rate : $r$<br>$FV &#x3D; PV(1+r)^n$<br>$C_0 + \\sum_{t&#x3D;1}^n C_t(1+r)^{-t}$</p>\n<p>Inventory<br>3 types of firms</p>\n<ul>\n<li>service:  provide services (like consulting or hairdressing)</li>\n<li>merchandiseres: buy finished products and then sell them</li>\n<li>manufacturers</li>\n</ul>\n<p> 2 formulas&#x2F;schedules:<br> dropout coasts &#x3D; inventorials exp<br> pexiod costs nominventoriable expensed as incurred </p>\n<p> $\\text{CGS cost of goods sold} &#x3D; \\text{Beginning Inventory} + \\text{Purchases} - \\text{Ending Inventory}$</p>\n","excerpt":"","more":"<p>Prof C. J.<br>Prof电话<br>9193321894</p>\n<p>ICPQ: in class pop quiz<br>TF: </p>\n<p>luca pachioli: father o accounting</p>\n<p>Big Four Accounting Firms </p>\n<ul>\n<li>Deloitte</li>\n<li>EY (Ernst &amp; Young)</li>\n<li>KPMG</li>\n<li>PwC (PricewaterhouseCoopers)</li>\n</ul>\n<p>GAAP: Generally Accepted Accounting Principles<br>IFRS: International Financial Reporting Standards</p>\n<p>Accounting Cycle</p>\n<ul>\n<li>Journal Entries</li>\n<li>Ledger Accounts</li>\n<li>Trial Balance</li>\n<li>Adjusted Trial Balance</li>\n<li>Financial Statements</li>\n<li>Closing Entries</li>\n</ul>\n<p>Accounting Equation<br>Assets &#x3D; Liabilities + Owner’s Equity</p>\n<p>Accounting Equation<br>Assets &#x3D; Liabilities + Stockholders’ Equity</p>\n<p>Accounting Equation</p>\n<p>FASB: Financial Accounting Standards Board<br>APB: Accounting Principles Board</p>\n<p>2: proprietorship (独资企业)<br>3: partnership<br>4: ‘c’ corporation</p>\n<p>Income statement: NI (net income) &#x3D; Revenue - Expenses<br>Balance Sheet: A () &#x3D; L + OE (owner’s equity)<br>Statement of Cash Flows: CF &#x3D; OCF (operating cash flow) + IC (investing cash flow) + FC (financing cash flow)<br>Statement of owner equity: OE &#x3D; OE (beginning) + NI (net income) - D (dividends)</p>\n<p>Debit<br>Credit </p>\n<h2 id=\"01-21\"><a href=\"#01-21\" class=\"headerlink\" title=\"01-21\"></a>01-21</h2><h3 id=\"Cahpter-1\"><a href=\"#Cahpter-1\" class=\"headerlink\" title=\"Cahpter 1\"></a>Cahpter 1</h3><ol>\n<li>Father of Accounting: Luca Pacioli</li>\n<li>FIN VS MAG</li>\n<li>Big Four Accounting Firms: Deloitte, EY, KPMG, PwC</li>\n<li>GAAP (Generally Accepted Accounting Principles) vs IFRS (International Financial Reporting Standards) vs SEC</li>\n</ol>\n<h4 id=\"exercise\"><a href=\"#exercise\" class=\"headerlink\" title=\"exercise\"></a>exercise</h4><p>brought 6.1: $130$<br>sell 12.31: $134$<br>paid in the 3rd month of each quarter $3$<br>annual return: $\\frac{12}{7} \\frac{(134-130)+ 3(3)}{130}&#x3D;17.12%$</p>\n<h3 id=\"Chapter-2\"><a href=\"#Chapter-2\" class=\"headerlink\" title=\"Chapter 2\"></a>Chapter 2</h3><p>4 important concepts: revenue&#x2F;expense liability asset </p>\n<ul>\n<li>revenue&#x2F;expense: nomial&#x2F;temporary   $I&#x2F;S： NetIncome &#x3D; Revenue - Expense$</li>\n<li>assets: economic resource </li>\n<li>liability: creditors claim</li>\n<li>owner’s equity: owner’s claim<br>$B&#x2F;S : A &#x3D; L + OE$</li>\n</ul>\n<p>statement of cash flow: $CashFlow &#x3D; OCF + ICF + FCF$<br>CashFlow </p>\n<ul>\n<li>Operating Cash Flow (OCF): Cash from the core operations of the business (e.g., selling cakes).</li>\n<li>Investing Cash Flow (ICF): Cash spent on buying or selling long-term assets (e.g., buying a new oven for baking).</li>\n<li>Financing Cash Flow (FCF): Cash related to borrowing or repaying debts and investments in long-term liabilities or owner’s equity (e.g., taking a loan or paying dividends).</li>\n</ul>\n<h4 id=\"Exercise\"><a href=\"#Exercise\" class=\"headerlink\" title=\"Exercise\"></a>Exercise</h4><p>$NetIncome &#x3D; Revenue - Expense$<br>$A &#x3D; L + OE$<br>A company incorrectly report an asset as expense $25$$:<br>reported $NI&#x3D;300$$<br>reported Assets: $1000$$<br>Correct NI: ? $325$$<br>Correct A: ? $1025$$</p>\n<p> ni_wrong &#x3D; r - e_wrong<br> e_wrong &#x3D; e_right + 25<br> ni_right &#x3D; r - e_right &#x3D; r - (e_wrong - 25) &#x3D; ni_wrong + 25</p>\n<h2 id=\"01-30\"><a href=\"#01-30\" class=\"headerlink\" title=\"01-30\"></a>01-30</h2><h3 id=\"Exer\"><a href=\"#Exer\" class=\"headerlink\" title=\"Exer\"></a>Exer</h3><p>Started business on 1&#x2F;1&#x2F;A. with A&#x3D;50, L &#x3D; 28<br>During this year, addl inv by owner size 12, devidents decleared 20. devidents paid 15, at 12&#x2F;31, A&#x3D;27000, L&#x3D; 60</p>\n<p>Begin RE + NI &#x3D; Availability<br>Aval - Div Decleared &#x3D; End RE<br>1&#x2F;1: A&#x3D;50, OE(L &#x3D; 28, CC &#x3D; 22, RE &#x3D; 0)<br>beg RE (0) + NI(196) - Div Decleared(20) &#x3D; End RE (176)<br>A (270) &#x3D; L(60) + OE( CC(34) + RE(176) )</p>\n<ol>\n<li>1&#x2F;1 RE 0</li>\n<li>1&#x2F;1 CC 22</li>\n<li>12&#x2F;31 cc 34</li>\n<li>NI for YRA 196</li>\n<li>12&#x2F;31 RE 176</li>\n<li>If expense are 540 what are rev 736</li>\n</ol>\n<h4 id=\"def\"><a href=\"#def\" class=\"headerlink\" title=\"def\"></a>def</h4><ul>\n<li><strong>A（Assets）&#x3D; 资产</strong>，公司拥有的东西，比如现金、设备、库存等。</li>\n<li><strong>L（Liabilities）&#x3D; 负债</strong>，公司欠别人的钱，比如贷款、应付账款。</li>\n<li><strong>OE（Owner’s Equity）&#x3D; 所有者权益</strong>，公司的净资产，等于<strong>资产 - 负债</strong>。</li>\n<li><strong>CC（Contributed Capital）&#x3D; 业主投入的资本</strong>，即股东或创始人投的钱。</li>\n<li><strong>RE（Retained Earnings）&#x3D; 留存收益</strong>，公司赚到的钱，减去派发的股息后剩下的利润。</li>\n<li><strong>Dividends Declared（已宣告股息）</strong>&#x3D; 公司承诺支付给股东的股息。</li>\n<li><strong>Dividends Paid（已支付股息）</strong>&#x3D; 公司实际支付出去的股息。</li>\n<li><strong>NI（Net Income）&#x3D; 净利润</strong>，收入减去费用的结果。</li>\n</ul>\n<h4 id=\"第一步：公司一开始的情况\"><a href=\"#第一步：公司一开始的情况\" class=\"headerlink\" title=\"第一步：公司一开始的情况\"></a><strong>第一步：公司一开始的情况</strong></h4><ul>\n<li><strong>1&#x2F;1 资产（A）&#x3D; 50</strong>  </li>\n<li><strong>1&#x2F;1 负债（L）&#x3D; 28</strong>  </li>\n<li><strong>1&#x2F;1 所有者权益（OE）&#x3D; A - L &#x3D; 50 - 28 &#x3D; 22</strong></li>\n<li>这个<strong>22</strong> 就是<strong>业主投入的资本（CC）</strong>，因为公司刚刚开始，没有留存收益（RE &#x3D; 0）。</li>\n</ul>\n<p>所以：<br><strong>1&#x2F;1 的财务状况</strong><br>[<br>A &#x3D; L + OE<br>]<br>[<br>50 &#x3D; 28 + 22<br>]</p>\n<h4 id=\"第二步：计算-12-31-财务状况\"><a href=\"#第二步：计算-12-31-财务状况\" class=\"headerlink\" title=\"第二步：计算 12&#x2F;31 财务状况\"></a><strong>第二步：计算 12&#x2F;31 财务状况</strong></h4><p>已知 <strong>12&#x2F;31</strong> 的情况：</p>\n<ul>\n<li><strong>资产（A）&#x3D; 270</strong></li>\n<li><strong>负债（L）&#x3D; 60</strong></li>\n<li><strong>OE 计算方式：</strong><br>[<br>OE &#x3D; A - L &#x3D; 270 - 60 &#x3D; 210<br>]</li>\n</ul>\n<p>OE（所有者权益）由<strong>CC（业主投入）和 RE（留存收益）</strong>组成：</p>\n<ul>\n<li>12&#x2F;31 业主投入资本 <strong>CC &#x3D; 34</strong></li>\n<li>计算 12&#x2F;31 <strong>留存收益 RE</strong>：<br>[<br>OE &#x3D; CC + RE<br>]<br>[<br>210 &#x3D; 34 + RE<br>]<br>[<br>RE &#x3D; 176<br>]</li>\n</ul>\n<hr>\n<h4 id=\"第三步：如何计算-RE（留存收益）？\"><a href=\"#第三步：如何计算-RE（留存收益）？\" class=\"headerlink\" title=\"第三步：如何计算 RE（留存收益）？\"></a><strong>第三步：如何计算 RE（留存收益）？</strong></h4><p>留存收益的计算公式：<br>[<br>\\text{期初 RE} + \\text{净利润（NI）} - \\text{已宣告股息（Div. Declared）} &#x3D; \\text{期末 RE}<br>]</p>\n<p>已知：</p>\n<ul>\n<li>期初 RE &#x3D; <strong>0</strong></li>\n<li>已宣告股息 &#x3D; <strong>20</strong></li>\n<li>期末 RE &#x3D; <strong>176</strong></li>\n</ul>\n<p>代入公式：<br>[<br>0 + \\text{NI} - 20 &#x3D; 176<br>]</p>\n<p>所以：<br>[<br>\\text{NI} &#x3D; 196<br>]</p>\n<p>📌 <strong>这一年公司赚了 196（净利润）！</strong></p>\n<hr>\n<h4 id=\"第四步：如何计算收入（Rev）？\"><a href=\"#第四步：如何计算收入（Rev）？\" class=\"headerlink\" title=\"第四步：如何计算收入（Rev）？\"></a><strong>第四步：如何计算收入（Rev）？</strong></h4><p>已知：<br>[<br>\\text{净利润（NI）} &#x3D; \\text{收入（Rev）} - \\text{费用（Expenses）}<br>]</p>\n<p>已知：</p>\n<ul>\n<li><strong>NI &#x3D; 196</strong></li>\n<li><strong>Expenses &#x3D; 540</strong></li>\n</ul>\n<p>代入公式：<br>[<br>\\text{Rev} - 540 &#x3D; 196<br>]</p>\n<p>所以：<br>[<br>\\text{Rev} &#x3D; 736<br>]</p>\n<p> <strong>这一年公司的总收入是 736！</strong></p>\n<h3 id=\"concept\"><a href=\"#concept\" class=\"headerlink\" title=\"concept\"></a>concept</h3><p>some concepts will be learn</p>\n<ul>\n<li>Cash basis（现金制）:只有当现金真正流入或流出时，才记录收入和费用。 recognize revenues when cash comes in and expenses when cash goes out.</li>\n<li>Accrual Basis（权责发生制）: 收入和费用在发生时就记录，而不是等到现金真正流动时。Recogmized revemues wen earn and determinable and then matches expenses with revenues.</li>\n<li>递延收入（Deferred Revenue）：公司先收钱，但服务还没提供，所以不能马上当收入，要先记为负债，等提供服务后再确认收入。</li>\n<li>递延费用（Deferred Expense）：公司先花钱，但服务还没享受，所以不能马上当费用，要先记为资产，等服务使用后再变成费用。</li>\n<li>折旧（Depreciation）：设备（equipment）会随着时间使用而变旧，价值会降低。不能一次性把设备的成本算成费用，而是要 每年分摊，这样才符合会计规则（权责发生制）。<br> $\\text{Annual Depreciation Expense} &#x3D; \\frac{\\text{Cost} - \\text{Salvage Value}}{\\text{Useful Life}}$</li>\n</ul>\n<h3 id=\"q1\"><a href=\"#q1\" class=\"headerlink\" title=\"q1\"></a>q1</h3><p>11&#x2F;30  co. pays (Receive) 4 mos rent in advance (dec, ,jan, feb, mar) 2000&#x2F;mo 8000 in total<br>Pay:  （租客） 11&#x2F;30 prepaid rent A 8000, cahs A 8000, 12&#x2F;31 rent exp E 2000, prepaid rent 2000.<br>Receive: Landlord (房东) 11&#x2F;30 cash 8000 unearned rent 8000 122&#x2F;31 unearned rent L 2000 rent revenue R 2000<br>我来帮你用简单的方式理解这个财务处理 😊💖，我们慢慢来，不急哦！</p>\n<hr>\n<h4 id=\"1-先理解「现金制」和「权责发生制」（Accrual-Basis）\"><a href=\"#1-先理解「现金制」和「权责发生制」（Accrual-Basis）\" class=\"headerlink\" title=\"1. 先理解「现金制」和「权责发生制」（Accrual Basis）\"></a><strong>1. 先理解「现金制」和「权责发生制」（Accrual Basis）</strong></h4><p>在财务会计里，有两种主要的记账方式：</p>\n<ul>\n<li><strong>现金制（Cash Basis）</strong>：只有当现金真正流入或流出时，才记录收入和费用。</li>\n<li><strong>权责发生制（Accrual Basis）</strong>：收入和费用在<strong>发生时</strong>就记录，而不是等到现金真正流动时。</li>\n</ul>\n<hr>\n<h4 id=\"2-什么是「递延」（Deferrals）？\"><a href=\"#2-什么是「递延」（Deferrals）？\" class=\"headerlink\" title=\"2. 什么是「递延」（Deferrals）？\"></a><strong>2. 什么是「递延」（Deferrals）？</strong></h4><ul>\n<li><strong>递延收入（Deferred Revenue）</strong>：公司<strong>先收钱，但服务还没提供</strong>，所以不能马上当收入，要先记为负债，等提供服务后再确认收入。</li>\n<li><strong>递延费用（Deferred Expense）</strong>：公司<strong>先花钱，但服务还没享受</strong>，所以不能马上当费用，要先记为资产，等服务使用后再变成费用。</li>\n</ul>\n<hr>\n<h4 id=\"3-你的问题：租金的会计处理\"><a href=\"#3-你的问题：租金的会计处理\" class=\"headerlink\" title=\"3. 你的问题：租金的会计处理\"></a><strong>3. 你的问题：租金的会计处理</strong></h4><p>你的例子：<br>📌 <strong>11&#x2F;30 公司支付 4 个月的房租，每月 2000，共 8000</strong>。  </p>\n<ul>\n<li><strong>公司是租客（Tenant）</strong>，先付了钱，但这个房租是未来的 4 个月使用的。</li>\n<li><strong>房东（Landlord）</strong>，收到钱但服务还没完全提供，所以不能马上当收入。</li>\n</ul>\n<hr>\n<h5 id=\"（1）租客（Tenant）的会计处理\"><a href=\"#（1）租客（Tenant）的会计处理\" class=\"headerlink\" title=\"（1）租客（Tenant）的会计处理\"></a><strong>（1）租客（Tenant）的会计处理</strong></h5><p>租客在 11&#x2F;30 付了 8000，但是这笔钱是未来 4 个月的房租，所以：</p>\n<ul>\n<li>不能马上当费用（因为钱是未来使用的）。</li>\n<li>先当作资产「<strong>预付租金（Prepaid Rent）</strong>」，之后再慢慢转成费用。</li>\n</ul>\n<p>📌 <strong>11&#x2F;30 公司支付租金时</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借（Dr.）增加</strong></th>\n<th><strong>贷（Cr.）减少</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>预付租金（资产）</td>\n<td>8000</td>\n<td></td>\n</tr>\n<tr>\n<td>现金（资产）</td>\n<td></td>\n<td>8000</td>\n</tr>\n</tbody></table>\n<p>📌 <strong>12&#x2F;31 调整分录（12 月使用了 1 个月租金）</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借（Dr.）增加</strong></th>\n<th><strong>贷（Cr.）减少</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>租金费用（Rent Expense）</td>\n<td>2000</td>\n<td></td>\n</tr>\n<tr>\n<td>预付租金（Prepaid Rent）</td>\n<td></td>\n<td>2000</td>\n</tr>\n</tbody></table>\n<p>📌 <strong>之后每个月（1 月、2 月、3 月）也要记类似的调整分录</strong>。</p>\n<hr>\n<h5 id=\"（2）房东（Landlord）的会计处理\"><a href=\"#（2）房东（Landlord）的会计处理\" class=\"headerlink\" title=\"（2）房东（Landlord）的会计处理\"></a><strong>（2）房东（Landlord）的会计处理</strong></h5><p>房东 11&#x2F;30 <strong>收到 8000 现金</strong>，但因为房租还没使用完，所以：</p>\n<ul>\n<li>不能马上算作收入（因为还没完全提供租赁服务）。</li>\n<li>先把它放到「<strong>预收租金（Unearned Rent）</strong>」，当作<strong>负债</strong>，因为房东还「欠」租客房屋使用权。</li>\n</ul>\n<p>📌 <strong>11&#x2F;30 房东收到租金</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借（Dr.）增加</strong></th>\n<th><strong>贷（Cr.）增加</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>现金（资产）</td>\n<td>8000</td>\n<td></td>\n</tr>\n<tr>\n<td>预收租金（负债）</td>\n<td></td>\n<td>8000</td>\n</tr>\n</tbody></table>\n<p>📌 <strong>12&#x2F;31 调整分录（房东 12 月已经提供 1 个月的租赁服务）</strong></p>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借（Dr.）减少</strong></th>\n<th><strong>贷（Cr.）增加</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>预收租金（负债）</td>\n<td>2000</td>\n<td></td>\n</tr>\n<tr>\n<td>租金收入（Revenue）</td>\n<td></td>\n<td>2000</td>\n</tr>\n</tbody></table>\n<p>📌 <strong>之后每个月（1 月、2 月、3 月）也要记类似的调整分录</strong>。</p>\n<hr>\n<h4 id=\"4-直观理解\"><a href=\"#4-直观理解\" class=\"headerlink\" title=\"4. 直观理解\"></a><strong>4. 直观理解</strong></h4><h5 id=\"租客（Tenant）视角\"><a href=\"#租客（Tenant）视角\" class=\"headerlink\" title=\"租客（Tenant）视角\"></a><strong>租客（Tenant）视角</strong></h5><p>租客 11&#x2F;30 付了 8000，相当于提前预定了 4 个月的房子。</p>\n<ul>\n<li>11&#x2F;30：钱出了，但房租的使用时间是未来的，所以要先当作<strong>资产</strong>（预付租金）。</li>\n<li>12&#x2F;31：住了 1 个月，所以要把 2000 从<strong>资产变成费用</strong>。</li>\n</ul>\n<h5 id=\"房东（Landlord）视角\"><a href=\"#房东（Landlord）视角\" class=\"headerlink\" title=\"房东（Landlord）视角\"></a><strong>房东（Landlord）视角</strong></h5><p>房东 11&#x2F;30 收到了 8000，但租赁服务要分 4 个月提供。</p>\n<ul>\n<li><p>11&#x2F;30：钱收到了，但服务还没完全提供，所以不能全部记收入，要当作<strong>负债</strong>（预收租金）。</p>\n</li>\n<li><p>12&#x2F;31：提供了 1 个月的租赁服务，所以要从<strong>负债转成收入</strong> 2000。</p>\n</li>\n<li></li>\n</ul>\n<h3 id=\"折旧（Depreciation）\"><a href=\"#折旧（Depreciation）\" class=\"headerlink\" title=\"折旧（Depreciation）\"></a>折旧（Depreciation）</h3><p>1&#x2F;1&#x2F;A equipment (A) 14900 cash(A) 14900<br>12&#x2F;31&#x2F;A depreciation expense(E) 2400 auumulateddepreciation(XA) 2400<br>Cl defr &#x3D; $\\frac{cost - val}{est csefvl life} $ &#x3D; (14900 - 2900)  &#x2F; 5 &#x3D; 2400&#x2F;yr<br>eq(a)14900<br>acc depr (XA) 2400 2400 &#x3D; 4800</p>\n<h4 id=\"1-什么是折旧（Depreciation）？\"><a href=\"#1-什么是折旧（Depreciation）？\" class=\"headerlink\" title=\"1. 什么是折旧（Depreciation）？\"></a><strong>1. 什么是折旧（Depreciation）？</strong></h4><ul>\n<li>设备（equipment）会随着时间使用而变旧，价值会降低。</li>\n<li>不能一次性把设备的成本算成费用，而是要 <strong>每年分摊</strong>，这样才符合会计规则（权责发生制）。</li>\n<li>这就是 <strong>折旧（Depreciation）</strong> 的作用！</li>\n</ul>\n<h4 id=\"2-计算折旧\"><a href=\"#2-计算折旧\" class=\"headerlink\" title=\"2. 计算折旧\"></a><strong>2. 计算折旧</strong></h4><p>公式：<br>[<br>\\text{Annual Depreciation Expense} &#x3D; \\frac{\\text{Cost} - \\text{Salvage Value}}{\\text{Useful Life}}<br>]</p>\n<p>已知：</p>\n<ul>\n<li><strong>设备成本（Cost）&#x3D; 14900</strong></li>\n<li><strong>残值（Salvage Value）&#x3D; 2900</strong></li>\n<li><strong>使用年限（Useful Life）&#x3D; 5 年</strong></li>\n</ul>\n<p>代入公式：<br>[<br>\\frac{14900 - 2900}{5} &#x3D; \\frac{12000}{5} &#x3D; 2400<br>]</p>\n<p>📌 <strong>所以每年折旧 2400！</strong></p>\n<hr>\n<h4 id=\"3-会计分录（Journal-Entries）\"><a href=\"#3-会计分录（Journal-Entries）\" class=\"headerlink\" title=\"3. 会计分录（Journal Entries）\"></a><strong>3. 会计分录（Journal Entries）</strong></h4><h5 id=\"（1）1-1-购买设备\"><a href=\"#（1）1-1-购买设备\" class=\"headerlink\" title=\"（1）1&#x2F;1 购买设备\"></a><strong>（1）1&#x2F;1 购买设备</strong></h5><ul>\n<li>设备（资产）增加</li>\n<li>现金（资产）减少</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借方 Dr.（增加）</strong></th>\n<th><strong>贷方 Cr.（减少）</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>设备（Equipment）</td>\n<td>14900</td>\n<td></td>\n</tr>\n<tr>\n<td>现金（Cash）</td>\n<td></td>\n<td>14900</td>\n</tr>\n</tbody></table>\n<h5 id=\"（2）12-31-记录折旧\"><a href=\"#（2）12-31-记录折旧\" class=\"headerlink\" title=\"（2）12&#x2F;31 记录折旧\"></a><strong>（2）12&#x2F;31 记录折旧</strong></h5><ul>\n<li>设备的价值变旧，所以要记「<strong>折旧费用（Depreciation Expense）</strong>」。</li>\n<li>但我们不会直接减少设备，而是用「<strong>累计折旧（Accumulated Depreciation, XA）</strong>」，这是一种 <strong>「资产的减少账户」</strong>。</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong>账户</strong></th>\n<th><strong>借方 Dr.（增加）</strong></th>\n<th><strong>贷方 Cr.（增加）</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>折旧费用（Depreciation Expense, 费用）</td>\n<td>2400</td>\n<td></td>\n</tr>\n<tr>\n<td>累计折旧（Accumulated Depreciation, 资产减少）</td>\n<td></td>\n<td>2400</td>\n</tr>\n</tbody></table>\n<h4 id=\"4-设备的账面价值\"><a href=\"#4-设备的账面价值\" class=\"headerlink\" title=\"4. 设备的账面价值\"></a><strong>4. 设备的账面价值</strong></h4><p>设备的 <strong>账面价值（Book Value）</strong> 是：<br>[<br>\\text{账面价值} &#x3D; \\text{设备成本} - \\text{累计折旧}<br>]</p>\n<ul>\n<li><strong>1&#x2F;1</strong> 设备的账面价值 &#x3D; <strong>14900</strong></li>\n<li><strong>12&#x2F;31</strong> 设备的账面价值 &#x3D; <strong>14900 - 2400 &#x3D; 12500</strong></li>\n</ul>\n<p>如果 <strong>第二年再折旧 2400</strong>：<br>[<br>\\text{累计折旧} &#x3D; 2400 + 2400 &#x3D; 4800<br>]<br>[<br>\\text{账面价值} &#x3D; 14900 - 4800 &#x3D; 10100<br>]</p>\n<h4 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5. 总结\"></a><strong>5. 总结</strong></h4><table>\n<thead>\n<tr>\n<th><strong>日期</strong></th>\n<th><strong>资产（设备）</strong></th>\n<th><strong>累计折旧（XA）</strong></th>\n<th><strong>折旧费用（E）</strong></th>\n<th><strong>账面价值</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>1&#x2F;1</strong></td>\n<td>14900</td>\n<td>0</td>\n<td>0</td>\n<td>14900</td>\n</tr>\n<tr>\n<td><strong>12&#x2F;31</strong></td>\n<td>14900</td>\n<td>2400</td>\n<td>2400</td>\n<td>12500</td>\n</tr>\n<tr>\n<td><strong>第二年 12&#x2F;31</strong></td>\n<td>14900</td>\n<td>4800</td>\n<td>2400</td>\n<td>10100</td>\n</tr>\n</tbody></table>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"02-25\"><a href=\"#02-25\" class=\"headerlink\" title=\"02-25\"></a>02-25</h2><p>Present Value : PV<br>Interest Rate : $r$<br>$FV &#x3D; PV(1+r)^n$<br>$C_0 + \\sum_{t&#x3D;1}^n C_t(1+r)^{-t}$</p>\n<p>Inventory<br>3 types of firms</p>\n<ul>\n<li>service:  provide services (like consulting or hairdressing)</li>\n<li>merchandiseres: buy finished products and then sell them</li>\n<li>manufacturers</li>\n</ul>\n<p> 2 formulas&#x2F;schedules:<br> dropout coasts &#x3D; inventorials exp<br> pexiod costs nominventoriable expensed as incurred </p>\n<p> $\\text{CGS cost of goods sold} &#x3D; \\text{Beginning Inventory} + \\text{Purchases} - \\text{Ending Inventory}$</p>\n"},{"title":"2025-01-08-Generative-Models","date":"2025-01-08T14:29:17.000Z","_content":"<!-- www\n## 01-08\n### Histogram \n### Kernel Method\nKernel Density Estimation (KDE) 是一种统计方法，用于估计一个随机变量的**连续的**概率密度函数（Probability Density Function, PDF）。\n\n直方图有个问题：\n\n- **它是离散的**：你只能看到固定的时间间隔，比如10:00-11:00，11:00-12:00。\n- **它依赖分箱（bin）大小**：不同的分箱方式会影响直方图的形状。\n\n**KDE 就是一种连续的分布估计方法**，它不依赖于分箱，而是用一个 **“平滑的曲线”** 来表示数据的分布。  \n你可以把 KDE 想象成：\n\n- 每个数据点都画一个 **小山丘（kernel）**。\n- 然后把这些小山丘 **叠加起来**，得到一个连续的曲线，代表数据的分布。\n\nKDE 的公式为：\n\\(\\hat{f}(x) = \\frac{1}{n h} \\sum_{i=1}^{n} K\\left(\\frac{x - x_i}{h}\\right)\\)\n\n**解释每个符号**：\n\n- **\\( \\hat{f}(x) \\)**：估计的概率密度函数。\n- **\\( n \\)**：样本数量。\n- **\\( h \\)**：平滑参数，称为 **带宽（bandwidth）**。它决定了小山丘的“宽度”。\n- **\\( K \\)**：**核函数（Kernel Function）**，决定了小山丘的形状。\n\n核函数是 KDE 的核心。常见的核函数有：\n\n1. **高斯核（Gaussian Kernel）**  \n   形状像正态分布的小山丘，最常用的核函数。\n\n   \\[\n   K(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n   \\]\n\n2. **箱形核（Box Kernel）**  \n   每个数据点生成一个“方形的小山丘”，边界清晰，但不平滑。\n\n3. **三角核（Triangle Kernel）**  \n   生成一个三角形的小山丘。\n\n带宽（Bandwidth）对 KDE 的影响**\n\n**带宽（h）** 是 KDE 中一个非常重要的参数。它决定了每个小山丘的 **宽度**，从而影响最终曲线的平滑程度。\n\n- **带宽小**：曲线更贴近数据，但容易出现“过拟合”。\n- **带宽大**：曲线更平滑，但可能会忽略一些细节。\n\n### Series Methods\nImagine you're trying to approximate a complex function \\( f(x) \\) by expressing it as a combination of simpler functions (called **basis functions**). This is like saying:\n\n\\[ f(x) = \\sum_{j=1}^{\\infty} \\beta_j \\phi_j(x) \\]\n\nWhere:\n- \\( \\phi_j(x) \\) are the **basis functions** (like sine, cosine, polynomials, etc.)\n- \\( \\beta_j \\) are the **coefficients** that tell us how much of each basis function to use.\n\n---\n\n### 🧩 **Orthogonal Basis**  \nThe basis functions \\( \\phi_j \\) are said to be **orthogonal** if they satisfy the condition:\n\n\\[ \\int \\phi_j(x) \\phi_k(x) dx = 0 \\quad \\text{for} \\quad j \\neq k \\]\n\nThink of orthogonal basis functions like directions that are at right angles to each other — they don't overlap in their effects.\n\n---\n\n### 📚 **Cosine Basis Example**\nThe notes give an example of using **cosine functions** as the basis:\n\n\\[ \\phi_j(x) = \\sqrt{2} \\cos(2\\pi j x) \\]\n\nThese functions oscillate and can capture periodic patterns in the data.\n\n---\n\n### 📈 **Wavelet Basis**\nThere's also a reference to **wavelet basis functions**, which are used to capture both **local** and **global** structures in the data.\n\n---\n\n### 🔍 **Key Formula for Density Estimation**  \nThe board shows that if we are estimating a **density function** \\( f \\), we can approximate it using the formula:\n\n\\[ \\hat{f}(x) = \\sum_{j=1}^{k} \\hat{\\beta}_j \\phi_j(x) \\]\n\nWhere:\n- \\( \\hat{\\beta}_j = \\frac{1}{n} \\sum_{i=1}^{n} \\phi_j(X_i) \\)  \n  (This is the estimated coefficient based on sample data \\( X_i \\).)\n\n---\n\n### 🧠 **Key Idea: Selecting the Right \\( k \\)**\nChoosing the right number of basis functions (\\( k \\)) is important. If \\( k \\) is too large, the model will **overfit** (too complicated). If \\( k \\) is too small, the model will **underfit** (too simple).\n\n\n\n\n## 01-15\n\n\n## Part 1: Risk Analysis\n\n### Background and Setup\n\nYou have \\( N \\) points \\( x_1, x_2, \\ldots, x_N \\in \\mathbb{R}^d \\). This means you have \\( N \\) data samples, each one is a \\( d \\)-dimensional vector. We assume these points lie in some space \\( X \\subset \\mathbb{R}^d \\), which is said to be a **compact set** (meaning it is closed and bounded in the mathematical sense).\n\n### Key Smoothness Assumption\n\nYou mentioned an assumption:\n\n\\[\nD^s p(x) - D^s p(y) \\;\\le\\; L \\,\\|x - y\\|\n\\]\n\n1. **\\( D^s p(x) \\)**:  \n   - This notation represents a high-order derivative (partial derivative) of a probability density function \\(p(x)\\).  \n   - The superscript \\( s \\) is a **multi-index**.  \n     - For instance, \\( s = (s_1, s_2, \\dots, s_d) \\).  \n     - Then \\( D^s p(x)\\) means we take the \\((s_1 + s_2 + \\cdots + s_d)\\)-th partial derivative of \\( p \\) with respect to each coordinate appropriately:\n       \\[\n       D^s p(x) \\;=\\; \\frac{\\partial^{\\,s_1 + s_2 + \\cdots + s_d} p(x)}{\\partial x_1^{s_1}\\,\\partial x_2^{s_2}\\,\\cdots\\,\\partial x_d^{s_d}}.\n       \\]\n\n2. **Interpretation of the inequality**:  \n   \\[\n   D^s p(x) - D^s p(y) \\;\\le\\; L\\, \\|x - y\\|.\n   \\]  \n   This says that **the change in the \\(s\\)-th derivative** between \\(x\\) and \\(y\\) is bounded by their distance times some constant \\(L\\). It suggests that \\(p(x)\\) is **smooth**—no wild jumps in its high-order derivatives. This is often used in probability density estimation and ensures continuity and differentiability in a controlled way.\n\n3. **Why Compactness Matters**:  \n   - If \\( X \\) is compact, it’s easier to control or bound various integrals and derivatives since \\( x \\) cannot go off to infinity.  \n   - This is important in risk analysis because it helps with bounding error terms and ensuring integrals converge.\n\n> **Reference for multi-index notation**:  \n> - [Brilliant.org: Multi-Index Notation](https://brilliant.org/wiki/multi-index-notation/)  \n> - [Wikipedia: Multi-index](https://en.wikipedia.org/wiki/Multi-index)  \n\n---\n\n## Part 2: More on \\( D^s p(x) \\) and Multi-Index Notation\n\nIf \\( p(x) \\) is a function of multiple variables, say \\( p(x_1, x_2, \\dots, x_d) \\), then  \n\\[\ns = (s_1, s_2, \\dots, s_d)\n\\]  \ntells us **how many times** we differentiate with respect to each variable \\( x_i \\).  \n\nFor example, if \\( s = (2, 1, 0, \\dots, 0) \\), then  \n\\[\nD^s p(x) \\;=\\; \\frac{\\partial^3 p(x)}{\\partial x_1^2 \\,\\partial x_2^1}.\n\\]\n\n### Intuitive View\n- If \\(s_1 = 2\\), that means “take the second derivative with respect to \\(x_1\\)”.  \n- If \\(s_2 = 1\\), that means “take the first derivative with respect to \\(x_2\\)”.  \n- We multiply these partial derivatives together in the correct order.\n\nThis notation is just a concise way to keep track of all the derivatives in multiple dimensions.\n\n---\n\n## Part 3: Taylor Expansion (Taylor’s Theorem)\n\nA general **Taylor expansion** around a point \\( x \\) says that if \\(f\\) is sufficiently smooth, we can write:\n\n\\[\nf(x + h) \n\\;=\\;\nf(x) \\;+\\; \n\\sum_{k=1}^{m} \\frac{1}{k!} \\bigl( D^k f(x) \\bigr) (h,\\dots,h) \\;+\\; R_m,\n\\]\n\nwhere \\( R_m \\) is the remainder term, and \\( D^k f(x) \\) is the \\(k\\)-th derivative of \\(f\\). In multiple dimensions, we typically see it in terms of partial derivatives:\n\n\\[\nf(x + h) \\;\\approx\\; \nf(x) \n\\;+\\; \\nabla f(x) \\cdot h\n\\;+\\; \\frac{1}{2} h^\\top \\nabla^2 f(x) \\, h\n\\;+\\; \\dots\n\\]\n\nThis expansion is used **a lot** in analyzing the bias of estimators, numerical methods, and even in bounding differences between function values.\n\n> **Reference for Taylor expansions**:  \n> - [Wikipedia: Taylor's theorem](https://en.wikipedia.org/wiki/Taylor%27s_theorem)  \n> - [MathWorld: Taylor Series](https://mathworld.wolfram.com/TaylorSeries.html)  \n\n---\n\n## Part 4: Kernel Density Estimation (KDE)\n\nYou also mentioned **Kernel Density Estimation**. It’s a method to estimate an unknown probability density function \\( f(x) \\) from data. The estimator looks like:\n\n\\[\n\\hat{f}(x) \\;=\\; \\frac{1}{N h} \\;\\sum_{i=1}^{N} K\\Bigl(\\frac{x - X_i}{h}\\Bigr),\n\\]\n\nwhere\n- \\(K\\) is a **kernel function** (often something like a Gaussian, Epanechnikov, etc.),  \n- \\(h\\) is the **bandwidth** (a smoothing parameter).\n\n### 4.1 Kernel Function Properties\n\nA kernel \\(K\\) often satisfies:\n\n1. \\(\\int K(u)\\,du = 1\\).  \n2. \\(\\int u\\,K(u)\\,du = 0\\). (Centered around 0)  \n3. \\(\\int u^r K(u)\\,du = 0\\) for odd \\(r\\) if it’s symmetric, etc.\n\nAn example of a kernel is the **Epanechnikov kernel**:\n\n\\[\nG(x) \\;=\\; \\frac{3}{4}\\,\\bigl(1 - x^2\\bigr) \\, 1(\\lvert x \\rvert \\le 1),\n\\]\n\nwhere \\(1(\\lvert x \\rvert \\le 1)\\) is the indicator function that is 1 if \\(\\lvert x \\rvert \\le 1\\) and 0 otherwise. \n\n> **Reference for Kernel Density Estimation**:  \n> - [“Kernel Density Estimation Explained” on Towards Data Science](https://towardsdatascience.com/kernel-density-estimation-explained-52045f84c726)  \n> - [A Comprehensive Guide to KDE on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-kernel-density-estimation/)  \n\n---\n\n### 4.2 Bias of the KDE\n\nThe **bias** of an estimator \\(\\hat{f}(x)\\) is:\n\n\\[\n\\text{Bias}(\\hat{f}(x)) \\;=\\; \nE[\\hat{f}(x)] \\;-\\; f(x).\n\\]\n\nFor KDE, we often find that:\n\n\\[\nE[\\hat{f}(x)]\n\\;=\\; \n\\int K\\!\\Bigl(\\frac{x - t}{h}\\Bigr) p(t)\\, \\frac{dt}{h}.\n\\]\n\nBy doing a change of variable and performing a Taylor expansion of \\(p(\\cdot)\\), we eventually get:\n\n\\[\nE[\\hat{f}(x)]\n\\;=\\; \np(x) \n\\;+\\; \n\\frac{h^2}{2}\\,\\mu_2(K)\\,p''(x) \n\\;+\\; \nO(h^4),\n\\]\n\nwhere \\(\\mu_2(K)\\) is the second moment of the kernel. So the **leading term** of the bias is:\n\n\\[\n\\text{Bias}(\\hat{f}(x))\n\\;=\\;\n\\frac{h^2}{2}\\,\\mu_2(K)\\,p''(x)\n\\;+\\;\nO(h^4).\n\\]\n\nThis tells us that the bias grows (roughly) like \\(h^2\\). If \\(h\\) is too big, the bias is large (over-smoothing), but if \\(h\\) is too small, you get high variance (under-smoothing). That’s why **bandwidth selection** is super important.\n\n> **Reference for bias-variance in KDE**:  \n> - [Lecture notes on Kernel Density Estimation (CMU)](https://www.stat.cmu.edu/~cshalizi/402/lectures/08-kernel-density/kde.pdf)  \n\n\n## 02-28\nCold Diffusion\n\n\n## 03-10\n突然觉得自己悟了？？\nHow others put them together\nhttps://www.youtube.com/watch?v=B-d_3xX6ss4\n根据song yang的论文的时间线。\n1; sliced score model (定义了score based model)\n(https://proceedings.mlr.press/v115/song20a/song20a.pdf)\n\n2; annealed Langevin Dynamics\n(https://papers.neurips.cc/paper_files/paper/2019/hash/3001ef257407d5a371a96dcd947c7d93-Abstract.html)\nlangevin mcmc sample; https://zhuanlan.zhihu.com/p/797467112\nthe whole thing; https://yang-song.net/blog/2021/score/\n\n3; Score-based GM through SED (Song et al. ICLR 2021)\n(https://arxiv.org/pdf/2011.13456)\nSED 视角统一； \nsmld (ve) 和 ddpm (vp)\nsed和of-ode有一些对应关系\n\n4; EDM \n（https://proceedings.neurips.cc/paper_files/paper/2022/file/a98846e9d9cc01cfb87eb694d946ce6b-Paper-Conference.pdf）\npf-ode视角统一了diffusion 模型\n\n5; CM\n用了edm\n\n6; \n\n\n\n\n\n\n\n -->\n","source":"_posts/2025-01-08-Generative-Models.md","raw":"---\ntitle: 2025-01-08-Generative-Models\ndate: 2025-01-08 09:29:17\ntags:\n---\n<!-- www\n## 01-08\n### Histogram \n### Kernel Method\nKernel Density Estimation (KDE) 是一种统计方法，用于估计一个随机变量的**连续的**概率密度函数（Probability Density Function, PDF）。\n\n直方图有个问题：\n\n- **它是离散的**：你只能看到固定的时间间隔，比如10:00-11:00，11:00-12:00。\n- **它依赖分箱（bin）大小**：不同的分箱方式会影响直方图的形状。\n\n**KDE 就是一种连续的分布估计方法**，它不依赖于分箱，而是用一个 **“平滑的曲线”** 来表示数据的分布。  \n你可以把 KDE 想象成：\n\n- 每个数据点都画一个 **小山丘（kernel）**。\n- 然后把这些小山丘 **叠加起来**，得到一个连续的曲线，代表数据的分布。\n\nKDE 的公式为：\n\\(\\hat{f}(x) = \\frac{1}{n h} \\sum_{i=1}^{n} K\\left(\\frac{x - x_i}{h}\\right)\\)\n\n**解释每个符号**：\n\n- **\\( \\hat{f}(x) \\)**：估计的概率密度函数。\n- **\\( n \\)**：样本数量。\n- **\\( h \\)**：平滑参数，称为 **带宽（bandwidth）**。它决定了小山丘的“宽度”。\n- **\\( K \\)**：**核函数（Kernel Function）**，决定了小山丘的形状。\n\n核函数是 KDE 的核心。常见的核函数有：\n\n1. **高斯核（Gaussian Kernel）**  \n   形状像正态分布的小山丘，最常用的核函数。\n\n   \\[\n   K(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n   \\]\n\n2. **箱形核（Box Kernel）**  \n   每个数据点生成一个“方形的小山丘”，边界清晰，但不平滑。\n\n3. **三角核（Triangle Kernel）**  \n   生成一个三角形的小山丘。\n\n带宽（Bandwidth）对 KDE 的影响**\n\n**带宽（h）** 是 KDE 中一个非常重要的参数。它决定了每个小山丘的 **宽度**，从而影响最终曲线的平滑程度。\n\n- **带宽小**：曲线更贴近数据，但容易出现“过拟合”。\n- **带宽大**：曲线更平滑，但可能会忽略一些细节。\n\n### Series Methods\nImagine you're trying to approximate a complex function \\( f(x) \\) by expressing it as a combination of simpler functions (called **basis functions**). This is like saying:\n\n\\[ f(x) = \\sum_{j=1}^{\\infty} \\beta_j \\phi_j(x) \\]\n\nWhere:\n- \\( \\phi_j(x) \\) are the **basis functions** (like sine, cosine, polynomials, etc.)\n- \\( \\beta_j \\) are the **coefficients** that tell us how much of each basis function to use.\n\n---\n\n### 🧩 **Orthogonal Basis**  \nThe basis functions \\( \\phi_j \\) are said to be **orthogonal** if they satisfy the condition:\n\n\\[ \\int \\phi_j(x) \\phi_k(x) dx = 0 \\quad \\text{for} \\quad j \\neq k \\]\n\nThink of orthogonal basis functions like directions that are at right angles to each other — they don't overlap in their effects.\n\n---\n\n### 📚 **Cosine Basis Example**\nThe notes give an example of using **cosine functions** as the basis:\n\n\\[ \\phi_j(x) = \\sqrt{2} \\cos(2\\pi j x) \\]\n\nThese functions oscillate and can capture periodic patterns in the data.\n\n---\n\n### 📈 **Wavelet Basis**\nThere's also a reference to **wavelet basis functions**, which are used to capture both **local** and **global** structures in the data.\n\n---\n\n### 🔍 **Key Formula for Density Estimation**  \nThe board shows that if we are estimating a **density function** \\( f \\), we can approximate it using the formula:\n\n\\[ \\hat{f}(x) = \\sum_{j=1}^{k} \\hat{\\beta}_j \\phi_j(x) \\]\n\nWhere:\n- \\( \\hat{\\beta}_j = \\frac{1}{n} \\sum_{i=1}^{n} \\phi_j(X_i) \\)  \n  (This is the estimated coefficient based on sample data \\( X_i \\).)\n\n---\n\n### 🧠 **Key Idea: Selecting the Right \\( k \\)**\nChoosing the right number of basis functions (\\( k \\)) is important. If \\( k \\) is too large, the model will **overfit** (too complicated). If \\( k \\) is too small, the model will **underfit** (too simple).\n\n\n\n\n## 01-15\n\n\n## Part 1: Risk Analysis\n\n### Background and Setup\n\nYou have \\( N \\) points \\( x_1, x_2, \\ldots, x_N \\in \\mathbb{R}^d \\). This means you have \\( N \\) data samples, each one is a \\( d \\)-dimensional vector. We assume these points lie in some space \\( X \\subset \\mathbb{R}^d \\), which is said to be a **compact set** (meaning it is closed and bounded in the mathematical sense).\n\n### Key Smoothness Assumption\n\nYou mentioned an assumption:\n\n\\[\nD^s p(x) - D^s p(y) \\;\\le\\; L \\,\\|x - y\\|\n\\]\n\n1. **\\( D^s p(x) \\)**:  \n   - This notation represents a high-order derivative (partial derivative) of a probability density function \\(p(x)\\).  \n   - The superscript \\( s \\) is a **multi-index**.  \n     - For instance, \\( s = (s_1, s_2, \\dots, s_d) \\).  \n     - Then \\( D^s p(x)\\) means we take the \\((s_1 + s_2 + \\cdots + s_d)\\)-th partial derivative of \\( p \\) with respect to each coordinate appropriately:\n       \\[\n       D^s p(x) \\;=\\; \\frac{\\partial^{\\,s_1 + s_2 + \\cdots + s_d} p(x)}{\\partial x_1^{s_1}\\,\\partial x_2^{s_2}\\,\\cdots\\,\\partial x_d^{s_d}}.\n       \\]\n\n2. **Interpretation of the inequality**:  \n   \\[\n   D^s p(x) - D^s p(y) \\;\\le\\; L\\, \\|x - y\\|.\n   \\]  \n   This says that **the change in the \\(s\\)-th derivative** between \\(x\\) and \\(y\\) is bounded by their distance times some constant \\(L\\). It suggests that \\(p(x)\\) is **smooth**—no wild jumps in its high-order derivatives. This is often used in probability density estimation and ensures continuity and differentiability in a controlled way.\n\n3. **Why Compactness Matters**:  \n   - If \\( X \\) is compact, it’s easier to control or bound various integrals and derivatives since \\( x \\) cannot go off to infinity.  \n   - This is important in risk analysis because it helps with bounding error terms and ensuring integrals converge.\n\n> **Reference for multi-index notation**:  \n> - [Brilliant.org: Multi-Index Notation](https://brilliant.org/wiki/multi-index-notation/)  \n> - [Wikipedia: Multi-index](https://en.wikipedia.org/wiki/Multi-index)  \n\n---\n\n## Part 2: More on \\( D^s p(x) \\) and Multi-Index Notation\n\nIf \\( p(x) \\) is a function of multiple variables, say \\( p(x_1, x_2, \\dots, x_d) \\), then  \n\\[\ns = (s_1, s_2, \\dots, s_d)\n\\]  \ntells us **how many times** we differentiate with respect to each variable \\( x_i \\).  \n\nFor example, if \\( s = (2, 1, 0, \\dots, 0) \\), then  \n\\[\nD^s p(x) \\;=\\; \\frac{\\partial^3 p(x)}{\\partial x_1^2 \\,\\partial x_2^1}.\n\\]\n\n### Intuitive View\n- If \\(s_1 = 2\\), that means “take the second derivative with respect to \\(x_1\\)”.  \n- If \\(s_2 = 1\\), that means “take the first derivative with respect to \\(x_2\\)”.  \n- We multiply these partial derivatives together in the correct order.\n\nThis notation is just a concise way to keep track of all the derivatives in multiple dimensions.\n\n---\n\n## Part 3: Taylor Expansion (Taylor’s Theorem)\n\nA general **Taylor expansion** around a point \\( x \\) says that if \\(f\\) is sufficiently smooth, we can write:\n\n\\[\nf(x + h) \n\\;=\\;\nf(x) \\;+\\; \n\\sum_{k=1}^{m} \\frac{1}{k!} \\bigl( D^k f(x) \\bigr) (h,\\dots,h) \\;+\\; R_m,\n\\]\n\nwhere \\( R_m \\) is the remainder term, and \\( D^k f(x) \\) is the \\(k\\)-th derivative of \\(f\\). In multiple dimensions, we typically see it in terms of partial derivatives:\n\n\\[\nf(x + h) \\;\\approx\\; \nf(x) \n\\;+\\; \\nabla f(x) \\cdot h\n\\;+\\; \\frac{1}{2} h^\\top \\nabla^2 f(x) \\, h\n\\;+\\; \\dots\n\\]\n\nThis expansion is used **a lot** in analyzing the bias of estimators, numerical methods, and even in bounding differences between function values.\n\n> **Reference for Taylor expansions**:  \n> - [Wikipedia: Taylor's theorem](https://en.wikipedia.org/wiki/Taylor%27s_theorem)  \n> - [MathWorld: Taylor Series](https://mathworld.wolfram.com/TaylorSeries.html)  \n\n---\n\n## Part 4: Kernel Density Estimation (KDE)\n\nYou also mentioned **Kernel Density Estimation**. It’s a method to estimate an unknown probability density function \\( f(x) \\) from data. The estimator looks like:\n\n\\[\n\\hat{f}(x) \\;=\\; \\frac{1}{N h} \\;\\sum_{i=1}^{N} K\\Bigl(\\frac{x - X_i}{h}\\Bigr),\n\\]\n\nwhere\n- \\(K\\) is a **kernel function** (often something like a Gaussian, Epanechnikov, etc.),  \n- \\(h\\) is the **bandwidth** (a smoothing parameter).\n\n### 4.1 Kernel Function Properties\n\nA kernel \\(K\\) often satisfies:\n\n1. \\(\\int K(u)\\,du = 1\\).  \n2. \\(\\int u\\,K(u)\\,du = 0\\). (Centered around 0)  \n3. \\(\\int u^r K(u)\\,du = 0\\) for odd \\(r\\) if it’s symmetric, etc.\n\nAn example of a kernel is the **Epanechnikov kernel**:\n\n\\[\nG(x) \\;=\\; \\frac{3}{4}\\,\\bigl(1 - x^2\\bigr) \\, 1(\\lvert x \\rvert \\le 1),\n\\]\n\nwhere \\(1(\\lvert x \\rvert \\le 1)\\) is the indicator function that is 1 if \\(\\lvert x \\rvert \\le 1\\) and 0 otherwise. \n\n> **Reference for Kernel Density Estimation**:  \n> - [“Kernel Density Estimation Explained” on Towards Data Science](https://towardsdatascience.com/kernel-density-estimation-explained-52045f84c726)  \n> - [A Comprehensive Guide to KDE on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-kernel-density-estimation/)  \n\n---\n\n### 4.2 Bias of the KDE\n\nThe **bias** of an estimator \\(\\hat{f}(x)\\) is:\n\n\\[\n\\text{Bias}(\\hat{f}(x)) \\;=\\; \nE[\\hat{f}(x)] \\;-\\; f(x).\n\\]\n\nFor KDE, we often find that:\n\n\\[\nE[\\hat{f}(x)]\n\\;=\\; \n\\int K\\!\\Bigl(\\frac{x - t}{h}\\Bigr) p(t)\\, \\frac{dt}{h}.\n\\]\n\nBy doing a change of variable and performing a Taylor expansion of \\(p(\\cdot)\\), we eventually get:\n\n\\[\nE[\\hat{f}(x)]\n\\;=\\; \np(x) \n\\;+\\; \n\\frac{h^2}{2}\\,\\mu_2(K)\\,p''(x) \n\\;+\\; \nO(h^4),\n\\]\n\nwhere \\(\\mu_2(K)\\) is the second moment of the kernel. So the **leading term** of the bias is:\n\n\\[\n\\text{Bias}(\\hat{f}(x))\n\\;=\\;\n\\frac{h^2}{2}\\,\\mu_2(K)\\,p''(x)\n\\;+\\;\nO(h^4).\n\\]\n\nThis tells us that the bias grows (roughly) like \\(h^2\\). If \\(h\\) is too big, the bias is large (over-smoothing), but if \\(h\\) is too small, you get high variance (under-smoothing). That’s why **bandwidth selection** is super important.\n\n> **Reference for bias-variance in KDE**:  \n> - [Lecture notes on Kernel Density Estimation (CMU)](https://www.stat.cmu.edu/~cshalizi/402/lectures/08-kernel-density/kde.pdf)  \n\n\n## 02-28\nCold Diffusion\n\n\n## 03-10\n突然觉得自己悟了？？\nHow others put them together\nhttps://www.youtube.com/watch?v=B-d_3xX6ss4\n根据song yang的论文的时间线。\n1; sliced score model (定义了score based model)\n(https://proceedings.mlr.press/v115/song20a/song20a.pdf)\n\n2; annealed Langevin Dynamics\n(https://papers.neurips.cc/paper_files/paper/2019/hash/3001ef257407d5a371a96dcd947c7d93-Abstract.html)\nlangevin mcmc sample; https://zhuanlan.zhihu.com/p/797467112\nthe whole thing; https://yang-song.net/blog/2021/score/\n\n3; Score-based GM through SED (Song et al. ICLR 2021)\n(https://arxiv.org/pdf/2011.13456)\nSED 视角统一； \nsmld (ve) 和 ddpm (vp)\nsed和of-ode有一些对应关系\n\n4; EDM \n（https://proceedings.neurips.cc/paper_files/paper/2022/file/a98846e9d9cc01cfb87eb694d946ce6b-Paper-Conference.pdf）\npf-ode视角统一了diffusion 模型\n\n5; CM\n用了edm\n\n6; \n\n\n\n\n\n\n\n -->\n","slug":"2025-01-08-Generative-Models","published":1,"updated":"2025-04-02T23:58:14.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsy001tzc3dhzzyh7h3","content":"<!-- www\n## 01-08\n### Histogram \n### Kernel Method\nKernel Density Estimation (KDE) 是一种统计方法，用于估计一个随机变量的**连续的**概率密度函数（Probability Density Function, PDF）。\n\n直方图有个问题：\n\n- **它是离散的**：你只能看到固定的时间间隔，比如10:00-11:00，11:00-12:00。\n- **它依赖分箱（bin）大小**：不同的分箱方式会影响直方图的形状。\n\n**KDE 就是一种连续的分布估计方法**，它不依赖于分箱，而是用一个 **“平滑的曲线”** 来表示数据的分布。  \n你可以把 KDE 想象成：\n\n- 每个数据点都画一个 **小山丘（kernel）**。\n- 然后把这些小山丘 **叠加起来**，得到一个连续的曲线，代表数据的分布。\n\nKDE 的公式为：\n\\(\\hat{f}(x) = \\frac{1}{n h} \\sum_{i=1}^{n} K\\left(\\frac{x - x_i}{h}\\right)\\)\n\n**解释每个符号**：\n\n- **\\( \\hat{f}(x) \\)**：估计的概率密度函数。\n- **\\( n \\)**：样本数量。\n- **\\( h \\)**：平滑参数，称为 **带宽（bandwidth）**。它决定了小山丘的“宽度”。\n- **\\( K \\)**：**核函数（Kernel Function）**，决定了小山丘的形状。\n\n核函数是 KDE 的核心。常见的核函数有：\n\n1. **高斯核（Gaussian Kernel）**  \n   形状像正态分布的小山丘，最常用的核函数。\n\n   \\[\n   K(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n   \\]\n\n2. **箱形核（Box Kernel）**  \n   每个数据点生成一个“方形的小山丘”，边界清晰，但不平滑。\n\n3. **三角核（Triangle Kernel）**  \n   生成一个三角形的小山丘。\n\n带宽（Bandwidth）对 KDE 的影响**\n\n**带宽（h）** 是 KDE 中一个非常重要的参数。它决定了每个小山丘的 **宽度**，从而影响最终曲线的平滑程度。\n\n- **带宽小**：曲线更贴近数据，但容易出现“过拟合”。\n- **带宽大**：曲线更平滑，但可能会忽略一些细节。\n\n### Series Methods\nImagine you're trying to approximate a complex function \\( f(x) \\) by expressing it as a combination of simpler functions (called **basis functions**). This is like saying:\n\n\\[ f(x) = \\sum_{j=1}^{\\infty} \\beta_j \\phi_j(x) \\]\n\nWhere:\n- \\( \\phi_j(x) \\) are the **basis functions** (like sine, cosine, polynomials, etc.)\n- \\( \\beta_j \\) are the **coefficients** that tell us how much of each basis function to use.\n\n---\n\n### 🧩 **Orthogonal Basis**  \nThe basis functions \\( \\phi_j \\) are said to be **orthogonal** if they satisfy the condition:\n\n\\[ \\int \\phi_j(x) \\phi_k(x) dx = 0 \\quad \\text{for} \\quad j \\neq k \\]\n\nThink of orthogonal basis functions like directions that are at right angles to each other — they don't overlap in their effects.\n\n---\n\n### 📚 **Cosine Basis Example**\nThe notes give an example of using **cosine functions** as the basis:\n\n\\[ \\phi_j(x) = \\sqrt{2} \\cos(2\\pi j x) \\]\n\nThese functions oscillate and can capture periodic patterns in the data.\n\n---\n\n### 📈 **Wavelet Basis**\nThere's also a reference to **wavelet basis functions**, which are used to capture both **local** and **global** structures in the data.\n\n---\n\n### 🔍 **Key Formula for Density Estimation**  \nThe board shows that if we are estimating a **density function** \\( f \\), we can approximate it using the formula:\n\n\\[ \\hat{f}(x) = \\sum_{j=1}^{k} \\hat{\\beta}_j \\phi_j(x) \\]\n\nWhere:\n- \\( \\hat{\\beta}_j = \\frac{1}{n} \\sum_{i=1}^{n} \\phi_j(X_i) \\)  \n  (This is the estimated coefficient based on sample data \\( X_i \\).)\n\n---\n\n### 🧠 **Key Idea: Selecting the Right \\( k \\)**\nChoosing the right number of basis functions (\\( k \\)) is important. If \\( k \\) is too large, the model will **overfit** (too complicated). If \\( k \\) is too small, the model will **underfit** (too simple).\n\n\n\n\n## 01-15\n\n\n## Part 1: Risk Analysis\n\n### Background and Setup\n\nYou have \\( N \\) points \\( x_1, x_2, \\ldots, x_N \\in \\mathbb{R}^d \\). This means you have \\( N \\) data samples, each one is a \\( d \\)-dimensional vector. We assume these points lie in some space \\( X \\subset \\mathbb{R}^d \\), which is said to be a **compact set** (meaning it is closed and bounded in the mathematical sense).\n\n### Key Smoothness Assumption\n\nYou mentioned an assumption:\n\n\\[\nD^s p(x) - D^s p(y) \\;\\le\\; L \\,\\|x - y\\|\n\\]\n\n1. **\\( D^s p(x) \\)**:  \n   - This notation represents a high-order derivative (partial derivative) of a probability density function \\(p(x)\\).  \n   - The superscript \\( s \\) is a **multi-index**.  \n     - For instance, \\( s = (s_1, s_2, \\dots, s_d) \\).  \n     - Then \\( D^s p(x)\\) means we take the \\((s_1 + s_2 + \\cdots + s_d)\\)-th partial derivative of \\( p \\) with respect to each coordinate appropriately:\n       \\[\n       D^s p(x) \\;=\\; \\frac{\\partial^{\\,s_1 + s_2 + \\cdots + s_d} p(x)}{\\partial x_1^{s_1}\\,\\partial x_2^{s_2}\\,\\cdots\\,\\partial x_d^{s_d}}.\n       \\]\n\n2. **Interpretation of the inequality**:  \n   \\[\n   D^s p(x) - D^s p(y) \\;\\le\\; L\\, \\|x - y\\|.\n   \\]  \n   This says that **the change in the \\(s\\)-th derivative** between \\(x\\) and \\(y\\) is bounded by their distance times some constant \\(L\\). It suggests that \\(p(x)\\) is **smooth**—no wild jumps in its high-order derivatives. This is often used in probability density estimation and ensures continuity and differentiability in a controlled way.\n\n3. **Why Compactness Matters**:  \n   - If \\( X \\) is compact, it’s easier to control or bound various integrals and derivatives since \\( x \\) cannot go off to infinity.  \n   - This is important in risk analysis because it helps with bounding error terms and ensuring integrals converge.\n\n> **Reference for multi-index notation**:  \n> - [Brilliant.org: Multi-Index Notation](https://brilliant.org/wiki/multi-index-notation/)  \n> - [Wikipedia: Multi-index](https://en.wikipedia.org/wiki/Multi-index)  \n\n---\n\n## Part 2: More on \\( D^s p(x) \\) and Multi-Index Notation\n\nIf \\( p(x) \\) is a function of multiple variables, say \\( p(x_1, x_2, \\dots, x_d) \\), then  \n\\[\ns = (s_1, s_2, \\dots, s_d)\n\\]  \ntells us **how many times** we differentiate with respect to each variable \\( x_i \\).  \n\nFor example, if \\( s = (2, 1, 0, \\dots, 0) \\), then  \n\\[\nD^s p(x) \\;=\\; \\frac{\\partial^3 p(x)}{\\partial x_1^2 \\,\\partial x_2^1}.\n\\]\n\n### Intuitive View\n- If \\(s_1 = 2\\), that means “take the second derivative with respect to \\(x_1\\)”.  \n- If \\(s_2 = 1\\), that means “take the first derivative with respect to \\(x_2\\)”.  \n- We multiply these partial derivatives together in the correct order.\n\nThis notation is just a concise way to keep track of all the derivatives in multiple dimensions.\n\n---\n\n## Part 3: Taylor Expansion (Taylor’s Theorem)\n\nA general **Taylor expansion** around a point \\( x \\) says that if \\(f\\) is sufficiently smooth, we can write:\n\n\\[\nf(x + h) \n\\;=\\;\nf(x) \\;+\\; \n\\sum_{k=1}^{m} \\frac{1}{k!} \\bigl( D^k f(x) \\bigr) (h,\\dots,h) \\;+\\; R_m,\n\\]\n\nwhere \\( R_m \\) is the remainder term, and \\( D^k f(x) \\) is the \\(k\\)-th derivative of \\(f\\). In multiple dimensions, we typically see it in terms of partial derivatives:\n\n\\[\nf(x + h) \\;\\approx\\; \nf(x) \n\\;+\\; \\nabla f(x) \\cdot h\n\\;+\\; \\frac{1}{2} h^\\top \\nabla^2 f(x) \\, h\n\\;+\\; \\dots\n\\]\n\nThis expansion is used **a lot** in analyzing the bias of estimators, numerical methods, and even in bounding differences between function values.\n\n> **Reference for Taylor expansions**:  \n> - [Wikipedia: Taylor's theorem](https://en.wikipedia.org/wiki/Taylor%27s_theorem)  \n> - [MathWorld: Taylor Series](https://mathworld.wolfram.com/TaylorSeries.html)  \n\n---\n\n## Part 4: Kernel Density Estimation (KDE)\n\nYou also mentioned **Kernel Density Estimation**. It’s a method to estimate an unknown probability density function \\( f(x) \\) from data. The estimator looks like:\n\n\\[\n\\hat{f}(x) \\;=\\; \\frac{1}{N h} \\;\\sum_{i=1}^{N} K\\Bigl(\\frac{x - X_i}{h}\\Bigr),\n\\]\n\nwhere\n- \\(K\\) is a **kernel function** (often something like a Gaussian, Epanechnikov, etc.),  \n- \\(h\\) is the **bandwidth** (a smoothing parameter).\n\n### 4.1 Kernel Function Properties\n\nA kernel \\(K\\) often satisfies:\n\n1. \\(\\int K(u)\\,du = 1\\).  \n2. \\(\\int u\\,K(u)\\,du = 0\\). (Centered around 0)  \n3. \\(\\int u^r K(u)\\,du = 0\\) for odd \\(r\\) if it’s symmetric, etc.\n\nAn example of a kernel is the **Epanechnikov kernel**:\n\n\\[\nG(x) \\;=\\; \\frac{3}{4}\\,\\bigl(1 - x^2\\bigr) \\, 1(\\lvert x \\rvert \\le 1),\n\\]\n\nwhere \\(1(\\lvert x \\rvert \\le 1)\\) is the indicator function that is 1 if \\(\\lvert x \\rvert \\le 1\\) and 0 otherwise. \n\n> **Reference for Kernel Density Estimation**:  \n> - [“Kernel Density Estimation Explained” on Towards Data Science](https://towardsdatascience.com/kernel-density-estimation-explained-52045f84c726)  \n> - [A Comprehensive Guide to KDE on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-kernel-density-estimation/)  \n\n---\n\n### 4.2 Bias of the KDE\n\nThe **bias** of an estimator \\(\\hat{f}(x)\\) is:\n\n\\[\n\\text{Bias}(\\hat{f}(x)) \\;=\\; \nE[\\hat{f}(x)] \\;-\\; f(x).\n\\]\n\nFor KDE, we often find that:\n\n\\[\nE[\\hat{f}(x)]\n\\;=\\; \n\\int K\\!\\Bigl(\\frac{x - t}{h}\\Bigr) p(t)\\, \\frac{dt}{h}.\n\\]\n\nBy doing a change of variable and performing a Taylor expansion of \\(p(\\cdot)\\), we eventually get:\n\n\\[\nE[\\hat{f}(x)]\n\\;=\\; \np(x) \n\\;+\\; \n\\frac{h^2}{2}\\,\\mu_2(K)\\,p''(x) \n\\;+\\; \nO(h^4),\n\\]\n\nwhere \\(\\mu_2(K)\\) is the second moment of the kernel. So the **leading term** of the bias is:\n\n\\[\n\\text{Bias}(\\hat{f}(x))\n\\;=\\;\n\\frac{h^2}{2}\\,\\mu_2(K)\\,p''(x)\n\\;+\\;\nO(h^4).\n\\]\n\nThis tells us that the bias grows (roughly) like \\(h^2\\). If \\(h\\) is too big, the bias is large (over-smoothing), but if \\(h\\) is too small, you get high variance (under-smoothing). That’s why **bandwidth selection** is super important.\n\n> **Reference for bias-variance in KDE**:  \n> - [Lecture notes on Kernel Density Estimation (CMU)](https://www.stat.cmu.edu/~cshalizi/402/lectures/08-kernel-density/kde.pdf)  \n\n\n## 02-28\nCold Diffusion\n\n\n## 03-10\n突然觉得自己悟了？？\nHow others put them together\nhttps://www.youtube.com/watch?v=B-d_3xX6ss4\n根据song yang的论文的时间线。\n1; sliced score model (定义了score based model)\n(https://proceedings.mlr.press/v115/song20a/song20a.pdf)\n\n2; annealed Langevin Dynamics\n(https://papers.neurips.cc/paper_files/paper/2019/hash/3001ef257407d5a371a96dcd947c7d93-Abstract.html)\nlangevin mcmc sample; https://zhuanlan.zhihu.com/p/797467112\nthe whole thing; https://yang-song.net/blog/2021/score/\n\n3; Score-based GM through SED (Song et al. ICLR 2021)\n(https://arxiv.org/pdf/2011.13456)\nSED 视角统一； \nsmld (ve) 和 ddpm (vp)\nsed和of-ode有一些对应关系\n\n4; EDM \n（https://proceedings.neurips.cc/paper_files/paper/2022/file/a98846e9d9cc01cfb87eb694d946ce6b-Paper-Conference.pdf）\npf-ode视角统一了diffusion 模型\n\n5; CM\n用了edm\n\n6; \n\n\n\n\n\n\n\n -->\n","excerpt":"","more":"<!-- www\n## 01-08\n### Histogram \n### Kernel Method\nKernel Density Estimation (KDE) 是一种统计方法，用于估计一个随机变量的**连续的**概率密度函数（Probability Density Function, PDF）。\n\n直方图有个问题：\n\n- **它是离散的**：你只能看到固定的时间间隔，比如10:00-11:00，11:00-12:00。\n- **它依赖分箱（bin）大小**：不同的分箱方式会影响直方图的形状。\n\n**KDE 就是一种连续的分布估计方法**，它不依赖于分箱，而是用一个 **“平滑的曲线”** 来表示数据的分布。  \n你可以把 KDE 想象成：\n\n- 每个数据点都画一个 **小山丘（kernel）**。\n- 然后把这些小山丘 **叠加起来**，得到一个连续的曲线，代表数据的分布。\n\nKDE 的公式为：\n\\(\\hat{f}(x) = \\frac{1}{n h} \\sum_{i=1}^{n} K\\left(\\frac{x - x_i}{h}\\right)\\)\n\n**解释每个符号**：\n\n- **\\( \\hat{f}(x) \\)**：估计的概率密度函数。\n- **\\( n \\)**：样本数量。\n- **\\( h \\)**：平滑参数，称为 **带宽（bandwidth）**。它决定了小山丘的“宽度”。\n- **\\( K \\)**：**核函数（Kernel Function）**，决定了小山丘的形状。\n\n核函数是 KDE 的核心。常见的核函数有：\n\n1. **高斯核（Gaussian Kernel）**  \n   形状像正态分布的小山丘，最常用的核函数。\n\n   \\[\n   K(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n   \\]\n\n2. **箱形核（Box Kernel）**  \n   每个数据点生成一个“方形的小山丘”，边界清晰，但不平滑。\n\n3. **三角核（Triangle Kernel）**  \n   生成一个三角形的小山丘。\n\n带宽（Bandwidth）对 KDE 的影响**\n\n**带宽（h）** 是 KDE 中一个非常重要的参数。它决定了每个小山丘的 **宽度**，从而影响最终曲线的平滑程度。\n\n- **带宽小**：曲线更贴近数据，但容易出现“过拟合”。\n- **带宽大**：曲线更平滑，但可能会忽略一些细节。\n\n### Series Methods\nImagine you're trying to approximate a complex function \\( f(x) \\) by expressing it as a combination of simpler functions (called **basis functions**). This is like saying:\n\n\\[ f(x) = \\sum_{j=1}^{\\infty} \\beta_j \\phi_j(x) \\]\n\nWhere:\n- \\( \\phi_j(x) \\) are the **basis functions** (like sine, cosine, polynomials, etc.)\n- \\( \\beta_j \\) are the **coefficients** that tell us how much of each basis function to use.\n\n---\n\n### 🧩 **Orthogonal Basis**  \nThe basis functions \\( \\phi_j \\) are said to be **orthogonal** if they satisfy the condition:\n\n\\[ \\int \\phi_j(x) \\phi_k(x) dx = 0 \\quad \\text{for} \\quad j \\neq k \\]\n\nThink of orthogonal basis functions like directions that are at right angles to each other — they don't overlap in their effects.\n\n---\n\n### 📚 **Cosine Basis Example**\nThe notes give an example of using **cosine functions** as the basis:\n\n\\[ \\phi_j(x) = \\sqrt{2} \\cos(2\\pi j x) \\]\n\nThese functions oscillate and can capture periodic patterns in the data.\n\n---\n\n### 📈 **Wavelet Basis**\nThere's also a reference to **wavelet basis functions**, which are used to capture both **local** and **global** structures in the data.\n\n---\n\n### 🔍 **Key Formula for Density Estimation**  \nThe board shows that if we are estimating a **density function** \\( f \\), we can approximate it using the formula:\n\n\\[ \\hat{f}(x) = \\sum_{j=1}^{k} \\hat{\\beta}_j \\phi_j(x) \\]\n\nWhere:\n- \\( \\hat{\\beta}_j = \\frac{1}{n} \\sum_{i=1}^{n} \\phi_j(X_i) \\)  \n  (This is the estimated coefficient based on sample data \\( X_i \\).)\n\n---\n\n### 🧠 **Key Idea: Selecting the Right \\( k \\)**\nChoosing the right number of basis functions (\\( k \\)) is important. If \\( k \\) is too large, the model will **overfit** (too complicated). If \\( k \\) is too small, the model will **underfit** (too simple).\n\n\n\n\n## 01-15\n\n\n## Part 1: Risk Analysis\n\n### Background and Setup\n\nYou have \\( N \\) points \\( x_1, x_2, \\ldots, x_N \\in \\mathbb{R}^d \\). This means you have \\( N \\) data samples, each one is a \\( d \\)-dimensional vector. We assume these points lie in some space \\( X \\subset \\mathbb{R}^d \\), which is said to be a **compact set** (meaning it is closed and bounded in the mathematical sense).\n\n### Key Smoothness Assumption\n\nYou mentioned an assumption:\n\n\\[\nD^s p(x) - D^s p(y) \\;\\le\\; L \\,\\|x - y\\|\n\\]\n\n1. **\\( D^s p(x) \\)**:  \n   - This notation represents a high-order derivative (partial derivative) of a probability density function \\(p(x)\\).  \n   - The superscript \\( s \\) is a **multi-index**.  \n     - For instance, \\( s = (s_1, s_2, \\dots, s_d) \\).  \n     - Then \\( D^s p(x)\\) means we take the \\((s_1 + s_2 + \\cdots + s_d)\\)-th partial derivative of \\( p \\) with respect to each coordinate appropriately:\n       \\[\n       D^s p(x) \\;=\\; \\frac{\\partial^{\\,s_1 + s_2 + \\cdots + s_d} p(x)}{\\partial x_1^{s_1}\\,\\partial x_2^{s_2}\\,\\cdots\\,\\partial x_d^{s_d}}.\n       \\]\n\n2. **Interpretation of the inequality**:  \n   \\[\n   D^s p(x) - D^s p(y) \\;\\le\\; L\\, \\|x - y\\|.\n   \\]  \n   This says that **the change in the \\(s\\)-th derivative** between \\(x\\) and \\(y\\) is bounded by their distance times some constant \\(L\\). It suggests that \\(p(x)\\) is **smooth**—no wild jumps in its high-order derivatives. This is often used in probability density estimation and ensures continuity and differentiability in a controlled way.\n\n3. **Why Compactness Matters**:  \n   - If \\( X \\) is compact, it’s easier to control or bound various integrals and derivatives since \\( x \\) cannot go off to infinity.  \n   - This is important in risk analysis because it helps with bounding error terms and ensuring integrals converge.\n\n> **Reference for multi-index notation**:  \n> - [Brilliant.org: Multi-Index Notation](https://brilliant.org/wiki/multi-index-notation/)  \n> - [Wikipedia: Multi-index](https://en.wikipedia.org/wiki/Multi-index)  \n\n---\n\n## Part 2: More on \\( D^s p(x) \\) and Multi-Index Notation\n\nIf \\( p(x) \\) is a function of multiple variables, say \\( p(x_1, x_2, \\dots, x_d) \\), then  \n\\[\ns = (s_1, s_2, \\dots, s_d)\n\\]  \ntells us **how many times** we differentiate with respect to each variable \\( x_i \\).  \n\nFor example, if \\( s = (2, 1, 0, \\dots, 0) \\), then  \n\\[\nD^s p(x) \\;=\\; \\frac{\\partial^3 p(x)}{\\partial x_1^2 \\,\\partial x_2^1}.\n\\]\n\n### Intuitive View\n- If \\(s_1 = 2\\), that means “take the second derivative with respect to \\(x_1\\)”.  \n- If \\(s_2 = 1\\), that means “take the first derivative with respect to \\(x_2\\)”.  \n- We multiply these partial derivatives together in the correct order.\n\nThis notation is just a concise way to keep track of all the derivatives in multiple dimensions.\n\n---\n\n## Part 3: Taylor Expansion (Taylor’s Theorem)\n\nA general **Taylor expansion** around a point \\( x \\) says that if \\(f\\) is sufficiently smooth, we can write:\n\n\\[\nf(x + h) \n\\;=\\;\nf(x) \\;+\\; \n\\sum_{k=1}^{m} \\frac{1}{k!} \\bigl( D^k f(x) \\bigr) (h,\\dots,h) \\;+\\; R_m,\n\\]\n\nwhere \\( R_m \\) is the remainder term, and \\( D^k f(x) \\) is the \\(k\\)-th derivative of \\(f\\). In multiple dimensions, we typically see it in terms of partial derivatives:\n\n\\[\nf(x + h) \\;\\approx\\; \nf(x) \n\\;+\\; \\nabla f(x) \\cdot h\n\\;+\\; \\frac{1}{2} h^\\top \\nabla^2 f(x) \\, h\n\\;+\\; \\dots\n\\]\n\nThis expansion is used **a lot** in analyzing the bias of estimators, numerical methods, and even in bounding differences between function values.\n\n> **Reference for Taylor expansions**:  \n> - [Wikipedia: Taylor's theorem](https://en.wikipedia.org/wiki/Taylor%27s_theorem)  \n> - [MathWorld: Taylor Series](https://mathworld.wolfram.com/TaylorSeries.html)  \n\n---\n\n## Part 4: Kernel Density Estimation (KDE)\n\nYou also mentioned **Kernel Density Estimation**. It’s a method to estimate an unknown probability density function \\( f(x) \\) from data. The estimator looks like:\n\n\\[\n\\hat{f}(x) \\;=\\; \\frac{1}{N h} \\;\\sum_{i=1}^{N} K\\Bigl(\\frac{x - X_i}{h}\\Bigr),\n\\]\n\nwhere\n- \\(K\\) is a **kernel function** (often something like a Gaussian, Epanechnikov, etc.),  \n- \\(h\\) is the **bandwidth** (a smoothing parameter).\n\n### 4.1 Kernel Function Properties\n\nA kernel \\(K\\) often satisfies:\n\n1. \\(\\int K(u)\\,du = 1\\).  \n2. \\(\\int u\\,K(u)\\,du = 0\\). (Centered around 0)  \n3. \\(\\int u^r K(u)\\,du = 0\\) for odd \\(r\\) if it’s symmetric, etc.\n\nAn example of a kernel is the **Epanechnikov kernel**:\n\n\\[\nG(x) \\;=\\; \\frac{3}{4}\\,\\bigl(1 - x^2\\bigr) \\, 1(\\lvert x \\rvert \\le 1),\n\\]\n\nwhere \\(1(\\lvert x \\rvert \\le 1)\\) is the indicator function that is 1 if \\(\\lvert x \\rvert \\le 1\\) and 0 otherwise. \n\n> **Reference for Kernel Density Estimation**:  \n> - [“Kernel Density Estimation Explained” on Towards Data Science](https://towardsdatascience.com/kernel-density-estimation-explained-52045f84c726)  \n> - [A Comprehensive Guide to KDE on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-kernel-density-estimation/)  \n\n---\n\n### 4.2 Bias of the KDE\n\nThe **bias** of an estimator \\(\\hat{f}(x)\\) is:\n\n\\[\n\\text{Bias}(\\hat{f}(x)) \\;=\\; \nE[\\hat{f}(x)] \\;-\\; f(x).\n\\]\n\nFor KDE, we often find that:\n\n\\[\nE[\\hat{f}(x)]\n\\;=\\; \n\\int K\\!\\Bigl(\\frac{x - t}{h}\\Bigr) p(t)\\, \\frac{dt}{h}.\n\\]\n\nBy doing a change of variable and performing a Taylor expansion of \\(p(\\cdot)\\), we eventually get:\n\n\\[\nE[\\hat{f}(x)]\n\\;=\\; \np(x) \n\\;+\\; \n\\frac{h^2}{2}\\,\\mu_2(K)\\,p''(x) \n\\;+\\; \nO(h^4),\n\\]\n\nwhere \\(\\mu_2(K)\\) is the second moment of the kernel. So the **leading term** of the bias is:\n\n\\[\n\\text{Bias}(\\hat{f}(x))\n\\;=\\;\n\\frac{h^2}{2}\\,\\mu_2(K)\\,p''(x)\n\\;+\\;\nO(h^4).\n\\]\n\nThis tells us that the bias grows (roughly) like \\(h^2\\). If \\(h\\) is too big, the bias is large (over-smoothing), but if \\(h\\) is too small, you get high variance (under-smoothing). That’s why **bandwidth selection** is super important.\n\n> **Reference for bias-variance in KDE**:  \n> - [Lecture notes on Kernel Density Estimation (CMU)](https://www.stat.cmu.edu/~cshalizi/402/lectures/08-kernel-density/kde.pdf)  \n\n\n## 02-28\nCold Diffusion\n\n\n## 03-10\n突然觉得自己悟了？？\nHow others put them together\nhttps://www.youtube.com/watch?v=B-d_3xX6ss4\n根据song yang的论文的时间线。\n1; sliced score model (定义了score based model)\n(https://proceedings.mlr.press/v115/song20a/song20a.pdf)\n\n2; annealed Langevin Dynamics\n(https://papers.neurips.cc/paper_files/paper/2019/hash/3001ef257407d5a371a96dcd947c7d93-Abstract.html)\nlangevin mcmc sample; https://zhuanlan.zhihu.com/p/797467112\nthe whole thing; https://yang-song.net/blog/2021/score/\n\n3; Score-based GM through SED (Song et al. ICLR 2021)\n(https://arxiv.org/pdf/2011.13456)\nSED 视角统一； \nsmld (ve) 和 ddpm (vp)\nsed和of-ode有一些对应关系\n\n4; EDM \n（https://proceedings.neurips.cc/paper_files/paper/2022/file/a98846e9d9cc01cfb87eb694d946ce6b-Paper-Conference.pdf）\npf-ode视角统一了diffusion 模型\n\n5; CM\n用了edm\n\n6; \n\n\n\n\n\n\n\n -->\n"},{"title":"2025-01-09-Casual-Course","date":"2025-01-08T15:03:21.000Z","_content":"www\n## 01-08\nAssignments (20%) 2-3人\nPaper review (15%) 单人\nPre (20%) 3\n\n### data analysis\n### Casual Inference\n\nIntervention\n\nATE Average Treatment Effect\n$T\\rightarrow Y$\n$ATE = \\mathbb{E}[Y(t=1) - Y(t=0)] = \\mathbb{E}[Y(1) - Y(0)]$\nonly one of Y(1) or Y(0) is observed (Random)\n\n$T\\perp Y(1), Y(0)$ T: treatment assignment\n$ATE = \\mathbb{E}[Y(1)] -\\mathbb{E}[Y(0)]$\n$= \\mathbb{E}[Y(1) | T=1] - \\mathbb{E}[Y(0) | T=0]$\n\nProblem: randomized data samples, \n\nDO operator\nDAG: Directed Acyclic Graph\n\nBayesian network\npr(X|nodes) = pr (X| parents of X)\n\nSlides 34 啥意思啊 Reduce casual relationship as do op, to observe conditional probabilityies\n\n### \n## 01-15\n$P_m$ manipulated proability\n\naverage casual effect\ncasual effect difference:$P(Y=1|do(X=1))-P(Y=1|do(X=0))$\n\n## 01-29\nEqualized odds\nprediction parity\n\n## 02-03\n### Counterfactual \n1. Abduction\n2.\n3. \n\n\n### Fair\nDiscrimination as a casual term\n\n\n弃坑了弃坑了，上了一半抑郁了再也没有在早上10点起床过\n","source":"_posts/2025-01-09-Casual-Course.md","raw":"---\ntitle: 2025-01-09-Casual-Course\ndate: 2025-01-08 10:03:21\ntags:\n---\nwww\n## 01-08\nAssignments (20%) 2-3人\nPaper review (15%) 单人\nPre (20%) 3\n\n### data analysis\n### Casual Inference\n\nIntervention\n\nATE Average Treatment Effect\n$T\\rightarrow Y$\n$ATE = \\mathbb{E}[Y(t=1) - Y(t=0)] = \\mathbb{E}[Y(1) - Y(0)]$\nonly one of Y(1) or Y(0) is observed (Random)\n\n$T\\perp Y(1), Y(0)$ T: treatment assignment\n$ATE = \\mathbb{E}[Y(1)] -\\mathbb{E}[Y(0)]$\n$= \\mathbb{E}[Y(1) | T=1] - \\mathbb{E}[Y(0) | T=0]$\n\nProblem: randomized data samples, \n\nDO operator\nDAG: Directed Acyclic Graph\n\nBayesian network\npr(X|nodes) = pr (X| parents of X)\n\nSlides 34 啥意思啊 Reduce casual relationship as do op, to observe conditional probabilityies\n\n### \n## 01-15\n$P_m$ manipulated proability\n\naverage casual effect\ncasual effect difference:$P(Y=1|do(X=1))-P(Y=1|do(X=0))$\n\n## 01-29\nEqualized odds\nprediction parity\n\n## 02-03\n### Counterfactual \n1. Abduction\n2.\n3. \n\n\n### Fair\nDiscrimination as a casual term\n\n\n弃坑了弃坑了，上了一半抑郁了再也没有在早上10点起床过\n","slug":"2025-01-09-Casual-Course","published":1,"updated":"2025-04-02T23:55:56.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsy001uzc3dgdl9aa7t","content":"<p>www</p>\n<h2 id=\"01-08\"><a href=\"#01-08\" class=\"headerlink\" title=\"01-08\"></a>01-08</h2><p>Assignments (20%) 2-3人<br>Paper review (15%) 单人<br>Pre (20%) 3</p>\n<h3 id=\"data-analysis\"><a href=\"#data-analysis\" class=\"headerlink\" title=\"data analysis\"></a>data analysis</h3><h3 id=\"Casual-Inference\"><a href=\"#Casual-Inference\" class=\"headerlink\" title=\"Casual Inference\"></a>Casual Inference</h3><p>Intervention</p>\n<p>ATE Average Treatment Effect<br>$T\\rightarrow Y$<br>$ATE &#x3D; \\mathbb{E}[Y(t&#x3D;1) - Y(t&#x3D;0)] &#x3D; \\mathbb{E}[Y(1) - Y(0)]$<br>only one of Y(1) or Y(0) is observed (Random)</p>\n<p>$T\\perp Y(1), Y(0)$ T: treatment assignment<br>$ATE &#x3D; \\mathbb{E}[Y(1)] -\\mathbb{E}[Y(0)]$<br>$&#x3D; \\mathbb{E}[Y(1) | T&#x3D;1] - \\mathbb{E}[Y(0) | T&#x3D;0]$</p>\n<p>Problem: randomized data samples, </p>\n<p>DO operator<br>DAG: Directed Acyclic Graph</p>\n<p>Bayesian network<br>pr(X|nodes) &#x3D; pr (X| parents of X)</p>\n<p>Slides 34 啥意思啊 Reduce casual relationship as do op, to observe conditional probabilityies</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"01-15\"><a href=\"#01-15\" class=\"headerlink\" title=\"01-15\"></a>01-15</h2><p>$P_m$ manipulated proability</p>\n<p>average casual effect<br>casual effect difference:$P(Y&#x3D;1|do(X&#x3D;1))-P(Y&#x3D;1|do(X&#x3D;0))$</p>\n<h2 id=\"01-29\"><a href=\"#01-29\" class=\"headerlink\" title=\"01-29\"></a>01-29</h2><p>Equalized odds<br>prediction parity</p>\n<h2 id=\"02-03\"><a href=\"#02-03\" class=\"headerlink\" title=\"02-03\"></a>02-03</h2><h3 id=\"Counterfactual\"><a href=\"#Counterfactual\" class=\"headerlink\" title=\"Counterfactual\"></a>Counterfactual</h3><ol>\n<li>Abduction</li>\n<li></li>\n<li></li>\n</ol>\n<h3 id=\"Fair\"><a href=\"#Fair\" class=\"headerlink\" title=\"Fair\"></a>Fair</h3><p>Discrimination as a casual term</p>\n<p>弃坑了弃坑了，上了一半抑郁了再也没有在早上10点起床过</p>\n","excerpt":"","more":"<p>www</p>\n<h2 id=\"01-08\"><a href=\"#01-08\" class=\"headerlink\" title=\"01-08\"></a>01-08</h2><p>Assignments (20%) 2-3人<br>Paper review (15%) 单人<br>Pre (20%) 3</p>\n<h3 id=\"data-analysis\"><a href=\"#data-analysis\" class=\"headerlink\" title=\"data analysis\"></a>data analysis</h3><h3 id=\"Casual-Inference\"><a href=\"#Casual-Inference\" class=\"headerlink\" title=\"Casual Inference\"></a>Casual Inference</h3><p>Intervention</p>\n<p>ATE Average Treatment Effect<br>$T\\rightarrow Y$<br>$ATE &#x3D; \\mathbb{E}[Y(t&#x3D;1) - Y(t&#x3D;0)] &#x3D; \\mathbb{E}[Y(1) - Y(0)]$<br>only one of Y(1) or Y(0) is observed (Random)</p>\n<p>$T\\perp Y(1), Y(0)$ T: treatment assignment<br>$ATE &#x3D; \\mathbb{E}[Y(1)] -\\mathbb{E}[Y(0)]$<br>$&#x3D; \\mathbb{E}[Y(1) | T&#x3D;1] - \\mathbb{E}[Y(0) | T&#x3D;0]$</p>\n<p>Problem: randomized data samples, </p>\n<p>DO operator<br>DAG: Directed Acyclic Graph</p>\n<p>Bayesian network<br>pr(X|nodes) &#x3D; pr (X| parents of X)</p>\n<p>Slides 34 啥意思啊 Reduce casual relationship as do op, to observe conditional probabilityies</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h2 id=\"01-15\"><a href=\"#01-15\" class=\"headerlink\" title=\"01-15\"></a>01-15</h2><p>$P_m$ manipulated proability</p>\n<p>average casual effect<br>casual effect difference:$P(Y&#x3D;1|do(X&#x3D;1))-P(Y&#x3D;1|do(X&#x3D;0))$</p>\n<h2 id=\"01-29\"><a href=\"#01-29\" class=\"headerlink\" title=\"01-29\"></a>01-29</h2><p>Equalized odds<br>prediction parity</p>\n<h2 id=\"02-03\"><a href=\"#02-03\" class=\"headerlink\" title=\"02-03\"></a>02-03</h2><h3 id=\"Counterfactual\"><a href=\"#Counterfactual\" class=\"headerlink\" title=\"Counterfactual\"></a>Counterfactual</h3><ol>\n<li>Abduction</li>\n<li></li>\n<li></li>\n</ol>\n<h3 id=\"Fair\"><a href=\"#Fair\" class=\"headerlink\" title=\"Fair\"></a>Fair</h3><p>Discrimination as a casual term</p>\n<p>弃坑了弃坑了，上了一半抑郁了再也没有在早上10点起床过</p>\n"},{"title":"LHY ML","date":"2024-03-08T15:36:24.000Z","_content":"\nhttps://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php\n\n## 2/18\n\n### Video 2\nPiecewise Linear\n\n$y = c * Sigmoid(b+wx_1)$, w, b, c,\n\n$\\theta$: A vector of all unknown variable\\\nGradient $ g =\\nabla L(\\theta^{0}) $\\\n$\\eta$: learning rate\\\nBatch, update, Epoch\n\nActivation function:\\\nSigmoid function  \nRectified Linear Unit (ReLU) max(0, )\n\n### Pytorch 1/2 \nMainly introduce some practical advice for coding. \n\n### Background propagation\nBack Propagation: an efficient way to calculate Gradient Descent:\\\nforward pass, backward pass\n\n没太懂\n\n### Predicting Pokémon CP\nRegression: difference in origin $x_{cp}$, and species\\\nGradient descent\\\nOverfitting Regularization\n\n### Pokemon classification\n#### Maximum Likelihood\n2-D Gaussian distribution:\\\n$f_{\\mu^1,\\Sigma^1}(x) = \\frac{1}{(2\\pi)^{D/2}|\\Sigma^1|^{1/2}} \\exp\\left(-\\frac{1}{2}(x - \\mu^1)^T(\\Sigma^1)^{-1}(x - \\mu^1)\\right)$\n\n$\\mu$ mean $\\sum$ covariance\\\n$\\mu^1 = \\begin{bmatrix}\n75.0 \\\\\n71.3 \\\\\n\\end{bmatrix}\n\\quad\n\\Sigma^1 = \\begin{bmatrix}\n874 & 327 \\\\\n327 & 929 \\\\\n\\end{bmatrix}$\n\n$P(C_1|x) = \\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1) + P(x|C_2)P(C_2)}$\n\nSimplify the function, substitute Gaussian into probability\\\n$P(C_1|x)=\\sigma(z) = \\sigma(wx+b)$\\\n$w=(\\mu^1-\\mu^2)^T\\sum^{-1}, b=...(scalar)$\\\nSo the Boundary for shared $\\sum$ is linear.\n\n### Logistic Regression \n（数学推导比较多）\n#### Loss function\nCross Entropy for a Bernoulli distribution  \n$H(p,q)=−[p\\log(q)+(1−p)\\log(1−q)]$\\\nwhich is better than Square Error. \n\nDiscriminative: Logistic Regression: Directly find $w$ and $b$, which generally have better performance  \nGenerative: Gaussian description: Have assumptions (Naive Bayes, or ...) of model and find $\\mu^1$, $\\mu^2$, $\\sum$ \n\n#### Multiclass Classification\n跳过了，想做hw再听，觉得现在对$f_{w, b}(x)$的理解还不深\n\n## 2/25\n\n### Video 1\nLoss on training data large: Model Bias (need a more complex model) or Optimization\\\nLoss on testing data large: Overfitting or mismatch -> more data \n\n### Video 2\nHow to Optimize:\\\n$\nL(\\theta) \\approx L(\\theta') + (\\theta - \\theta')^T \\vec{g} + \\frac{1}{2} (\\theta - \\theta')^T H (\\theta - \\theta')\n$  \nGradient $\\vec{g}$:  \n$\\vec{g} = \\nabla L(\\theta')$  \n$g_i = \\frac{\\partial L(\\theta')}{\\partial \\theta_i}$  \n$\\vec{g} =\n\\begin{bmatrix}\n\\frac{\\partial L}{\\partial \\theta_1} \\\\\n\\frac{\\partial L}{\\partial \\theta_2} \\\\\n\\vdots \\\\\n\\frac{\\partial L}{\\partial \\theta_n}\n\\end{bmatrix}$  \nHessian $H$ is a matrix $H_{ij} = \\frac{\\partial^2 L(\\theta')}{\\partial \\theta_i \\partial \\theta_j}$  \nFor all $v$:\n1. $v^T Hv > 0$: $H$ is positive definite, $L(\\theta) > L(\\theta')$: Local minima\n2. $v^T Hv < 0$: $H$ is negative definite, $L(\\theta) < L(\\theta')$: Local maxima\n3. Some eigenvalues are $+$, some are $-$: Saddle point  \nEmpirical learning: \n\n### Video 3\nBatch: large batch $N$ not necessarily need longer time for gradient computing (parallel computing)\n\n### Video 4\nAdaptive $\\eta$ (learning rate):\\\nError surface  \nCritical points (local minima, saddle point):\n1. Adagrad \n2. RMSProp\n3. Adam: RMSProp + Momentum\n\nLearning Rate Scheduling:  \nLearning rate Decay  \nWarm up (Residual Network, Transformer Classification)\n\n### Video 5\nRegression:  \nRight answer: $\\hat{y} \\leftrightarrow y$  \nClassification: class: one-hot vector: $\\hat{y} \\leftrightarrow y' = \\text{softmax}(y)$  \nSoft-max (Normalize): $n \\geq 3$: $y_i' = \\frac{\\exp(y_i)}{\\sum_j \\exp(y_j)}$  \n$n=2$ $y' = \\text{sigmoid}(y)$\n\nDistance $e$:  \nMean Square Error (MSE): $e = \\sum (\\hat{y_i} - y_i')^2$  \nCross-entropy: $e = -\\sum \\hat{y_i} \\ln y_i'$  \nMinimize Cross-entropy $\\leftrightarrow$ Maximize likelihood\n\n### Basic Theory\nWe want $L(h_{\\text{train}}, D_{\\text{all}}) - L(h_{\\text{all}}, D_{\\text{all}}) \\leq \\delta$\\\n$\\forall h \\in \\mathcal{H}, |L(h, D_{\\text{train}}) - L(h, D_{\\text{all}})| \\leq \\frac{\\delta}{2}$\n\n### Gradient Descent \n\n### Beyond Adam 1\n\n### Beyond Adam 2\n\n## 3/04 CNN\n\n### Video\nImage as input\n\n#### V1\nTensor: a Matrix >= 3 dimensional  \n1. Observation 1:  \nReceptive Field: Kernel Size (3x3), Stride (1 or 2, padding 0, hope receptive field are intersecting)  \n2. Observation 2  \nShared parameters: filter  \n1 + 2 -> Convolution Layer -> CNN (designed for image)\n\n#### V2\nEach filter detects a small pattern (3 * 3 * channel_num, which is a tensor)  \nFeature Map  \n3. Observation 3  \nMax Pooling: Operator  \nConvolutional Layer + Pooling  \n\n### Spatial Transformer Layer\nCNN is not invariant to scaling and rotation \nInterpolation.\n\n## 3/11 Self-attention\n\n### Video 1\nSequence Labeling  \nSelf-Attention: dot product additive \n\n### Video 2\nSelf-attention  \nMultihead self-attention  \nTruncated self-attention  \nCNN is a simplified self-attention (limited to receptive field)  \nRNN, GNN (Graph Neural Network)\n\n### GNN 1\nConvolution (spatial-based/Spectral-based)\n\n#### Spatial-based\nTerminology:  \nAggregate: use neighbor features to update the next hidden state  \nReadout: use all nodes' features to represent the whole graph  \nNN4G  \nDCNN  \nGAT (Graph Attention Network)  \nGraph Isomorphism Network\n\n### GNN 2\nDeep Graph Library\n\n#### Graph Signal Processing \nGraph Laplacian:  \nDegree Matrix $D$, Adjacency Matrix: $A$, $L$ is an operation on graph  \n$L = D - A = U \\Lambda U^T$  \nDiscrete time Fourier basis $\\lambda$ wave length  \n$(Lf)(v_i) = \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))$  \n$\\begin{aligned}\nf^T L f &= \\sum_{v_i \\in V} f(v_i) \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))\\\\\n&= \\frac{1}{2} \\sum_{v_i \\in V} \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))^2\n\\end{aligned}\n$\n\nGraph Fourier Transform of signal $\\hat{x}$: $\\hat{x} = U ^T x, \\hat{x}_i = u_i \\cdot x$  \nInverse Graph Fourier Transform of signal $\\hat{x}$: $x = U ^T \\hat{x}$\n\nFiltering: Convolution in time domain is multiplication in frequency domain\n\nChebNet  \n听不懂在干什么\n\n#### Spectral-based\n\n## 3/18\n\n### Video 1 Batch Normalization\nBatch Normalization  \nInternal Covariate Shift\n\n### Video 2 Seq2seq\nTransformer  \nSeq2seq:  \nChatbox,  \nNLP\n\n## Video 3 Decoder\nAutoregressive  \nMasked Self-attention\n\n## NAT Non autoregressive translation\n像一个NAT发展的论文综述  \nNaive approach,  \nautoregressive,  \nGAN, \n\nImprovement\n1. Fertility\n2. Sequence-level knowledge distillation\n3. Noisy Parallel Decoding NPD\n\nVanilla NAT, Iterative Refinement, Insertion-based, Insertion+Deletion, CTC-based, Masked-predict, Kermit, CTC, LAS, Imputer (CTC+Mask-Predict)\n\n## Pointer Network\n\n## 3/25\n\n### Video 1 GAN\nDiscriminator\n\n### Video 2 GAN\nJS Divergence\\\n$G^*= \\arg \\min(G) \\max(D) \\mathcal{V}(G, D)$\n![alt text](LHY-ML/image-1.png)\n$JS(P \\parallel Q) = \\frac{1}{2} KL(P \\parallel M) + \\frac{1}{2} KL(Q \\parallel M)$\\\n$KL(P \\parallel Q) = \\sum_{x} P(x) \\log\\left(\\frac{P(x)}{Q(x)}\\right)$\n\nWGAN\\ \nWasserstein distance: improve JS divergence: $JS(P_G, P_{\\text{data}}) \\rightarrow W(P_G, P_{\\text{data}})$\\\n$\\max_{D \\in 1-\\text{Lipschitz}} \\left\\{ \\mathbb{E}_{x \\sim P_{\\text{data}}} [D(x)] - \\mathbb{E}_{x \\sim P_{G}} [D(x)] \\right\\}$\\\nthe $D(x)$ should be smooth enough\n\n### Video 3 BERT anecdote\nCBOW (2 transforms): word embedding\\\ncontextualized word embedding\\\nMulti BERT: Zero-shot Reading Comprehension, alignment\n\n### Video 4 Cycle GAN\nCycle/Dual/Disco GAN: $G_{x\\rightarrow y}$, $G_{y\\rightarrow x}$\n\n### The theory of GAN (1)\n$\\max_{D} \\mathcal{V}(G, D)$ maximize the discriminator D in GAN  \n\n$\\mathcal{V}(G, D) = \\mathbb{E}_{x \\sim P_{\\text{data}}} [\\log D(x)] + \\mathbb{E}_{x \\sim P_{G}} [\\log(1 - D(x))]$  \n$\\mathcal{V}(G, D) = \\int_{x} P_{\\text{data}}(x)\\log D(x) \\, dx + \\int_{x} P_{G}(x)\\log(1 - D(x)) \\, dx$\n\n$\\mathcal{V}(G, D) = P_{\\text{data}}(x)\\log D(x) + P_{G}(x)\\log(1 - D(x))$ \n\n$D^*(x) = \\frac{P_{\\text{data}}(x)}{P_{\\text{data}}(x) + P_{G}(x)}$\n\n## 4/01\n\n### Video 1 \nSelf-supervised Learning\n\n### Video 2 BERT intro\nMasking Input: Mask  \nNext Sentence Prediction: [CLS] sentence 1. [SEP] sentence 2.\\\nPre-trained Fine-tune for Downstream Tasks:\\\nGLUE: General Language Understanding Evaluation\\\nin seq, out class: sentiment analysis\\\nin seq ((n)), out seq (n): POG tagging\\\nin 2 seqs, out class: NLI Natural language inference\\\nin seqs, out seqs: QA Extract-based Question Answer\n\nMASS\\ BART T5, C4 (open sourced resource)\n\n### Video 3 BERT anecdote\nSame with above\n\n### Video 4 GPT outlook\nLinear Transform -> Softmax -> distribution  \nFew-shot learning, one-shot, zero-shot learning  \nSimCLR, BYOL,  \nSpeech GLUE - SUPERB\n\n## 4/15\n????\n\n## 4/22\nAuto encoder\n\n### Video 1 basic idea\nsame idea with Cycle GAN, embedding, representation, code  \nDimension reduction: not deep learning based PCA, t-SNE  \nDe-noising Auto-encoder\n\nVideo 2-8 are all anomaly detection\n\n### Video 2  \nFeature disentanglement: know the content of embedding: Voice Conversion  \nDiscrete Representation: VQVAE\n\n### Video 3\nAnomaly detection: other methods outlier, novelty, exception  \none class classifier: Approach: Auto-encoder\n\n### Video 4\nA confidence score $c$, a threshold $\\lambda$, smaller than, anomaly.\n\n### Video 5\nGenerating anomaly data\n\n### Video 6 \nWithout Labels  \nhttps://github.com/ahaque/twitch-troll-detection \n\n### Video 7\nGaussian Distribution  \nAssume the data points are samples from a probability density function $f_{\\theta}(x)$\\\n$\\theta$ determine the shape of $f_{\\theta}(x)$\\\n$L(\\theta)=f_{\\theta}(x^1)f_{\\theta}(x^2)...f_{\\theta}(x^N)$\\\n$\\theta^* = \\arg \\max_\\theta L(\\theta), \\theta=(\\mu, \\Sigma)$\\\n$f_{\\mu,\\Sigma}(x) = \\frac{1}{(2\\pi)^{D/2}}\\frac{1}{|\\Sigma|^{1/2}} \\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)$\n\n### Video 8\nAuto-encoder\n\n## 4/29\n\n### Video 1 Explainable ML Local  \nLoss of an example: Gradient: Saliency Map  \nLimitation: Noisy Gradient, SmoothGrad  \nMFCC  \nAttention is Explainable  \nProbing: CNN BLSTM\n\n### Video 2 Explainable ML Global \n\n## 5/06\n\n### Video 1\nAttack  \n$x^* = \\arg_{d(x^0, x)<\\epsilon} \\min L(x)$\n\n#### Non-targeted\n$e(,)$ cross entropy\\\n$L(x) = -e(y, \\hat y)$\n\n#### Targeted\n$L(x) = -e(y, \\hat y) + e(y, y_{\\text{target}})$\\\n$\\hat y$: real case\\\n$y_{\\text{target}}$: what you wish to be perceived\n\n#### Non-perceivable \n$d(x^0, x) < \\epsilon$,  \nL2-norm, L-infinity\n\n### Video 2\nBlack box attack: Proxy Network  \nEnsemble Network, one-pixel, universal adversarial attack  \nBeyond Images, speech processing, Natural  \nAdversarial reprogramming  \nFilter\n\n## 7/03\nhttps://www.bilibili.com/video/BV1734y1c7Hb?p=2&spm_id_from=pageDriver&vd_source=441679270dda23308fe16f3c5602b058\n\n### Video 1 Diffusion Model\nDenoise module: picture + noise -> predict noise, then -noise -> picture  \nTrain the noise predictor\n\nDiffuse process: \n```\nfor step in range(1000): \n    generate noise[i] pic[i] = pic[i-1] + noise[i]\ntrain: \n    given pic[i-1], pic[i]\n    learn noise[i]\n```\n![alt text](2024-03-08-LHY-ML/image-2.png)\n\n### Video 2 \nText to picture  \nDALL-E Decoder: Autoregressive/Diffusion Model  \nImagen (Google):\n\nFramework:  \nEncoder: GPT/BERT  \nEncoder -> Generation model (Latent Representation) -> Decoder\n\n### Video 3 原理\n解释 Training， Sampling\n\n$x_0:$ a picture,\n\n$x_t:$ pic + noise $t$\n\n### Video 4 \nMaximum likelihood Estimation:\n$P_{\\text{data}}(x)$ True Distribution of Data  \n$P_{\\theta}(x)$ Probability distribution of data $x$ given parameters $\\theta$  \n$\\{x^1, x^2, \\cdots, x^m\\}$ Observed data samples\n\nNetwork: $z \\rightarrow \\theta \\rightarrow P_{\\theta}(x) \\rightarrow P_{\\text{data}}(x)$\\\nmaximize $P_{\\theta}(x^1)P_{\\theta}(x^2) \\cdots P_{\\theta}(x^m)$\n\n$\\theta^* = \\arg \\max_\\theta \\log P_{\\theta}(x^1)P_{\\theta}(x^2) \\cdots P_{\\theta}(x^m)$\n\n$\\theta^* = \\arg \\max_\\theta \\mathbb{E}_{x \\sim P_{\\text{data}}} \\log P_{\\theta}(x)$\n\n$\\theta^* = \\arg \\max_\\theta \\int_{x} P_{\\text{data}}(x) \\log P_{\\theta}(x) dx$\n\n$\\theta^* = \\arg \\max_\\theta \\left( \\int_{x} P_{\\text{data}}(x) \\log P_{\\theta}(x) dx - \\int_{x} P_{\\text{data}}(x) \\log P_{\\text{data}}(x) dx \\right)$\n\n$\\theta^* = \\arg \\max_\\theta \\int_{x} P_{\\text{data}}(x) \\log \\frac{P_{\\theta}(x)}{P_{\\text{data}}(x)} dx$\n\n$\\theta^* = \\arg \\max_\\theta -KL(P_{\\text{data}} || P_{\\theta})$\n\n#### VAE\nCompute $P_{\\theta}(x)$  \nNetwork: $G(z) = x$  \n$P_{\\theta}(x) = \\int P_{\\theta}(x|z)P_{\\theta}(z) dz$\n\n$P_{\\theta}(z|x) = \\frac{P_{\\theta}(x|z)P_{\\theta}(z)}{P_{\\theta}(x)}$\n\nDDPM\n\n### Video 5\nVAE: Variational Auto-encoder  \n$P_{\\theta}(x) = \\int P_{\\theta}(x|z)P_{\\theta}(z) dz$  \n$P_{\\theta}(z|x) = \\frac{P_{\\theta}(x|z)P_{\\theta}(z)}{P_{\\theta}(x)}$\n\n# VAE\nhttps://www.bilibili.com/video/BV1yD4y1i7Jm/?p=44&vd_source=441679270dda23308fe16f3c5602b058  \nhttps://www.cnblogs.com/wxkang/p/17128108.html  \n比较主流的生成模型：HMM, NB, GMM (Gaussian Mixture Model)\n\nKL divergence: $KL(P||Q) = \\int P(x) \\log \\frac{P(x)}{Q(x)} dx$, $KL(P||Q) \\neq KL(Q||P)$\n\nAE: 与 PCA, SVD 目的相同，矩阵降维技术。\n\nlatent variable $z$, assume it follows the prior distribution of $P(z) \\sim N(0,1)$\n\n$P(x|z) \\sim N(\\mu(z), \\sigma(z))$ \n\n$P(x) = \\int P(z) P(x|z) dz$\n\nTo Maximize Likelihood of observed $x$: $L = \\sum_x \\log P(x)$\n\nELBO Evidence Lower Bound\n\n# MCMC\n看不懂：仿佛在谈收敛快慢和平衡状态 $\\pi$ 的问题  \nhttps://zhuanlan.zhihu.com/p/143016455  \nhttps://www.cnblogs.com/pinard/p/6625739.html\n\n### Monte Carlo Integration\nIf $X$ is uniformly distributed on $[a,b]$:\\\n$\\int_a^b f(x)dx = \\int_a^b f(x) \\frac{1}{b-a}dx = \\mathbb{E}_{x \\sim U(a,b)}[f(x)] = \\frac{1}{N}\\sum_{i=1}^N f(x_i)$\n\nIf we know the distribution of $X$ on $[a, b] = p(x)$:\\\n$\\int_a^b f(x)dx = \\int_a^b \\frac{f(x)}{p(x)} p(x) dx = \\mathbb{E}_{x \\sim p(x)}[f(x)] = \\frac{1}{N}\\sum_{i=1}^N \\frac{f(x_i)}{p(x_i)}$\n\n### Acceptance-Rejection Sampling\nhttps://blog.quantitations.com/inference/2012/11/24/rejection-sampling-proof\n\n方便采样的常用概率分布函数 (proposal distribution) $q(x)$ 以及一个常量 $k$ 使得 $p(x)$ 总在 $k q(x)$ 的下方\n\n### MCMC\n\n","source":"_posts/2024-03-08-LHY-ML.md","raw":"---\ntitle: LHY ML\ndate: 2024-03-08 10:36:24\ntags:\n---\n\nhttps://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php\n\n## 2/18\n\n### Video 2\nPiecewise Linear\n\n$y = c * Sigmoid(b+wx_1)$, w, b, c,\n\n$\\theta$: A vector of all unknown variable\\\nGradient $ g =\\nabla L(\\theta^{0}) $\\\n$\\eta$: learning rate\\\nBatch, update, Epoch\n\nActivation function:\\\nSigmoid function  \nRectified Linear Unit (ReLU) max(0, )\n\n### Pytorch 1/2 \nMainly introduce some practical advice for coding. \n\n### Background propagation\nBack Propagation: an efficient way to calculate Gradient Descent:\\\nforward pass, backward pass\n\n没太懂\n\n### Predicting Pokémon CP\nRegression: difference in origin $x_{cp}$, and species\\\nGradient descent\\\nOverfitting Regularization\n\n### Pokemon classification\n#### Maximum Likelihood\n2-D Gaussian distribution:\\\n$f_{\\mu^1,\\Sigma^1}(x) = \\frac{1}{(2\\pi)^{D/2}|\\Sigma^1|^{1/2}} \\exp\\left(-\\frac{1}{2}(x - \\mu^1)^T(\\Sigma^1)^{-1}(x - \\mu^1)\\right)$\n\n$\\mu$ mean $\\sum$ covariance\\\n$\\mu^1 = \\begin{bmatrix}\n75.0 \\\\\n71.3 \\\\\n\\end{bmatrix}\n\\quad\n\\Sigma^1 = \\begin{bmatrix}\n874 & 327 \\\\\n327 & 929 \\\\\n\\end{bmatrix}$\n\n$P(C_1|x) = \\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1) + P(x|C_2)P(C_2)}$\n\nSimplify the function, substitute Gaussian into probability\\\n$P(C_1|x)=\\sigma(z) = \\sigma(wx+b)$\\\n$w=(\\mu^1-\\mu^2)^T\\sum^{-1}, b=...(scalar)$\\\nSo the Boundary for shared $\\sum$ is linear.\n\n### Logistic Regression \n（数学推导比较多）\n#### Loss function\nCross Entropy for a Bernoulli distribution  \n$H(p,q)=−[p\\log(q)+(1−p)\\log(1−q)]$\\\nwhich is better than Square Error. \n\nDiscriminative: Logistic Regression: Directly find $w$ and $b$, which generally have better performance  \nGenerative: Gaussian description: Have assumptions (Naive Bayes, or ...) of model and find $\\mu^1$, $\\mu^2$, $\\sum$ \n\n#### Multiclass Classification\n跳过了，想做hw再听，觉得现在对$f_{w, b}(x)$的理解还不深\n\n## 2/25\n\n### Video 1\nLoss on training data large: Model Bias (need a more complex model) or Optimization\\\nLoss on testing data large: Overfitting or mismatch -> more data \n\n### Video 2\nHow to Optimize:\\\n$\nL(\\theta) \\approx L(\\theta') + (\\theta - \\theta')^T \\vec{g} + \\frac{1}{2} (\\theta - \\theta')^T H (\\theta - \\theta')\n$  \nGradient $\\vec{g}$:  \n$\\vec{g} = \\nabla L(\\theta')$  \n$g_i = \\frac{\\partial L(\\theta')}{\\partial \\theta_i}$  \n$\\vec{g} =\n\\begin{bmatrix}\n\\frac{\\partial L}{\\partial \\theta_1} \\\\\n\\frac{\\partial L}{\\partial \\theta_2} \\\\\n\\vdots \\\\\n\\frac{\\partial L}{\\partial \\theta_n}\n\\end{bmatrix}$  \nHessian $H$ is a matrix $H_{ij} = \\frac{\\partial^2 L(\\theta')}{\\partial \\theta_i \\partial \\theta_j}$  \nFor all $v$:\n1. $v^T Hv > 0$: $H$ is positive definite, $L(\\theta) > L(\\theta')$: Local minima\n2. $v^T Hv < 0$: $H$ is negative definite, $L(\\theta) < L(\\theta')$: Local maxima\n3. Some eigenvalues are $+$, some are $-$: Saddle point  \nEmpirical learning: \n\n### Video 3\nBatch: large batch $N$ not necessarily need longer time for gradient computing (parallel computing)\n\n### Video 4\nAdaptive $\\eta$ (learning rate):\\\nError surface  \nCritical points (local minima, saddle point):\n1. Adagrad \n2. RMSProp\n3. Adam: RMSProp + Momentum\n\nLearning Rate Scheduling:  \nLearning rate Decay  \nWarm up (Residual Network, Transformer Classification)\n\n### Video 5\nRegression:  \nRight answer: $\\hat{y} \\leftrightarrow y$  \nClassification: class: one-hot vector: $\\hat{y} \\leftrightarrow y' = \\text{softmax}(y)$  \nSoft-max (Normalize): $n \\geq 3$: $y_i' = \\frac{\\exp(y_i)}{\\sum_j \\exp(y_j)}$  \n$n=2$ $y' = \\text{sigmoid}(y)$\n\nDistance $e$:  \nMean Square Error (MSE): $e = \\sum (\\hat{y_i} - y_i')^2$  \nCross-entropy: $e = -\\sum \\hat{y_i} \\ln y_i'$  \nMinimize Cross-entropy $\\leftrightarrow$ Maximize likelihood\n\n### Basic Theory\nWe want $L(h_{\\text{train}}, D_{\\text{all}}) - L(h_{\\text{all}}, D_{\\text{all}}) \\leq \\delta$\\\n$\\forall h \\in \\mathcal{H}, |L(h, D_{\\text{train}}) - L(h, D_{\\text{all}})| \\leq \\frac{\\delta}{2}$\n\n### Gradient Descent \n\n### Beyond Adam 1\n\n### Beyond Adam 2\n\n## 3/04 CNN\n\n### Video\nImage as input\n\n#### V1\nTensor: a Matrix >= 3 dimensional  \n1. Observation 1:  \nReceptive Field: Kernel Size (3x3), Stride (1 or 2, padding 0, hope receptive field are intersecting)  \n2. Observation 2  \nShared parameters: filter  \n1 + 2 -> Convolution Layer -> CNN (designed for image)\n\n#### V2\nEach filter detects a small pattern (3 * 3 * channel_num, which is a tensor)  \nFeature Map  \n3. Observation 3  \nMax Pooling: Operator  \nConvolutional Layer + Pooling  \n\n### Spatial Transformer Layer\nCNN is not invariant to scaling and rotation \nInterpolation.\n\n## 3/11 Self-attention\n\n### Video 1\nSequence Labeling  \nSelf-Attention: dot product additive \n\n### Video 2\nSelf-attention  \nMultihead self-attention  \nTruncated self-attention  \nCNN is a simplified self-attention (limited to receptive field)  \nRNN, GNN (Graph Neural Network)\n\n### GNN 1\nConvolution (spatial-based/Spectral-based)\n\n#### Spatial-based\nTerminology:  \nAggregate: use neighbor features to update the next hidden state  \nReadout: use all nodes' features to represent the whole graph  \nNN4G  \nDCNN  \nGAT (Graph Attention Network)  \nGraph Isomorphism Network\n\n### GNN 2\nDeep Graph Library\n\n#### Graph Signal Processing \nGraph Laplacian:  \nDegree Matrix $D$, Adjacency Matrix: $A$, $L$ is an operation on graph  \n$L = D - A = U \\Lambda U^T$  \nDiscrete time Fourier basis $\\lambda$ wave length  \n$(Lf)(v_i) = \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))$  \n$\\begin{aligned}\nf^T L f &= \\sum_{v_i \\in V} f(v_i) \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))\\\\\n&= \\frac{1}{2} \\sum_{v_i \\in V} \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))^2\n\\end{aligned}\n$\n\nGraph Fourier Transform of signal $\\hat{x}$: $\\hat{x} = U ^T x, \\hat{x}_i = u_i \\cdot x$  \nInverse Graph Fourier Transform of signal $\\hat{x}$: $x = U ^T \\hat{x}$\n\nFiltering: Convolution in time domain is multiplication in frequency domain\n\nChebNet  \n听不懂在干什么\n\n#### Spectral-based\n\n## 3/18\n\n### Video 1 Batch Normalization\nBatch Normalization  \nInternal Covariate Shift\n\n### Video 2 Seq2seq\nTransformer  \nSeq2seq:  \nChatbox,  \nNLP\n\n## Video 3 Decoder\nAutoregressive  \nMasked Self-attention\n\n## NAT Non autoregressive translation\n像一个NAT发展的论文综述  \nNaive approach,  \nautoregressive,  \nGAN, \n\nImprovement\n1. Fertility\n2. Sequence-level knowledge distillation\n3. Noisy Parallel Decoding NPD\n\nVanilla NAT, Iterative Refinement, Insertion-based, Insertion+Deletion, CTC-based, Masked-predict, Kermit, CTC, LAS, Imputer (CTC+Mask-Predict)\n\n## Pointer Network\n\n## 3/25\n\n### Video 1 GAN\nDiscriminator\n\n### Video 2 GAN\nJS Divergence\\\n$G^*= \\arg \\min(G) \\max(D) \\mathcal{V}(G, D)$\n![alt text](LHY-ML/image-1.png)\n$JS(P \\parallel Q) = \\frac{1}{2} KL(P \\parallel M) + \\frac{1}{2} KL(Q \\parallel M)$\\\n$KL(P \\parallel Q) = \\sum_{x} P(x) \\log\\left(\\frac{P(x)}{Q(x)}\\right)$\n\nWGAN\\ \nWasserstein distance: improve JS divergence: $JS(P_G, P_{\\text{data}}) \\rightarrow W(P_G, P_{\\text{data}})$\\\n$\\max_{D \\in 1-\\text{Lipschitz}} \\left\\{ \\mathbb{E}_{x \\sim P_{\\text{data}}} [D(x)] - \\mathbb{E}_{x \\sim P_{G}} [D(x)] \\right\\}$\\\nthe $D(x)$ should be smooth enough\n\n### Video 3 BERT anecdote\nCBOW (2 transforms): word embedding\\\ncontextualized word embedding\\\nMulti BERT: Zero-shot Reading Comprehension, alignment\n\n### Video 4 Cycle GAN\nCycle/Dual/Disco GAN: $G_{x\\rightarrow y}$, $G_{y\\rightarrow x}$\n\n### The theory of GAN (1)\n$\\max_{D} \\mathcal{V}(G, D)$ maximize the discriminator D in GAN  \n\n$\\mathcal{V}(G, D) = \\mathbb{E}_{x \\sim P_{\\text{data}}} [\\log D(x)] + \\mathbb{E}_{x \\sim P_{G}} [\\log(1 - D(x))]$  \n$\\mathcal{V}(G, D) = \\int_{x} P_{\\text{data}}(x)\\log D(x) \\, dx + \\int_{x} P_{G}(x)\\log(1 - D(x)) \\, dx$\n\n$\\mathcal{V}(G, D) = P_{\\text{data}}(x)\\log D(x) + P_{G}(x)\\log(1 - D(x))$ \n\n$D^*(x) = \\frac{P_{\\text{data}}(x)}{P_{\\text{data}}(x) + P_{G}(x)}$\n\n## 4/01\n\n### Video 1 \nSelf-supervised Learning\n\n### Video 2 BERT intro\nMasking Input: Mask  \nNext Sentence Prediction: [CLS] sentence 1. [SEP] sentence 2.\\\nPre-trained Fine-tune for Downstream Tasks:\\\nGLUE: General Language Understanding Evaluation\\\nin seq, out class: sentiment analysis\\\nin seq ((n)), out seq (n): POG tagging\\\nin 2 seqs, out class: NLI Natural language inference\\\nin seqs, out seqs: QA Extract-based Question Answer\n\nMASS\\ BART T5, C4 (open sourced resource)\n\n### Video 3 BERT anecdote\nSame with above\n\n### Video 4 GPT outlook\nLinear Transform -> Softmax -> distribution  \nFew-shot learning, one-shot, zero-shot learning  \nSimCLR, BYOL,  \nSpeech GLUE - SUPERB\n\n## 4/15\n????\n\n## 4/22\nAuto encoder\n\n### Video 1 basic idea\nsame idea with Cycle GAN, embedding, representation, code  \nDimension reduction: not deep learning based PCA, t-SNE  \nDe-noising Auto-encoder\n\nVideo 2-8 are all anomaly detection\n\n### Video 2  \nFeature disentanglement: know the content of embedding: Voice Conversion  \nDiscrete Representation: VQVAE\n\n### Video 3\nAnomaly detection: other methods outlier, novelty, exception  \none class classifier: Approach: Auto-encoder\n\n### Video 4\nA confidence score $c$, a threshold $\\lambda$, smaller than, anomaly.\n\n### Video 5\nGenerating anomaly data\n\n### Video 6 \nWithout Labels  \nhttps://github.com/ahaque/twitch-troll-detection \n\n### Video 7\nGaussian Distribution  \nAssume the data points are samples from a probability density function $f_{\\theta}(x)$\\\n$\\theta$ determine the shape of $f_{\\theta}(x)$\\\n$L(\\theta)=f_{\\theta}(x^1)f_{\\theta}(x^2)...f_{\\theta}(x^N)$\\\n$\\theta^* = \\arg \\max_\\theta L(\\theta), \\theta=(\\mu, \\Sigma)$\\\n$f_{\\mu,\\Sigma}(x) = \\frac{1}{(2\\pi)^{D/2}}\\frac{1}{|\\Sigma|^{1/2}} \\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)$\n\n### Video 8\nAuto-encoder\n\n## 4/29\n\n### Video 1 Explainable ML Local  \nLoss of an example: Gradient: Saliency Map  \nLimitation: Noisy Gradient, SmoothGrad  \nMFCC  \nAttention is Explainable  \nProbing: CNN BLSTM\n\n### Video 2 Explainable ML Global \n\n## 5/06\n\n### Video 1\nAttack  \n$x^* = \\arg_{d(x^0, x)<\\epsilon} \\min L(x)$\n\n#### Non-targeted\n$e(,)$ cross entropy\\\n$L(x) = -e(y, \\hat y)$\n\n#### Targeted\n$L(x) = -e(y, \\hat y) + e(y, y_{\\text{target}})$\\\n$\\hat y$: real case\\\n$y_{\\text{target}}$: what you wish to be perceived\n\n#### Non-perceivable \n$d(x^0, x) < \\epsilon$,  \nL2-norm, L-infinity\n\n### Video 2\nBlack box attack: Proxy Network  \nEnsemble Network, one-pixel, universal adversarial attack  \nBeyond Images, speech processing, Natural  \nAdversarial reprogramming  \nFilter\n\n## 7/03\nhttps://www.bilibili.com/video/BV1734y1c7Hb?p=2&spm_id_from=pageDriver&vd_source=441679270dda23308fe16f3c5602b058\n\n### Video 1 Diffusion Model\nDenoise module: picture + noise -> predict noise, then -noise -> picture  \nTrain the noise predictor\n\nDiffuse process: \n```\nfor step in range(1000): \n    generate noise[i] pic[i] = pic[i-1] + noise[i]\ntrain: \n    given pic[i-1], pic[i]\n    learn noise[i]\n```\n![alt text](2024-03-08-LHY-ML/image-2.png)\n\n### Video 2 \nText to picture  \nDALL-E Decoder: Autoregressive/Diffusion Model  \nImagen (Google):\n\nFramework:  \nEncoder: GPT/BERT  \nEncoder -> Generation model (Latent Representation) -> Decoder\n\n### Video 3 原理\n解释 Training， Sampling\n\n$x_0:$ a picture,\n\n$x_t:$ pic + noise $t$\n\n### Video 4 \nMaximum likelihood Estimation:\n$P_{\\text{data}}(x)$ True Distribution of Data  \n$P_{\\theta}(x)$ Probability distribution of data $x$ given parameters $\\theta$  \n$\\{x^1, x^2, \\cdots, x^m\\}$ Observed data samples\n\nNetwork: $z \\rightarrow \\theta \\rightarrow P_{\\theta}(x) \\rightarrow P_{\\text{data}}(x)$\\\nmaximize $P_{\\theta}(x^1)P_{\\theta}(x^2) \\cdots P_{\\theta}(x^m)$\n\n$\\theta^* = \\arg \\max_\\theta \\log P_{\\theta}(x^1)P_{\\theta}(x^2) \\cdots P_{\\theta}(x^m)$\n\n$\\theta^* = \\arg \\max_\\theta \\mathbb{E}_{x \\sim P_{\\text{data}}} \\log P_{\\theta}(x)$\n\n$\\theta^* = \\arg \\max_\\theta \\int_{x} P_{\\text{data}}(x) \\log P_{\\theta}(x) dx$\n\n$\\theta^* = \\arg \\max_\\theta \\left( \\int_{x} P_{\\text{data}}(x) \\log P_{\\theta}(x) dx - \\int_{x} P_{\\text{data}}(x) \\log P_{\\text{data}}(x) dx \\right)$\n\n$\\theta^* = \\arg \\max_\\theta \\int_{x} P_{\\text{data}}(x) \\log \\frac{P_{\\theta}(x)}{P_{\\text{data}}(x)} dx$\n\n$\\theta^* = \\arg \\max_\\theta -KL(P_{\\text{data}} || P_{\\theta})$\n\n#### VAE\nCompute $P_{\\theta}(x)$  \nNetwork: $G(z) = x$  \n$P_{\\theta}(x) = \\int P_{\\theta}(x|z)P_{\\theta}(z) dz$\n\n$P_{\\theta}(z|x) = \\frac{P_{\\theta}(x|z)P_{\\theta}(z)}{P_{\\theta}(x)}$\n\nDDPM\n\n### Video 5\nVAE: Variational Auto-encoder  \n$P_{\\theta}(x) = \\int P_{\\theta}(x|z)P_{\\theta}(z) dz$  \n$P_{\\theta}(z|x) = \\frac{P_{\\theta}(x|z)P_{\\theta}(z)}{P_{\\theta}(x)}$\n\n# VAE\nhttps://www.bilibili.com/video/BV1yD4y1i7Jm/?p=44&vd_source=441679270dda23308fe16f3c5602b058  \nhttps://www.cnblogs.com/wxkang/p/17128108.html  \n比较主流的生成模型：HMM, NB, GMM (Gaussian Mixture Model)\n\nKL divergence: $KL(P||Q) = \\int P(x) \\log \\frac{P(x)}{Q(x)} dx$, $KL(P||Q) \\neq KL(Q||P)$\n\nAE: 与 PCA, SVD 目的相同，矩阵降维技术。\n\nlatent variable $z$, assume it follows the prior distribution of $P(z) \\sim N(0,1)$\n\n$P(x|z) \\sim N(\\mu(z), \\sigma(z))$ \n\n$P(x) = \\int P(z) P(x|z) dz$\n\nTo Maximize Likelihood of observed $x$: $L = \\sum_x \\log P(x)$\n\nELBO Evidence Lower Bound\n\n# MCMC\n看不懂：仿佛在谈收敛快慢和平衡状态 $\\pi$ 的问题  \nhttps://zhuanlan.zhihu.com/p/143016455  \nhttps://www.cnblogs.com/pinard/p/6625739.html\n\n### Monte Carlo Integration\nIf $X$ is uniformly distributed on $[a,b]$:\\\n$\\int_a^b f(x)dx = \\int_a^b f(x) \\frac{1}{b-a}dx = \\mathbb{E}_{x \\sim U(a,b)}[f(x)] = \\frac{1}{N}\\sum_{i=1}^N f(x_i)$\n\nIf we know the distribution of $X$ on $[a, b] = p(x)$:\\\n$\\int_a^b f(x)dx = \\int_a^b \\frac{f(x)}{p(x)} p(x) dx = \\mathbb{E}_{x \\sim p(x)}[f(x)] = \\frac{1}{N}\\sum_{i=1}^N \\frac{f(x_i)}{p(x_i)}$\n\n### Acceptance-Rejection Sampling\nhttps://blog.quantitations.com/inference/2012/11/24/rejection-sampling-proof\n\n方便采样的常用概率分布函数 (proposal distribution) $q(x)$ 以及一个常量 $k$ 使得 $p(x)$ 总在 $k q(x)$ 的下方\n\n### MCMC\n\n","slug":"2024-03-08-LHY-ML","published":1,"updated":"2024-12-15T03:58:17.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagsz001vzc3dbods73t8","content":"<p><a href=\"https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php\">https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php</a></p>\n<h2 id=\"2-18\"><a href=\"#2-18\" class=\"headerlink\" title=\"2&#x2F;18\"></a>2&#x2F;18</h2><h3 id=\"Video-2\"><a href=\"#Video-2\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>Piecewise Linear</p>\n<p>$y &#x3D; c * Sigmoid(b+wx_1)$, w, b, c,</p>\n<p>$\\theta$: A vector of all unknown variable<br>Gradient $ g &#x3D;\\nabla L(\\theta^{0}) $<br>$\\eta$: learning rate<br>Batch, update, Epoch</p>\n<p>Activation function:<br>Sigmoid function<br>Rectified Linear Unit (ReLU) max(0, )</p>\n<h3 id=\"Pytorch-1-2\"><a href=\"#Pytorch-1-2\" class=\"headerlink\" title=\"Pytorch 1&#x2F;2\"></a>Pytorch 1&#x2F;2</h3><p>Mainly introduce some practical advice for coding. </p>\n<h3 id=\"Background-propagation\"><a href=\"#Background-propagation\" class=\"headerlink\" title=\"Background propagation\"></a>Background propagation</h3><p>Back Propagation: an efficient way to calculate Gradient Descent:<br>forward pass, backward pass</p>\n<p>没太懂</p>\n<h3 id=\"Predicting-Pokemon-CP\"><a href=\"#Predicting-Pokemon-CP\" class=\"headerlink\" title=\"Predicting Pokémon CP\"></a>Predicting Pokémon CP</h3><p>Regression: difference in origin $x_{cp}$, and species<br>Gradient descent<br>Overfitting Regularization</p>\n<h3 id=\"Pokemon-classification\"><a href=\"#Pokemon-classification\" class=\"headerlink\" title=\"Pokemon classification\"></a>Pokemon classification</h3><h4 id=\"Maximum-Likelihood\"><a href=\"#Maximum-Likelihood\" class=\"headerlink\" title=\"Maximum Likelihood\"></a>Maximum Likelihood</h4><p>2-D Gaussian distribution:<br>$f_{\\mu^1,\\Sigma^1}(x) &#x3D; \\frac{1}{(2\\pi)^{D&#x2F;2}|\\Sigma^1|^{1&#x2F;2}} \\exp\\left(-\\frac{1}{2}(x - \\mu^1)^T(\\Sigma^1)^{-1}(x - \\mu^1)\\right)$</p>\n<p>$\\mu$ mean $\\sum$ covariance<br>$\\mu^1 &#x3D; \\begin{bmatrix}<br>75.0 \\<br>71.3 \\<br>\\end{bmatrix}<br>\\quad<br>\\Sigma^1 &#x3D; \\begin{bmatrix}<br>874 &amp; 327 \\<br>327 &amp; 929 \\<br>\\end{bmatrix}$</p>\n<p>$P(C_1|x) &#x3D; \\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1) + P(x|C_2)P(C_2)}$</p>\n<p>Simplify the function, substitute Gaussian into probability<br>$P(C_1|x)&#x3D;\\sigma(z) &#x3D; \\sigma(wx+b)$<br>$w&#x3D;(\\mu^1-\\mu^2)^T\\sum^{-1}, b&#x3D;…(scalar)$<br>So the Boundary for shared $\\sum$ is linear.</p>\n<h3 id=\"Logistic-Regression\"><a href=\"#Logistic-Regression\" class=\"headerlink\" title=\"Logistic Regression\"></a>Logistic Regression</h3><p>（数学推导比较多）</p>\n<h4 id=\"Loss-function\"><a href=\"#Loss-function\" class=\"headerlink\" title=\"Loss function\"></a>Loss function</h4><p>Cross Entropy for a Bernoulli distribution<br>$H(p,q)&#x3D;−[p\\log(q)+(1−p)\\log(1−q)]$<br>which is better than Square Error. </p>\n<p>Discriminative: Logistic Regression: Directly find $w$ and $b$, which generally have better performance<br>Generative: Gaussian description: Have assumptions (Naive Bayes, or …) of model and find $\\mu^1$, $\\mu^2$, $\\sum$ </p>\n<h4 id=\"Multiclass-Classification\"><a href=\"#Multiclass-Classification\" class=\"headerlink\" title=\"Multiclass Classification\"></a>Multiclass Classification</h4><p>跳过了，想做hw再听，觉得现在对$f_{w, b}(x)$的理解还不深</p>\n<h2 id=\"2-25\"><a href=\"#2-25\" class=\"headerlink\" title=\"2&#x2F;25\"></a>2&#x2F;25</h2><h3 id=\"Video-1\"><a href=\"#Video-1\" class=\"headerlink\" title=\"Video 1\"></a>Video 1</h3><p>Loss on training data large: Model Bias (need a more complex model) or Optimization<br>Loss on testing data large: Overfitting or mismatch -&gt; more data </p>\n<h3 id=\"Video-2-1\"><a href=\"#Video-2-1\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>How to Optimize:<br>$<br>L(\\theta) \\approx L(\\theta’) + (\\theta - \\theta’)^T \\vec{g} + \\frac{1}{2} (\\theta - \\theta’)^T H (\\theta - \\theta’)<br>$<br>Gradient $\\vec{g}$:<br>$\\vec{g} &#x3D; \\nabla L(\\theta’)$<br>$g_i &#x3D; \\frac{\\partial L(\\theta’)}{\\partial \\theta_i}$<br>$\\vec{g} &#x3D;<br>\\begin{bmatrix}<br>\\frac{\\partial L}{\\partial \\theta_1} \\<br>\\frac{\\partial L}{\\partial \\theta_2} \\<br>\\vdots \\<br>\\frac{\\partial L}{\\partial \\theta_n}<br>\\end{bmatrix}$<br>Hessian $H$ is a matrix $H_{ij} &#x3D; \\frac{\\partial^2 L(\\theta’)}{\\partial \\theta_i \\partial \\theta_j}$<br>For all $v$:</p>\n<ol>\n<li>$v^T Hv &gt; 0$: $H$ is positive definite, $L(\\theta) &gt; L(\\theta’)$: Local minima</li>\n<li>$v^T Hv &lt; 0$: $H$ is negative definite, $L(\\theta) &lt; L(\\theta’)$: Local maxima</li>\n<li>Some eigenvalues are $+$, some are $-$: Saddle point<br>Empirical learning:</li>\n</ol>\n<h3 id=\"Video-3\"><a href=\"#Video-3\" class=\"headerlink\" title=\"Video 3\"></a>Video 3</h3><p>Batch: large batch $N$ not necessarily need longer time for gradient computing (parallel computing)</p>\n<h3 id=\"Video-4\"><a href=\"#Video-4\" class=\"headerlink\" title=\"Video 4\"></a>Video 4</h3><p>Adaptive $\\eta$ (learning rate):<br>Error surface<br>Critical points (local minima, saddle point):</p>\n<ol>\n<li>Adagrad </li>\n<li>RMSProp</li>\n<li>Adam: RMSProp + Momentum</li>\n</ol>\n<p>Learning Rate Scheduling:<br>Learning rate Decay<br>Warm up (Residual Network, Transformer Classification)</p>\n<h3 id=\"Video-5\"><a href=\"#Video-5\" class=\"headerlink\" title=\"Video 5\"></a>Video 5</h3><p>Regression:<br>Right answer: $\\hat{y} \\leftrightarrow y$<br>Classification: class: one-hot vector: $\\hat{y} \\leftrightarrow y’ &#x3D; \\text{softmax}(y)$<br>Soft-max (Normalize): $n \\geq 3$: $y_i’ &#x3D; \\frac{\\exp(y_i)}{\\sum_j \\exp(y_j)}$<br>$n&#x3D;2$ $y’ &#x3D; \\text{sigmoid}(y)$</p>\n<p>Distance $e$:<br>Mean Square Error (MSE): $e &#x3D; \\sum (\\hat{y_i} - y_i’)^2$<br>Cross-entropy: $e &#x3D; -\\sum \\hat{y_i} \\ln y_i’$<br>Minimize Cross-entropy $\\leftrightarrow$ Maximize likelihood</p>\n<h3 id=\"Basic-Theory\"><a href=\"#Basic-Theory\" class=\"headerlink\" title=\"Basic Theory\"></a>Basic Theory</h3><p>We want $L(h_{\\text{train}}, D_{\\text{all}}) - L(h_{\\text{all}}, D_{\\text{all}}) \\leq \\delta$<br>$\\forall h \\in \\mathcal{H}, |L(h, D_{\\text{train}}) - L(h, D_{\\text{all}})| \\leq \\frac{\\delta}{2}$</p>\n<h3 id=\"Gradient-Descent\"><a href=\"#Gradient-Descent\" class=\"headerlink\" title=\"Gradient Descent\"></a>Gradient Descent</h3><h3 id=\"Beyond-Adam-1\"><a href=\"#Beyond-Adam-1\" class=\"headerlink\" title=\"Beyond Adam 1\"></a>Beyond Adam 1</h3><h3 id=\"Beyond-Adam-2\"><a href=\"#Beyond-Adam-2\" class=\"headerlink\" title=\"Beyond Adam 2\"></a>Beyond Adam 2</h3><h2 id=\"3-04-CNN\"><a href=\"#3-04-CNN\" class=\"headerlink\" title=\"3&#x2F;04 CNN\"></a>3&#x2F;04 CNN</h2><h3 id=\"Video\"><a href=\"#Video\" class=\"headerlink\" title=\"Video\"></a>Video</h3><p>Image as input</p>\n<h4 id=\"V1\"><a href=\"#V1\" class=\"headerlink\" title=\"V1\"></a>V1</h4><p>Tensor: a Matrix &gt;&#x3D; 3 dimensional  </p>\n<ol>\n<li>Observation 1:<br>Receptive Field: Kernel Size (3x3), Stride (1 or 2, padding 0, hope receptive field are intersecting)  </li>\n<li>Observation 2<br>Shared parameters: filter<br>1 + 2 -&gt; Convolution Layer -&gt; CNN (designed for image)</li>\n</ol>\n<h4 id=\"V2\"><a href=\"#V2\" class=\"headerlink\" title=\"V2\"></a>V2</h4><p>Each filter detects a small pattern (3 * 3 * channel_num, which is a tensor)<br>Feature Map<br>3. Observation 3<br>Max Pooling: Operator<br>Convolutional Layer + Pooling  </p>\n<h3 id=\"Spatial-Transformer-Layer\"><a href=\"#Spatial-Transformer-Layer\" class=\"headerlink\" title=\"Spatial Transformer Layer\"></a>Spatial Transformer Layer</h3><p>CNN is not invariant to scaling and rotation<br>Interpolation.</p>\n<h2 id=\"3-11-Self-attention\"><a href=\"#3-11-Self-attention\" class=\"headerlink\" title=\"3&#x2F;11 Self-attention\"></a>3&#x2F;11 Self-attention</h2><h3 id=\"Video-1-1\"><a href=\"#Video-1-1\" class=\"headerlink\" title=\"Video 1\"></a>Video 1</h3><p>Sequence Labeling<br>Self-Attention: dot product additive </p>\n<h3 id=\"Video-2-2\"><a href=\"#Video-2-2\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>Self-attention<br>Multihead self-attention<br>Truncated self-attention<br>CNN is a simplified self-attention (limited to receptive field)<br>RNN, GNN (Graph Neural Network)</p>\n<h3 id=\"GNN-1\"><a href=\"#GNN-1\" class=\"headerlink\" title=\"GNN 1\"></a>GNN 1</h3><p>Convolution (spatial-based&#x2F;Spectral-based)</p>\n<h4 id=\"Spatial-based\"><a href=\"#Spatial-based\" class=\"headerlink\" title=\"Spatial-based\"></a>Spatial-based</h4><p>Terminology:<br>Aggregate: use neighbor features to update the next hidden state<br>Readout: use all nodes’ features to represent the whole graph<br>NN4G<br>DCNN<br>GAT (Graph Attention Network)<br>Graph Isomorphism Network</p>\n<h3 id=\"GNN-2\"><a href=\"#GNN-2\" class=\"headerlink\" title=\"GNN 2\"></a>GNN 2</h3><p>Deep Graph Library</p>\n<h4 id=\"Graph-Signal-Processing\"><a href=\"#Graph-Signal-Processing\" class=\"headerlink\" title=\"Graph Signal Processing\"></a>Graph Signal Processing</h4><p>Graph Laplacian:<br>Degree Matrix $D$, Adjacency Matrix: $A$, $L$ is an operation on graph<br>$L &#x3D; D - A &#x3D; U \\Lambda U^T$<br>Discrete time Fourier basis $\\lambda$ wave length<br>$(Lf)(v_i) &#x3D; \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))$<br>$\\begin{aligned}<br>f^T L f &amp;&#x3D; \\sum_{v_i \\in V} f(v_i) \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))\\<br>&amp;&#x3D; \\frac{1}{2} \\sum_{v_i \\in V} \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))^2<br>\\end{aligned}<br>$</p>\n<p>Graph Fourier Transform of signal $\\hat{x}$: $\\hat{x} &#x3D; U ^T x, \\hat{x}_i &#x3D; u_i \\cdot x$<br>Inverse Graph Fourier Transform of signal $\\hat{x}$: $x &#x3D; U ^T \\hat{x}$</p>\n<p>Filtering: Convolution in time domain is multiplication in frequency domain</p>\n<p>ChebNet<br>听不懂在干什么</p>\n<h4 id=\"Spectral-based\"><a href=\"#Spectral-based\" class=\"headerlink\" title=\"Spectral-based\"></a>Spectral-based</h4><h2 id=\"3-18\"><a href=\"#3-18\" class=\"headerlink\" title=\"3&#x2F;18\"></a>3&#x2F;18</h2><h3 id=\"Video-1-Batch-Normalization\"><a href=\"#Video-1-Batch-Normalization\" class=\"headerlink\" title=\"Video 1 Batch Normalization\"></a>Video 1 Batch Normalization</h3><p>Batch Normalization<br>Internal Covariate Shift</p>\n<h3 id=\"Video-2-Seq2seq\"><a href=\"#Video-2-Seq2seq\" class=\"headerlink\" title=\"Video 2 Seq2seq\"></a>Video 2 Seq2seq</h3><p>Transformer<br>Seq2seq:<br>Chatbox,<br>NLP</p>\n<h2 id=\"Video-3-Decoder\"><a href=\"#Video-3-Decoder\" class=\"headerlink\" title=\"Video 3 Decoder\"></a>Video 3 Decoder</h2><p>Autoregressive<br>Masked Self-attention</p>\n<h2 id=\"NAT-Non-autoregressive-translation\"><a href=\"#NAT-Non-autoregressive-translation\" class=\"headerlink\" title=\"NAT Non autoregressive translation\"></a>NAT Non autoregressive translation</h2><p>像一个NAT发展的论文综述<br>Naive approach,<br>autoregressive,<br>GAN, </p>\n<p>Improvement</p>\n<ol>\n<li>Fertility</li>\n<li>Sequence-level knowledge distillation</li>\n<li>Noisy Parallel Decoding NPD</li>\n</ol>\n<p>Vanilla NAT, Iterative Refinement, Insertion-based, Insertion+Deletion, CTC-based, Masked-predict, Kermit, CTC, LAS, Imputer (CTC+Mask-Predict)</p>\n<h2 id=\"Pointer-Network\"><a href=\"#Pointer-Network\" class=\"headerlink\" title=\"Pointer Network\"></a>Pointer Network</h2><h2 id=\"3-25\"><a href=\"#3-25\" class=\"headerlink\" title=\"3&#x2F;25\"></a>3&#x2F;25</h2><h3 id=\"Video-1-GAN\"><a href=\"#Video-1-GAN\" class=\"headerlink\" title=\"Video 1 GAN\"></a>Video 1 GAN</h3><p>Discriminator</p>\n<h3 id=\"Video-2-GAN\"><a href=\"#Video-2-GAN\" class=\"headerlink\" title=\"Video 2 GAN\"></a>Video 2 GAN</h3><p>JS Divergence<br>$G^*&#x3D; \\arg \\min(G) \\max(D) \\mathcal{V}(G, D)$<br><img src=\"/LHY-ML/image-1.png\" alt=\"alt text\"><br>$JS(P \\parallel Q) &#x3D; \\frac{1}{2} KL(P \\parallel M) + \\frac{1}{2} KL(Q \\parallel M)$<br>$KL(P \\parallel Q) &#x3D; \\sum_{x} P(x) \\log\\left(\\frac{P(x)}{Q(x)}\\right)$</p>\n<p>WGAN\\<br>Wasserstein distance: improve JS divergence: $JS(P_G, P_{\\text{data}}) \\rightarrow W(P_G, P_{\\text{data}})$<br>$\\max_{D \\in 1-\\text{Lipschitz}} \\left{ \\mathbb{E}<em>{x \\sim P</em>{\\text{data}}} [D(x)] - \\mathbb{E}<em>{x \\sim P</em>{G}} [D(x)] \\right}$<br>the $D(x)$ should be smooth enough</p>\n<h3 id=\"Video-3-BERT-anecdote\"><a href=\"#Video-3-BERT-anecdote\" class=\"headerlink\" title=\"Video 3 BERT anecdote\"></a>Video 3 BERT anecdote</h3><p>CBOW (2 transforms): word embedding<br>contextualized word embedding<br>Multi BERT: Zero-shot Reading Comprehension, alignment</p>\n<h3 id=\"Video-4-Cycle-GAN\"><a href=\"#Video-4-Cycle-GAN\" class=\"headerlink\" title=\"Video 4 Cycle GAN\"></a>Video 4 Cycle GAN</h3><p>Cycle&#x2F;Dual&#x2F;Disco GAN: $G_{x\\rightarrow y}$, $G_{y\\rightarrow x}$</p>\n<h3 id=\"The-theory-of-GAN-1\"><a href=\"#The-theory-of-GAN-1\" class=\"headerlink\" title=\"The theory of GAN (1)\"></a>The theory of GAN (1)</h3><p>$\\max_{D} \\mathcal{V}(G, D)$ maximize the discriminator D in GAN  </p>\n<p>$\\mathcal{V}(G, D) &#x3D; \\mathbb{E}<em>{x \\sim P</em>{\\text{data}}} [\\log D(x)] + \\mathbb{E}<em>{x \\sim P</em>{G}} [\\log(1 - D(x))]$<br>$\\mathcal{V}(G, D) &#x3D; \\int_{x} P_{\\text{data}}(x)\\log D(x) , dx + \\int_{x} P_{G}(x)\\log(1 - D(x)) , dx$</p>\n<p>$\\mathcal{V}(G, D) &#x3D; P_{\\text{data}}(x)\\log D(x) + P_{G}(x)\\log(1 - D(x))$ </p>\n<p>$D^*(x) &#x3D; \\frac{P_{\\text{data}}(x)}{P_{\\text{data}}(x) + P_{G}(x)}$</p>\n<h2 id=\"4-01\"><a href=\"#4-01\" class=\"headerlink\" title=\"4&#x2F;01\"></a>4&#x2F;01</h2><h3 id=\"Video-1-2\"><a href=\"#Video-1-2\" class=\"headerlink\" title=\"Video 1\"></a>Video 1</h3><p>Self-supervised Learning</p>\n<h3 id=\"Video-2-BERT-intro\"><a href=\"#Video-2-BERT-intro\" class=\"headerlink\" title=\"Video 2 BERT intro\"></a>Video 2 BERT intro</h3><p>Masking Input: Mask<br>Next Sentence Prediction: [CLS] sentence 1. [SEP] sentence 2.<br>Pre-trained Fine-tune for Downstream Tasks:<br>GLUE: General Language Understanding Evaluation<br>in seq, out class: sentiment analysis<br>in seq ((n)), out seq (n): POG tagging<br>in 2 seqs, out class: NLI Natural language inference<br>in seqs, out seqs: QA Extract-based Question Answer</p>\n<p>MASS\\ BART T5, C4 (open sourced resource)</p>\n<h3 id=\"Video-3-BERT-anecdote-1\"><a href=\"#Video-3-BERT-anecdote-1\" class=\"headerlink\" title=\"Video 3 BERT anecdote\"></a>Video 3 BERT anecdote</h3><p>Same with above</p>\n<h3 id=\"Video-4-GPT-outlook\"><a href=\"#Video-4-GPT-outlook\" class=\"headerlink\" title=\"Video 4 GPT outlook\"></a>Video 4 GPT outlook</h3><p>Linear Transform -&gt; Softmax -&gt; distribution<br>Few-shot learning, one-shot, zero-shot learning<br>SimCLR, BYOL,<br>Speech GLUE - SUPERB</p>\n<h2 id=\"4-15\"><a href=\"#4-15\" class=\"headerlink\" title=\"4&#x2F;15\"></a>4&#x2F;15</h2><p>????</p>\n<h2 id=\"4-22\"><a href=\"#4-22\" class=\"headerlink\" title=\"4&#x2F;22\"></a>4&#x2F;22</h2><p>Auto encoder</p>\n<h3 id=\"Video-1-basic-idea\"><a href=\"#Video-1-basic-idea\" class=\"headerlink\" title=\"Video 1 basic idea\"></a>Video 1 basic idea</h3><p>same idea with Cycle GAN, embedding, representation, code<br>Dimension reduction: not deep learning based PCA, t-SNE<br>De-noising Auto-encoder</p>\n<p>Video 2-8 are all anomaly detection</p>\n<h3 id=\"Video-2-3\"><a href=\"#Video-2-3\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>Feature disentanglement: know the content of embedding: Voice Conversion<br>Discrete Representation: VQVAE</p>\n<h3 id=\"Video-3-1\"><a href=\"#Video-3-1\" class=\"headerlink\" title=\"Video 3\"></a>Video 3</h3><p>Anomaly detection: other methods outlier, novelty, exception<br>one class classifier: Approach: Auto-encoder</p>\n<h3 id=\"Video-4-1\"><a href=\"#Video-4-1\" class=\"headerlink\" title=\"Video 4\"></a>Video 4</h3><p>A confidence score $c$, a threshold $\\lambda$, smaller than, anomaly.</p>\n<h3 id=\"Video-5-1\"><a href=\"#Video-5-1\" class=\"headerlink\" title=\"Video 5\"></a>Video 5</h3><p>Generating anomaly data</p>\n<h3 id=\"Video-6\"><a href=\"#Video-6\" class=\"headerlink\" title=\"Video 6\"></a>Video 6</h3><p>Without Labels<br><a href=\"https://github.com/ahaque/twitch-troll-detection\">https://github.com/ahaque/twitch-troll-detection</a> </p>\n<h3 id=\"Video-7\"><a href=\"#Video-7\" class=\"headerlink\" title=\"Video 7\"></a>Video 7</h3><p>Gaussian Distribution<br>Assume the data points are samples from a probability density function $f_{\\theta}(x)$<br>$\\theta$ determine the shape of $f_{\\theta}(x)$<br>$L(\\theta)&#x3D;f_{\\theta}(x^1)f_{\\theta}(x^2)…f_{\\theta}(x^N)$<br>$\\theta^* &#x3D; \\arg \\max_\\theta L(\\theta), \\theta&#x3D;(\\mu, \\Sigma)$<br>$f_{\\mu,\\Sigma}(x) &#x3D; \\frac{1}{(2\\pi)^{D&#x2F;2}}\\frac{1}{|\\Sigma|^{1&#x2F;2}} \\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)$</p>\n<h3 id=\"Video-8\"><a href=\"#Video-8\" class=\"headerlink\" title=\"Video 8\"></a>Video 8</h3><p>Auto-encoder</p>\n<h2 id=\"4-29\"><a href=\"#4-29\" class=\"headerlink\" title=\"4&#x2F;29\"></a>4&#x2F;29</h2><h3 id=\"Video-1-Explainable-ML-Local\"><a href=\"#Video-1-Explainable-ML-Local\" class=\"headerlink\" title=\"Video 1 Explainable ML Local\"></a>Video 1 Explainable ML Local</h3><p>Loss of an example: Gradient: Saliency Map<br>Limitation: Noisy Gradient, SmoothGrad<br>MFCC<br>Attention is Explainable<br>Probing: CNN BLSTM</p>\n<h3 id=\"Video-2-Explainable-ML-Global\"><a href=\"#Video-2-Explainable-ML-Global\" class=\"headerlink\" title=\"Video 2 Explainable ML Global\"></a>Video 2 Explainable ML Global</h3><h2 id=\"5-06\"><a href=\"#5-06\" class=\"headerlink\" title=\"5&#x2F;06\"></a>5&#x2F;06</h2><h3 id=\"Video-1-3\"><a href=\"#Video-1-3\" class=\"headerlink\" title=\"Video 1\"></a>Video 1</h3><p>Attack<br>$x^* &#x3D; \\arg_{d(x^0, x)&lt;\\epsilon} \\min L(x)$</p>\n<h4 id=\"Non-targeted\"><a href=\"#Non-targeted\" class=\"headerlink\" title=\"Non-targeted\"></a>Non-targeted</h4><p>$e(,)$ cross entropy<br>$L(x) &#x3D; -e(y, \\hat y)$</p>\n<h4 id=\"Targeted\"><a href=\"#Targeted\" class=\"headerlink\" title=\"Targeted\"></a>Targeted</h4><p>$L(x) &#x3D; -e(y, \\hat y) + e(y, y_{\\text{target}})$<br>$\\hat y$: real case<br>$y_{\\text{target}}$: what you wish to be perceived</p>\n<h4 id=\"Non-perceivable\"><a href=\"#Non-perceivable\" class=\"headerlink\" title=\"Non-perceivable\"></a>Non-perceivable</h4><p>$d(x^0, x) &lt; \\epsilon$,<br>L2-norm, L-infinity</p>\n<h3 id=\"Video-2-4\"><a href=\"#Video-2-4\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>Black box attack: Proxy Network<br>Ensemble Network, one-pixel, universal adversarial attack<br>Beyond Images, speech processing, Natural<br>Adversarial reprogramming<br>Filter</p>\n<h2 id=\"7-03\"><a href=\"#7-03\" class=\"headerlink\" title=\"7&#x2F;03\"></a>7&#x2F;03</h2><p><a href=\"https://www.bilibili.com/video/BV1734y1c7Hb?p=2&spm_id_from=pageDriver&vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1734y1c7Hb?p=2&amp;spm_id_from=pageDriver&amp;vd_source=441679270dda23308fe16f3c5602b058</a></p>\n<h3 id=\"Video-1-Diffusion-Model\"><a href=\"#Video-1-Diffusion-Model\" class=\"headerlink\" title=\"Video 1 Diffusion Model\"></a>Video 1 Diffusion Model</h3><p>Denoise module: picture + noise -&gt; predict noise, then -noise -&gt; picture<br>Train the noise predictor</p>\n<p>Diffuse process: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for step in range(1000): </span><br><span class=\"line\">    generate noise[i] pic[i] = pic[i-1] + noise[i]</span><br><span class=\"line\">train: </span><br><span class=\"line\">    given pic[i-1], pic[i]</span><br><span class=\"line\">    learn noise[i]</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2024-03-08-LHY-ML/image-2.png\" alt=\"alt text\"></p>\n<h3 id=\"Video-2-5\"><a href=\"#Video-2-5\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>Text to picture<br>DALL-E Decoder: Autoregressive&#x2F;Diffusion Model<br>Imagen (Google):</p>\n<p>Framework:<br>Encoder: GPT&#x2F;BERT<br>Encoder -&gt; Generation model (Latent Representation) -&gt; Decoder</p>\n<h3 id=\"Video-3-原理\"><a href=\"#Video-3-原理\" class=\"headerlink\" title=\"Video 3 原理\"></a>Video 3 原理</h3><p>解释 Training， Sampling</p>\n<p>$x_0:$ a picture,</p>\n<p>$x_t:$ pic + noise $t$</p>\n<h3 id=\"Video-4-2\"><a href=\"#Video-4-2\" class=\"headerlink\" title=\"Video 4\"></a>Video 4</h3><p>Maximum likelihood Estimation:<br>$P_{\\text{data}}(x)$ True Distribution of Data<br>$P_{\\theta}(x)$ Probability distribution of data $x$ given parameters $\\theta$<br>${x^1, x^2, \\cdots, x^m}$ Observed data samples</p>\n<p>Network: $z \\rightarrow \\theta \\rightarrow P_{\\theta}(x) \\rightarrow P_{\\text{data}}(x)$<br>maximize $P_{\\theta}(x^1)P_{\\theta}(x^2) \\cdots P_{\\theta}(x^m)$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta \\log P_{\\theta}(x^1)P_{\\theta}(x^2) \\cdots P_{\\theta}(x^m)$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta \\mathbb{E}<em>{x \\sim P</em>{\\text{data}}} \\log P_{\\theta}(x)$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta \\int_{x} P_{\\text{data}}(x) \\log P_{\\theta}(x) dx$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta \\left( \\int_{x} P_{\\text{data}}(x) \\log P_{\\theta}(x) dx - \\int_{x} P_{\\text{data}}(x) \\log P_{\\text{data}}(x) dx \\right)$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta \\int_{x} P_{\\text{data}}(x) \\log \\frac{P_{\\theta}(x)}{P_{\\text{data}}(x)} dx$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta -KL(P_{\\text{data}} || P_{\\theta})$</p>\n<h4 id=\"VAE\"><a href=\"#VAE\" class=\"headerlink\" title=\"VAE\"></a>VAE</h4><p>Compute $P_{\\theta}(x)$<br>Network: $G(z) &#x3D; x$<br>$P_{\\theta}(x) &#x3D; \\int P_{\\theta}(x|z)P_{\\theta}(z) dz$</p>\n<p>$P_{\\theta}(z|x) &#x3D; \\frac{P_{\\theta}(x|z)P_{\\theta}(z)}{P_{\\theta}(x)}$</p>\n<p>DDPM</p>\n<h3 id=\"Video-5-2\"><a href=\"#Video-5-2\" class=\"headerlink\" title=\"Video 5\"></a>Video 5</h3><p>VAE: Variational Auto-encoder<br>$P_{\\theta}(x) &#x3D; \\int P_{\\theta}(x|z)P_{\\theta}(z) dz$<br>$P_{\\theta}(z|x) &#x3D; \\frac{P_{\\theta}(x|z)P_{\\theta}(z)}{P_{\\theta}(x)}$</p>\n<h1 id=\"VAE-1\"><a href=\"#VAE-1\" class=\"headerlink\" title=\"VAE\"></a>VAE</h1><p><a href=\"https://www.bilibili.com/video/BV1yD4y1i7Jm/?p=44&vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1yD4y1i7Jm/?p=44&amp;vd_source=441679270dda23308fe16f3c5602b058</a><br><a href=\"https://www.cnblogs.com/wxkang/p/17128108.html\">https://www.cnblogs.com/wxkang/p/17128108.html</a><br>比较主流的生成模型：HMM, NB, GMM (Gaussian Mixture Model)</p>\n<p>KL divergence: $KL(P||Q) &#x3D; \\int P(x) \\log \\frac{P(x)}{Q(x)} dx$, $KL(P||Q) \\neq KL(Q||P)$</p>\n<p>AE: 与 PCA, SVD 目的相同，矩阵降维技术。</p>\n<p>latent variable $z$, assume it follows the prior distribution of $P(z) \\sim N(0,1)$</p>\n<p>$P(x|z) \\sim N(\\mu(z), \\sigma(z))$ </p>\n<p>$P(x) &#x3D; \\int P(z) P(x|z) dz$</p>\n<p>To Maximize Likelihood of observed $x$: $L &#x3D; \\sum_x \\log P(x)$</p>\n<p>ELBO Evidence Lower Bound</p>\n<h1 id=\"MCMC\"><a href=\"#MCMC\" class=\"headerlink\" title=\"MCMC\"></a>MCMC</h1><p>看不懂：仿佛在谈收敛快慢和平衡状态 $\\pi$ 的问题<br><a href=\"https://zhuanlan.zhihu.com/p/143016455\">https://zhuanlan.zhihu.com/p/143016455</a><br><a href=\"https://www.cnblogs.com/pinard/p/6625739.html\">https://www.cnblogs.com/pinard/p/6625739.html</a></p>\n<h3 id=\"Monte-Carlo-Integration\"><a href=\"#Monte-Carlo-Integration\" class=\"headerlink\" title=\"Monte Carlo Integration\"></a>Monte Carlo Integration</h3><p>If $X$ is uniformly distributed on $[a,b]$:<br>$\\int_a^b f(x)dx &#x3D; \\int_a^b f(x) \\frac{1}{b-a}dx &#x3D; \\mathbb{E}<em>{x \\sim U(a,b)}[f(x)] &#x3D; \\frac{1}{N}\\sum</em>{i&#x3D;1}^N f(x_i)$</p>\n<p>If we know the distribution of $X$ on $[a, b] &#x3D; p(x)$:<br>$\\int_a^b f(x)dx &#x3D; \\int_a^b \\frac{f(x)}{p(x)} p(x) dx &#x3D; \\mathbb{E}<em>{x \\sim p(x)}[f(x)] &#x3D; \\frac{1}{N}\\sum</em>{i&#x3D;1}^N \\frac{f(x_i)}{p(x_i)}$</p>\n<h3 id=\"Acceptance-Rejection-Sampling\"><a href=\"#Acceptance-Rejection-Sampling\" class=\"headerlink\" title=\"Acceptance-Rejection Sampling\"></a>Acceptance-Rejection Sampling</h3><p><a href=\"https://blog.quantitations.com/inference/2012/11/24/rejection-sampling-proof\">https://blog.quantitations.com/inference/2012/11/24/rejection-sampling-proof</a></p>\n<p>方便采样的常用概率分布函数 (proposal distribution) $q(x)$ 以及一个常量 $k$ 使得 $p(x)$ 总在 $k q(x)$ 的下方</p>\n<h3 id=\"MCMC-1\"><a href=\"#MCMC-1\" class=\"headerlink\" title=\"MCMC\"></a>MCMC</h3>","excerpt":"","more":"<p><a href=\"https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php\">https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php</a></p>\n<h2 id=\"2-18\"><a href=\"#2-18\" class=\"headerlink\" title=\"2&#x2F;18\"></a>2&#x2F;18</h2><h3 id=\"Video-2\"><a href=\"#Video-2\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>Piecewise Linear</p>\n<p>$y &#x3D; c * Sigmoid(b+wx_1)$, w, b, c,</p>\n<p>$\\theta$: A vector of all unknown variable<br>Gradient $ g &#x3D;\\nabla L(\\theta^{0}) $<br>$\\eta$: learning rate<br>Batch, update, Epoch</p>\n<p>Activation function:<br>Sigmoid function<br>Rectified Linear Unit (ReLU) max(0, )</p>\n<h3 id=\"Pytorch-1-2\"><a href=\"#Pytorch-1-2\" class=\"headerlink\" title=\"Pytorch 1&#x2F;2\"></a>Pytorch 1&#x2F;2</h3><p>Mainly introduce some practical advice for coding. </p>\n<h3 id=\"Background-propagation\"><a href=\"#Background-propagation\" class=\"headerlink\" title=\"Background propagation\"></a>Background propagation</h3><p>Back Propagation: an efficient way to calculate Gradient Descent:<br>forward pass, backward pass</p>\n<p>没太懂</p>\n<h3 id=\"Predicting-Pokemon-CP\"><a href=\"#Predicting-Pokemon-CP\" class=\"headerlink\" title=\"Predicting Pokémon CP\"></a>Predicting Pokémon CP</h3><p>Regression: difference in origin $x_{cp}$, and species<br>Gradient descent<br>Overfitting Regularization</p>\n<h3 id=\"Pokemon-classification\"><a href=\"#Pokemon-classification\" class=\"headerlink\" title=\"Pokemon classification\"></a>Pokemon classification</h3><h4 id=\"Maximum-Likelihood\"><a href=\"#Maximum-Likelihood\" class=\"headerlink\" title=\"Maximum Likelihood\"></a>Maximum Likelihood</h4><p>2-D Gaussian distribution:<br>$f_{\\mu^1,\\Sigma^1}(x) &#x3D; \\frac{1}{(2\\pi)^{D&#x2F;2}|\\Sigma^1|^{1&#x2F;2}} \\exp\\left(-\\frac{1}{2}(x - \\mu^1)^T(\\Sigma^1)^{-1}(x - \\mu^1)\\right)$</p>\n<p>$\\mu$ mean $\\sum$ covariance<br>$\\mu^1 &#x3D; \\begin{bmatrix}<br>75.0 \\<br>71.3 \\<br>\\end{bmatrix}<br>\\quad<br>\\Sigma^1 &#x3D; \\begin{bmatrix}<br>874 &amp; 327 \\<br>327 &amp; 929 \\<br>\\end{bmatrix}$</p>\n<p>$P(C_1|x) &#x3D; \\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1) + P(x|C_2)P(C_2)}$</p>\n<p>Simplify the function, substitute Gaussian into probability<br>$P(C_1|x)&#x3D;\\sigma(z) &#x3D; \\sigma(wx+b)$<br>$w&#x3D;(\\mu^1-\\mu^2)^T\\sum^{-1}, b&#x3D;…(scalar)$<br>So the Boundary for shared $\\sum$ is linear.</p>\n<h3 id=\"Logistic-Regression\"><a href=\"#Logistic-Regression\" class=\"headerlink\" title=\"Logistic Regression\"></a>Logistic Regression</h3><p>（数学推导比较多）</p>\n<h4 id=\"Loss-function\"><a href=\"#Loss-function\" class=\"headerlink\" title=\"Loss function\"></a>Loss function</h4><p>Cross Entropy for a Bernoulli distribution<br>$H(p,q)&#x3D;−[p\\log(q)+(1−p)\\log(1−q)]$<br>which is better than Square Error. </p>\n<p>Discriminative: Logistic Regression: Directly find $w$ and $b$, which generally have better performance<br>Generative: Gaussian description: Have assumptions (Naive Bayes, or …) of model and find $\\mu^1$, $\\mu^2$, $\\sum$ </p>\n<h4 id=\"Multiclass-Classification\"><a href=\"#Multiclass-Classification\" class=\"headerlink\" title=\"Multiclass Classification\"></a>Multiclass Classification</h4><p>跳过了，想做hw再听，觉得现在对$f_{w, b}(x)$的理解还不深</p>\n<h2 id=\"2-25\"><a href=\"#2-25\" class=\"headerlink\" title=\"2&#x2F;25\"></a>2&#x2F;25</h2><h3 id=\"Video-1\"><a href=\"#Video-1\" class=\"headerlink\" title=\"Video 1\"></a>Video 1</h3><p>Loss on training data large: Model Bias (need a more complex model) or Optimization<br>Loss on testing data large: Overfitting or mismatch -&gt; more data </p>\n<h3 id=\"Video-2-1\"><a href=\"#Video-2-1\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>How to Optimize:<br>$<br>L(\\theta) \\approx L(\\theta’) + (\\theta - \\theta’)^T \\vec{g} + \\frac{1}{2} (\\theta - \\theta’)^T H (\\theta - \\theta’)<br>$<br>Gradient $\\vec{g}$:<br>$\\vec{g} &#x3D; \\nabla L(\\theta’)$<br>$g_i &#x3D; \\frac{\\partial L(\\theta’)}{\\partial \\theta_i}$<br>$\\vec{g} &#x3D;<br>\\begin{bmatrix}<br>\\frac{\\partial L}{\\partial \\theta_1} \\<br>\\frac{\\partial L}{\\partial \\theta_2} \\<br>\\vdots \\<br>\\frac{\\partial L}{\\partial \\theta_n}<br>\\end{bmatrix}$<br>Hessian $H$ is a matrix $H_{ij} &#x3D; \\frac{\\partial^2 L(\\theta’)}{\\partial \\theta_i \\partial \\theta_j}$<br>For all $v$:</p>\n<ol>\n<li>$v^T Hv &gt; 0$: $H$ is positive definite, $L(\\theta) &gt; L(\\theta’)$: Local minima</li>\n<li>$v^T Hv &lt; 0$: $H$ is negative definite, $L(\\theta) &lt; L(\\theta’)$: Local maxima</li>\n<li>Some eigenvalues are $+$, some are $-$: Saddle point<br>Empirical learning:</li>\n</ol>\n<h3 id=\"Video-3\"><a href=\"#Video-3\" class=\"headerlink\" title=\"Video 3\"></a>Video 3</h3><p>Batch: large batch $N$ not necessarily need longer time for gradient computing (parallel computing)</p>\n<h3 id=\"Video-4\"><a href=\"#Video-4\" class=\"headerlink\" title=\"Video 4\"></a>Video 4</h3><p>Adaptive $\\eta$ (learning rate):<br>Error surface<br>Critical points (local minima, saddle point):</p>\n<ol>\n<li>Adagrad </li>\n<li>RMSProp</li>\n<li>Adam: RMSProp + Momentum</li>\n</ol>\n<p>Learning Rate Scheduling:<br>Learning rate Decay<br>Warm up (Residual Network, Transformer Classification)</p>\n<h3 id=\"Video-5\"><a href=\"#Video-5\" class=\"headerlink\" title=\"Video 5\"></a>Video 5</h3><p>Regression:<br>Right answer: $\\hat{y} \\leftrightarrow y$<br>Classification: class: one-hot vector: $\\hat{y} \\leftrightarrow y’ &#x3D; \\text{softmax}(y)$<br>Soft-max (Normalize): $n \\geq 3$: $y_i’ &#x3D; \\frac{\\exp(y_i)}{\\sum_j \\exp(y_j)}$<br>$n&#x3D;2$ $y’ &#x3D; \\text{sigmoid}(y)$</p>\n<p>Distance $e$:<br>Mean Square Error (MSE): $e &#x3D; \\sum (\\hat{y_i} - y_i’)^2$<br>Cross-entropy: $e &#x3D; -\\sum \\hat{y_i} \\ln y_i’$<br>Minimize Cross-entropy $\\leftrightarrow$ Maximize likelihood</p>\n<h3 id=\"Basic-Theory\"><a href=\"#Basic-Theory\" class=\"headerlink\" title=\"Basic Theory\"></a>Basic Theory</h3><p>We want $L(h_{\\text{train}}, D_{\\text{all}}) - L(h_{\\text{all}}, D_{\\text{all}}) \\leq \\delta$<br>$\\forall h \\in \\mathcal{H}, |L(h, D_{\\text{train}}) - L(h, D_{\\text{all}})| \\leq \\frac{\\delta}{2}$</p>\n<h3 id=\"Gradient-Descent\"><a href=\"#Gradient-Descent\" class=\"headerlink\" title=\"Gradient Descent\"></a>Gradient Descent</h3><h3 id=\"Beyond-Adam-1\"><a href=\"#Beyond-Adam-1\" class=\"headerlink\" title=\"Beyond Adam 1\"></a>Beyond Adam 1</h3><h3 id=\"Beyond-Adam-2\"><a href=\"#Beyond-Adam-2\" class=\"headerlink\" title=\"Beyond Adam 2\"></a>Beyond Adam 2</h3><h2 id=\"3-04-CNN\"><a href=\"#3-04-CNN\" class=\"headerlink\" title=\"3&#x2F;04 CNN\"></a>3&#x2F;04 CNN</h2><h3 id=\"Video\"><a href=\"#Video\" class=\"headerlink\" title=\"Video\"></a>Video</h3><p>Image as input</p>\n<h4 id=\"V1\"><a href=\"#V1\" class=\"headerlink\" title=\"V1\"></a>V1</h4><p>Tensor: a Matrix &gt;&#x3D; 3 dimensional  </p>\n<ol>\n<li>Observation 1:<br>Receptive Field: Kernel Size (3x3), Stride (1 or 2, padding 0, hope receptive field are intersecting)  </li>\n<li>Observation 2<br>Shared parameters: filter<br>1 + 2 -&gt; Convolution Layer -&gt; CNN (designed for image)</li>\n</ol>\n<h4 id=\"V2\"><a href=\"#V2\" class=\"headerlink\" title=\"V2\"></a>V2</h4><p>Each filter detects a small pattern (3 * 3 * channel_num, which is a tensor)<br>Feature Map<br>3. Observation 3<br>Max Pooling: Operator<br>Convolutional Layer + Pooling  </p>\n<h3 id=\"Spatial-Transformer-Layer\"><a href=\"#Spatial-Transformer-Layer\" class=\"headerlink\" title=\"Spatial Transformer Layer\"></a>Spatial Transformer Layer</h3><p>CNN is not invariant to scaling and rotation<br>Interpolation.</p>\n<h2 id=\"3-11-Self-attention\"><a href=\"#3-11-Self-attention\" class=\"headerlink\" title=\"3&#x2F;11 Self-attention\"></a>3&#x2F;11 Self-attention</h2><h3 id=\"Video-1-1\"><a href=\"#Video-1-1\" class=\"headerlink\" title=\"Video 1\"></a>Video 1</h3><p>Sequence Labeling<br>Self-Attention: dot product additive </p>\n<h3 id=\"Video-2-2\"><a href=\"#Video-2-2\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>Self-attention<br>Multihead self-attention<br>Truncated self-attention<br>CNN is a simplified self-attention (limited to receptive field)<br>RNN, GNN (Graph Neural Network)</p>\n<h3 id=\"GNN-1\"><a href=\"#GNN-1\" class=\"headerlink\" title=\"GNN 1\"></a>GNN 1</h3><p>Convolution (spatial-based&#x2F;Spectral-based)</p>\n<h4 id=\"Spatial-based\"><a href=\"#Spatial-based\" class=\"headerlink\" title=\"Spatial-based\"></a>Spatial-based</h4><p>Terminology:<br>Aggregate: use neighbor features to update the next hidden state<br>Readout: use all nodes’ features to represent the whole graph<br>NN4G<br>DCNN<br>GAT (Graph Attention Network)<br>Graph Isomorphism Network</p>\n<h3 id=\"GNN-2\"><a href=\"#GNN-2\" class=\"headerlink\" title=\"GNN 2\"></a>GNN 2</h3><p>Deep Graph Library</p>\n<h4 id=\"Graph-Signal-Processing\"><a href=\"#Graph-Signal-Processing\" class=\"headerlink\" title=\"Graph Signal Processing\"></a>Graph Signal Processing</h4><p>Graph Laplacian:<br>Degree Matrix $D$, Adjacency Matrix: $A$, $L$ is an operation on graph<br>$L &#x3D; D - A &#x3D; U \\Lambda U^T$<br>Discrete time Fourier basis $\\lambda$ wave length<br>$(Lf)(v_i) &#x3D; \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))$<br>$\\begin{aligned}<br>f^T L f &amp;&#x3D; \\sum_{v_i \\in V} f(v_i) \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))\\<br>&amp;&#x3D; \\frac{1}{2} \\sum_{v_i \\in V} \\sum_{v_j \\in V} w_{i,j}(f(v_i) - f(v_j))^2<br>\\end{aligned}<br>$</p>\n<p>Graph Fourier Transform of signal $\\hat{x}$: $\\hat{x} &#x3D; U ^T x, \\hat{x}_i &#x3D; u_i \\cdot x$<br>Inverse Graph Fourier Transform of signal $\\hat{x}$: $x &#x3D; U ^T \\hat{x}$</p>\n<p>Filtering: Convolution in time domain is multiplication in frequency domain</p>\n<p>ChebNet<br>听不懂在干什么</p>\n<h4 id=\"Spectral-based\"><a href=\"#Spectral-based\" class=\"headerlink\" title=\"Spectral-based\"></a>Spectral-based</h4><h2 id=\"3-18\"><a href=\"#3-18\" class=\"headerlink\" title=\"3&#x2F;18\"></a>3&#x2F;18</h2><h3 id=\"Video-1-Batch-Normalization\"><a href=\"#Video-1-Batch-Normalization\" class=\"headerlink\" title=\"Video 1 Batch Normalization\"></a>Video 1 Batch Normalization</h3><p>Batch Normalization<br>Internal Covariate Shift</p>\n<h3 id=\"Video-2-Seq2seq\"><a href=\"#Video-2-Seq2seq\" class=\"headerlink\" title=\"Video 2 Seq2seq\"></a>Video 2 Seq2seq</h3><p>Transformer<br>Seq2seq:<br>Chatbox,<br>NLP</p>\n<h2 id=\"Video-3-Decoder\"><a href=\"#Video-3-Decoder\" class=\"headerlink\" title=\"Video 3 Decoder\"></a>Video 3 Decoder</h2><p>Autoregressive<br>Masked Self-attention</p>\n<h2 id=\"NAT-Non-autoregressive-translation\"><a href=\"#NAT-Non-autoregressive-translation\" class=\"headerlink\" title=\"NAT Non autoregressive translation\"></a>NAT Non autoregressive translation</h2><p>像一个NAT发展的论文综述<br>Naive approach,<br>autoregressive,<br>GAN, </p>\n<p>Improvement</p>\n<ol>\n<li>Fertility</li>\n<li>Sequence-level knowledge distillation</li>\n<li>Noisy Parallel Decoding NPD</li>\n</ol>\n<p>Vanilla NAT, Iterative Refinement, Insertion-based, Insertion+Deletion, CTC-based, Masked-predict, Kermit, CTC, LAS, Imputer (CTC+Mask-Predict)</p>\n<h2 id=\"Pointer-Network\"><a href=\"#Pointer-Network\" class=\"headerlink\" title=\"Pointer Network\"></a>Pointer Network</h2><h2 id=\"3-25\"><a href=\"#3-25\" class=\"headerlink\" title=\"3&#x2F;25\"></a>3&#x2F;25</h2><h3 id=\"Video-1-GAN\"><a href=\"#Video-1-GAN\" class=\"headerlink\" title=\"Video 1 GAN\"></a>Video 1 GAN</h3><p>Discriminator</p>\n<h3 id=\"Video-2-GAN\"><a href=\"#Video-2-GAN\" class=\"headerlink\" title=\"Video 2 GAN\"></a>Video 2 GAN</h3><p>JS Divergence<br>$G^*&#x3D; \\arg \\min(G) \\max(D) \\mathcal{V}(G, D)$<br><img src=\"/LHY-ML/image-1.png\" alt=\"alt text\"><br>$JS(P \\parallel Q) &#x3D; \\frac{1}{2} KL(P \\parallel M) + \\frac{1}{2} KL(Q \\parallel M)$<br>$KL(P \\parallel Q) &#x3D; \\sum_{x} P(x) \\log\\left(\\frac{P(x)}{Q(x)}\\right)$</p>\n<p>WGAN\\<br>Wasserstein distance: improve JS divergence: $JS(P_G, P_{\\text{data}}) \\rightarrow W(P_G, P_{\\text{data}})$<br>$\\max_{D \\in 1-\\text{Lipschitz}} \\left{ \\mathbb{E}<em>{x \\sim P</em>{\\text{data}}} [D(x)] - \\mathbb{E}<em>{x \\sim P</em>{G}} [D(x)] \\right}$<br>the $D(x)$ should be smooth enough</p>\n<h3 id=\"Video-3-BERT-anecdote\"><a href=\"#Video-3-BERT-anecdote\" class=\"headerlink\" title=\"Video 3 BERT anecdote\"></a>Video 3 BERT anecdote</h3><p>CBOW (2 transforms): word embedding<br>contextualized word embedding<br>Multi BERT: Zero-shot Reading Comprehension, alignment</p>\n<h3 id=\"Video-4-Cycle-GAN\"><a href=\"#Video-4-Cycle-GAN\" class=\"headerlink\" title=\"Video 4 Cycle GAN\"></a>Video 4 Cycle GAN</h3><p>Cycle&#x2F;Dual&#x2F;Disco GAN: $G_{x\\rightarrow y}$, $G_{y\\rightarrow x}$</p>\n<h3 id=\"The-theory-of-GAN-1\"><a href=\"#The-theory-of-GAN-1\" class=\"headerlink\" title=\"The theory of GAN (1)\"></a>The theory of GAN (1)</h3><p>$\\max_{D} \\mathcal{V}(G, D)$ maximize the discriminator D in GAN  </p>\n<p>$\\mathcal{V}(G, D) &#x3D; \\mathbb{E}<em>{x \\sim P</em>{\\text{data}}} [\\log D(x)] + \\mathbb{E}<em>{x \\sim P</em>{G}} [\\log(1 - D(x))]$<br>$\\mathcal{V}(G, D) &#x3D; \\int_{x} P_{\\text{data}}(x)\\log D(x) , dx + \\int_{x} P_{G}(x)\\log(1 - D(x)) , dx$</p>\n<p>$\\mathcal{V}(G, D) &#x3D; P_{\\text{data}}(x)\\log D(x) + P_{G}(x)\\log(1 - D(x))$ </p>\n<p>$D^*(x) &#x3D; \\frac{P_{\\text{data}}(x)}{P_{\\text{data}}(x) + P_{G}(x)}$</p>\n<h2 id=\"4-01\"><a href=\"#4-01\" class=\"headerlink\" title=\"4&#x2F;01\"></a>4&#x2F;01</h2><h3 id=\"Video-1-2\"><a href=\"#Video-1-2\" class=\"headerlink\" title=\"Video 1\"></a>Video 1</h3><p>Self-supervised Learning</p>\n<h3 id=\"Video-2-BERT-intro\"><a href=\"#Video-2-BERT-intro\" class=\"headerlink\" title=\"Video 2 BERT intro\"></a>Video 2 BERT intro</h3><p>Masking Input: Mask<br>Next Sentence Prediction: [CLS] sentence 1. [SEP] sentence 2.<br>Pre-trained Fine-tune for Downstream Tasks:<br>GLUE: General Language Understanding Evaluation<br>in seq, out class: sentiment analysis<br>in seq ((n)), out seq (n): POG tagging<br>in 2 seqs, out class: NLI Natural language inference<br>in seqs, out seqs: QA Extract-based Question Answer</p>\n<p>MASS\\ BART T5, C4 (open sourced resource)</p>\n<h3 id=\"Video-3-BERT-anecdote-1\"><a href=\"#Video-3-BERT-anecdote-1\" class=\"headerlink\" title=\"Video 3 BERT anecdote\"></a>Video 3 BERT anecdote</h3><p>Same with above</p>\n<h3 id=\"Video-4-GPT-outlook\"><a href=\"#Video-4-GPT-outlook\" class=\"headerlink\" title=\"Video 4 GPT outlook\"></a>Video 4 GPT outlook</h3><p>Linear Transform -&gt; Softmax -&gt; distribution<br>Few-shot learning, one-shot, zero-shot learning<br>SimCLR, BYOL,<br>Speech GLUE - SUPERB</p>\n<h2 id=\"4-15\"><a href=\"#4-15\" class=\"headerlink\" title=\"4&#x2F;15\"></a>4&#x2F;15</h2><p>????</p>\n<h2 id=\"4-22\"><a href=\"#4-22\" class=\"headerlink\" title=\"4&#x2F;22\"></a>4&#x2F;22</h2><p>Auto encoder</p>\n<h3 id=\"Video-1-basic-idea\"><a href=\"#Video-1-basic-idea\" class=\"headerlink\" title=\"Video 1 basic idea\"></a>Video 1 basic idea</h3><p>same idea with Cycle GAN, embedding, representation, code<br>Dimension reduction: not deep learning based PCA, t-SNE<br>De-noising Auto-encoder</p>\n<p>Video 2-8 are all anomaly detection</p>\n<h3 id=\"Video-2-3\"><a href=\"#Video-2-3\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>Feature disentanglement: know the content of embedding: Voice Conversion<br>Discrete Representation: VQVAE</p>\n<h3 id=\"Video-3-1\"><a href=\"#Video-3-1\" class=\"headerlink\" title=\"Video 3\"></a>Video 3</h3><p>Anomaly detection: other methods outlier, novelty, exception<br>one class classifier: Approach: Auto-encoder</p>\n<h3 id=\"Video-4-1\"><a href=\"#Video-4-1\" class=\"headerlink\" title=\"Video 4\"></a>Video 4</h3><p>A confidence score $c$, a threshold $\\lambda$, smaller than, anomaly.</p>\n<h3 id=\"Video-5-1\"><a href=\"#Video-5-1\" class=\"headerlink\" title=\"Video 5\"></a>Video 5</h3><p>Generating anomaly data</p>\n<h3 id=\"Video-6\"><a href=\"#Video-6\" class=\"headerlink\" title=\"Video 6\"></a>Video 6</h3><p>Without Labels<br><a href=\"https://github.com/ahaque/twitch-troll-detection\">https://github.com/ahaque/twitch-troll-detection</a> </p>\n<h3 id=\"Video-7\"><a href=\"#Video-7\" class=\"headerlink\" title=\"Video 7\"></a>Video 7</h3><p>Gaussian Distribution<br>Assume the data points are samples from a probability density function $f_{\\theta}(x)$<br>$\\theta$ determine the shape of $f_{\\theta}(x)$<br>$L(\\theta)&#x3D;f_{\\theta}(x^1)f_{\\theta}(x^2)…f_{\\theta}(x^N)$<br>$\\theta^* &#x3D; \\arg \\max_\\theta L(\\theta), \\theta&#x3D;(\\mu, \\Sigma)$<br>$f_{\\mu,\\Sigma}(x) &#x3D; \\frac{1}{(2\\pi)^{D&#x2F;2}}\\frac{1}{|\\Sigma|^{1&#x2F;2}} \\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)$</p>\n<h3 id=\"Video-8\"><a href=\"#Video-8\" class=\"headerlink\" title=\"Video 8\"></a>Video 8</h3><p>Auto-encoder</p>\n<h2 id=\"4-29\"><a href=\"#4-29\" class=\"headerlink\" title=\"4&#x2F;29\"></a>4&#x2F;29</h2><h3 id=\"Video-1-Explainable-ML-Local\"><a href=\"#Video-1-Explainable-ML-Local\" class=\"headerlink\" title=\"Video 1 Explainable ML Local\"></a>Video 1 Explainable ML Local</h3><p>Loss of an example: Gradient: Saliency Map<br>Limitation: Noisy Gradient, SmoothGrad<br>MFCC<br>Attention is Explainable<br>Probing: CNN BLSTM</p>\n<h3 id=\"Video-2-Explainable-ML-Global\"><a href=\"#Video-2-Explainable-ML-Global\" class=\"headerlink\" title=\"Video 2 Explainable ML Global\"></a>Video 2 Explainable ML Global</h3><h2 id=\"5-06\"><a href=\"#5-06\" class=\"headerlink\" title=\"5&#x2F;06\"></a>5&#x2F;06</h2><h3 id=\"Video-1-3\"><a href=\"#Video-1-3\" class=\"headerlink\" title=\"Video 1\"></a>Video 1</h3><p>Attack<br>$x^* &#x3D; \\arg_{d(x^0, x)&lt;\\epsilon} \\min L(x)$</p>\n<h4 id=\"Non-targeted\"><a href=\"#Non-targeted\" class=\"headerlink\" title=\"Non-targeted\"></a>Non-targeted</h4><p>$e(,)$ cross entropy<br>$L(x) &#x3D; -e(y, \\hat y)$</p>\n<h4 id=\"Targeted\"><a href=\"#Targeted\" class=\"headerlink\" title=\"Targeted\"></a>Targeted</h4><p>$L(x) &#x3D; -e(y, \\hat y) + e(y, y_{\\text{target}})$<br>$\\hat y$: real case<br>$y_{\\text{target}}$: what you wish to be perceived</p>\n<h4 id=\"Non-perceivable\"><a href=\"#Non-perceivable\" class=\"headerlink\" title=\"Non-perceivable\"></a>Non-perceivable</h4><p>$d(x^0, x) &lt; \\epsilon$,<br>L2-norm, L-infinity</p>\n<h3 id=\"Video-2-4\"><a href=\"#Video-2-4\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>Black box attack: Proxy Network<br>Ensemble Network, one-pixel, universal adversarial attack<br>Beyond Images, speech processing, Natural<br>Adversarial reprogramming<br>Filter</p>\n<h2 id=\"7-03\"><a href=\"#7-03\" class=\"headerlink\" title=\"7&#x2F;03\"></a>7&#x2F;03</h2><p><a href=\"https://www.bilibili.com/video/BV1734y1c7Hb?p=2&spm_id_from=pageDriver&vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1734y1c7Hb?p=2&amp;spm_id_from=pageDriver&amp;vd_source=441679270dda23308fe16f3c5602b058</a></p>\n<h3 id=\"Video-1-Diffusion-Model\"><a href=\"#Video-1-Diffusion-Model\" class=\"headerlink\" title=\"Video 1 Diffusion Model\"></a>Video 1 Diffusion Model</h3><p>Denoise module: picture + noise -&gt; predict noise, then -noise -&gt; picture<br>Train the noise predictor</p>\n<p>Diffuse process: </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for step in range(1000): </span><br><span class=\"line\">    generate noise[i] pic[i] = pic[i-1] + noise[i]</span><br><span class=\"line\">train: </span><br><span class=\"line\">    given pic[i-1], pic[i]</span><br><span class=\"line\">    learn noise[i]</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2024-03-08-LHY-ML/image-2.png\" alt=\"alt text\"></p>\n<h3 id=\"Video-2-5\"><a href=\"#Video-2-5\" class=\"headerlink\" title=\"Video 2\"></a>Video 2</h3><p>Text to picture<br>DALL-E Decoder: Autoregressive&#x2F;Diffusion Model<br>Imagen (Google):</p>\n<p>Framework:<br>Encoder: GPT&#x2F;BERT<br>Encoder -&gt; Generation model (Latent Representation) -&gt; Decoder</p>\n<h3 id=\"Video-3-原理\"><a href=\"#Video-3-原理\" class=\"headerlink\" title=\"Video 3 原理\"></a>Video 3 原理</h3><p>解释 Training， Sampling</p>\n<p>$x_0:$ a picture,</p>\n<p>$x_t:$ pic + noise $t$</p>\n<h3 id=\"Video-4-2\"><a href=\"#Video-4-2\" class=\"headerlink\" title=\"Video 4\"></a>Video 4</h3><p>Maximum likelihood Estimation:<br>$P_{\\text{data}}(x)$ True Distribution of Data<br>$P_{\\theta}(x)$ Probability distribution of data $x$ given parameters $\\theta$<br>${x^1, x^2, \\cdots, x^m}$ Observed data samples</p>\n<p>Network: $z \\rightarrow \\theta \\rightarrow P_{\\theta}(x) \\rightarrow P_{\\text{data}}(x)$<br>maximize $P_{\\theta}(x^1)P_{\\theta}(x^2) \\cdots P_{\\theta}(x^m)$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta \\log P_{\\theta}(x^1)P_{\\theta}(x^2) \\cdots P_{\\theta}(x^m)$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta \\mathbb{E}<em>{x \\sim P</em>{\\text{data}}} \\log P_{\\theta}(x)$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta \\int_{x} P_{\\text{data}}(x) \\log P_{\\theta}(x) dx$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta \\left( \\int_{x} P_{\\text{data}}(x) \\log P_{\\theta}(x) dx - \\int_{x} P_{\\text{data}}(x) \\log P_{\\text{data}}(x) dx \\right)$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta \\int_{x} P_{\\text{data}}(x) \\log \\frac{P_{\\theta}(x)}{P_{\\text{data}}(x)} dx$</p>\n<p>$\\theta^* &#x3D; \\arg \\max_\\theta -KL(P_{\\text{data}} || P_{\\theta})$</p>\n<h4 id=\"VAE\"><a href=\"#VAE\" class=\"headerlink\" title=\"VAE\"></a>VAE</h4><p>Compute $P_{\\theta}(x)$<br>Network: $G(z) &#x3D; x$<br>$P_{\\theta}(x) &#x3D; \\int P_{\\theta}(x|z)P_{\\theta}(z) dz$</p>\n<p>$P_{\\theta}(z|x) &#x3D; \\frac{P_{\\theta}(x|z)P_{\\theta}(z)}{P_{\\theta}(x)}$</p>\n<p>DDPM</p>\n<h3 id=\"Video-5-2\"><a href=\"#Video-5-2\" class=\"headerlink\" title=\"Video 5\"></a>Video 5</h3><p>VAE: Variational Auto-encoder<br>$P_{\\theta}(x) &#x3D; \\int P_{\\theta}(x|z)P_{\\theta}(z) dz$<br>$P_{\\theta}(z|x) &#x3D; \\frac{P_{\\theta}(x|z)P_{\\theta}(z)}{P_{\\theta}(x)}$</p>\n<h1 id=\"VAE-1\"><a href=\"#VAE-1\" class=\"headerlink\" title=\"VAE\"></a>VAE</h1><p><a href=\"https://www.bilibili.com/video/BV1yD4y1i7Jm/?p=44&vd_source=441679270dda23308fe16f3c5602b058\">https://www.bilibili.com/video/BV1yD4y1i7Jm/?p=44&amp;vd_source=441679270dda23308fe16f3c5602b058</a><br><a href=\"https://www.cnblogs.com/wxkang/p/17128108.html\">https://www.cnblogs.com/wxkang/p/17128108.html</a><br>比较主流的生成模型：HMM, NB, GMM (Gaussian Mixture Model)</p>\n<p>KL divergence: $KL(P||Q) &#x3D; \\int P(x) \\log \\frac{P(x)}{Q(x)} dx$, $KL(P||Q) \\neq KL(Q||P)$</p>\n<p>AE: 与 PCA, SVD 目的相同，矩阵降维技术。</p>\n<p>latent variable $z$, assume it follows the prior distribution of $P(z) \\sim N(0,1)$</p>\n<p>$P(x|z) \\sim N(\\mu(z), \\sigma(z))$ </p>\n<p>$P(x) &#x3D; \\int P(z) P(x|z) dz$</p>\n<p>To Maximize Likelihood of observed $x$: $L &#x3D; \\sum_x \\log P(x)$</p>\n<p>ELBO Evidence Lower Bound</p>\n<h1 id=\"MCMC\"><a href=\"#MCMC\" class=\"headerlink\" title=\"MCMC\"></a>MCMC</h1><p>看不懂：仿佛在谈收敛快慢和平衡状态 $\\pi$ 的问题<br><a href=\"https://zhuanlan.zhihu.com/p/143016455\">https://zhuanlan.zhihu.com/p/143016455</a><br><a href=\"https://www.cnblogs.com/pinard/p/6625739.html\">https://www.cnblogs.com/pinard/p/6625739.html</a></p>\n<h3 id=\"Monte-Carlo-Integration\"><a href=\"#Monte-Carlo-Integration\" class=\"headerlink\" title=\"Monte Carlo Integration\"></a>Monte Carlo Integration</h3><p>If $X$ is uniformly distributed on $[a,b]$:<br>$\\int_a^b f(x)dx &#x3D; \\int_a^b f(x) \\frac{1}{b-a}dx &#x3D; \\mathbb{E}<em>{x \\sim U(a,b)}[f(x)] &#x3D; \\frac{1}{N}\\sum</em>{i&#x3D;1}^N f(x_i)$</p>\n<p>If we know the distribution of $X$ on $[a, b] &#x3D; p(x)$:<br>$\\int_a^b f(x)dx &#x3D; \\int_a^b \\frac{f(x)}{p(x)} p(x) dx &#x3D; \\mathbb{E}<em>{x \\sim p(x)}[f(x)] &#x3D; \\frac{1}{N}\\sum</em>{i&#x3D;1}^N \\frac{f(x_i)}{p(x_i)}$</p>\n<h3 id=\"Acceptance-Rejection-Sampling\"><a href=\"#Acceptance-Rejection-Sampling\" class=\"headerlink\" title=\"Acceptance-Rejection Sampling\"></a>Acceptance-Rejection Sampling</h3><p><a href=\"https://blog.quantitations.com/inference/2012/11/24/rejection-sampling-proof\">https://blog.quantitations.com/inference/2012/11/24/rejection-sampling-proof</a></p>\n<p>方便采样的常用概率分布函数 (proposal distribution) $q(x)$ 以及一个常量 $k$ 使得 $p(x)$ 总在 $k q(x)$ 的下方</p>\n<h3 id=\"MCMC-1\"><a href=\"#MCMC-1\" class=\"headerlink\" title=\"MCMC\"></a>MCMC</h3>"},{"title":"2025-04-01-Linux-server-proxy-issue","date":"2025-04-01T19:23:11.000Z","_content":"\n今天试图解决国内服务器网络连接国外网站失败问题。\n\n我是mac m3 pro芯片。\n\n首先在linux服务器上安装aria2。\n\n## aria2 下载\n如果有sudo权限，就很简单。\n```\nsudo apt install aria2\n```\n\n如果没有，\naria2最新版本可查看：https://github.com/aria2/aria2/releases/  可以将release-1.37.0换成最新版本\n\n太长不看简略版\n```\ncd ~\nwget https://github.com/aria2/aria2/releases/download/release-1.37.0/aria2-1.37.0.tar.gz\ntar -xzvf aria2-1.37.0.tar.gz\ncd aria2-1.37.0\n\n./configure --prefix=$HOME/.local\n\nmake -j$(nproc)       # 使用多核加速编译\nmake install          # 安装到 ~/.local\n\necho 'export PATH=\"$HOME/.local/bin:$PATH\"' >> ~/.bashrc\nsource ~/.bashrc     # 立即生效\n\naria2c --version\n\n```\n\n\n\n\n## m3 microsocks 下载\n(~~我也不知道为什么只能ssh~~)\n\n```\ngit clone git@github.com:rofl0r/microsocks.git\ncd microsocks\n```\n\n因为我是m3芯片所以make会不同\n``` make CC=clang ```\n如果是x86之类，这样就可以\n```make```\n\n运行\n```\n./microsocks -p 1080\n```","source":"_posts/2025-04-01-Linux-server-proxy-issue.md","raw":"---\ntitle: 2025-04-01-Linux-server-proxy-issue\ndate: 2025-04-01 15:23:11\ntags:\n---\n\n今天试图解决国内服务器网络连接国外网站失败问题。\n\n我是mac m3 pro芯片。\n\n首先在linux服务器上安装aria2。\n\n## aria2 下载\n如果有sudo权限，就很简单。\n```\nsudo apt install aria2\n```\n\n如果没有，\naria2最新版本可查看：https://github.com/aria2/aria2/releases/  可以将release-1.37.0换成最新版本\n\n太长不看简略版\n```\ncd ~\nwget https://github.com/aria2/aria2/releases/download/release-1.37.0/aria2-1.37.0.tar.gz\ntar -xzvf aria2-1.37.0.tar.gz\ncd aria2-1.37.0\n\n./configure --prefix=$HOME/.local\n\nmake -j$(nproc)       # 使用多核加速编译\nmake install          # 安装到 ~/.local\n\necho 'export PATH=\"$HOME/.local/bin:$PATH\"' >> ~/.bashrc\nsource ~/.bashrc     # 立即生效\n\naria2c --version\n\n```\n\n\n\n\n## m3 microsocks 下载\n(~~我也不知道为什么只能ssh~~)\n\n```\ngit clone git@github.com:rofl0r/microsocks.git\ncd microsocks\n```\n\n因为我是m3芯片所以make会不同\n``` make CC=clang ```\n如果是x86之类，这样就可以\n```make```\n\n运行\n```\n./microsocks -p 1080\n```","slug":"2025-04-01-Linux-server-proxy-issue","published":1,"updated":"2025-04-02T23:32:10.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagt0001wzc3ddo0nd80h","content":"<p>今天试图解决国内服务器网络连接国外网站失败问题。</p>\n<p>我是mac m3 pro芯片。</p>\n<p>首先在linux服务器上安装aria2。</p>\n<h2 id=\"aria2-下载\"><a href=\"#aria2-下载\" class=\"headerlink\" title=\"aria2 下载\"></a>aria2 下载</h2><p>如果有sudo权限，就很简单。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install aria2</span><br></pre></td></tr></table></figure>\n\n<p>如果没有，<br>aria2最新版本可查看：<a href=\"https://github.com/aria2/aria2/releases/\">https://github.com/aria2/aria2/releases/</a>  可以将release-1.37.0换成最新版本</p>\n<p>太长不看简略版</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~</span><br><span class=\"line\">wget https://github.com/aria2/aria2/releases/download/release-1.37.0/aria2-1.37.0.tar.gz</span><br><span class=\"line\">tar -xzvf aria2-1.37.0.tar.gz</span><br><span class=\"line\">cd aria2-1.37.0</span><br><span class=\"line\"></span><br><span class=\"line\">./configure --prefix=$HOME/.local</span><br><span class=\"line\"></span><br><span class=\"line\">make -j$(nproc)       # 使用多核加速编译</span><br><span class=\"line\">make install          # 安装到 ~/.local</span><br><span class=\"line\"></span><br><span class=\"line\">echo &#x27;export PATH=&quot;$HOME/.local/bin:$PATH&quot;&#x27; &gt;&gt; ~/.bashrc</span><br><span class=\"line\">source ~/.bashrc     # 立即生效</span><br><span class=\"line\"></span><br><span class=\"line\">aria2c --version</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n\n<h2 id=\"m3-microsocks-下载\"><a href=\"#m3-microsocks-下载\" class=\"headerlink\" title=\"m3 microsocks 下载\"></a>m3 microsocks 下载</h2><p>(<del>我也不知道为什么只能ssh</del>)</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone git@github.com:rofl0r/microsocks.git</span><br><span class=\"line\">cd microsocks</span><br></pre></td></tr></table></figure>\n\n<p>因为我是m3芯片所以make会不同<br><code>make CC=clang</code><br>如果是x86之类，这样就可以<br><code>make</code></p>\n<p>运行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./microsocks -p 1080</span><br></pre></td></tr></table></figure>","excerpt":"","more":"<p>今天试图解决国内服务器网络连接国外网站失败问题。</p>\n<p>我是mac m3 pro芯片。</p>\n<p>首先在linux服务器上安装aria2。</p>\n<h2 id=\"aria2-下载\"><a href=\"#aria2-下载\" class=\"headerlink\" title=\"aria2 下载\"></a>aria2 下载</h2><p>如果有sudo权限，就很简单。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install aria2</span><br></pre></td></tr></table></figure>\n\n<p>如果没有，<br>aria2最新版本可查看：<a href=\"https://github.com/aria2/aria2/releases/\">https://github.com/aria2/aria2/releases/</a>  可以将release-1.37.0换成最新版本</p>\n<p>太长不看简略版</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd ~</span><br><span class=\"line\">wget https://github.com/aria2/aria2/releases/download/release-1.37.0/aria2-1.37.0.tar.gz</span><br><span class=\"line\">tar -xzvf aria2-1.37.0.tar.gz</span><br><span class=\"line\">cd aria2-1.37.0</span><br><span class=\"line\"></span><br><span class=\"line\">./configure --prefix=$HOME/.local</span><br><span class=\"line\"></span><br><span class=\"line\">make -j$(nproc)       # 使用多核加速编译</span><br><span class=\"line\">make install          # 安装到 ~/.local</span><br><span class=\"line\"></span><br><span class=\"line\">echo &#x27;export PATH=&quot;$HOME/.local/bin:$PATH&quot;&#x27; &gt;&gt; ~/.bashrc</span><br><span class=\"line\">source ~/.bashrc     # 立即生效</span><br><span class=\"line\"></span><br><span class=\"line\">aria2c --version</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n\n<h2 id=\"m3-microsocks-下载\"><a href=\"#m3-microsocks-下载\" class=\"headerlink\" title=\"m3 microsocks 下载\"></a>m3 microsocks 下载</h2><p>(<del>我也不知道为什么只能ssh</del>)</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone git@github.com:rofl0r/microsocks.git</span><br><span class=\"line\">cd microsocks</span><br></pre></td></tr></table></figure>\n\n<p>因为我是m3芯片所以make会不同<br><code>make CC=clang</code><br>如果是x86之类，这样就可以<br><code>make</code></p>\n<p>运行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./microsocks -p 1080</span><br></pre></td></tr></table></figure>"},{"title":"2025-01-29-CV","date":"2025-01-29T21:02:37.000Z","_content":"\n我觉得教授说的很有道理。 First use simple cases as examples, then gradually increase the difficulty.\nFor example the gradient descent. Use 2 * 2 as example, then others. \n\n## U-Net 论文阅读\nhttps://github.com/zhixuhao/unet\n\n### Terms\nImage segmentation: assign every pixel a label \\\n\n\n### Motivation\nPrevious method:\n- Ciresan et al. : Purely CNN (?)\n    - slow: redundancy of patches\n    - trade-off between localization accuracy and the use of context\n\n### Propose method: \nFully CN:\n-  pooling op are replaced by upsampling op:  increase the resolution\n- \n\n(excessive) Date Augmentation: elastic deformation\n- \n\n### Results\n- Pixel error: compare 2 pic\n- Rand Error\n\n## 期末\n吗的，没有认真听过一节课。我真恶心。\n以下是期末复习计划： 1.先把所有的作业看懂。然后理一下作业里的知识点和公式。不能带cheatsheeet所以玩啦\ncv复习技巧\n1. 以作业为主。把作业每题都手作一遍。\n2. 看讲义。讲义里很多重要的公式（不要看太细，重点看作业里出现的）\n3. 考完试把cv的作业都补一遍。\n\n感觉要考quiz的原题。可能要看一遍，不然这门课就完了。\n复习微积分，线性代数。\n\n\n## hw 1\nexam style problem:\n1, 2, 3.1\n\n### 1. cor/conv\nCorrelation:\ncorrelation coefficient \ncorrelation formula at position $i = \\sum_{j=0}^{k-1} I[i + j] \\cdot H[j]$\n\nconvolution:$i = \\sum_{j=0}^{k-1} I[i - j] \\cdot H[j]$\nfull/valid/same\n大小 valid < same < full\n\n\n### 2. smoothing\ngaussian(u, v) =def= e...\nseperability与简便计算\n\n### 2. differentiation\n#### def\n区分\nfinite difference: $I_c(r, c) \\approx I(r, c + 1) - I(r, c)$\ncentral difference: $I_c(r, c) \\approx \\frac{I(r, c+1) - I(r, c-1)}{2}$\n\n#### sobel filter\n不要忘记系数啊。。。（normalize系数可以保证亮度正常\nsmoothing $s =\\frac{1}{4} \\begin{bmatrix} 1, 2, 1 \\end{bmatrix}^T$\ndifferentiation: $d =\\frac{1}{2} \\begin{bmatrix} 1, 0, -1 \\end{bmatrix}^T $\n$v=s^Td, h=d^Ts$\n\nsepearable\n![alt text](image.png)晕\n\n### 3. interpolation(x)\n点的权重为对角正方形的面积\nbilinear; \n$\\delta a = a - \\lfloor a \\rfloor$, $\\delta b = b - \\lfloor b \\rfloor$\n$\\begin{aligned}\nI(a,b) &= I(\\lfloor a \\rfloor, \\lfloor b \\rfloor)(1 - \\delta a)(1 - \\delta b) \\\\\n&+ I(\\lfloor a \\rfloor, \\lfloor b \\rfloor + 1)(1 - \\delta a)\\delta b \\\\\n&+ I(\\lfloor a \\rfloor + 1, \\lfloor b \\rfloor)\\delta a(1 - \\delta b) \\\\\n&+ I(\\lfloor a \\rfloor + 1, \\lfloor b \\rfloor + 1)\\delta a\\delta b\n\\end{aligned}$\n\n\n\n## hw 2\nexam problem:\n1.1 - 1.8 ， 3.1， 4.1\n给f(x, y)\n1.1. 求gradient $\\nabla f=$\n1.2 stationary point 判定(local max/min/saddle) D= f_xx * f_yy-f_xy^2\n1.3 ordinary gradient descent\n1.4 gradient descent with momentum\n1.5 step of Newton's method\n1.6 1. 哪个离真实值更近2. Gauss-Newton method 是否可用\n1.7 GD的convergence point\n1.8 数值精度是否影响收敛\n\n3.1 SGD 手算\n一个数据点？\n\n4.1\nSG和batch\n\n\nconcepts\njacobian: 一阶导, hessian: 二阶导\n### notation:\nrisk function(给定f(x)) = loss function(未知fx？)\nfirst-order gradient descent 只是近似\n    how to derive step size $\\alpha_k$\n        fix \n        adam?\n        momentum\n    how to determine the local min\n        line search\n    terminaltion check\n    SGD\n        mini batch average\n        epoch \nsecond-order\n    Newton's method\n        Hessian\n        positive-definite: asymptotically faster convergence\n    Newton-Raphson method:\n        f shuold be convex\n\n### formula\n$\\nabla f(x,y)= \\begin{bmatrix}\\frac{\\partial f}{\\partial x}\\\\[6pt]\\frac{\\partial f}{\\partial y}\\end{bmatrix}$\n\n$H_f(x,y)=\\begin{bmatrix}\\frac{\\partial^2 f}{\\partial x^2} & \\frac{\\partial^2 f}{\\partial x\\partial y}\\\\[6pt]\\frac{\\partial^2 f}{\\partial y\\partial x} & \\frac{\\partial^2 f}{\\partial y^2}\\end{bmatrix}$\n\n$p_{k+1} = \\mu p_k - \\alpha_k \\nabla f(x_k)$\n$x_{k+1} = x_k + p_{k+1}$\n$x_k$是位置，$p_k$是momentum，$\\alpha_k$是步长，$\\nabla f(x_k)$是梯度， \nsince starts with zero velocity,$p_0=0$\n\n$\\phi_n$ loss, risk = loss function\n\n$f(\\mathbf{z})$ risk\n$\\mathbf{g}_0=\\nabla f(\\mathbf{z}_0)$ gradient\n$H(\\mathbf{z}_0)$ curvature of f near z0\n$H(\\mathbf{z}_0) = \\left[ \\frac{\\partial^2 f}{\\partial z_i \\partial z_j} \\right]_{\\mathbf{z} = \\mathbf{z}_0}$\n\nNewton Method\n$f(\\mathbf{z}) \\approx f(\\mathbf{z}_0) + \\nabla f(\\mathbf{z}_0)^T (\\mathbf{z} - \\mathbf{z}_0) + \\frac{1}{2} (\\mathbf{z} - \\mathbf{z}_0)^T H(\\mathbf{z}_0) (\\mathbf{z} - \\mathbf{z}_0)$\n\n$H_0 \\Delta \\mathbf{z}_0 = -\\mathbf{g}_0\n\\Rightarrow\n\\Delta \\mathbf{z}_0=z-z_0 = - H_0^{-1} \\mathbf{g}_0$\n\nNewton-rapthon\n$f(\\mathbf{z}) = \\sum_{n=1}^{N} \\phi_n^2(\\mathbf{z})$\n\n\n## hw3\n1    2.1-2    3.1\n1.1 求矩阵row/null space的unit vector\n1.2 x使x^2最小\n1.3 求x解集\n1.5 bcce 待公式\n1.6 Lucas-Kanade tracker\n\n\n\n\n\n\n### concept\n#### BCCE的前提假设\n如果一个点在现实世界中移动，它的亮度在图像中是不会变的\n公式表达；$a(t) = e(x(t), t)\\Rightarrow \\frac{da(t)}{dt} = 0$\n![alt text](2025-01-29-CV/image.png)\n$\\frac{d}{dt} a(t) = 0\n\\Rightarrow \n\\frac{\\partial e}{\\partial x^T} \\cdot \\frac{dx}{dt} + \\frac{\\partial e}{\\partial t} = 0$\n\nu: image velocity\n$\\delta x$ displacemen\nu=$\\delta x / \\delta t$, $\\delta t \\to\\infty$\n\n$u\\nabla e(x)/|\\nabla e(x)|$\nnormal component $\\nu =def=n(x)^{\\top}u(x)$\n\n#### apreture probelm\nBCCE是标量方程， $u = (u_x, u_y)^T$是二维，所以只能知道u的方向...\nMotion Field\t真实世界中物体运动在图像上的投影（我们想知道的）\nOptical Flow\t我们从图像中通过亮度变化估计到的速度（我们能观测到的）\n$\\nu(x) = \\mathbf{n}(x)^T u(x)$ 提督方向*\n$\\nu(x)$ 某个pixel速度沿着这个方向的“可观测分量”。\n只能知道u的方向。  \nthe normal compenet of motion $\\nu$\n\n因为们不能只靠一个像素就估计出完整的运动向量，所以用一个整体的方法去估计图像中所有像素的运动向量（光流）Optical flow\n1 data term: $E_\\text{data} = \\sum_{x} \\left( \\frac{\\partial e}{\\partial x} \\cdot u(x) + \\frac{\\partial e}{\\partial t} \\right)^2$满足BCCE function\n2 smoothness term: $E_\\text{smooth} = \\sum_{x} \\left( \\frac{\\partial u_x}{\\partial x} + \\frac{\\partial u_y}{\\partial y} \\right)^2$\n$E = \\lambda E_\\text{data} + (1 - \\lambda) E_\\text{smooth}$\n可能的缺点Tend to blur the solution near motion boundaries\n\n\n#### Local support motion estimation (using tracking windows)\nx是二维坐标$x \\in \\mathbb{R}^2$, f(x), g(x)是两幅图像\n我们把一个local的小窗口看作一个整体, 从x_f移动到x_g=x_f+d, 对应的图像是f(x_f)和g(x_f+d),枚举周围的x，计算平方loss，权重和距离有关 w(x-x_f)\n$W(x_f)$是个集合={pixel in window}\n$w(x) = \\begin{cases}1 & \\text{if } |x_1| \\le h \\text{ and } |x_2| \\le h \\\\0 & \\text{otherwise}\\end{cases}$只是定义窗口时2h+1 ^2的小正方形\n\n高斯，只是换种w\n$w(x) \\propto \\begin{cases}e^{- \\frac{1}{2} \\left( \\frac{\\|x\\|}{\\sigma} \\right)^2 } & \\text{if } |x_1| \\le h, |x_2| \\le h \\\\0 & \\text{otherwise}\\end{cases}$\n\n1. grid search x\n2. Lucas-kanade tracker(using Newton-Raphson)\nGoal \n    find d that min $L(\\mathbf{d}) = \\sum_x [g(x + \\mathbf{d}) - f(x)]^2 w(x - x_f)$ \\\n    线性近似$g(x + \\mathbf{d}) \\approx g(x) + \\nabla g(x)^T \\mathbf{d}$\n    $L(\\mathbf{d}) \\approx \\mathbf{d}^T A \\mathbf{d} - 2 \\mathbf{b}^T \\mathbf{d} + \\text{const}$\n    L'(d)=0得到$A \\mathbf{d} = \\mathbf{b}$\n    因为是近似的，我们不能一次算出真正的$\\mathbf{d}^*$\n\n详细计算(感觉这里写的不对，应该改一下推导过程...)\n$L(\\mathbf{d}) \\approx \\sum_x \\left[\\nabla g(x)^T \\mathbf{d} + g(x) - f(x)\\right]^2 w(x - x_f)$\n$L(\\mathbf{d}) = \\mathbf{d}^T A \\mathbf{d} - 2 \\mathbf{b}^T \\mathbf{d} + \\text{const}$\n$A = \\sum_x \\nabla g(x) \\nabla g(x)^T w(x - x_f)$\n$\\mathbf{b} = \\sum_x \\nabla g(x) [f(x) - g(x)] w(x - x_f)$\n$\\nabla g(x) \\in \\mathbb{R}^2$, $\\nabla g(x) \\nabla g(x)^T$是2x2的矩阵，$A \\in \\mathbb{R}^{2 \\times 2}$整个窗口中这些小矩阵的加权和, $\\mathbf{b} \\in \\mathbb{R}^2$整个窗口中这些小矩阵{梯度和误差的加权}求和\n\n为什么不解$A \\mathbf{d} = \\mathbf{b}$， 而是迭代： 因泰勒一阶近似要d很小。但是因为离散，d相对大。\n为什么双线性插值？因为Gauss-Newton得到的d*可能小数。\n复习一下Gauss-Newton:\n    https://chatgpt.com/c/67f2aa07-57a4-8002-a98f-851def653450\n\n头晕，不学了。\nlarge motio用pyramid track\nbcce，和motion track的所有问题 https://chatgpt.com/c/67f1a7c8-8c80-8002-a3cc-0b2b4e14f4fe\n\n## hw4\n#### 4 Rrigid Geo transf \n忘记的线代：\ndot prod/ Proj\n$a^Tb=ab\\cos\\theta$, $a^Tb=0 \\iff a\\perp b$\n![alt text](2025-01-29-CV/image-2.png)\n$\\text{proj}_{\\mathbf{a}} \\mathbf{v} = \\frac{\\mathbf{a}^T \\mathbf{v}}{\\mathbf{a}^T \\mathbf{a}} \\mathbf{a}$\n\n$P^x=P$ 几何，投影。\n\ncross prod\n右手系为正\n$\\|\\mathbf{c}\\| = \\|\\mathbf{a} \\times \\mathbf{b}\\| = \\|\\mathbf{a}\\|\\|\\mathbf{b}\\| \\sin\\theta$ 平行四边形面积\n$[\\mathbf{a}]_\\times = \\begin{bmatrix}\n0 & -a_z & a_y \\\\\na_z & 0 & -a_x \\\\\n-a_y & a_x & 0\n\\end{bmatrix}$\n$\\mathbf{a} \\times \\mathbf{p} = [\\mathbf{a}]_\\times \\mathbf{p}$\n\ntriple product\n$\\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c})$ abc平行六边形体积\n\ncoord translation\n太有趣了但是看不懂呜呜，里面的数学（应该是矩阵论）是我想学的数学，虽然学数学的不会叫这个数学 https://zhuanlan.zhihu.com/p/508149559\n\n从0->1， 左上角left superscript 是system index, 0 is omitted as world ref sys $S_0$\n\n\n\n\n#### 4 pinhole camera model\npinhole小孔/ optical axis穿过pinhole垂直于成像面的线/ (projection ray)/image plane（成像的面）\ntrade off between sharp and bright\n（把pinhole可以是面积圆，不影响，还会变亮（？\n倒像是实像，但是可以等价成对应的虚像。就等价成pinhole camera model 啦\n于是pinhole->center of projection,成像面(front screen)对称过去的是image plane,\nprincipal plane \n\npixel image coordinate system 左上角为原点 $(\\xi, \\mu)$\ncamera reference system P 在center of proj sys坐标中的位置$P=(X, Y, Z)$, Z is called depth\ncanonical image coordinate system $(x, y), x=X, y=Y$\n\n在写法中$(\\xi, \\mu)$会表示 image pixel 为单位，$(x, y)$会表示canonical中 sys的坐标，单位mm\n例如: \nprincipal point $\\pi_0=(\\xi_0, \\mu_0)$, scaling factor $s_x, s_y$ pixel per mm\n$(\\xi , \\mu)= (s_x x + \\xi_0, s_y y + \\mu_0)$\n$x/f=X/Z$, $y/Z=Y/Z$\n\n$\\boldsymbol{\\xi} = K_s \\mathbf{p} + \\boldsymbol{\\pi}_0$\n不想看了， 好烦 https://chatgpt.com/c/67f2c6fa-1284-8002-b9a3-7b967317097a\n\n#### epipolar geo\nepipolar plane, baseline, image plane, （book是epi plane的旋转轴，比喻成书脊）\n\n已知条件：\n不妨以相机a构建坐标系$P_a=(0,0,0)$,朝向为$D_a=\\mathbf I_{3\\times3}$, $I_a:z=f$, $P=(X, Y, Z)$, camera b 的位置 $^at_b$, 旋转矩阵$^aR_b$\n\n可以求：\n可以得到相机b的朝向是$^aR_b D_a = D_b$， 位置是$^at_b$， \n是$I_a$和AP连线的焦点A=(0, 0, 0), $I_b$也是已知的,\n方程类是$kRx-f=0$, k=[0, 0, 1], \nBP的方程是，令kR=[u, v, w], 则BP为$L(d)=t+d (kR)^T$, \nABP方程是$[t]_\\times (X, Y, Z)=0$, \n$^ap_a$: 联立 z=f和[X, Y, Z][x, y, z]^T=0, \n$^ap_b$同理已知，$^bp_b=R (^ap_b-t)$\n\n求I_b方程的过程:\n$^aI_b$的方程: $z=f$,既  $k^b\\vec{x}$+d=0，k=[0, 0, 1]\n带入点(0, 0, f)得$d=-f$。 \n$^aR_a \\ ^a \\vec{x}= ^b\\vec{x}$， 带入上式得$kR^a \\vec{x}+d=0$\n\n但是讲义上不是这么推的, 0个人关心proj center A, B在哪， 其实是有的..., t是相对位置。\n给定$a={}^a p_a = \\begin{bmatrix} x_a \\\\ y_a \\\\ f \\end{bmatrix},\\quad\nb={}^b p_b = \\begin{bmatrix} x_b \\\\ y_b \\\\ f \\end{bmatrix}$, 已知a, b, R, t, e=$^ae_b$是baseline和$I_a$的交点。\n\n根据几何变换有以下成立，\n$R^T=\\ ^bR_a$, \n因为根据逆变换$ ^aR_b\\  ^bR_a^T$,即 $RR^T=I$\n\n$Rt=-^bt_a$, 因为左=右= $^b \\vec {AB}$\n\n在sys A中, \n$R^Tb=\\ ^ap_b$，因为$^bR_a \\ ^bp=\\ ^ap-^at_b$,所以令p=camera b， $^bR_a \\ ^bp_b=\\  ^ap_b-^at_b$ 左边是$R^Tb$， 右边是sys a下的\n$a=\\ ^ap_a$\n令sys的A的原点为$O_A$， 这个式子就是$O_A A\\cdot (O_AB\\times BA)=0$\n$O_AB+BA=O_AA$带入检查得到$R^Tb=a-^at_b$\n两边同乘$R$得到$b=R(a-t)$不符合$^bp=R(^ap-t)$ ？？？\n\nepipoplar constrain $b^TEa=0$, where $E=R[t]_\\times$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQestions\n思考方式； 这里一共说了几个概念，几个公式，概念之间的逻辑什么，变量的定义和维度是什么\n\n1. GD在>=1数据的时候咋（back prop）更新的啊\n2. 好难理解为什么“如果一个点在真实世界中运动，它在图像中的亮度值是不会变的”这个假设会得到$ \\frac{d}{dt} e(x(t), t) = 0$\n虽然可以解释$e$是亮度，是关于位置向量$x$和时间$t$的函数，但是为什么$e$对$t$求导=0.  $e$的含义是什么...任意一个符合\"亮度不变的点\"的亮度...?\n哪个点?图像中的还是世界里的。图像中的点。其实感觉条件应该说成“任意真实世界的点，在图像中的像亮度不变”。这样好像可以理解。x,t也是图像中的位置和时间。\n\n可能误解的原因是总觉得图像是离散的pixel,现实世界是连续的，所以潜意识里出现了更多的变量，导致感觉条件不完全。\n3. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/2025-01-29-CV.md","raw":"---\ntitle: 2025-01-29-CV\ndate: 2025-01-29 16:02:37\ntags:\n---\n\n我觉得教授说的很有道理。 First use simple cases as examples, then gradually increase the difficulty.\nFor example the gradient descent. Use 2 * 2 as example, then others. \n\n## U-Net 论文阅读\nhttps://github.com/zhixuhao/unet\n\n### Terms\nImage segmentation: assign every pixel a label \\\n\n\n### Motivation\nPrevious method:\n- Ciresan et al. : Purely CNN (?)\n    - slow: redundancy of patches\n    - trade-off between localization accuracy and the use of context\n\n### Propose method: \nFully CN:\n-  pooling op are replaced by upsampling op:  increase the resolution\n- \n\n(excessive) Date Augmentation: elastic deformation\n- \n\n### Results\n- Pixel error: compare 2 pic\n- Rand Error\n\n## 期末\n吗的，没有认真听过一节课。我真恶心。\n以下是期末复习计划： 1.先把所有的作业看懂。然后理一下作业里的知识点和公式。不能带cheatsheeet所以玩啦\ncv复习技巧\n1. 以作业为主。把作业每题都手作一遍。\n2. 看讲义。讲义里很多重要的公式（不要看太细，重点看作业里出现的）\n3. 考完试把cv的作业都补一遍。\n\n感觉要考quiz的原题。可能要看一遍，不然这门课就完了。\n复习微积分，线性代数。\n\n\n## hw 1\nexam style problem:\n1, 2, 3.1\n\n### 1. cor/conv\nCorrelation:\ncorrelation coefficient \ncorrelation formula at position $i = \\sum_{j=0}^{k-1} I[i + j] \\cdot H[j]$\n\nconvolution:$i = \\sum_{j=0}^{k-1} I[i - j] \\cdot H[j]$\nfull/valid/same\n大小 valid < same < full\n\n\n### 2. smoothing\ngaussian(u, v) =def= e...\nseperability与简便计算\n\n### 2. differentiation\n#### def\n区分\nfinite difference: $I_c(r, c) \\approx I(r, c + 1) - I(r, c)$\ncentral difference: $I_c(r, c) \\approx \\frac{I(r, c+1) - I(r, c-1)}{2}$\n\n#### sobel filter\n不要忘记系数啊。。。（normalize系数可以保证亮度正常\nsmoothing $s =\\frac{1}{4} \\begin{bmatrix} 1, 2, 1 \\end{bmatrix}^T$\ndifferentiation: $d =\\frac{1}{2} \\begin{bmatrix} 1, 0, -1 \\end{bmatrix}^T $\n$v=s^Td, h=d^Ts$\n\nsepearable\n![alt text](image.png)晕\n\n### 3. interpolation(x)\n点的权重为对角正方形的面积\nbilinear; \n$\\delta a = a - \\lfloor a \\rfloor$, $\\delta b = b - \\lfloor b \\rfloor$\n$\\begin{aligned}\nI(a,b) &= I(\\lfloor a \\rfloor, \\lfloor b \\rfloor)(1 - \\delta a)(1 - \\delta b) \\\\\n&+ I(\\lfloor a \\rfloor, \\lfloor b \\rfloor + 1)(1 - \\delta a)\\delta b \\\\\n&+ I(\\lfloor a \\rfloor + 1, \\lfloor b \\rfloor)\\delta a(1 - \\delta b) \\\\\n&+ I(\\lfloor a \\rfloor + 1, \\lfloor b \\rfloor + 1)\\delta a\\delta b\n\\end{aligned}$\n\n\n\n## hw 2\nexam problem:\n1.1 - 1.8 ， 3.1， 4.1\n给f(x, y)\n1.1. 求gradient $\\nabla f=$\n1.2 stationary point 判定(local max/min/saddle) D= f_xx * f_yy-f_xy^2\n1.3 ordinary gradient descent\n1.4 gradient descent with momentum\n1.5 step of Newton's method\n1.6 1. 哪个离真实值更近2. Gauss-Newton method 是否可用\n1.7 GD的convergence point\n1.8 数值精度是否影响收敛\n\n3.1 SGD 手算\n一个数据点？\n\n4.1\nSG和batch\n\n\nconcepts\njacobian: 一阶导, hessian: 二阶导\n### notation:\nrisk function(给定f(x)) = loss function(未知fx？)\nfirst-order gradient descent 只是近似\n    how to derive step size $\\alpha_k$\n        fix \n        adam?\n        momentum\n    how to determine the local min\n        line search\n    terminaltion check\n    SGD\n        mini batch average\n        epoch \nsecond-order\n    Newton's method\n        Hessian\n        positive-definite: asymptotically faster convergence\n    Newton-Raphson method:\n        f shuold be convex\n\n### formula\n$\\nabla f(x,y)= \\begin{bmatrix}\\frac{\\partial f}{\\partial x}\\\\[6pt]\\frac{\\partial f}{\\partial y}\\end{bmatrix}$\n\n$H_f(x,y)=\\begin{bmatrix}\\frac{\\partial^2 f}{\\partial x^2} & \\frac{\\partial^2 f}{\\partial x\\partial y}\\\\[6pt]\\frac{\\partial^2 f}{\\partial y\\partial x} & \\frac{\\partial^2 f}{\\partial y^2}\\end{bmatrix}$\n\n$p_{k+1} = \\mu p_k - \\alpha_k \\nabla f(x_k)$\n$x_{k+1} = x_k + p_{k+1}$\n$x_k$是位置，$p_k$是momentum，$\\alpha_k$是步长，$\\nabla f(x_k)$是梯度， \nsince starts with zero velocity,$p_0=0$\n\n$\\phi_n$ loss, risk = loss function\n\n$f(\\mathbf{z})$ risk\n$\\mathbf{g}_0=\\nabla f(\\mathbf{z}_0)$ gradient\n$H(\\mathbf{z}_0)$ curvature of f near z0\n$H(\\mathbf{z}_0) = \\left[ \\frac{\\partial^2 f}{\\partial z_i \\partial z_j} \\right]_{\\mathbf{z} = \\mathbf{z}_0}$\n\nNewton Method\n$f(\\mathbf{z}) \\approx f(\\mathbf{z}_0) + \\nabla f(\\mathbf{z}_0)^T (\\mathbf{z} - \\mathbf{z}_0) + \\frac{1}{2} (\\mathbf{z} - \\mathbf{z}_0)^T H(\\mathbf{z}_0) (\\mathbf{z} - \\mathbf{z}_0)$\n\n$H_0 \\Delta \\mathbf{z}_0 = -\\mathbf{g}_0\n\\Rightarrow\n\\Delta \\mathbf{z}_0=z-z_0 = - H_0^{-1} \\mathbf{g}_0$\n\nNewton-rapthon\n$f(\\mathbf{z}) = \\sum_{n=1}^{N} \\phi_n^2(\\mathbf{z})$\n\n\n## hw3\n1    2.1-2    3.1\n1.1 求矩阵row/null space的unit vector\n1.2 x使x^2最小\n1.3 求x解集\n1.5 bcce 待公式\n1.6 Lucas-Kanade tracker\n\n\n\n\n\n\n### concept\n#### BCCE的前提假设\n如果一个点在现实世界中移动，它的亮度在图像中是不会变的\n公式表达；$a(t) = e(x(t), t)\\Rightarrow \\frac{da(t)}{dt} = 0$\n![alt text](2025-01-29-CV/image.png)\n$\\frac{d}{dt} a(t) = 0\n\\Rightarrow \n\\frac{\\partial e}{\\partial x^T} \\cdot \\frac{dx}{dt} + \\frac{\\partial e}{\\partial t} = 0$\n\nu: image velocity\n$\\delta x$ displacemen\nu=$\\delta x / \\delta t$, $\\delta t \\to\\infty$\n\n$u\\nabla e(x)/|\\nabla e(x)|$\nnormal component $\\nu =def=n(x)^{\\top}u(x)$\n\n#### apreture probelm\nBCCE是标量方程， $u = (u_x, u_y)^T$是二维，所以只能知道u的方向...\nMotion Field\t真实世界中物体运动在图像上的投影（我们想知道的）\nOptical Flow\t我们从图像中通过亮度变化估计到的速度（我们能观测到的）\n$\\nu(x) = \\mathbf{n}(x)^T u(x)$ 提督方向*\n$\\nu(x)$ 某个pixel速度沿着这个方向的“可观测分量”。\n只能知道u的方向。  \nthe normal compenet of motion $\\nu$\n\n因为们不能只靠一个像素就估计出完整的运动向量，所以用一个整体的方法去估计图像中所有像素的运动向量（光流）Optical flow\n1 data term: $E_\\text{data} = \\sum_{x} \\left( \\frac{\\partial e}{\\partial x} \\cdot u(x) + \\frac{\\partial e}{\\partial t} \\right)^2$满足BCCE function\n2 smoothness term: $E_\\text{smooth} = \\sum_{x} \\left( \\frac{\\partial u_x}{\\partial x} + \\frac{\\partial u_y}{\\partial y} \\right)^2$\n$E = \\lambda E_\\text{data} + (1 - \\lambda) E_\\text{smooth}$\n可能的缺点Tend to blur the solution near motion boundaries\n\n\n#### Local support motion estimation (using tracking windows)\nx是二维坐标$x \\in \\mathbb{R}^2$, f(x), g(x)是两幅图像\n我们把一个local的小窗口看作一个整体, 从x_f移动到x_g=x_f+d, 对应的图像是f(x_f)和g(x_f+d),枚举周围的x，计算平方loss，权重和距离有关 w(x-x_f)\n$W(x_f)$是个集合={pixel in window}\n$w(x) = \\begin{cases}1 & \\text{if } |x_1| \\le h \\text{ and } |x_2| \\le h \\\\0 & \\text{otherwise}\\end{cases}$只是定义窗口时2h+1 ^2的小正方形\n\n高斯，只是换种w\n$w(x) \\propto \\begin{cases}e^{- \\frac{1}{2} \\left( \\frac{\\|x\\|}{\\sigma} \\right)^2 } & \\text{if } |x_1| \\le h, |x_2| \\le h \\\\0 & \\text{otherwise}\\end{cases}$\n\n1. grid search x\n2. Lucas-kanade tracker(using Newton-Raphson)\nGoal \n    find d that min $L(\\mathbf{d}) = \\sum_x [g(x + \\mathbf{d}) - f(x)]^2 w(x - x_f)$ \\\n    线性近似$g(x + \\mathbf{d}) \\approx g(x) + \\nabla g(x)^T \\mathbf{d}$\n    $L(\\mathbf{d}) \\approx \\mathbf{d}^T A \\mathbf{d} - 2 \\mathbf{b}^T \\mathbf{d} + \\text{const}$\n    L'(d)=0得到$A \\mathbf{d} = \\mathbf{b}$\n    因为是近似的，我们不能一次算出真正的$\\mathbf{d}^*$\n\n详细计算(感觉这里写的不对，应该改一下推导过程...)\n$L(\\mathbf{d}) \\approx \\sum_x \\left[\\nabla g(x)^T \\mathbf{d} + g(x) - f(x)\\right]^2 w(x - x_f)$\n$L(\\mathbf{d}) = \\mathbf{d}^T A \\mathbf{d} - 2 \\mathbf{b}^T \\mathbf{d} + \\text{const}$\n$A = \\sum_x \\nabla g(x) \\nabla g(x)^T w(x - x_f)$\n$\\mathbf{b} = \\sum_x \\nabla g(x) [f(x) - g(x)] w(x - x_f)$\n$\\nabla g(x) \\in \\mathbb{R}^2$, $\\nabla g(x) \\nabla g(x)^T$是2x2的矩阵，$A \\in \\mathbb{R}^{2 \\times 2}$整个窗口中这些小矩阵的加权和, $\\mathbf{b} \\in \\mathbb{R}^2$整个窗口中这些小矩阵{梯度和误差的加权}求和\n\n为什么不解$A \\mathbf{d} = \\mathbf{b}$， 而是迭代： 因泰勒一阶近似要d很小。但是因为离散，d相对大。\n为什么双线性插值？因为Gauss-Newton得到的d*可能小数。\n复习一下Gauss-Newton:\n    https://chatgpt.com/c/67f2aa07-57a4-8002-a98f-851def653450\n\n头晕，不学了。\nlarge motio用pyramid track\nbcce，和motion track的所有问题 https://chatgpt.com/c/67f1a7c8-8c80-8002-a3cc-0b2b4e14f4fe\n\n## hw4\n#### 4 Rrigid Geo transf \n忘记的线代：\ndot prod/ Proj\n$a^Tb=ab\\cos\\theta$, $a^Tb=0 \\iff a\\perp b$\n![alt text](2025-01-29-CV/image-2.png)\n$\\text{proj}_{\\mathbf{a}} \\mathbf{v} = \\frac{\\mathbf{a}^T \\mathbf{v}}{\\mathbf{a}^T \\mathbf{a}} \\mathbf{a}$\n\n$P^x=P$ 几何，投影。\n\ncross prod\n右手系为正\n$\\|\\mathbf{c}\\| = \\|\\mathbf{a} \\times \\mathbf{b}\\| = \\|\\mathbf{a}\\|\\|\\mathbf{b}\\| \\sin\\theta$ 平行四边形面积\n$[\\mathbf{a}]_\\times = \\begin{bmatrix}\n0 & -a_z & a_y \\\\\na_z & 0 & -a_x \\\\\n-a_y & a_x & 0\n\\end{bmatrix}$\n$\\mathbf{a} \\times \\mathbf{p} = [\\mathbf{a}]_\\times \\mathbf{p}$\n\ntriple product\n$\\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c})$ abc平行六边形体积\n\ncoord translation\n太有趣了但是看不懂呜呜，里面的数学（应该是矩阵论）是我想学的数学，虽然学数学的不会叫这个数学 https://zhuanlan.zhihu.com/p/508149559\n\n从0->1， 左上角left superscript 是system index, 0 is omitted as world ref sys $S_0$\n\n\n\n\n#### 4 pinhole camera model\npinhole小孔/ optical axis穿过pinhole垂直于成像面的线/ (projection ray)/image plane（成像的面）\ntrade off between sharp and bright\n（把pinhole可以是面积圆，不影响，还会变亮（？\n倒像是实像，但是可以等价成对应的虚像。就等价成pinhole camera model 啦\n于是pinhole->center of projection,成像面(front screen)对称过去的是image plane,\nprincipal plane \n\npixel image coordinate system 左上角为原点 $(\\xi, \\mu)$\ncamera reference system P 在center of proj sys坐标中的位置$P=(X, Y, Z)$, Z is called depth\ncanonical image coordinate system $(x, y), x=X, y=Y$\n\n在写法中$(\\xi, \\mu)$会表示 image pixel 为单位，$(x, y)$会表示canonical中 sys的坐标，单位mm\n例如: \nprincipal point $\\pi_0=(\\xi_0, \\mu_0)$, scaling factor $s_x, s_y$ pixel per mm\n$(\\xi , \\mu)= (s_x x + \\xi_0, s_y y + \\mu_0)$\n$x/f=X/Z$, $y/Z=Y/Z$\n\n$\\boldsymbol{\\xi} = K_s \\mathbf{p} + \\boldsymbol{\\pi}_0$\n不想看了， 好烦 https://chatgpt.com/c/67f2c6fa-1284-8002-b9a3-7b967317097a\n\n#### epipolar geo\nepipolar plane, baseline, image plane, （book是epi plane的旋转轴，比喻成书脊）\n\n已知条件：\n不妨以相机a构建坐标系$P_a=(0,0,0)$,朝向为$D_a=\\mathbf I_{3\\times3}$, $I_a:z=f$, $P=(X, Y, Z)$, camera b 的位置 $^at_b$, 旋转矩阵$^aR_b$\n\n可以求：\n可以得到相机b的朝向是$^aR_b D_a = D_b$， 位置是$^at_b$， \n是$I_a$和AP连线的焦点A=(0, 0, 0), $I_b$也是已知的,\n方程类是$kRx-f=0$, k=[0, 0, 1], \nBP的方程是，令kR=[u, v, w], 则BP为$L(d)=t+d (kR)^T$, \nABP方程是$[t]_\\times (X, Y, Z)=0$, \n$^ap_a$: 联立 z=f和[X, Y, Z][x, y, z]^T=0, \n$^ap_b$同理已知，$^bp_b=R (^ap_b-t)$\n\n求I_b方程的过程:\n$^aI_b$的方程: $z=f$,既  $k^b\\vec{x}$+d=0，k=[0, 0, 1]\n带入点(0, 0, f)得$d=-f$。 \n$^aR_a \\ ^a \\vec{x}= ^b\\vec{x}$， 带入上式得$kR^a \\vec{x}+d=0$\n\n但是讲义上不是这么推的, 0个人关心proj center A, B在哪， 其实是有的..., t是相对位置。\n给定$a={}^a p_a = \\begin{bmatrix} x_a \\\\ y_a \\\\ f \\end{bmatrix},\\quad\nb={}^b p_b = \\begin{bmatrix} x_b \\\\ y_b \\\\ f \\end{bmatrix}$, 已知a, b, R, t, e=$^ae_b$是baseline和$I_a$的交点。\n\n根据几何变换有以下成立，\n$R^T=\\ ^bR_a$, \n因为根据逆变换$ ^aR_b\\  ^bR_a^T$,即 $RR^T=I$\n\n$Rt=-^bt_a$, 因为左=右= $^b \\vec {AB}$\n\n在sys A中, \n$R^Tb=\\ ^ap_b$，因为$^bR_a \\ ^bp=\\ ^ap-^at_b$,所以令p=camera b， $^bR_a \\ ^bp_b=\\  ^ap_b-^at_b$ 左边是$R^Tb$， 右边是sys a下的\n$a=\\ ^ap_a$\n令sys的A的原点为$O_A$， 这个式子就是$O_A A\\cdot (O_AB\\times BA)=0$\n$O_AB+BA=O_AA$带入检查得到$R^Tb=a-^at_b$\n两边同乘$R$得到$b=R(a-t)$不符合$^bp=R(^ap-t)$ ？？？\n\nepipoplar constrain $b^TEa=0$, where $E=R[t]_\\times$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQestions\n思考方式； 这里一共说了几个概念，几个公式，概念之间的逻辑什么，变量的定义和维度是什么\n\n1. GD在>=1数据的时候咋（back prop）更新的啊\n2. 好难理解为什么“如果一个点在真实世界中运动，它在图像中的亮度值是不会变的”这个假设会得到$ \\frac{d}{dt} e(x(t), t) = 0$\n虽然可以解释$e$是亮度，是关于位置向量$x$和时间$t$的函数，但是为什么$e$对$t$求导=0.  $e$的含义是什么...任意一个符合\"亮度不变的点\"的亮度...?\n哪个点?图像中的还是世界里的。图像中的点。其实感觉条件应该说成“任意真实世界的点，在图像中的像亮度不变”。这样好像可以理解。x,t也是图像中的位置和时间。\n\n可能误解的原因是总觉得图像是离散的pixel,现实世界是连续的，所以潜意识里出现了更多的变量，导致感觉条件不完全。\n3. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"2025-01-29-CV","published":1,"updated":"2025-04-08T21:40:43.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagt0001xzc3d69qehcym","content":"<p>我觉得教授说的很有道理。 First use simple cases as examples, then gradually increase the difficulty.<br>For example the gradient descent. Use 2 * 2 as example, then others. </p>\n<h2 id=\"U-Net-论文阅读\"><a href=\"#U-Net-论文阅读\" class=\"headerlink\" title=\"U-Net 论文阅读\"></a>U-Net 论文阅读</h2><p><a href=\"https://github.com/zhixuhao/unet\">https://github.com/zhixuhao/unet</a></p>\n<h3 id=\"Terms\"><a href=\"#Terms\" class=\"headerlink\" title=\"Terms\"></a>Terms</h3><p>Image segmentation: assign every pixel a label \\</p>\n<h3 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h3><p>Previous method:</p>\n<ul>\n<li>Ciresan et al. : Purely CNN (?)<ul>\n<li>slow: redundancy of patches</li>\n<li>trade-off between localization accuracy and the use of context</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Propose-method\"><a href=\"#Propose-method\" class=\"headerlink\" title=\"Propose method:\"></a>Propose method:</h3><h2 id=\"Fully-CN-pooling-op-are-replaced-by-upsampling-op-increase-the-resolution\"><a href=\"#Fully-CN-pooling-op-are-replaced-by-upsampling-op-increase-the-resolution\" class=\"headerlink\" title=\"Fully CN:-  pooling op are replaced by upsampling op:  increase the resolution\"></a>Fully CN:<br>-  pooling op are replaced by upsampling op:  increase the resolution</h2><h2 id=\"excessive-Date-Augmentation-elastic-deformation\"><a href=\"#excessive-Date-Augmentation-elastic-deformation\" class=\"headerlink\" title=\"(excessive) Date Augmentation: elastic deformation\"></a>(excessive) Date Augmentation: elastic deformation</h2><h3 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h3><ul>\n<li>Pixel error: compare 2 pic</li>\n<li>Rand Error</li>\n</ul>\n<h2 id=\"期末\"><a href=\"#期末\" class=\"headerlink\" title=\"期末\"></a>期末</h2><p>吗的，没有认真听过一节课。我真恶心。<br>以下是期末复习计划： 1.先把所有的作业看懂。然后理一下作业里的知识点和公式。不能带cheatsheeet所以玩啦<br>cv复习技巧</p>\n<ol>\n<li>以作业为主。把作业每题都手作一遍。</li>\n<li>看讲义。讲义里很多重要的公式（不要看太细，重点看作业里出现的）</li>\n<li>考完试把cv的作业都补一遍。</li>\n</ol>\n<p>感觉要考quiz的原题。可能要看一遍，不然这门课就完了。<br>复习微积分，线性代数。</p>\n<h2 id=\"hw-1\"><a href=\"#hw-1\" class=\"headerlink\" title=\"hw 1\"></a>hw 1</h2><p>exam style problem:<br>1, 2, 3.1</p>\n<h3 id=\"1-cor-conv\"><a href=\"#1-cor-conv\" class=\"headerlink\" title=\"1. cor&#x2F;conv\"></a>1. cor&#x2F;conv</h3><p>Correlation:<br>correlation coefficient<br>correlation formula at position $i &#x3D; \\sum_{j&#x3D;0}^{k-1} I[i + j] \\cdot H[j]$</p>\n<p>convolution:$i &#x3D; \\sum_{j&#x3D;0}^{k-1} I[i - j] \\cdot H[j]$<br>full&#x2F;valid&#x2F;same<br>大小 valid &lt; same &lt; full</p>\n<h3 id=\"2-smoothing\"><a href=\"#2-smoothing\" class=\"headerlink\" title=\"2. smoothing\"></a>2. smoothing</h3><p>gaussian(u, v) &#x3D;def&#x3D; e…<br>seperability与简便计算</p>\n<h3 id=\"2-differentiation\"><a href=\"#2-differentiation\" class=\"headerlink\" title=\"2. differentiation\"></a>2. differentiation</h3><h4 id=\"def\"><a href=\"#def\" class=\"headerlink\" title=\"def\"></a>def</h4><p>区分<br>finite difference: $I_c(r, c) \\approx I(r, c + 1) - I(r, c)$<br>central difference: $I_c(r, c) \\approx \\frac{I(r, c+1) - I(r, c-1)}{2}$</p>\n<h4 id=\"sobel-filter\"><a href=\"#sobel-filter\" class=\"headerlink\" title=\"sobel filter\"></a>sobel filter</h4><p>不要忘记系数啊。。。（normalize系数可以保证亮度正常<br>smoothing $s &#x3D;\\frac{1}{4} \\begin{bmatrix} 1, 2, 1 \\end{bmatrix}^T$<br>differentiation: $d &#x3D;\\frac{1}{2} \\begin{bmatrix} 1, 0, -1 \\end{bmatrix}^T $<br>$v&#x3D;s^Td, h&#x3D;d^Ts$</p>\n<p>sepearable<br><img src=\"/image.png\" alt=\"alt text\">晕</p>\n<h3 id=\"3-interpolation-x\"><a href=\"#3-interpolation-x\" class=\"headerlink\" title=\"3. interpolation(x)\"></a>3. interpolation(x)</h3><p>点的权重为对角正方形的面积<br>bilinear;<br>$\\delta a &#x3D; a - \\lfloor a \\rfloor$, $\\delta b &#x3D; b - \\lfloor b \\rfloor$<br>$\\begin{aligned}<br>I(a,b) &amp;&#x3D; I(\\lfloor a \\rfloor, \\lfloor b \\rfloor)(1 - \\delta a)(1 - \\delta b) \\<br>&amp;+ I(\\lfloor a \\rfloor, \\lfloor b \\rfloor + 1)(1 - \\delta a)\\delta b \\<br>&amp;+ I(\\lfloor a \\rfloor + 1, \\lfloor b \\rfloor)\\delta a(1 - \\delta b) \\<br>&amp;+ I(\\lfloor a \\rfloor + 1, \\lfloor b \\rfloor + 1)\\delta a\\delta b<br>\\end{aligned}$</p>\n<h2 id=\"hw-2\"><a href=\"#hw-2\" class=\"headerlink\" title=\"hw 2\"></a>hw 2</h2><p>exam problem:<br>1.1 - 1.8 ， 3.1， 4.1<br>给f(x, y)<br>1.1. 求gradient $\\nabla f&#x3D;$<br>1.2 stationary point 判定(local max&#x2F;min&#x2F;saddle) D&#x3D; f_xx * f_yy-f_xy^2<br>1.3 ordinary gradient descent<br>1.4 gradient descent with momentum<br>1.5 step of Newton’s method<br>1.6 1. 哪个离真实值更近2. Gauss-Newton method 是否可用<br>1.7 GD的convergence point<br>1.8 数值精度是否影响收敛</p>\n<p>3.1 SGD 手算<br>一个数据点？</p>\n<p>4.1<br>SG和batch</p>\n<p>concepts<br>jacobian: 一阶导, hessian: 二阶导</p>\n<h3 id=\"notation\"><a href=\"#notation\" class=\"headerlink\" title=\"notation:\"></a>notation:</h3><p>risk function(给定f(x)) &#x3D; loss function(未知fx？)<br>first-order gradient descent 只是近似<br>    how to derive step size $\\alpha_k$<br>        fix<br>        adam?<br>        momentum<br>    how to determine the local min<br>        line search<br>    terminaltion check<br>    SGD<br>        mini batch average<br>        epoch<br>second-order<br>    Newton’s method<br>        Hessian<br>        positive-definite: asymptotically faster convergence<br>    Newton-Raphson method:<br>        f shuold be convex</p>\n<h3 id=\"formula\"><a href=\"#formula\" class=\"headerlink\" title=\"formula\"></a>formula</h3><p>$\\nabla f(x,y)&#x3D; \\begin{bmatrix}\\frac{\\partial f}{\\partial x}\\[6pt]\\frac{\\partial f}{\\partial y}\\end{bmatrix}$</p>\n<p>$H_f(x,y)&#x3D;\\begin{bmatrix}\\frac{\\partial^2 f}{\\partial x^2} &amp; \\frac{\\partial^2 f}{\\partial x\\partial y}\\[6pt]\\frac{\\partial^2 f}{\\partial y\\partial x} &amp; \\frac{\\partial^2 f}{\\partial y^2}\\end{bmatrix}$</p>\n<p>$p_{k+1} &#x3D; \\mu p_k - \\alpha_k \\nabla f(x_k)$<br>$x_{k+1} &#x3D; x_k + p_{k+1}$<br>$x_k$是位置，$p_k$是momentum，$\\alpha_k$是步长，$\\nabla f(x_k)$是梯度，<br>since starts with zero velocity,$p_0&#x3D;0$</p>\n<p>$\\phi_n$ loss, risk &#x3D; loss function</p>\n<p>$f(\\mathbf{z})$ risk<br>$\\mathbf{g}_0&#x3D;\\nabla f(\\mathbf{z}_0)$ gradient<br>$H(\\mathbf{z}_0)$ curvature of f near z0<br>$H(\\mathbf{z}<em>0) &#x3D; \\left[ \\frac{\\partial^2 f}{\\partial z_i \\partial z_j} \\right]</em>{\\mathbf{z} &#x3D; \\mathbf{z}_0}$</p>\n<p>Newton Method<br>$f(\\mathbf{z}) \\approx f(\\mathbf{z}_0) + \\nabla f(\\mathbf{z}_0)^T (\\mathbf{z} - \\mathbf{z}_0) + \\frac{1}{2} (\\mathbf{z} - \\mathbf{z}_0)^T H(\\mathbf{z}_0) (\\mathbf{z} - \\mathbf{z}_0)$</p>\n<p>$H_0 \\Delta \\mathbf{z}_0 &#x3D; -\\mathbf{g}_0<br>\\Rightarrow<br>\\Delta \\mathbf{z}_0&#x3D;z-z_0 &#x3D; - H_0^{-1} \\mathbf{g}_0$</p>\n<p>Newton-rapthon<br>$f(\\mathbf{z}) &#x3D; \\sum_{n&#x3D;1}^{N} \\phi_n^2(\\mathbf{z})$</p>\n<h2 id=\"hw3\"><a href=\"#hw3\" class=\"headerlink\" title=\"hw3\"></a>hw3</h2><p>1    2.1-2    3.1<br>1.1 求矩阵row&#x2F;null space的unit vector<br>1.2 x使x^2最小<br>1.3 求x解集<br>1.5 bcce 待公式<br>1.6 Lucas-Kanade tracker</p>\n<h3 id=\"concept\"><a href=\"#concept\" class=\"headerlink\" title=\"concept\"></a>concept</h3><h4 id=\"BCCE的前提假设\"><a href=\"#BCCE的前提假设\" class=\"headerlink\" title=\"BCCE的前提假设\"></a>BCCE的前提假设</h4><p>如果一个点在现实世界中移动，它的亮度在图像中是不会变的<br>公式表达；$a(t) &#x3D; e(x(t), t)\\Rightarrow \\frac{da(t)}{dt} &#x3D; 0$<br><img src=\"/2025-01-29-CV/image.png\" alt=\"alt text\"><br>$\\frac{d}{dt} a(t) &#x3D; 0<br>\\Rightarrow<br>\\frac{\\partial e}{\\partial x^T} \\cdot \\frac{dx}{dt} + \\frac{\\partial e}{\\partial t} &#x3D; 0$</p>\n<p>u: image velocity<br>$\\delta x$ displacemen<br>u&#x3D;$\\delta x &#x2F; \\delta t$, $\\delta t \\to\\infty$</p>\n<p>$u\\nabla e(x)&#x2F;|\\nabla e(x)|$<br>normal component $\\nu &#x3D;def&#x3D;n(x)^{\\top}u(x)$</p>\n<h4 id=\"apreture-probelm\"><a href=\"#apreture-probelm\" class=\"headerlink\" title=\"apreture probelm\"></a>apreture probelm</h4><p>BCCE是标量方程， $u &#x3D; (u_x, u_y)^T$是二维，所以只能知道u的方向…<br>Motion Field\t真实世界中物体运动在图像上的投影（我们想知道的）<br>Optical Flow\t我们从图像中通过亮度变化估计到的速度（我们能观测到的）<br>$\\nu(x) &#x3D; \\mathbf{n}(x)^T u(x)$ 提督方向*<br>$\\nu(x)$ 某个pixel速度沿着这个方向的“可观测分量”。<br>只能知道u的方向。<br>the normal compenet of motion $\\nu$</p>\n<p>因为们不能只靠一个像素就估计出完整的运动向量，所以用一个整体的方法去估计图像中所有像素的运动向量（光流）Optical flow<br>1 data term: $E_\\text{data} &#x3D; \\sum_{x} \\left( \\frac{\\partial e}{\\partial x} \\cdot u(x) + \\frac{\\partial e}{\\partial t} \\right)^2$满足BCCE function<br>2 smoothness term: $E_\\text{smooth} &#x3D; \\sum_{x} \\left( \\frac{\\partial u_x}{\\partial x} + \\frac{\\partial u_y}{\\partial y} \\right)^2$<br>$E &#x3D; \\lambda E_\\text{data} + (1 - \\lambda) E_\\text{smooth}$<br>可能的缺点Tend to blur the solution near motion boundaries</p>\n<h4 id=\"Local-support-motion-estimation-using-tracking-windows\"><a href=\"#Local-support-motion-estimation-using-tracking-windows\" class=\"headerlink\" title=\"Local support motion estimation (using tracking windows)\"></a>Local support motion estimation (using tracking windows)</h4><p>x是二维坐标$x \\in \\mathbb{R}^2$, f(x), g(x)是两幅图像<br>我们把一个local的小窗口看作一个整体, 从x_f移动到x_g&#x3D;x_f+d, 对应的图像是f(x_f)和g(x_f+d),枚举周围的x，计算平方loss，权重和距离有关 w(x-x_f)<br>$W(x_f)$是个集合&#x3D;{pixel in window}<br>$w(x) &#x3D; \\begin{cases}1 &amp; \\text{if } |x_1| \\le h \\text{ and } |x_2| \\le h \\0 &amp; \\text{otherwise}\\end{cases}$只是定义窗口时2h+1 ^2的小正方形</p>\n<p>高斯，只是换种w<br>$w(x) \\propto \\begin{cases}e^{- \\frac{1}{2} \\left( \\frac{|x|}{\\sigma} \\right)^2 } &amp; \\text{if } |x_1| \\le h, |x_2| \\le h \\0 &amp; \\text{otherwise}\\end{cases}$</p>\n<ol>\n<li>grid search x</li>\n<li>Lucas-kanade tracker(using Newton-Raphson)<br>Goal<br> find d that min $L(\\mathbf{d}) &#x3D; \\sum_x [g(x + \\mathbf{d}) - f(x)]^2 w(x - x_f)$ <br> 线性近似$g(x + \\mathbf{d}) \\approx g(x) + \\nabla g(x)^T \\mathbf{d}$<br> $L(\\mathbf{d}) \\approx \\mathbf{d}^T A \\mathbf{d} - 2 \\mathbf{b}^T \\mathbf{d} + \\text{const}$<br> L’(d)&#x3D;0得到$A \\mathbf{d} &#x3D; \\mathbf{b}$<br> 因为是近似的，我们不能一次算出真正的$\\mathbf{d}^*$</li>\n</ol>\n<p>详细计算(感觉这里写的不对，应该改一下推导过程…)<br>$L(\\mathbf{d}) \\approx \\sum_x \\left[\\nabla g(x)^T \\mathbf{d} + g(x) - f(x)\\right]^2 w(x - x_f)$<br>$L(\\mathbf{d}) &#x3D; \\mathbf{d}^T A \\mathbf{d} - 2 \\mathbf{b}^T \\mathbf{d} + \\text{const}$<br>$A &#x3D; \\sum_x \\nabla g(x) \\nabla g(x)^T w(x - x_f)$<br>$\\mathbf{b} &#x3D; \\sum_x \\nabla g(x) [f(x) - g(x)] w(x - x_f)$<br>$\\nabla g(x) \\in \\mathbb{R}^2$, $\\nabla g(x) \\nabla g(x)^T$是2x2的矩阵，$A \\in \\mathbb{R}^{2 \\times 2}$整个窗口中这些小矩阵的加权和, $\\mathbf{b} \\in \\mathbb{R}^2$整个窗口中这些小矩阵{梯度和误差的加权}求和</p>\n<p>为什么不解$A \\mathbf{d} &#x3D; \\mathbf{b}$， 而是迭代： 因泰勒一阶近似要d很小。但是因为离散，d相对大。<br>为什么双线性插值？因为Gauss-Newton得到的d*可能小数。<br>复习一下Gauss-Newton:<br>    <a href=\"https://chatgpt.com/c/67f2aa07-57a4-8002-a98f-851def653450\">https://chatgpt.com/c/67f2aa07-57a4-8002-a98f-851def653450</a></p>\n<p>头晕，不学了。<br>large motio用pyramid track<br>bcce，和motion track的所有问题 <a href=\"https://chatgpt.com/c/67f1a7c8-8c80-8002-a3cc-0b2b4e14f4fe\">https://chatgpt.com/c/67f1a7c8-8c80-8002-a3cc-0b2b4e14f4fe</a></p>\n<h2 id=\"hw4\"><a href=\"#hw4\" class=\"headerlink\" title=\"hw4\"></a>hw4</h2><h4 id=\"4-Rrigid-Geo-transf\"><a href=\"#4-Rrigid-Geo-transf\" class=\"headerlink\" title=\"4 Rrigid Geo transf\"></a>4 Rrigid Geo transf</h4><p>忘记的线代：<br>dot prod&#x2F; Proj<br>$a^Tb&#x3D;ab\\cos\\theta$, $a^Tb&#x3D;0 \\iff a\\perp b$<br><img src=\"/2025-01-29-CV/image-2.png\" alt=\"alt text\"><br>$\\text{proj}_{\\mathbf{a}} \\mathbf{v} &#x3D; \\frac{\\mathbf{a}^T \\mathbf{v}}{\\mathbf{a}^T \\mathbf{a}} \\mathbf{a}$</p>\n<p>$P^x&#x3D;P$ 几何，投影。</p>\n<p>cross prod<br>右手系为正<br>$|\\mathbf{c}| &#x3D; |\\mathbf{a} \\times \\mathbf{b}| &#x3D; |\\mathbf{a}||\\mathbf{b}| \\sin\\theta$ 平行四边形面积<br>$[\\mathbf{a}]_\\times &#x3D; \\begin{bmatrix}<br>0 &amp; -a_z &amp; a_y \\<br>a_z &amp; 0 &amp; -a_x \\<br>-a_y &amp; a_x &amp; 0<br>\\end{bmatrix}$<br>$\\mathbf{a} \\times \\mathbf{p} &#x3D; [\\mathbf{a}]_\\times \\mathbf{p}$</p>\n<p>triple product<br>$\\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c})$ abc平行六边形体积</p>\n<p>coord translation<br>太有趣了但是看不懂呜呜，里面的数学（应该是矩阵论）是我想学的数学，虽然学数学的不会叫这个数学 <a href=\"https://zhuanlan.zhihu.com/p/508149559\">https://zhuanlan.zhihu.com/p/508149559</a></p>\n<p>从0-&gt;1， 左上角left superscript 是system index, 0 is omitted as world ref sys $S_0$</p>\n<h4 id=\"4-pinhole-camera-model\"><a href=\"#4-pinhole-camera-model\" class=\"headerlink\" title=\"4 pinhole camera model\"></a>4 pinhole camera model</h4><p>pinhole小孔&#x2F; optical axis穿过pinhole垂直于成像面的线&#x2F; (projection ray)&#x2F;image plane（成像的面）<br>trade off between sharp and bright<br>（把pinhole可以是面积圆，不影响，还会变亮（？<br>倒像是实像，但是可以等价成对应的虚像。就等价成pinhole camera model 啦<br>于是pinhole-&gt;center of projection,成像面(front screen)对称过去的是image plane,<br>principal plane </p>\n<p>pixel image coordinate system 左上角为原点 $(\\xi, \\mu)$<br>camera reference system P 在center of proj sys坐标中的位置$P&#x3D;(X, Y, Z)$, Z is called depth<br>canonical image coordinate system $(x, y), x&#x3D;X, y&#x3D;Y$</p>\n<p>在写法中$(\\xi, \\mu)$会表示 image pixel 为单位，$(x, y)$会表示canonical中 sys的坐标，单位mm<br>例如:<br>principal point $\\pi_0&#x3D;(\\xi_0, \\mu_0)$, scaling factor $s_x, s_y$ pixel per mm<br>$(\\xi , \\mu)&#x3D; (s_x x + \\xi_0, s_y y + \\mu_0)$<br>$x&#x2F;f&#x3D;X&#x2F;Z$, $y&#x2F;Z&#x3D;Y&#x2F;Z$</p>\n<p>$\\boldsymbol{\\xi} &#x3D; K_s \\mathbf{p} + \\boldsymbol{\\pi}_0$<br>不想看了， 好烦 <a href=\"https://chatgpt.com/c/67f2c6fa-1284-8002-b9a3-7b967317097a\">https://chatgpt.com/c/67f2c6fa-1284-8002-b9a3-7b967317097a</a></p>\n<h4 id=\"epipolar-geo\"><a href=\"#epipolar-geo\" class=\"headerlink\" title=\"epipolar geo\"></a>epipolar geo</h4><p>epipolar plane, baseline, image plane, （book是epi plane的旋转轴，比喻成书脊）</p>\n<p>已知条件：<br>不妨以相机a构建坐标系$P_a&#x3D;(0,0,0)$,朝向为$D_a&#x3D;\\mathbf I_{3\\times3}$, $I_a:z&#x3D;f$, $P&#x3D;(X, Y, Z)$, camera b 的位置 $^at_b$, 旋转矩阵$^aR_b$</p>\n<p>可以求：<br>可以得到相机b的朝向是$^aR_b D_a &#x3D; D_b$， 位置是$^at_b$，<br>是$I_a$和AP连线的焦点A&#x3D;(0, 0, 0), $I_b$也是已知的,<br>方程类是$kRx-f&#x3D;0$, k&#x3D;[0, 0, 1],<br>BP的方程是，令kR&#x3D;[u, v, w], 则BP为$L(d)&#x3D;t+d (kR)^T$,<br>ABP方程是$[t]_\\times (X, Y, Z)&#x3D;0$,<br>$^ap_a$: 联立 z&#x3D;f和[X, Y, Z][x, y, z]^T&#x3D;0,<br>$^ap_b$同理已知，$^bp_b&#x3D;R (^ap_b-t)$</p>\n<p>求I_b方程的过程:<br>$^aI_b$的方程: $z&#x3D;f$,既  $k^b\\vec{x}$+d&#x3D;0，k&#x3D;[0, 0, 1]<br>带入点(0, 0, f)得$d&#x3D;-f$。<br>$^aR_a \\ ^a \\vec{x}&#x3D; ^b\\vec{x}$， 带入上式得$kR^a \\vec{x}+d&#x3D;0$</p>\n<p>但是讲义上不是这么推的, 0个人关心proj center A, B在哪， 其实是有的…, t是相对位置。<br>给定$a&#x3D;{}^a p_a &#x3D; \\begin{bmatrix} x_a \\ y_a \\ f \\end{bmatrix},\\quad<br>b&#x3D;{}^b p_b &#x3D; \\begin{bmatrix} x_b \\ y_b \\ f \\end{bmatrix}$, 已知a, b, R, t, e&#x3D;$^ae_b$是baseline和$I_a$的交点。</p>\n<p>根据几何变换有以下成立，<br>$R^T&#x3D;\\ ^bR_a$,<br>因为根据逆变换$ ^aR_b\\  ^bR_a^T$,即 $RR^T&#x3D;I$</p>\n<p>$Rt&#x3D;-^bt_a$, 因为左&#x3D;右&#x3D; $^b \\vec {AB}$</p>\n<p>在sys A中,<br>$R^Tb&#x3D;\\ ^ap_b$，因为$^bR_a \\ ^bp&#x3D;\\ ^ap-^at_b$,所以令p&#x3D;camera b， $^bR_a \\ ^bp_b&#x3D;\\  ^ap_b-^at_b$ 左边是$R^Tb$， 右边是sys a下的<br>$a&#x3D;\\ ^ap_a$<br>令sys的A的原点为$O_A$， 这个式子就是$O_A A\\cdot (O_AB\\times BA)&#x3D;0$<br>$O_AB+BA&#x3D;O_AA$带入检查得到$R^Tb&#x3D;a-^at_b$<br>两边同乘$R$得到$b&#x3D;R(a-t)$不符合$^bp&#x3D;R(^ap-t)$ ？？？</p>\n<p>epipoplar constrain $b^TEa&#x3D;0$, where $E&#x3D;R[t]_\\times$</p>\n<p>Qestions<br>思考方式； 这里一共说了几个概念，几个公式，概念之间的逻辑什么，变量的定义和维度是什么</p>\n<ol>\n<li>GD在&gt;&#x3D;1数据的时候咋（back prop）更新的啊</li>\n<li>好难理解为什么“如果一个点在真实世界中运动，它在图像中的亮度值是不会变的”这个假设会得到$ \\frac{d}{dt} e(x(t), t) &#x3D; 0$<br>虽然可以解释$e$是亮度，是关于位置向量$x$和时间$t$的函数，但是为什么$e$对$t$求导&#x3D;0.  $e$的含义是什么…任意一个符合”亮度不变的点”的亮度…?<br>哪个点?图像中的还是世界里的。图像中的点。其实感觉条件应该说成“任意真实世界的点，在图像中的像亮度不变”。这样好像可以理解。x,t也是图像中的位置和时间。</li>\n</ol>\n<p>可能误解的原因是总觉得图像是离散的pixel,现实世界是连续的，所以潜意识里出现了更多的变量，导致感觉条件不完全。<br>3. </p>\n","excerpt":"","more":"<p>我觉得教授说的很有道理。 First use simple cases as examples, then gradually increase the difficulty.<br>For example the gradient descent. Use 2 * 2 as example, then others. </p>\n<h2 id=\"U-Net-论文阅读\"><a href=\"#U-Net-论文阅读\" class=\"headerlink\" title=\"U-Net 论文阅读\"></a>U-Net 论文阅读</h2><p><a href=\"https://github.com/zhixuhao/unet\">https://github.com/zhixuhao/unet</a></p>\n<h3 id=\"Terms\"><a href=\"#Terms\" class=\"headerlink\" title=\"Terms\"></a>Terms</h3><p>Image segmentation: assign every pixel a label \\</p>\n<h3 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h3><p>Previous method:</p>\n<ul>\n<li>Ciresan et al. : Purely CNN (?)<ul>\n<li>slow: redundancy of patches</li>\n<li>trade-off between localization accuracy and the use of context</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Propose-method\"><a href=\"#Propose-method\" class=\"headerlink\" title=\"Propose method:\"></a>Propose method:</h3><h2 id=\"Fully-CN-pooling-op-are-replaced-by-upsampling-op-increase-the-resolution\"><a href=\"#Fully-CN-pooling-op-are-replaced-by-upsampling-op-increase-the-resolution\" class=\"headerlink\" title=\"Fully CN:-  pooling op are replaced by upsampling op:  increase the resolution\"></a>Fully CN:<br>-  pooling op are replaced by upsampling op:  increase the resolution</h2><h2 id=\"excessive-Date-Augmentation-elastic-deformation\"><a href=\"#excessive-Date-Augmentation-elastic-deformation\" class=\"headerlink\" title=\"(excessive) Date Augmentation: elastic deformation\"></a>(excessive) Date Augmentation: elastic deformation</h2><h3 id=\"Results\"><a href=\"#Results\" class=\"headerlink\" title=\"Results\"></a>Results</h3><ul>\n<li>Pixel error: compare 2 pic</li>\n<li>Rand Error</li>\n</ul>\n<h2 id=\"期末\"><a href=\"#期末\" class=\"headerlink\" title=\"期末\"></a>期末</h2><p>吗的，没有认真听过一节课。我真恶心。<br>以下是期末复习计划： 1.先把所有的作业看懂。然后理一下作业里的知识点和公式。不能带cheatsheeet所以玩啦<br>cv复习技巧</p>\n<ol>\n<li>以作业为主。把作业每题都手作一遍。</li>\n<li>看讲义。讲义里很多重要的公式（不要看太细，重点看作业里出现的）</li>\n<li>考完试把cv的作业都补一遍。</li>\n</ol>\n<p>感觉要考quiz的原题。可能要看一遍，不然这门课就完了。<br>复习微积分，线性代数。</p>\n<h2 id=\"hw-1\"><a href=\"#hw-1\" class=\"headerlink\" title=\"hw 1\"></a>hw 1</h2><p>exam style problem:<br>1, 2, 3.1</p>\n<h3 id=\"1-cor-conv\"><a href=\"#1-cor-conv\" class=\"headerlink\" title=\"1. cor&#x2F;conv\"></a>1. cor&#x2F;conv</h3><p>Correlation:<br>correlation coefficient<br>correlation formula at position $i &#x3D; \\sum_{j&#x3D;0}^{k-1} I[i + j] \\cdot H[j]$</p>\n<p>convolution:$i &#x3D; \\sum_{j&#x3D;0}^{k-1} I[i - j] \\cdot H[j]$<br>full&#x2F;valid&#x2F;same<br>大小 valid &lt; same &lt; full</p>\n<h3 id=\"2-smoothing\"><a href=\"#2-smoothing\" class=\"headerlink\" title=\"2. smoothing\"></a>2. smoothing</h3><p>gaussian(u, v) &#x3D;def&#x3D; e…<br>seperability与简便计算</p>\n<h3 id=\"2-differentiation\"><a href=\"#2-differentiation\" class=\"headerlink\" title=\"2. differentiation\"></a>2. differentiation</h3><h4 id=\"def\"><a href=\"#def\" class=\"headerlink\" title=\"def\"></a>def</h4><p>区分<br>finite difference: $I_c(r, c) \\approx I(r, c + 1) - I(r, c)$<br>central difference: $I_c(r, c) \\approx \\frac{I(r, c+1) - I(r, c-1)}{2}$</p>\n<h4 id=\"sobel-filter\"><a href=\"#sobel-filter\" class=\"headerlink\" title=\"sobel filter\"></a>sobel filter</h4><p>不要忘记系数啊。。。（normalize系数可以保证亮度正常<br>smoothing $s &#x3D;\\frac{1}{4} \\begin{bmatrix} 1, 2, 1 \\end{bmatrix}^T$<br>differentiation: $d &#x3D;\\frac{1}{2} \\begin{bmatrix} 1, 0, -1 \\end{bmatrix}^T $<br>$v&#x3D;s^Td, h&#x3D;d^Ts$</p>\n<p>sepearable<br><img src=\"/image.png\" alt=\"alt text\">晕</p>\n<h3 id=\"3-interpolation-x\"><a href=\"#3-interpolation-x\" class=\"headerlink\" title=\"3. interpolation(x)\"></a>3. interpolation(x)</h3><p>点的权重为对角正方形的面积<br>bilinear;<br>$\\delta a &#x3D; a - \\lfloor a \\rfloor$, $\\delta b &#x3D; b - \\lfloor b \\rfloor$<br>$\\begin{aligned}<br>I(a,b) &amp;&#x3D; I(\\lfloor a \\rfloor, \\lfloor b \\rfloor)(1 - \\delta a)(1 - \\delta b) \\<br>&amp;+ I(\\lfloor a \\rfloor, \\lfloor b \\rfloor + 1)(1 - \\delta a)\\delta b \\<br>&amp;+ I(\\lfloor a \\rfloor + 1, \\lfloor b \\rfloor)\\delta a(1 - \\delta b) \\<br>&amp;+ I(\\lfloor a \\rfloor + 1, \\lfloor b \\rfloor + 1)\\delta a\\delta b<br>\\end{aligned}$</p>\n<h2 id=\"hw-2\"><a href=\"#hw-2\" class=\"headerlink\" title=\"hw 2\"></a>hw 2</h2><p>exam problem:<br>1.1 - 1.8 ， 3.1， 4.1<br>给f(x, y)<br>1.1. 求gradient $\\nabla f&#x3D;$<br>1.2 stationary point 判定(local max&#x2F;min&#x2F;saddle) D&#x3D; f_xx * f_yy-f_xy^2<br>1.3 ordinary gradient descent<br>1.4 gradient descent with momentum<br>1.5 step of Newton’s method<br>1.6 1. 哪个离真实值更近2. Gauss-Newton method 是否可用<br>1.7 GD的convergence point<br>1.8 数值精度是否影响收敛</p>\n<p>3.1 SGD 手算<br>一个数据点？</p>\n<p>4.1<br>SG和batch</p>\n<p>concepts<br>jacobian: 一阶导, hessian: 二阶导</p>\n<h3 id=\"notation\"><a href=\"#notation\" class=\"headerlink\" title=\"notation:\"></a>notation:</h3><p>risk function(给定f(x)) &#x3D; loss function(未知fx？)<br>first-order gradient descent 只是近似<br>    how to derive step size $\\alpha_k$<br>        fix<br>        adam?<br>        momentum<br>    how to determine the local min<br>        line search<br>    terminaltion check<br>    SGD<br>        mini batch average<br>        epoch<br>second-order<br>    Newton’s method<br>        Hessian<br>        positive-definite: asymptotically faster convergence<br>    Newton-Raphson method:<br>        f shuold be convex</p>\n<h3 id=\"formula\"><a href=\"#formula\" class=\"headerlink\" title=\"formula\"></a>formula</h3><p>$\\nabla f(x,y)&#x3D; \\begin{bmatrix}\\frac{\\partial f}{\\partial x}\\[6pt]\\frac{\\partial f}{\\partial y}\\end{bmatrix}$</p>\n<p>$H_f(x,y)&#x3D;\\begin{bmatrix}\\frac{\\partial^2 f}{\\partial x^2} &amp; \\frac{\\partial^2 f}{\\partial x\\partial y}\\[6pt]\\frac{\\partial^2 f}{\\partial y\\partial x} &amp; \\frac{\\partial^2 f}{\\partial y^2}\\end{bmatrix}$</p>\n<p>$p_{k+1} &#x3D; \\mu p_k - \\alpha_k \\nabla f(x_k)$<br>$x_{k+1} &#x3D; x_k + p_{k+1}$<br>$x_k$是位置，$p_k$是momentum，$\\alpha_k$是步长，$\\nabla f(x_k)$是梯度，<br>since starts with zero velocity,$p_0&#x3D;0$</p>\n<p>$\\phi_n$ loss, risk &#x3D; loss function</p>\n<p>$f(\\mathbf{z})$ risk<br>$\\mathbf{g}_0&#x3D;\\nabla f(\\mathbf{z}_0)$ gradient<br>$H(\\mathbf{z}_0)$ curvature of f near z0<br>$H(\\mathbf{z}<em>0) &#x3D; \\left[ \\frac{\\partial^2 f}{\\partial z_i \\partial z_j} \\right]</em>{\\mathbf{z} &#x3D; \\mathbf{z}_0}$</p>\n<p>Newton Method<br>$f(\\mathbf{z}) \\approx f(\\mathbf{z}_0) + \\nabla f(\\mathbf{z}_0)^T (\\mathbf{z} - \\mathbf{z}_0) + \\frac{1}{2} (\\mathbf{z} - \\mathbf{z}_0)^T H(\\mathbf{z}_0) (\\mathbf{z} - \\mathbf{z}_0)$</p>\n<p>$H_0 \\Delta \\mathbf{z}_0 &#x3D; -\\mathbf{g}_0<br>\\Rightarrow<br>\\Delta \\mathbf{z}_0&#x3D;z-z_0 &#x3D; - H_0^{-1} \\mathbf{g}_0$</p>\n<p>Newton-rapthon<br>$f(\\mathbf{z}) &#x3D; \\sum_{n&#x3D;1}^{N} \\phi_n^2(\\mathbf{z})$</p>\n<h2 id=\"hw3\"><a href=\"#hw3\" class=\"headerlink\" title=\"hw3\"></a>hw3</h2><p>1    2.1-2    3.1<br>1.1 求矩阵row&#x2F;null space的unit vector<br>1.2 x使x^2最小<br>1.3 求x解集<br>1.5 bcce 待公式<br>1.6 Lucas-Kanade tracker</p>\n<h3 id=\"concept\"><a href=\"#concept\" class=\"headerlink\" title=\"concept\"></a>concept</h3><h4 id=\"BCCE的前提假设\"><a href=\"#BCCE的前提假设\" class=\"headerlink\" title=\"BCCE的前提假设\"></a>BCCE的前提假设</h4><p>如果一个点在现实世界中移动，它的亮度在图像中是不会变的<br>公式表达；$a(t) &#x3D; e(x(t), t)\\Rightarrow \\frac{da(t)}{dt} &#x3D; 0$<br><img src=\"/2025-01-29-CV/image.png\" alt=\"alt text\"><br>$\\frac{d}{dt} a(t) &#x3D; 0<br>\\Rightarrow<br>\\frac{\\partial e}{\\partial x^T} \\cdot \\frac{dx}{dt} + \\frac{\\partial e}{\\partial t} &#x3D; 0$</p>\n<p>u: image velocity<br>$\\delta x$ displacemen<br>u&#x3D;$\\delta x &#x2F; \\delta t$, $\\delta t \\to\\infty$</p>\n<p>$u\\nabla e(x)&#x2F;|\\nabla e(x)|$<br>normal component $\\nu &#x3D;def&#x3D;n(x)^{\\top}u(x)$</p>\n<h4 id=\"apreture-probelm\"><a href=\"#apreture-probelm\" class=\"headerlink\" title=\"apreture probelm\"></a>apreture probelm</h4><p>BCCE是标量方程， $u &#x3D; (u_x, u_y)^T$是二维，所以只能知道u的方向…<br>Motion Field\t真实世界中物体运动在图像上的投影（我们想知道的）<br>Optical Flow\t我们从图像中通过亮度变化估计到的速度（我们能观测到的）<br>$\\nu(x) &#x3D; \\mathbf{n}(x)^T u(x)$ 提督方向*<br>$\\nu(x)$ 某个pixel速度沿着这个方向的“可观测分量”。<br>只能知道u的方向。<br>the normal compenet of motion $\\nu$</p>\n<p>因为们不能只靠一个像素就估计出完整的运动向量，所以用一个整体的方法去估计图像中所有像素的运动向量（光流）Optical flow<br>1 data term: $E_\\text{data} &#x3D; \\sum_{x} \\left( \\frac{\\partial e}{\\partial x} \\cdot u(x) + \\frac{\\partial e}{\\partial t} \\right)^2$满足BCCE function<br>2 smoothness term: $E_\\text{smooth} &#x3D; \\sum_{x} \\left( \\frac{\\partial u_x}{\\partial x} + \\frac{\\partial u_y}{\\partial y} \\right)^2$<br>$E &#x3D; \\lambda E_\\text{data} + (1 - \\lambda) E_\\text{smooth}$<br>可能的缺点Tend to blur the solution near motion boundaries</p>\n<h4 id=\"Local-support-motion-estimation-using-tracking-windows\"><a href=\"#Local-support-motion-estimation-using-tracking-windows\" class=\"headerlink\" title=\"Local support motion estimation (using tracking windows)\"></a>Local support motion estimation (using tracking windows)</h4><p>x是二维坐标$x \\in \\mathbb{R}^2$, f(x), g(x)是两幅图像<br>我们把一个local的小窗口看作一个整体, 从x_f移动到x_g&#x3D;x_f+d, 对应的图像是f(x_f)和g(x_f+d),枚举周围的x，计算平方loss，权重和距离有关 w(x-x_f)<br>$W(x_f)$是个集合&#x3D;{pixel in window}<br>$w(x) &#x3D; \\begin{cases}1 &amp; \\text{if } |x_1| \\le h \\text{ and } |x_2| \\le h \\0 &amp; \\text{otherwise}\\end{cases}$只是定义窗口时2h+1 ^2的小正方形</p>\n<p>高斯，只是换种w<br>$w(x) \\propto \\begin{cases}e^{- \\frac{1}{2} \\left( \\frac{|x|}{\\sigma} \\right)^2 } &amp; \\text{if } |x_1| \\le h, |x_2| \\le h \\0 &amp; \\text{otherwise}\\end{cases}$</p>\n<ol>\n<li>grid search x</li>\n<li>Lucas-kanade tracker(using Newton-Raphson)<br>Goal<br> find d that min $L(\\mathbf{d}) &#x3D; \\sum_x [g(x + \\mathbf{d}) - f(x)]^2 w(x - x_f)$ <br> 线性近似$g(x + \\mathbf{d}) \\approx g(x) + \\nabla g(x)^T \\mathbf{d}$<br> $L(\\mathbf{d}) \\approx \\mathbf{d}^T A \\mathbf{d} - 2 \\mathbf{b}^T \\mathbf{d} + \\text{const}$<br> L’(d)&#x3D;0得到$A \\mathbf{d} &#x3D; \\mathbf{b}$<br> 因为是近似的，我们不能一次算出真正的$\\mathbf{d}^*$</li>\n</ol>\n<p>详细计算(感觉这里写的不对，应该改一下推导过程…)<br>$L(\\mathbf{d}) \\approx \\sum_x \\left[\\nabla g(x)^T \\mathbf{d} + g(x) - f(x)\\right]^2 w(x - x_f)$<br>$L(\\mathbf{d}) &#x3D; \\mathbf{d}^T A \\mathbf{d} - 2 \\mathbf{b}^T \\mathbf{d} + \\text{const}$<br>$A &#x3D; \\sum_x \\nabla g(x) \\nabla g(x)^T w(x - x_f)$<br>$\\mathbf{b} &#x3D; \\sum_x \\nabla g(x) [f(x) - g(x)] w(x - x_f)$<br>$\\nabla g(x) \\in \\mathbb{R}^2$, $\\nabla g(x) \\nabla g(x)^T$是2x2的矩阵，$A \\in \\mathbb{R}^{2 \\times 2}$整个窗口中这些小矩阵的加权和, $\\mathbf{b} \\in \\mathbb{R}^2$整个窗口中这些小矩阵{梯度和误差的加权}求和</p>\n<p>为什么不解$A \\mathbf{d} &#x3D; \\mathbf{b}$， 而是迭代： 因泰勒一阶近似要d很小。但是因为离散，d相对大。<br>为什么双线性插值？因为Gauss-Newton得到的d*可能小数。<br>复习一下Gauss-Newton:<br>    <a href=\"https://chatgpt.com/c/67f2aa07-57a4-8002-a98f-851def653450\">https://chatgpt.com/c/67f2aa07-57a4-8002-a98f-851def653450</a></p>\n<p>头晕，不学了。<br>large motio用pyramid track<br>bcce，和motion track的所有问题 <a href=\"https://chatgpt.com/c/67f1a7c8-8c80-8002-a3cc-0b2b4e14f4fe\">https://chatgpt.com/c/67f1a7c8-8c80-8002-a3cc-0b2b4e14f4fe</a></p>\n<h2 id=\"hw4\"><a href=\"#hw4\" class=\"headerlink\" title=\"hw4\"></a>hw4</h2><h4 id=\"4-Rrigid-Geo-transf\"><a href=\"#4-Rrigid-Geo-transf\" class=\"headerlink\" title=\"4 Rrigid Geo transf\"></a>4 Rrigid Geo transf</h4><p>忘记的线代：<br>dot prod&#x2F; Proj<br>$a^Tb&#x3D;ab\\cos\\theta$, $a^Tb&#x3D;0 \\iff a\\perp b$<br><img src=\"/2025-01-29-CV/image-2.png\" alt=\"alt text\"><br>$\\text{proj}_{\\mathbf{a}} \\mathbf{v} &#x3D; \\frac{\\mathbf{a}^T \\mathbf{v}}{\\mathbf{a}^T \\mathbf{a}} \\mathbf{a}$</p>\n<p>$P^x&#x3D;P$ 几何，投影。</p>\n<p>cross prod<br>右手系为正<br>$|\\mathbf{c}| &#x3D; |\\mathbf{a} \\times \\mathbf{b}| &#x3D; |\\mathbf{a}||\\mathbf{b}| \\sin\\theta$ 平行四边形面积<br>$[\\mathbf{a}]_\\times &#x3D; \\begin{bmatrix}<br>0 &amp; -a_z &amp; a_y \\<br>a_z &amp; 0 &amp; -a_x \\<br>-a_y &amp; a_x &amp; 0<br>\\end{bmatrix}$<br>$\\mathbf{a} \\times \\mathbf{p} &#x3D; [\\mathbf{a}]_\\times \\mathbf{p}$</p>\n<p>triple product<br>$\\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c})$ abc平行六边形体积</p>\n<p>coord translation<br>太有趣了但是看不懂呜呜，里面的数学（应该是矩阵论）是我想学的数学，虽然学数学的不会叫这个数学 <a href=\"https://zhuanlan.zhihu.com/p/508149559\">https://zhuanlan.zhihu.com/p/508149559</a></p>\n<p>从0-&gt;1， 左上角left superscript 是system index, 0 is omitted as world ref sys $S_0$</p>\n<h4 id=\"4-pinhole-camera-model\"><a href=\"#4-pinhole-camera-model\" class=\"headerlink\" title=\"4 pinhole camera model\"></a>4 pinhole camera model</h4><p>pinhole小孔&#x2F; optical axis穿过pinhole垂直于成像面的线&#x2F; (projection ray)&#x2F;image plane（成像的面）<br>trade off between sharp and bright<br>（把pinhole可以是面积圆，不影响，还会变亮（？<br>倒像是实像，但是可以等价成对应的虚像。就等价成pinhole camera model 啦<br>于是pinhole-&gt;center of projection,成像面(front screen)对称过去的是image plane,<br>principal plane </p>\n<p>pixel image coordinate system 左上角为原点 $(\\xi, \\mu)$<br>camera reference system P 在center of proj sys坐标中的位置$P&#x3D;(X, Y, Z)$, Z is called depth<br>canonical image coordinate system $(x, y), x&#x3D;X, y&#x3D;Y$</p>\n<p>在写法中$(\\xi, \\mu)$会表示 image pixel 为单位，$(x, y)$会表示canonical中 sys的坐标，单位mm<br>例如:<br>principal point $\\pi_0&#x3D;(\\xi_0, \\mu_0)$, scaling factor $s_x, s_y$ pixel per mm<br>$(\\xi , \\mu)&#x3D; (s_x x + \\xi_0, s_y y + \\mu_0)$<br>$x&#x2F;f&#x3D;X&#x2F;Z$, $y&#x2F;Z&#x3D;Y&#x2F;Z$</p>\n<p>$\\boldsymbol{\\xi} &#x3D; K_s \\mathbf{p} + \\boldsymbol{\\pi}_0$<br>不想看了， 好烦 <a href=\"https://chatgpt.com/c/67f2c6fa-1284-8002-b9a3-7b967317097a\">https://chatgpt.com/c/67f2c6fa-1284-8002-b9a3-7b967317097a</a></p>\n<h4 id=\"epipolar-geo\"><a href=\"#epipolar-geo\" class=\"headerlink\" title=\"epipolar geo\"></a>epipolar geo</h4><p>epipolar plane, baseline, image plane, （book是epi plane的旋转轴，比喻成书脊）</p>\n<p>已知条件：<br>不妨以相机a构建坐标系$P_a&#x3D;(0,0,0)$,朝向为$D_a&#x3D;\\mathbf I_{3\\times3}$, $I_a:z&#x3D;f$, $P&#x3D;(X, Y, Z)$, camera b 的位置 $^at_b$, 旋转矩阵$^aR_b$</p>\n<p>可以求：<br>可以得到相机b的朝向是$^aR_b D_a &#x3D; D_b$， 位置是$^at_b$，<br>是$I_a$和AP连线的焦点A&#x3D;(0, 0, 0), $I_b$也是已知的,<br>方程类是$kRx-f&#x3D;0$, k&#x3D;[0, 0, 1],<br>BP的方程是，令kR&#x3D;[u, v, w], 则BP为$L(d)&#x3D;t+d (kR)^T$,<br>ABP方程是$[t]_\\times (X, Y, Z)&#x3D;0$,<br>$^ap_a$: 联立 z&#x3D;f和[X, Y, Z][x, y, z]^T&#x3D;0,<br>$^ap_b$同理已知，$^bp_b&#x3D;R (^ap_b-t)$</p>\n<p>求I_b方程的过程:<br>$^aI_b$的方程: $z&#x3D;f$,既  $k^b\\vec{x}$+d&#x3D;0，k&#x3D;[0, 0, 1]<br>带入点(0, 0, f)得$d&#x3D;-f$。<br>$^aR_a \\ ^a \\vec{x}&#x3D; ^b\\vec{x}$， 带入上式得$kR^a \\vec{x}+d&#x3D;0$</p>\n<p>但是讲义上不是这么推的, 0个人关心proj center A, B在哪， 其实是有的…, t是相对位置。<br>给定$a&#x3D;{}^a p_a &#x3D; \\begin{bmatrix} x_a \\ y_a \\ f \\end{bmatrix},\\quad<br>b&#x3D;{}^b p_b &#x3D; \\begin{bmatrix} x_b \\ y_b \\ f \\end{bmatrix}$, 已知a, b, R, t, e&#x3D;$^ae_b$是baseline和$I_a$的交点。</p>\n<p>根据几何变换有以下成立，<br>$R^T&#x3D;\\ ^bR_a$,<br>因为根据逆变换$ ^aR_b\\  ^bR_a^T$,即 $RR^T&#x3D;I$</p>\n<p>$Rt&#x3D;-^bt_a$, 因为左&#x3D;右&#x3D; $^b \\vec {AB}$</p>\n<p>在sys A中,<br>$R^Tb&#x3D;\\ ^ap_b$，因为$^bR_a \\ ^bp&#x3D;\\ ^ap-^at_b$,所以令p&#x3D;camera b， $^bR_a \\ ^bp_b&#x3D;\\  ^ap_b-^at_b$ 左边是$R^Tb$， 右边是sys a下的<br>$a&#x3D;\\ ^ap_a$<br>令sys的A的原点为$O_A$， 这个式子就是$O_A A\\cdot (O_AB\\times BA)&#x3D;0$<br>$O_AB+BA&#x3D;O_AA$带入检查得到$R^Tb&#x3D;a-^at_b$<br>两边同乘$R$得到$b&#x3D;R(a-t)$不符合$^bp&#x3D;R(^ap-t)$ ？？？</p>\n<p>epipoplar constrain $b^TEa&#x3D;0$, where $E&#x3D;R[t]_\\times$</p>\n<p>Qestions<br>思考方式； 这里一共说了几个概念，几个公式，概念之间的逻辑什么，变量的定义和维度是什么</p>\n<ol>\n<li>GD在&gt;&#x3D;1数据的时候咋（back prop）更新的啊</li>\n<li>好难理解为什么“如果一个点在真实世界中运动，它在图像中的亮度值是不会变的”这个假设会得到$ \\frac{d}{dt} e(x(t), t) &#x3D; 0$<br>虽然可以解释$e$是亮度，是关于位置向量$x$和时间$t$的函数，但是为什么$e$对$t$求导&#x3D;0.  $e$的含义是什么…任意一个符合”亮度不变的点”的亮度…?<br>哪个点?图像中的还是世界里的。图像中的点。其实感觉条件应该说成“任意真实世界的点，在图像中的像亮度不变”。这样好像可以理解。x,t也是图像中的位置和时间。</li>\n</ol>\n<p>可能误解的原因是总觉得图像是离散的pixel,现实世界是连续的，所以潜意识里出现了更多的变量，导致感觉条件不完全。<br>3. </p>\n"},{"title":"hello","date":"2024-11-11T01:01:44.000Z","_content":"hello world.","source":"_posts/hello.md","raw":"---\ntitle: hello\ndate: 2024-11-10 20:01:44\ntags:\n---\nhello world.","slug":"hello","published":1,"updated":"2025-04-02T23:59:02.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagt1001yzc3d862v7xba","content":"<p>hello world.</p>\n","excerpt":"","more":"<p>hello world.</p>\n"},{"title":"2025-01-11-NLP","date":"2025-01-09T17:25:42.000Z","_content":"\n01/09\nNLP current challenges:\n- Hallucination\n- Ribustness and safety\n- Interpretability and controllability\n- Reasoning","source":"_posts/2025-01-11-NLP.md","raw":"---\ntitle: 2025-01-11-NLP\ndate: 2025-01-09 12:25:42\ntags:\n---\n\n01/09\nNLP current challenges:\n- Hallucination\n- Ribustness and safety\n- Interpretability and controllability\n- Reasoning","slug":"2025-01-11-NLP","published":1,"updated":"2025-01-09T17:28:29.000Z","comments":1,"layout":"post","photos":[],"_id":"cm9bnagt1001zzc3da2hm2geh","content":"<p>01&#x2F;09<br>NLP current challenges:</p>\n<ul>\n<li>Hallucination</li>\n<li>Ribustness and safety</li>\n<li>Interpretability and controllability</li>\n<li>Reasoning</li>\n</ul>\n","excerpt":"","more":"<p>01&#x2F;09<br>NLP current challenges:</p>\n<ul>\n<li>Hallucination</li>\n<li>Ribustness and safety</li>\n<li>Interpretability and controllability</li>\n<li>Reasoning</li>\n</ul>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cm9bnagsh001dzc3d8u1l9o7c","tag_id":"cm9bnagsh001ezc3d816x5syl","_id":"cm9bnagsi001gzc3d6m7c6g8n"},{"post_id":"cm9bnagsh001dzc3d8u1l9o7c","tag_id":"cm9bnagsi001fzc3d8gifdruz","_id":"cm9bnagsi001hzc3d12yo05om"}],"Tag":[{"name":"music","_id":"cm9bnagsh001ezc3d816x5syl"},{"name":"tools","_id":"cm9bnagsi001fzc3d8gifdruz"}]}}