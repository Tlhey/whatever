<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>2025-01-08-Generative-Models | Tlhey</title><meta name="author" content="Tlhey"><meta name="copyright" content="Tlhey"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="www 01-08HistogramKernel MethodKernel Density Estimation (KDE) 是一种统计方法，用于估计一个随机变量的连续的概率密度函数（Probability Density Function,..."><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "2025-01-08-Generative-Models",
  "url": "https://tlhey.github.io/whatever/2025/01/08/2025-01-08-Generative-Models/",
  "image": "https://tlhey.github.io/whatever/whatever/img/Lain/Lain_008.jpeg",
  "datePublished": "2025-01-08T17:29:17.000Z",
  "dateModified": "2025-05-10T23:08:35.226Z",
  "author": [
    {
      "@type": "Person",
      "name": "Tlhey",
      "url": "https://tlhey.github.io/whatever/"
    }
  ]
}</script><link rel="shortcut icon" href="/whatever/img/favicon.png"><link rel="canonical" href="https://tlhey.github.io/whatever/2025/01/08/2025-01-08-Generative-Models/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="manifest" href="/whatever/manifest.json"/><link rel="apple-touch-icon" sizes="180x180" href="/whatever/img/Pink.jpeg"/><link rel="icon" type="image/png" sizes="32x32" href="/whatever/img/Pink.jpeg"/><link rel="icon" type="image/png" sizes="16x16" href="/whatever/img/Pink.jpeg"/><link rel="mask-icon" href="/whatever/img/safari-pinned-tab.svg" color="#5bbad5"/><link rel="stylesheet" href="/whatever/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/whatever/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '2025-01-08-Generative-Models',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/whatever/css/modify.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/whatever/img/background.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/whatever/img/Pink.jpeg" onerror="this.onerror=null;this.src='/whatever/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/whatever/archives/"><div class="headline">Articles</div><div class="length-num">54</div></a><a href="/whatever/tags/"><div class="headline">Tags</div><div class="length-num">8</div></a><a href="/whatever/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/whatever/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/whatever/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/whatever/img/Lain/Lain_008.jpeg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/whatever/"><img class="site-icon" src="/whatever/img/Pink.jpeg" alt="Logo"><span class="site-name">Tlhey</span></a><a class="nav-page-title" href="/whatever/"><span class="site-name">2025-01-08-Generative-Models</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/whatever/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/whatever/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">2025-01-08-Generative-Models</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-01-08T17:29:17.000Z" title="Created 2025-01-08 09:29:17">2025-01-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-05-10T23:08:35.226Z" title="Updated 2025-05-10 16:08:35">2025-05-10</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>www</p>
<h2 id="01-08"><a href="#01-08" class="headerlink" title="01-08"></a>01-08</h2><h3 id="Histogram"><a href="#Histogram" class="headerlink" title="Histogram"></a>Histogram</h3><h3 id="Kernel-Method"><a href="#Kernel-Method" class="headerlink" title="Kernel Method"></a>Kernel Method</h3><p>Kernel Density Estimation (KDE) 是一种统计方法，用于估计一个随机变量的<strong>连续的</strong>概率密度函数（Probability Density Function, PDF）。</p>
<p>直方图有个问题：</p>
<ul>
<li><strong>它是离散的</strong>：你只能看到固定的时间间隔，比如10:00-11:00，11:00-12:00。</li>
<li><strong>它依赖分箱（bin）大小</strong>：不同的分箱方式会影响直方图的形状。</li>
</ul>
<p><strong>KDE 就是一种连续的分布估计方法</strong>，它不依赖于分箱，而是用一个 <strong>“平滑的曲线”</strong> 来表示数据的分布。<br>你可以把 KDE 想象成：</p>
<ul>
<li>每个数据点都画一个 <strong>小山丘（kernel）</strong>。</li>
<li>然后把这些小山丘 <strong>叠加起来</strong>，得到一个连续的曲线，代表数据的分布。</li>
</ul>
<p>KDE 的公式为：<br>(\hat{f}(x) &#x3D; \frac{1}{n h} \sum_{i&#x3D;1}^{n} K\left(\frac{x - x_i}{h}\right))</p>
<p><strong>解释每个符号</strong>：</p>
<ul>
<li><strong>( \hat{f}(x) )</strong>：估计的概率密度函数。</li>
<li><strong>( n )</strong>：样本数量。</li>
<li><strong>( h )</strong>：平滑参数，称为 <strong>带宽（bandwidth）</strong>。它决定了小山丘的“宽度”。</li>
<li><strong>( K )</strong>：<strong>核函数（Kernel Function）</strong>，决定了小山丘的形状。</li>
</ul>
<p>核函数是 KDE 的核心。常见的核函数有：</p>
<ol>
<li><p><strong>高斯核（Gaussian Kernel）</strong><br>形状像正态分布的小山丘，最常用的核函数。</p>
<p>[<br>K(x) &#x3D; \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}<br>]</p>
</li>
<li><p><strong>箱形核（Box Kernel）</strong><br>每个数据点生成一个“方形的小山丘”，边界清晰，但不平滑。</p>
</li>
<li><p><strong>三角核（Triangle Kernel）</strong><br>生成一个三角形的小山丘。</p>
</li>
</ol>
<p>带宽（Bandwidth）对 KDE 的影响**</p>
<p><strong>带宽（h）</strong> 是 KDE 中一个非常重要的参数。它决定了每个小山丘的 <strong>宽度</strong>，从而影响最终曲线的平滑程度。</p>
<ul>
<li><strong>带宽小</strong>：曲线更贴近数据，但容易出现“过拟合”。</li>
<li><strong>带宽大</strong>：曲线更平滑，但可能会忽略一些细节。</li>
</ul>
<h3 id="Series-Methods"><a href="#Series-Methods" class="headerlink" title="Series Methods"></a>Series Methods</h3><p>Imagine you’re trying to approximate a complex function ( f(x) ) by expressing it as a combination of simpler functions (called <strong>basis functions</strong>). This is like saying:</p>
<p>[ f(x) &#x3D; \sum_{j&#x3D;1}^{\infty} \beta_j \phi_j(x) ]</p>
<p>Where:</p>
<ul>
<li>( \phi_j(x) ) are the <strong>basis functions</strong> (like sine, cosine, polynomials, etc.)</li>
<li>( \beta_j ) are the <strong>coefficients</strong> that tell us how much of each basis function to use.</li>
</ul>
<hr>
<h3 id="🧩-Orthogonal-Basis"><a href="#🧩-Orthogonal-Basis" class="headerlink" title="🧩 Orthogonal Basis"></a>🧩 <strong>Orthogonal Basis</strong></h3><p>The basis functions ( \phi_j ) are said to be <strong>orthogonal</strong> if they satisfy the condition:</p>
<p>[ \int \phi_j(x) \phi_k(x) dx &#x3D; 0 \quad \text{for} \quad j \neq k ]</p>
<p>Think of orthogonal basis functions like directions that are at right angles to each other — they don’t overlap in their effects.</p>
<hr>
<h3 id="📚-Cosine-Basis-Example"><a href="#📚-Cosine-Basis-Example" class="headerlink" title="📚 Cosine Basis Example"></a>📚 <strong>Cosine Basis Example</strong></h3><p>The notes give an example of using <strong>cosine functions</strong> as the basis:</p>
<p>[ \phi_j(x) &#x3D; \sqrt{2} \cos(2\pi j x) ]</p>
<p>These functions oscillate and can capture periodic patterns in the data.</p>
<hr>
<h3 id="📈-Wavelet-Basis"><a href="#📈-Wavelet-Basis" class="headerlink" title="📈 Wavelet Basis"></a>📈 <strong>Wavelet Basis</strong></h3><p>There’s also a reference to <strong>wavelet basis functions</strong>, which are used to capture both <strong>local</strong> and <strong>global</strong> structures in the data.</p>
<hr>
<h3 id="🔍-Key-Formula-for-Density-Estimation"><a href="#🔍-Key-Formula-for-Density-Estimation" class="headerlink" title="🔍 Key Formula for Density Estimation"></a>🔍 <strong>Key Formula for Density Estimation</strong></h3><p>The board shows that if we are estimating a <strong>density function</strong> ( f ), we can approximate it using the formula:</p>
<p>[ \hat{f}(x) &#x3D; \sum_{j&#x3D;1}^{k} \hat{\beta}_j \phi_j(x) ]</p>
<p>Where:</p>
<ul>
<li>( \hat{\beta}<em>j &#x3D; \frac{1}{n} \sum</em>{i&#x3D;1}^{n} \phi_j(X_i) )<br>(This is the estimated coefficient based on sample data ( X_i ).)</li>
</ul>
<hr>
<h3 id="🧠-Key-Idea-Selecting-the-Right-k"><a href="#🧠-Key-Idea-Selecting-the-Right-k" class="headerlink" title="🧠 Key Idea: Selecting the Right ( k )"></a>🧠 <strong>Key Idea: Selecting the Right ( k )</strong></h3><p>Choosing the right number of basis functions (( k )) is important. If ( k ) is too large, the model will <strong>overfit</strong> (too complicated). If ( k ) is too small, the model will <strong>underfit</strong> (too simple).</p>
<h2 id="01-15"><a href="#01-15" class="headerlink" title="01-15"></a>01-15</h2><h2 id="Part-1-Risk-Analysis"><a href="#Part-1-Risk-Analysis" class="headerlink" title="Part 1: Risk Analysis"></a>Part 1: Risk Analysis</h2><h3 id="Background-and-Setup"><a href="#Background-and-Setup" class="headerlink" title="Background and Setup"></a>Background and Setup</h3><p>You have ( N ) points ( x_1, x_2, \ldots, x_N \in \mathbb{R}^d ). This means you have ( N ) data samples, each one is a ( d )-dimensional vector. We assume these points lie in some space ( X \subset \mathbb{R}^d ), which is said to be a <strong>compact set</strong> (meaning it is closed and bounded in the mathematical sense).</p>
<h3 id="Key-Smoothness-Assumption"><a href="#Key-Smoothness-Assumption" class="headerlink" title="Key Smoothness Assumption"></a>Key Smoothness Assumption</h3><p>You mentioned an assumption:</p>
<p>[<br>D^s p(x) - D^s p(y) ;\le; L ,|x - y|<br>]</p>
<ol>
<li><p><strong>( D^s p(x) )</strong>:  </p>
<ul>
<li>This notation represents a high-order derivative (partial derivative) of a probability density function (p(x)).  </li>
<li>The superscript ( s ) is a <strong>multi-index</strong>.  <ul>
<li>For instance, ( s &#x3D; (s_1, s_2, \dots, s_d) ).  </li>
<li>Then ( D^s p(x)) means we take the ((s_1 + s_2 + \cdots + s_d))-th partial derivative of ( p ) with respect to each coordinate appropriately:<br>[<br>D^s p(x) ;&#x3D;; \frac{\partial^{,s_1 + s_2 + \cdots + s_d} p(x)}{\partial x_1^{s_1},\partial x_2^{s_2},\cdots,\partial x_d^{s_d}}.<br>]</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Interpretation of the inequality</strong>:<br>[<br>D^s p(x) - D^s p(y) ;\le; L, |x - y|.<br>]<br>This says that <strong>the change in the (s)-th derivative</strong> between (x) and (y) is bounded by their distance times some constant (L). It suggests that (p(x)) is <strong>smooth</strong>—no wild jumps in its high-order derivatives. This is often used in probability density estimation and ensures continuity and differentiability in a controlled way.</p>
</li>
<li><p><strong>Why Compactness Matters</strong>:  </p>
<ul>
<li>If ( X ) is compact, it’s easier to control or bound various integrals and derivatives since ( x ) cannot go off to infinity.  </li>
<li>This is important in risk analysis because it helps with bounding error terms and ensuring integrals converge.</li>
</ul>
</li>
</ol>
<blockquote>
<p><strong>Reference for multi-index notation</strong>:  </p>
<ul>
<li><a target="_blank" rel="noopener" href="https://brilliant.org/wiki/multi-index-notation/">Brilliant.org: Multi-Index Notation</a>  </li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Multi-index">Wikipedia: Multi-index</a></li>
</ul>
</blockquote>
<hr>
<h2 id="Part-2-More-on-D-s-p-x-and-Multi-Index-Notation"><a href="#Part-2-More-on-D-s-p-x-and-Multi-Index-Notation" class="headerlink" title="Part 2: More on ( D^s p(x) ) and Multi-Index Notation"></a>Part 2: More on ( D^s p(x) ) and Multi-Index Notation</h2><p>If ( p(x) ) is a function of multiple variables, say ( p(x_1, x_2, \dots, x_d) ), then<br>[<br>s &#x3D; (s_1, s_2, \dots, s_d)<br>]<br>tells us <strong>how many times</strong> we differentiate with respect to each variable ( x_i ).  </p>
<p>For example, if ( s &#x3D; (2, 1, 0, \dots, 0) ), then<br>[<br>D^s p(x) ;&#x3D;; \frac{\partial^3 p(x)}{\partial x_1^2 ,\partial x_2^1}.<br>]</p>
<h3 id="Intuitive-View"><a href="#Intuitive-View" class="headerlink" title="Intuitive View"></a>Intuitive View</h3><ul>
<li>If (s_1 &#x3D; 2), that means “take the second derivative with respect to (x_1)”.  </li>
<li>If (s_2 &#x3D; 1), that means “take the first derivative with respect to (x_2)”.  </li>
<li>We multiply these partial derivatives together in the correct order.</li>
</ul>
<p>This notation is just a concise way to keep track of all the derivatives in multiple dimensions.</p>
<hr>
<h2 id="Part-3-Taylor-Expansion-Taylor’s-Theorem"><a href="#Part-3-Taylor-Expansion-Taylor’s-Theorem" class="headerlink" title="Part 3: Taylor Expansion (Taylor’s Theorem)"></a>Part 3: Taylor Expansion (Taylor’s Theorem)</h2><p>A general <strong>Taylor expansion</strong> around a point ( x ) says that if (f) is sufficiently smooth, we can write:</p>
<p>[<br>f(x + h)<br>;&#x3D;;<br>f(x) ;+;<br>\sum_{k&#x3D;1}^{m} \frac{1}{k!} \bigl( D^k f(x) \bigr) (h,\dots,h) ;+; R_m,<br>]</p>
<p>where ( R_m ) is the remainder term, and ( D^k f(x) ) is the (k)-th derivative of (f). In multiple dimensions, we typically see it in terms of partial derivatives:</p>
<p>[<br>f(x + h) ;\approx;<br>f(x)<br>;+; \nabla f(x) \cdot h<br>;+; \frac{1}{2} h^\top \nabla^2 f(x) , h<br>;+; \dots<br>]</p>
<p>This expansion is used <strong>a lot</strong> in analyzing the bias of estimators, numerical methods, and even in bounding differences between function values.</p>
<blockquote>
<p><strong>Reference for Taylor expansions</strong>:  </p>
<ul>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Taylor%27s_theorem">Wikipedia: Taylor’s theorem</a>  </li>
<li><a target="_blank" rel="noopener" href="https://mathworld.wolfram.com/TaylorSeries.html">MathWorld: Taylor Series</a></li>
</ul>
</blockquote>
<hr>
<h2 id="Part-4-Kernel-Density-Estimation-KDE"><a href="#Part-4-Kernel-Density-Estimation-KDE" class="headerlink" title="Part 4: Kernel Density Estimation (KDE)"></a>Part 4: Kernel Density Estimation (KDE)</h2><p>You also mentioned <strong>Kernel Density Estimation</strong>. It’s a method to estimate an unknown probability density function ( f(x) ) from data. The estimator looks like:</p>
<p>[<br>\hat{f}(x) ;&#x3D;; \frac{1}{N h} ;\sum_{i&#x3D;1}^{N} K\Bigl(\frac{x - X_i}{h}\Bigr),<br>]</p>
<p>where</p>
<ul>
<li>(K) is a <strong>kernel function</strong> (often something like a Gaussian, Epanechnikov, etc.),  </li>
<li>(h) is the <strong>bandwidth</strong> (a smoothing parameter).</li>
</ul>
<h3 id="4-1-Kernel-Function-Properties"><a href="#4-1-Kernel-Function-Properties" class="headerlink" title="4.1 Kernel Function Properties"></a>4.1 Kernel Function Properties</h3><p>A kernel (K) often satisfies:</p>
<ol>
<li>(\int K(u),du &#x3D; 1).  </li>
<li>(\int u,K(u),du &#x3D; 0). (Centered around 0)  </li>
<li>(\int u^r K(u),du &#x3D; 0) for odd (r) if it’s symmetric, etc.</li>
</ol>
<p>An example of a kernel is the <strong>Epanechnikov kernel</strong>:</p>
<p>[<br>G(x) ;&#x3D;; \frac{3}{4},\bigl(1 - x^2\bigr) , 1(\lvert x \rvert \le 1),<br>]</p>
<p>where (1(\lvert x \rvert \le 1)) is the indicator function that is 1 if (\lvert x \rvert \le 1) and 0 otherwise. </p>
<blockquote>
<p><strong>Reference for Kernel Density Estimation</strong>:  </p>
<ul>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/kernel-density-estimation-explained-52045f84c726">“Kernel Density Estimation Explained” on Towards Data Science</a>  </li>
<li><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-kernel-density-estimation/">A Comprehensive Guide to KDE on Analytics Vidhya</a></li>
</ul>
</blockquote>
<hr>
<h3 id="4-2-Bias-of-the-KDE"><a href="#4-2-Bias-of-the-KDE" class="headerlink" title="4.2 Bias of the KDE"></a>4.2 Bias of the KDE</h3><p>The <strong>bias</strong> of an estimator (\hat{f}(x)) is:</p>
<p>[<br>\text{Bias}(\hat{f}(x)) ;&#x3D;;<br>E[\hat{f}(x)] ;-; f(x).<br>]</p>
<p>For KDE, we often find that:</p>
<p>[<br>E[\hat{f}(x)]<br>;&#x3D;;<br>\int K!\Bigl(\frac{x - t}{h}\Bigr) p(t), \frac{dt}{h}.<br>]</p>
<p>By doing a change of variable and performing a Taylor expansion of (p(\cdot)), we eventually get:</p>
<p>[<br>E[\hat{f}(x)]<br>;&#x3D;;<br>p(x)<br>;+;<br>\frac{h^2}{2},\mu_2(K),p’’(x)<br>;+;<br>O(h^4),<br>]</p>
<p>where (\mu_2(K)) is the second moment of the kernel. So the <strong>leading term</strong> of the bias is:</p>
<p>[<br>\text{Bias}(\hat{f}(x))<br>;&#x3D;;<br>\frac{h^2}{2},\mu_2(K),p’’(x)<br>;+;<br>O(h^4).<br>]</p>
<p>This tells us that the bias grows (roughly) like (h^2). If (h) is too big, the bias is large (over-smoothing), but if (h) is too small, you get high variance (under-smoothing). That’s why <strong>bandwidth selection</strong> is super important.</p>
<blockquote>
<p><strong>Reference for bias-variance in KDE</strong>:  </p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.stat.cmu.edu/~cshalizi/402/lectures/08-kernel-density/kde.pdf">Lecture notes on Kernel Density Estimation (CMU)</a></li>
</ul>
</blockquote>
<h2 id="02-28"><a href="#02-28" class="headerlink" title="02-28"></a>02-28</h2><p>Cold Diffusion</p>
<h2 id="03-10"><a href="#03-10" class="headerlink" title="03-10"></a>03-10</h2><p>突然觉得自己悟了？？<br>How others put them together<br><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=B-d_3xX6ss4">https://www.youtube.com/watch?v=B-d_3xX6ss4</a><br>根据song yang的论文的时间线。<br>1; sliced score model (定义了score based model)<br>(<a target="_blank" rel="noopener" href="https://proceedings.mlr.press/v115/song20a/song20a.pdf">https://proceedings.mlr.press/v115/song20a/song20a.pdf</a>)</p>
<p>2; annealed Langevin Dynamics<br>(<a target="_blank" rel="noopener" href="https://papers.neurips.cc/paper_files/paper/2019/hash/3001ef257407d5a371a96dcd947c7d93-Abstract.html">https://papers.neurips.cc/paper_files/paper/2019/hash/3001ef257407d5a371a96dcd947c7d93-Abstract.html</a>)<br>langevin mcmc sample; <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/797467112">https://zhuanlan.zhihu.com/p/797467112</a><br>the whole thing; <a target="_blank" rel="noopener" href="https://yang-song.net/blog/2021/score/">https://yang-song.net/blog/2021/score/</a></p>
<p>3; Score-based GM through SED (Song et al. ICLR 2021)<br>(<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2011.13456">https://arxiv.org/pdf/2011.13456</a>)<br>SED 视角统一；<br>smld (ve) 和 ddpm (vp)<br>sed和of-ode有一些对应关系</p>
<p>4; EDM<br>（<a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/a98846e9d9cc01cfb87eb694d946ce6b-Paper-Conference.pdf%EF%BC%89">https://proceedings.neurips.cc/paper_files/paper/2022/file/a98846e9d9cc01cfb87eb694d946ce6b-Paper-Conference.pdf）</a><br>pf-ode视角统一了diffusion 模型</p>
<p>5; CM<br>用了edm</p>
<p>6; </p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/whatever/tags/Notes/">Notes</a></div><div class="post-share"><div class="social-share" data-image="/whatever/whatever/img/Lain/Lain_008.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/whatever/img/Pink.jpeg" onerror="this.onerror=null;this.src='/whatever/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Tlhey</div><div class="author-info-description"></div><div class="site-data"><a href="/whatever/archives/"><div class="headline">Articles</div><div class="length-num">54</div></a><a href="/whatever/tags/"><div class="headline">Tags</div><div class="length-num">8</div></a><a href="/whatever/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Tlhey"><i class="fab fa-github"></i><span>www</span></a></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#01-08"><span class="toc-number">1.</span> <span class="toc-text">01-08</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Histogram"><span class="toc-number">1.1.</span> <span class="toc-text">Histogram</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kernel-Method"><span class="toc-number">1.2.</span> <span class="toc-text">Kernel Method</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Series-Methods"><span class="toc-number">1.3.</span> <span class="toc-text">Series Methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%A7%A9-Orthogonal-Basis"><span class="toc-number">1.4.</span> <span class="toc-text">🧩 Orthogonal Basis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%93%9A-Cosine-Basis-Example"><span class="toc-number">1.5.</span> <span class="toc-text">📚 Cosine Basis Example</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%93%88-Wavelet-Basis"><span class="toc-number">1.6.</span> <span class="toc-text">📈 Wavelet Basis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%94%8D-Key-Formula-for-Density-Estimation"><span class="toc-number">1.7.</span> <span class="toc-text">🔍 Key Formula for Density Estimation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%A7%A0-Key-Idea-Selecting-the-Right-k"><span class="toc-number">1.8.</span> <span class="toc-text">🧠 Key Idea: Selecting the Right ( k )</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#01-15"><span class="toc-number">2.</span> <span class="toc-text">01-15</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-1-Risk-Analysis"><span class="toc-number">3.</span> <span class="toc-text">Part 1: Risk Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Background-and-Setup"><span class="toc-number">3.1.</span> <span class="toc-text">Background and Setup</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Key-Smoothness-Assumption"><span class="toc-number">3.2.</span> <span class="toc-text">Key Smoothness Assumption</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-2-More-on-D-s-p-x-and-Multi-Index-Notation"><span class="toc-number">4.</span> <span class="toc-text">Part 2: More on ( D^s p(x) ) and Multi-Index Notation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Intuitive-View"><span class="toc-number">4.1.</span> <span class="toc-text">Intuitive View</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-3-Taylor-Expansion-Taylor%E2%80%99s-Theorem"><span class="toc-number">5.</span> <span class="toc-text">Part 3: Taylor Expansion (Taylor’s Theorem)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-4-Kernel-Density-Estimation-KDE"><span class="toc-number">6.</span> <span class="toc-text">Part 4: Kernel Density Estimation (KDE)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Kernel-Function-Properties"><span class="toc-number">6.1.</span> <span class="toc-text">4.1 Kernel Function Properties</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Bias-of-the-KDE"><span class="toc-number">6.2.</span> <span class="toc-text">4.2 Bias of the KDE</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#02-28"><span class="toc-number">7.</span> <span class="toc-text">02-28</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#03-10"><span class="toc-number">8.</span> <span class="toc-text">03-10</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url(/whatever/img/Lain/Lain_008.jpeg);"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By Tlhey</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/whatever/js/utils.js"></script><script src="/whatever/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>